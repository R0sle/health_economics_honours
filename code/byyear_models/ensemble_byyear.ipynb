{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import optuna.visualization as vis\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../split_year_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = pd.read_csv(filepath + '/test/X_test.csv')\n",
    "test_data_x = test_data_x.drop(columns=['Unnamed: 0'], axis=1)\n",
    "test_data_y = pd.read_csv(filepath + '/test/y_test.csv')\n",
    "test_data_y = test_data_y.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "for fold in range(0, 5):\n",
    "    tdata_x85 = pd.read_csv(filepath + '/train/X_train_' + str(fold) + '_85.csv')\n",
    "    tdata_x85 = tdata_x85.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    tdata_y85 = pd.read_csv(filepath + '/train/y_train_' + str(fold) + '_85.csv')\n",
    "    tdata_y85 = tdata_y85.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "    tdata_x95 = pd.read_csv(filepath + '/train/X_train_' + str(fold) + '_95.csv')\n",
    "    tdata_x95 = tdata_x95.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    tdata_y95 = pd.read_csv(filepath + '/train/y_train_' + str(fold) + '_95.csv')\n",
    "    tdata_y95 = tdata_y95.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "    tdata_x1 = pd.read_csv(filepath + '/train/X_train_' + str(fold) + '_1.csv')\n",
    "    tdata_x1 = tdata_x1.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    tdata_y1 = pd.read_csv(filepath + '/train/y_train_' + str(fold) + '_1.csv')\n",
    "    tdata_y1 = tdata_y1.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "    train[fold] = [tdata_x85, tdata_y85, tdata_x95, tdata_y95, tdata_x1, tdata_y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {}\n",
    "for fold in range(0, 5):\n",
    "    vdata_x = pd.read_csv(filepath + '/val/X_val_' + str(fold) + '.csv')\n",
    "    vdata_x = vdata_x.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    vdata_y = pd.read_csv(filepath + '/val/y_val_' + str(fold) + '.csv')\n",
    "    vdata_y = vdata_y.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    validation[fold] = [vdata_x, vdata_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../split_year_data/countries_dict.pkl', 'rb') as f:\n",
    "    countries_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.read_csv('../../split_year_data/train_val.csv')\n",
    "train_val = train_val.drop(columns=['Unnamed: 0'], axis=1)\n",
    "train_val_input = train_val.drop(columns=['Maternal mortality ratio (national estimate, per 100,000 live births)'], axis=1)\n",
    "train_val_label = train_val['Maternal mortality ratio (national estimate, per 100,000 live births)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using the Random Forest and LightGBM models trained on the full dataset and dataset with a missing data threshold of 95% because XGBoost models and all models trained on dataset with 85% threshold had lower performance across all metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_models = []\n",
    "rf_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_col_needed = []\n",
    "rf_col_needed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../split_year_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the models on their best hyperparameters and storing them in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, fold_num in enumerate(['1', '2', '3', '4', '5']):\n",
    "    for thresh, thresh_name in enumerate(['Threshold 85%', 'Threshold 95%', 'None']):\n",
    "        if thresh == 1:\n",
    "            continue\n",
    "\n",
    "        if thresh == 0:\n",
    "            name = '85'\n",
    "        elif thresh == 1:\n",
    "            name = '95'\n",
    "        else: name = '1'\n",
    "\n",
    "        best_params = joblib.load(f\"{output_dir}/lightgbm/best_params_{fold}_{name}.pkl\")\n",
    "\n",
    "        train_input_data = train[fold][thresh * 2].copy()\n",
    "        train_input_data['setting'] = train_input_data['setting'].astype(\"category\")\n",
    "        train_input_data.columns = train_input_data.columns.str.replace(r'[\\\"\\[\\]\\{\\}\\\\:,]', '', regex=True)\n",
    "        lgbm_col_needed.append(train_input_data.columns.tolist())\n",
    "\n",
    "        train_label = train[fold][thresh * 2 + 1].copy()\n",
    "        train_label.column = 'Maternal mortality ratio (national estimate per 100000 live births)'\n",
    "\n",
    "        loaded_model = lgb.LGBMRegressor(**best_params, verbosity = -1)\n",
    "        train_load = loaded_model.fit(train_input_data, train_label)\n",
    "        lgbm_models.append(train_load)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for fold, fold_num in enumerate(['1', '2', '3', '4', '5']):\n",
    "    for thresh, thresh_name in enumerate(['Threshold 85%', 'Threshold 95%', 'None']):\n",
    "\n",
    "        if thresh == 1:\n",
    "            continue\n",
    "        \n",
    "        if thresh == 0:\n",
    "            name = '85'\n",
    "        elif thresh == 1:\n",
    "            name = '95'\n",
    "        else: name = '1'\n",
    "\n",
    "        best_params = joblib.load(f\"{output_dir}/random_forest/best_params_{fold}_{name}.pkl\")\n",
    "        train_input_data = train[fold][thresh * 2].copy()\n",
    "        train_input_data['setting'] = train_input_data['setting'].map(countries_dict)\n",
    "        train_label = train[fold][thresh * 2 + 1].copy()\n",
    "        rf_col_needed.append(train_input_data.columns.tolist())\n",
    "\n",
    "        loaded_model = RandomForestRegressor(**best_params)\n",
    "        train_load = loaded_model.fit(train_input_data, train_label)\n",
    "        rf_models.append(train_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_models), len(lgbm_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LGBMRegressor(bagging_fraction=0.46422916813430687, bagging_freq=2,\n",
       "               boosting_type='dart', l1_norm=4.4852748600985146e-05,\n",
       "               l2_norm=0.00019727191645972726, learning_rate=0.0841403960017377,\n",
       "               max_tree_depth=21, number_trees=252, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.5310090771576965, bagging_freq=6,\n",
       "               boosting_type='dart', l1_norm=0.0007074939068738357,\n",
       "               l2_norm=4.9620295490784465e-05, learning_rate=0.11041661896818841,\n",
       "               max_tree_depth=24, number_trees=282, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.61489782009405, bagging_freq=3,\n",
       "               boosting_type='dart', l1_norm=0.0005707417481197812,\n",
       "               l2_norm=0.00045912693969249804, learning_rate=0.16789852752946396,\n",
       "               max_tree_depth=22, number_trees=39, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.25798883959105195, bagging_freq=1,\n",
       "               boosting_type='dart', l1_norm=5.182615080547187e-05,\n",
       "               l2_norm=0.0006040212578897649, learning_rate=0.29973667852228486,\n",
       "               max_tree_depth=7, number_trees=90, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.9662965259618201, bagging_freq=0,\n",
       "               boosting_type='dart', l1_norm=0.0009115555723850486,\n",
       "               l2_norm=0.000816597296632138, learning_rate=0.6308378150488286,\n",
       "               max_tree_depth=15, number_trees=216, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.6602531121655265, bagging_freq=1,\n",
       "               boosting_type='dart', l1_norm=0.0005554834327937355,\n",
       "               l2_norm=0.00010704242989595481, learning_rate=0.38992186546512325,\n",
       "               max_tree_depth=7, number_trees=286, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.45459071884667585, bagging_freq=10,\n",
       "               boosting_type='dart', l1_norm=0.00045347331628954547,\n",
       "               l2_norm=0.0009151269047328503, learning_rate=0.10664810834372365,\n",
       "               max_tree_depth=7, number_trees=260, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.863736623457597, bagging_freq=1,\n",
       "               boosting_type='dart', l1_norm=9.527474491753565e-06,\n",
       "               l2_norm=0.0004308282230345845, learning_rate=0.30898186846169984,\n",
       "               max_tree_depth=17, number_trees=132, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.8318129072844922, bagging_freq=9,\n",
       "               boosting_type='dart', l1_norm=0.0003166453648668742,\n",
       "               l2_norm=0.0009324587861489461, learning_rate=0.9219479637742897,\n",
       "               max_tree_depth=13, number_trees=255, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.48338742066319224, bagging_freq=2,\n",
       "               l1_norm=0.0007263725423399532, l2_norm=0.0007397426324339357,\n",
       "               learning_rate=0.1988182225885291, max_tree_depth=17,\n",
       "               number_trees=121, verbosity=-1),\n",
       " RandomForestRegressor(max_depth=16, max_samples=0.030676784528067588,\n",
       "                       min_samples_split=4, n_estimators=53),\n",
       " RandomForestRegressor(max_depth=22, max_samples=0.967463306088819,\n",
       "                       min_samples_split=3, n_estimators=140),\n",
       " RandomForestRegressor(max_depth=3, max_samples=0.07548262876215607,\n",
       "                       n_estimators=286),\n",
       " RandomForestRegressor(max_depth=24, max_samples=0.5129763129785564,\n",
       "                       min_samples_split=8, n_estimators=26),\n",
       " RandomForestRegressor(max_depth=5, max_samples=0.207148510753365,\n",
       "                       min_samples_split=3, n_estimators=164),\n",
       " RandomForestRegressor(max_depth=14, max_samples=0.9796539692217939,\n",
       "                       min_samples_split=4, n_estimators=219),\n",
       " RandomForestRegressor(max_depth=7, max_samples=0.058111979264986194,\n",
       "                       min_samples_split=4, n_estimators=20),\n",
       " RandomForestRegressor(max_depth=19, max_samples=0.4177782782723607,\n",
       "                       n_estimators=244),\n",
       " RandomForestRegressor(max_depth=5, max_samples=0.3322352442798227,\n",
       "                       n_estimators=10),\n",
       " RandomForestRegressor(max_depth=16, max_samples=0.99936637014797,\n",
       "                       n_estimators=213)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine models into a single list of base estimators\n",
    "base_estimators = lgbm_models + rf_models\n",
    "(base_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_input['setting'] = train_val_input['setting'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for idx, model in enumerate(base_estimators):\n",
    "        if idx < 10:\n",
    "            train_val_input_subset = train_val_input.copy()\n",
    "            train_val_input_subset.columns = train_val_input_subset.columns.str.replace(r'[\\\"\\[\\]\\{\\}\\\\:,]', '', regex=True)\n",
    "            train_val_input_subset = train_val_input_subset[lgbm_col_needed[idx]]\n",
    "            \n",
    "        else:\n",
    "            train_val_input_relevant = train_val_input[rf_col_needed[idx - 10]]\n",
    "            train_val_input_subset = train_val_input_relevant.copy()\n",
    "            train_val_input_subset['setting'] = train_val_input_subset['setting'].map(countries_dict)\n",
    "\n",
    "        predictions.append(model.predict(train_val_input_subset))\n",
    "\n",
    "stacked_predictions = np.column_stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    stacked_predictions, train_val_label, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_meta_train_scaled = scaler.fit_transform(X_meta_train)\n",
    "X_meta_val_scaled = scaler.transform(X_meta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scaler = StandardScaler()\n",
    "y_meta_train_scaled = target_scaler.fit_transform(np.array(y_meta_train).reshape(-1, 1)).ravel()\n",
    "y_meta_val_scaled = target_scaler.transform(np.array(y_meta_val).reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to finetune the weights given to each of the base models in the voting ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_objective(trial):\n",
    "\n",
    "    weights = []\n",
    "    for i in range(20):\n",
    "        weights.append(trial.suggest_float(\"weights_\" + str(i), 0.0, 1.0))\n",
    "\n",
    "    w_sum = sum(weights)\n",
    "    w_normalised = [w / w_sum for w in weights]\n",
    "\n",
    "    weighted_predictions = np.dot(stacked_predictions, w_normalised)\n",
    "\n",
    "    return mean_squared_error(train_val_label, weighted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:05:22,694] A new study created in memory with name: no-name-ad32ffe7-d331-453e-8857-414aa53f1ae5\n",
      "[I 2025-08-01 08:05:22,709] Trial 0 finished with value: 2800.235415875602 and parameters: {'weights_0': 0.7779705994884244, 'weights_1': 0.1090569528183204, 'weights_2': 0.1176980737784421, 'weights_3': 0.4916437769060842, 'weights_4': 0.4634521869023104, 'weights_5': 0.6986082211091447, 'weights_6': 0.23278863415586692, 'weights_7': 0.901015038320828, 'weights_8': 0.2011353147583852, 'weights_9': 0.874044275065608, 'weights_10': 0.3105758654963994, 'weights_11': 0.5160852749719109, 'weights_12': 0.7774008920612505, 'weights_13': 0.9786957251213666, 'weights_14': 0.04817220316743753, 'weights_15': 0.16850239126906508, 'weights_16': 0.06134063801663958, 'weights_17': 0.2230452498414437, 'weights_18': 0.8464624181558037, 'weights_19': 0.649141040064727}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,727] Trial 1 finished with value: 3021.148042677537 and parameters: {'weights_0': 0.6723836168705645, 'weights_1': 0.13177047594197666, 'weights_2': 0.9570160023714576, 'weights_3': 0.2424676885635889, 'weights_4': 0.8689893197200788, 'weights_5': 0.24881654473326087, 'weights_6': 0.4659933079943166, 'weights_7': 0.8847237854182818, 'weights_8': 0.7682673730923705, 'weights_9': 0.5762699549576467, 'weights_10': 0.4409041763036752, 'weights_11': 0.8024426948240304, 'weights_12': 0.12154914263363448, 'weights_13': 0.8647402327683891, 'weights_14': 0.7382458871131706, 'weights_15': 0.8754788663117564, 'weights_16': 0.6306751365854428, 'weights_17': 0.05189542790275403, 'weights_18': 0.09247050136229762, 'weights_19': 0.7842166406785555}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,749] Trial 2 finished with value: 3503.8876857560076 and parameters: {'weights_0': 0.6216306399691472, 'weights_1': 0.9464248455362884, 'weights_2': 0.2983814831938729, 'weights_3': 0.3652012569687617, 'weights_4': 0.5328679769498315, 'weights_5': 0.3438972324836762, 'weights_6': 0.7256319658455138, 'weights_7': 0.8777425490209042, 'weights_8': 0.909987946820182, 'weights_9': 0.0771471003216242, 'weights_10': 0.3806986958324139, 'weights_11': 0.7245441849330856, 'weights_12': 0.015952902249053436, 'weights_13': 0.2818316841348385, 'weights_14': 0.9192921983039867, 'weights_15': 0.4095445948100054, 'weights_16': 0.949901257979327, 'weights_17': 0.37390516419350783, 'weights_18': 0.8520967470888491, 'weights_19': 0.9147556992055165}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,810] Trial 3 finished with value: 3632.82866272976 and parameters: {'weights_0': 0.5857400394756408, 'weights_1': 0.65034788404531, 'weights_2': 0.9690322845417954, 'weights_3': 0.0005533135460326077, 'weights_4': 0.8428406425320173, 'weights_5': 0.7825925743218001, 'weights_6': 0.4493165386667166, 'weights_7': 0.8777743805524709, 'weights_8': 0.9349243144546986, 'weights_9': 0.45182698377950814, 'weights_10': 0.7761545982462037, 'weights_11': 0.054104554463853094, 'weights_12': 0.7853148454880525, 'weights_13': 0.24627545840909637, 'weights_14': 0.3665000048807746, 'weights_15': 0.22140009225909485, 'weights_16': 0.14899519567450303, 'weights_17': 0.05327807023579845, 'weights_18': 0.30365783558858284, 'weights_19': 0.15252388877105594}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,844] Trial 4 finished with value: 3700.2517585693868 and parameters: {'weights_0': 0.8823947396250535, 'weights_1': 0.10521674083000243, 'weights_2': 0.5631854619760167, 'weights_3': 0.2975891693125241, 'weights_4': 0.27820692563406535, 'weights_5': 0.14342622395314697, 'weights_6': 0.6597394926240657, 'weights_7': 0.9423212797817438, 'weights_8': 0.9201358391524559, 'weights_9': 0.4777079055488359, 'weights_10': 0.5821414721124263, 'weights_11': 0.5616992024564265, 'weights_12': 0.829856817446284, 'weights_13': 0.4276534858333547, 'weights_14': 0.9383428868885727, 'weights_15': 0.984434777152149, 'weights_16': 0.31644090039252226, 'weights_17': 0.7451014834646027, 'weights_18': 0.522025204125264, 'weights_19': 0.015790829311391974}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,849] Trial 5 finished with value: 3200.0394855015143 and parameters: {'weights_0': 0.9934771192892747, 'weights_1': 0.07853666574077933, 'weights_2': 0.5379977925004087, 'weights_3': 0.6760001495182749, 'weights_4': 0.3723513940624632, 'weights_5': 0.8751322781767588, 'weights_6': 0.28497948627682534, 'weights_7': 0.6137844358596721, 'weights_8': 0.46360951415003615, 'weights_9': 0.5688310088419348, 'weights_10': 0.40256574019889635, 'weights_11': 0.11862821390875966, 'weights_12': 0.8387574782208498, 'weights_13': 0.7589402001694151, 'weights_14': 0.5469703680621953, 'weights_15': 0.895663231630113, 'weights_16': 0.2295746523778336, 'weights_17': 0.9216255590266643, 'weights_18': 0.09508150059885467, 'weights_19': 0.0686737040362958}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,852] Trial 6 finished with value: 3523.755425871151 and parameters: {'weights_0': 0.7646320942279358, 'weights_1': 0.3114566430374034, 'weights_2': 0.6897205119819566, 'weights_3': 0.5930138613652606, 'weights_4': 0.3507258863228585, 'weights_5': 0.4477477860189649, 'weights_6': 0.05701990142129798, 'weights_7': 0.40879759406185046, 'weights_8': 0.4663455731956533, 'weights_9': 0.09813058352151471, 'weights_10': 0.9739730754357748, 'weights_11': 0.8435233777489152, 'weights_12': 0.7742954112003043, 'weights_13': 0.14859927963168962, 'weights_14': 0.335821611444589, 'weights_15': 0.6132566959811453, 'weights_16': 0.9581855428841041, 'weights_17': 0.9987389809034176, 'weights_18': 0.006401541712001357, 'weights_19': 0.7195141774798512}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,857] Trial 7 finished with value: 3248.107980102617 and parameters: {'weights_0': 0.046276935518918316, 'weights_1': 0.7190444222324662, 'weights_2': 0.09697959653291233, 'weights_3': 0.03404622789479672, 'weights_4': 0.7803871326323419, 'weights_5': 0.21105807710707458, 'weights_6': 0.46204804364247265, 'weights_7': 0.6726615515001734, 'weights_8': 0.1932345674841779, 'weights_9': 0.5791915706486269, 'weights_10': 0.8526301837741797, 'weights_11': 0.3152408424165849, 'weights_12': 0.4701355326192971, 'weights_13': 0.6846275074313205, 'weights_14': 0.0501427781162086, 'weights_15': 0.6197786922266658, 'weights_16': 0.8877563906313876, 'weights_17': 0.4531685662751539, 'weights_18': 0.5578252519630185, 'weights_19': 0.4498390914265006}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,866] Trial 8 finished with value: 3629.6097322893856 and parameters: {'weights_0': 0.007203066483491782, 'weights_1': 0.5262347905930879, 'weights_2': 0.7577719577774755, 'weights_3': 0.2898905579759079, 'weights_4': 0.8898806876226579, 'weights_5': 0.3703722781375114, 'weights_6': 0.8891920021512337, 'weights_7': 0.4555526619746699, 'weights_8': 0.6407691311454506, 'weights_9': 0.13300086246742893, 'weights_10': 0.8245825427202732, 'weights_11': 0.4968342461208357, 'weights_12': 0.5197032827052086, 'weights_13': 0.3543162418933503, 'weights_14': 0.7867395029374962, 'weights_15': 0.573746974263384, 'weights_16': 0.8119572390895481, 'weights_17': 0.9416300241236661, 'weights_18': 0.5807927645864136, 'weights_19': 0.709529008391794}. Best is trial 0 with value: 2800.235415875602.\n",
      "[I 2025-08-01 08:05:22,897] Trial 9 finished with value: 2403.8963887856626 and parameters: {'weights_0': 0.08447901503055233, 'weights_1': 0.6122255819234538, 'weights_2': 0.09887845522737315, 'weights_3': 0.2365826559183909, 'weights_4': 0.08595186549666034, 'weights_5': 0.5672603726522691, 'weights_6': 0.00043780233781109956, 'weights_7': 0.7673487849382864, 'weights_8': 0.029410054578991707, 'weights_9': 0.8319390731924219, 'weights_10': 0.13324410331804737, 'weights_11': 0.597098454591047, 'weights_12': 0.08985340882157877, 'weights_13': 0.568254400339837, 'weights_14': 0.6250368662748416, 'weights_15': 0.13517773500146768, 'weights_16': 0.6756067388241724, 'weights_17': 0.28395900804026175, 'weights_18': 0.05037534665211729, 'weights_19': 0.9304061280171356}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,000] Trial 10 finished with value: 2807.8535961938633 and parameters: {'weights_0': 0.3119326642766421, 'weights_1': 0.8830524008307434, 'weights_2': 0.27145454768285604, 'weights_3': 0.9167957202465048, 'weights_4': 0.06581680014409158, 'weights_5': 0.6260627161043115, 'weights_6': 0.010760333953252755, 'weights_7': 0.08278316487958459, 'weights_8': 0.0017814905378180645, 'weights_9': 0.9452984448268613, 'weights_10': 0.04503515252522909, 'weights_11': 0.9428186236309902, 'weights_12': 0.23763425286716888, 'weights_13': 0.5388657907120749, 'weights_14': 0.5876932522614168, 'weights_15': 0.017241689639571164, 'weights_16': 0.5741844909057652, 'weights_17': 0.6281705580029853, 'weights_18': 0.2995625638919447, 'weights_19': 0.39367957610076265}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,148] Trial 11 finished with value: 2894.6679294956907 and parameters: {'weights_0': 0.35188387161390183, 'weights_1': 0.327351911750857, 'weights_2': 0.03532799902582434, 'weights_3': 0.4917454932062646, 'weights_4': 0.0007370710133160069, 'weights_5': 0.6320265213655741, 'weights_6': 0.2088139293516008, 'weights_7': 0.7065009634347694, 'weights_8': 0.19243547848501869, 'weights_9': 0.9586995002456763, 'weights_10': 0.10755758834375773, 'weights_11': 0.537557566116932, 'weights_12': 0.9943814168217741, 'weights_13': 0.9390220565926987, 'weights_14': 0.010117148138468757, 'weights_15': 0.0014037943936631159, 'weights_16': 0.380617639981217, 'weights_17': 0.26672753909071956, 'weights_18': 0.9561636299323276, 'weights_19': 0.9975833975298095}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,261] Trial 12 finished with value: 2691.1483609339807 and parameters: {'weights_0': 0.3931329420486857, 'weights_1': 0.3436088616829424, 'weights_2': 0.25401709924089677, 'weights_3': 0.7852956737559575, 'weights_4': 0.609873489797945, 'weights_5': 0.6337999446813899, 'weights_6': 0.22706416692628795, 'weights_7': 0.7483642396403245, 'weights_8': 0.038490410492424215, 'weights_9': 0.7699361840804562, 'weights_10': 0.21226861590644341, 'weights_11': 0.3400436845315257, 'weights_12': 0.5061874123979853, 'weights_13': 0.5853357665042384, 'weights_14': 0.19807832846228962, 'weights_15': 0.22810280029146704, 'weights_16': 0.008799737506554071, 'weights_17': 0.23147483385837217, 'weights_18': 0.7676447592627345, 'weights_19': 0.5775562211002833}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,408] Trial 13 finished with value: 3096.104909264643 and parameters: {'weights_0': 0.2293635381487242, 'weights_1': 0.38065015032115146, 'weights_2': 0.30942796323567806, 'weights_3': 0.9401315822050836, 'weights_4': 0.66494344136717, 'weights_5': 0.9465860612398419, 'weights_6': 0.13333025485855587, 'weights_7': 0.2451994575669183, 'weights_8': 0.04390322973676604, 'weights_9': 0.763048699682907, 'weights_10': 0.22503815956744636, 'weights_11': 0.29642458541551536, 'weights_12': 0.3797772381389922, 'weights_13': 0.5852319852029201, 'weights_14': 0.26233692040916856, 'weights_15': 0.32794738453748196, 'weights_16': 0.7213341321537003, 'weights_17': 0.21658607055987036, 'weights_18': 0.7221151383050647, 'weights_19': 0.33749499833593266}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,515] Trial 14 finished with value: 2878.678460476438 and parameters: {'weights_0': 0.44501304639909395, 'weights_1': 0.557804621002119, 'weights_2': 0.2140286296660527, 'weights_3': 0.7056427750004345, 'weights_4': 0.19750301126634673, 'weights_5': 0.5522411398260495, 'weights_6': 0.3226583515845457, 'weights_7': 0.7167878713799264, 'weights_8': 0.3236578869938539, 'weights_9': 0.7461159338889166, 'weights_10': 0.16146062434353087, 'weights_11': 0.36382552643055316, 'weights_12': 0.5867418281557111, 'weights_13': 0.6570025189360389, 'weights_14': 0.2121588091593437, 'weights_15': 0.19229493833538702, 'weights_16': 0.4566776587044151, 'weights_17': 0.3429095175366698, 'weights_18': 0.3338622317648148, 'weights_19': 0.583496051643896}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,607] Trial 15 finished with value: 2941.6269406531587 and parameters: {'weights_0': 0.1981396171853852, 'weights_1': 0.7863644305772921, 'weights_2': 0.43305815331356856, 'weights_3': 0.7766505676805714, 'weights_4': 0.6840358737184516, 'weights_5': 0.5034032496757004, 'weights_6': 0.0026986122953157983, 'weights_7': 0.5891599142640664, 'weights_8': 0.10076431489775187, 'weights_9': 0.7372141387500664, 'weights_10': 0.5408504548307713, 'weights_11': 0.6671423761605858, 'weights_12': 0.30625310847871334, 'weights_13': 0.047832984453931804, 'weights_14': 0.46882773699567787, 'weights_15': 0.33589756571872886, 'weights_16': 0.6870085017187639, 'weights_17': 0.5564686691729421, 'weights_18': 0.7007914779953979, 'weights_19': 0.8477278804733248}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,726] Trial 16 finished with value: 3567.289842030697 and parameters: {'weights_0': 0.46731009102917087, 'weights_1': 0.3969425140912646, 'weights_2': 0.00028601567111519177, 'weights_3': 0.1155196815160251, 'weights_4': 0.5657407856503063, 'weights_5': 0.003996610067895423, 'weights_6': 0.34988433933636776, 'weights_7': 0.7764320164295737, 'weights_8': 0.32794309571936053, 'weights_9': 0.27436896239816755, 'weights_10': 0.24205009661441987, 'weights_11': 0.20936717216490863, 'weights_12': 0.5847466441951459, 'weights_13': 0.45870026707923667, 'weights_14': 0.6533754504870986, 'weights_15': 0.12513461605537543, 'weights_16': 0.4898675148013, 'weights_17': 0.12477825737232173, 'weights_18': 0.3927982387238121, 'weights_19': 0.5484852307014376}. Best is trial 9 with value: 2403.8963887856626.\n",
      "[I 2025-08-01 08:05:23,834] Trial 17 finished with value: 2183.479864829434 and parameters: {'weights_0': 0.12606567346602593, 'weights_1': 0.23247517984324828, 'weights_2': 0.17720955886646006, 'weights_3': 0.8384549224672329, 'weights_4': 0.1770862320346962, 'weights_5': 0.7865418233033642, 'weights_6': 0.12301660655317917, 'weights_7': 0.9988329810903169, 'weights_8': 0.2939448731207398, 'weights_9': 0.8622334070401645, 'weights_10': 0.015467412826371763, 'weights_11': 0.41004074167123655, 'weights_12': 0.17106967790945338, 'weights_13': 0.7575042334845566, 'weights_14': 0.4530562516956872, 'weights_15': 0.43177190474393734, 'weights_16': 0.044329889632484853, 'weights_17': 0.4163686814955291, 'weights_18': 0.1789055119955523, 'weights_19': 0.2753712610351454}. Best is trial 17 with value: 2183.479864829434.\n",
      "[I 2025-08-01 08:05:23,926] Trial 18 finished with value: 2363.3718725981935 and parameters: {'weights_0': 0.11879657270624727, 'weights_1': 0.2516534477886409, 'weights_2': 0.1692655914429082, 'weights_3': 0.407237058909639, 'weights_4': 0.1599737940747797, 'weights_5': 0.8257976361287974, 'weights_6': 0.1333224475406835, 'weights_7': 0.9959020937072707, 'weights_8': 0.33521789363993715, 'weights_9': 0.8798551575291003, 'weights_10': 0.02687956245220499, 'weights_11': 0.6497163949084543, 'weights_12': 0.01605939133876555, 'weights_13': 0.7941447606811993, 'weights_14': 0.44580661042695574, 'weights_15': 0.7509155376552241, 'weights_16': 0.774946828141285, 'weights_17': 0.6928123334389786, 'weights_18': 0.1638331379851203, 'weights_19': 0.25949815807077137}. Best is trial 17 with value: 2183.479864829434.\n",
      "[I 2025-08-01 08:05:24,046] Trial 19 finished with value: 3010.880523367873 and parameters: {'weights_0': 0.16028072586007824, 'weights_1': 0.21855014741457246, 'weights_2': 0.41051758612277217, 'weights_3': 0.9943364013987397, 'weights_4': 0.1787848938030689, 'weights_5': 0.9856849781449128, 'weights_6': 0.5920801494878958, 'weights_7': 0.33145944967496366, 'weights_8': 0.587474876460258, 'weights_9': 0.2973848861815637, 'weights_10': 0.012758720745471751, 'weights_11': 0.42732559857943914, 'weights_12': 0.18315369873945864, 'weights_13': 0.8040203540085854, 'weights_14': 0.4447903830091109, 'weights_15': 0.7442448479650567, 'weights_16': 0.7983324359972916, 'weights_17': 0.7336088294901313, 'weights_18': 0.22099769774782307, 'weights_19': 0.2413447963438778}. Best is trial 17 with value: 2183.479864829434.\n",
      "[I 2025-08-01 08:05:24,170] Trial 20 finished with value: 2100.877873932618 and parameters: {'weights_0': 0.25193865639616014, 'weights_1': 0.0025802499502498577, 'weights_2': 0.18303431296608896, 'weights_3': 0.4234002706020371, 'weights_4': 0.19140142065698573, 'weights_5': 0.7977858052138577, 'weights_6': 0.11037111623146097, 'weights_7': 0.9992285954132281, 'weights_8': 0.3369049686232217, 'weights_9': 0.99851416975816, 'weights_10': 0.0077910580808722915, 'weights_11': 0.665495030232231, 'weights_12': 0.010581420696650657, 'weights_13': 0.8485598536594943, 'weights_14': 0.35589620719458637, 'weights_15': 0.7501479590407084, 'weights_16': 0.24262283194370315, 'weights_17': 0.7570228100108871, 'weights_18': 0.18377280110258284, 'weights_19': 0.2623542280478457}. Best is trial 20 with value: 2100.877873932618.\n",
      "[I 2025-08-01 08:05:24,285] Trial 21 finished with value: 2065.577727881272 and parameters: {'weights_0': 0.2744482525311056, 'weights_1': 0.006509957400331112, 'weights_2': 0.16386049528518004, 'weights_3': 0.3871823393986723, 'weights_4': 0.20180668550797146, 'weights_5': 0.7991164176900053, 'weights_6': 0.129736198835354, 'weights_7': 0.9966940727342641, 'weights_8': 0.3414490107546273, 'weights_9': 0.9945534370686965, 'weights_10': 0.01881654323998289, 'weights_11': 0.682492185315674, 'weights_12': 0.009274588160593063, 'weights_13': 0.8689936570946952, 'weights_14': 0.39092256822224125, 'weights_15': 0.738980727500905, 'weights_16': 0.11391226493963966, 'weights_17': 0.8085327501979072, 'weights_18': 0.18432535793972965, 'weights_19': 0.28388236503919045}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:24,413] Trial 22 finished with value: 2188.021131217503 and parameters: {'weights_0': 0.2672418943048863, 'weights_1': 0.028305998592582315, 'weights_2': 0.3586045850040701, 'weights_3': 0.6146515933772707, 'weights_4': 0.2835768164883833, 'weights_5': 0.763886133224789, 'weights_6': 0.12131735893421204, 'weights_7': 0.9938524910152741, 'weights_8': 0.3695194183913141, 'weights_9': 0.9915361597388602, 'weights_10': 0.08381413194617049, 'weights_11': 0.7813161305460055, 'weights_12': 0.1187528242019511, 'weights_13': 0.8897704948615247, 'weights_14': 0.3687784651353234, 'weights_15': 0.7346858268496452, 'weights_16': 0.13246570178564454, 'weights_17': 0.8247020952115054, 'weights_18': 0.19804801730787583, 'weights_19': 0.19666242772703924}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:24,564] Trial 23 finished with value: 2308.067846523119 and parameters: {'weights_0': 0.2598625979876327, 'weights_1': 0.0131937532818279, 'weights_2': 0.1606309526345334, 'weights_3': 0.4136680814167957, 'weights_4': 0.25159869520443356, 'weights_5': 0.8800569779795497, 'weights_6': 0.3782313899865385, 'weights_7': 0.846646417806503, 'weights_8': 0.24805087487028854, 'weights_9': 0.9907475685708416, 'weights_10': 0.3014010233444507, 'weights_11': 0.9875675325595914, 'weights_12': 0.006595419804183447, 'weights_13': 0.7056333112088379, 'weights_14': 0.3041124401837694, 'weights_15': 0.4917339875229235, 'weights_16': 0.23790652269243098, 'weights_17': 0.490975508580717, 'weights_18': 0.4248588628267749, 'weights_19': 0.31340040746283376}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:24,666] Trial 24 finished with value: 2312.51243953369 and parameters: {'weights_0': 0.1483438252058249, 'weights_1': 0.19472068146700117, 'weights_2': 0.2084456954014269, 'weights_3': 0.5522572313067405, 'weights_4': 0.42391024017758683, 'weights_5': 0.7259016746684391, 'weights_6': 0.10926572943875937, 'weights_7': 0.9943530291380654, 'weights_8': 0.40778814509309863, 'weights_9': 0.6528833438724049, 'weights_10': 0.6386489433909179, 'weights_11': 0.8674028838776866, 'weights_12': 0.22625900002521138, 'weights_13': 0.8919958366338546, 'weights_14': 0.12973620544240083, 'weights_15': 0.5046927567210817, 'weights_16': 0.12325216784359964, 'weights_17': 0.8084445207990488, 'weights_18': 0.15929343610397745, 'weights_19': 0.1390086781827322}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:24,739] Trial 25 finished with value: 2503.7949726975125 and parameters: {'weights_0': 0.3731604886517642, 'weights_1': 0.44504898498443235, 'weights_2': 0.4602385643544565, 'weights_3': 0.17200483026073787, 'weights_4': 0.12605124593001815, 'weights_5': 0.8901995717596732, 'weights_6': 0.19137070882026103, 'weights_7': 0.8139104189626355, 'weights_8': 0.5711670199479808, 'weights_9': 0.8848585971838863, 'weights_10': 0.014941508075654506, 'weights_11': 0.4516202323998001, 'weights_12': 0.34565176658125213, 'weights_13': 0.9812739766150629, 'weights_14': 0.403183251097599, 'weights_15': 0.8431036494248599, 'weights_16': 0.25262104099651017, 'weights_17': 0.8634464606394332, 'weights_18': 0.2674532265619928, 'weights_19': 0.3776710773929306}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:24,854] Trial 26 finished with value: 2591.4932863167205 and parameters: {'weights_0': 0.5308503627743659, 'weights_1': 0.17039592410980783, 'weights_2': 0.3592139193481791, 'weights_3': 0.42852672501253186, 'weights_4': 0.011142994727827649, 'weights_5': 0.706365896061731, 'weights_6': 0.8723200863245496, 'weights_7': 0.9347066045636137, 'weights_8': 0.28791517137597505, 'weights_9': 0.8210705374380749, 'weights_10': 0.15986299079061037, 'weights_11': 0.704722826110401, 'weights_12': 0.088636586817748, 'weights_13': 0.8300388243458751, 'weights_14': 0.5506069769462362, 'weights_15': 0.6672067766915555, 'weights_16': 0.008307353145785845, 'weights_17': 0.5886457175294127, 'weights_18': 0.4297668731965717, 'weights_19': 0.46229536724180853}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:24,938] Trial 27 finished with value: 2497.3469814190817 and parameters: {'weights_0': 0.277530591272246, 'weights_1': 0.0010287905142045534, 'weights_2': 0.07482512634763065, 'weights_3': 0.8260645963228429, 'weights_4': 0.33112535627286954, 'weights_5': 0.8089748360827863, 'weights_6': 0.2800761928437755, 'weights_7': 0.539008910746851, 'weights_8': 0.4334880340483438, 'weights_9': 0.6638935927211778, 'weights_10': 0.11304765433142984, 'weights_11': 0.6156414785718365, 'weights_12': 0.1787947930666845, 'weights_13': 0.7312360582596987, 'weights_14': 0.5230355853807903, 'weights_15': 0.962457161160066, 'weights_16': 0.3633093884717897, 'weights_17': 0.6616606371961216, 'weights_18': 0.12092829315352577, 'weights_19': 0.28555816828270425}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,025] Trial 28 finished with value: 2338.835755242949 and parameters: {'weights_0': 0.19120008214445733, 'weights_1': 0.2501255224544716, 'weights_2': 0.6283032754855928, 'weights_3': 0.3345960363500329, 'weights_4': 0.9936418579892072, 'weights_5': 0.9927917344366123, 'weights_6': 0.08633073313575577, 'weights_7': 0.8162577106461704, 'weights_8': 0.12876289291051257, 'weights_9': 0.923178673846952, 'weights_10': 0.2776297836951088, 'weights_11': 0.41639565481780044, 'weights_12': 0.07366428484024477, 'weights_13': 0.6285855686461533, 'weights_14': 0.24075969021069604, 'weights_15': 0.4735630028442427, 'weights_16': 0.19072196865545887, 'weights_17': 0.43333411688353307, 'weights_18': 0.2279567337422735, 'weights_19': 0.08906513013791062}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,115] Trial 29 finished with value: 2503.5825478538172 and parameters: {'weights_0': 0.08899457949438189, 'weights_1': 0.1532210308070804, 'weights_2': 0.3549272139078111, 'weights_3': 0.5211613335757171, 'weights_4': 0.4439796625235558, 'weights_5': 0.7219422744367082, 'weights_6': 0.19304060932837247, 'weights_7': 0.9337479730558026, 'weights_8': 0.5381697097766291, 'weights_9': 0.8434629018655277, 'weights_10': 0.3625340135370797, 'weights_11': 0.2111191116471214, 'weights_12': 0.28202475350679, 'weights_13': 0.9483837141262517, 'weights_14': 0.3206866731401273, 'weights_15': 0.8028266560225263, 'weights_16': 0.0873583863894603, 'weights_17': 0.5448030353750446, 'weights_18': 0.37759033701329836, 'weights_19': 0.18474176690471206}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,218] Trial 30 finished with value: 2424.233724356653 and parameters: {'weights_0': 0.3372309050591385, 'weights_1': 0.07328689973793444, 'weights_2': 0.15313891326421156, 'weights_3': 0.44624807046029363, 'weights_4': 0.2316041321522102, 'weights_5': 0.6565665597115516, 'weights_6': 0.399829549720105, 'weights_7': 0.14774460379818677, 'weights_8': 0.6478839898006464, 'weights_9': 0.9122289534894491, 'weights_10': 0.07616580645524723, 'weights_11': 0.4879490069741496, 'weights_12': 0.16581668644336195, 'weights_13': 0.7841162913252208, 'weights_14': 0.15437420048492817, 'weights_15': 0.3998084154135631, 'weights_16': 0.06040828139063214, 'weights_17': 0.7981281982784046, 'weights_18': 0.0026752316157144795, 'weights_19': 0.40384404315952704}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,342] Trial 31 finished with value: 2194.8650941124356 and parameters: {'weights_0': 0.2624594720881009, 'weights_1': 0.04663168517191463, 'weights_2': 0.23273116493434398, 'weights_3': 0.6317696822878025, 'weights_4': 0.09119433559672678, 'weights_5': 0.7848005417655216, 'weights_6': 0.16251621294448604, 'weights_7': 0.9905523516003619, 'weights_8': 0.2489836227221287, 'weights_9': 0.9892194653791391, 'weights_10': 0.0726930498917106, 'weights_11': 0.7617556367471016, 'weights_12': 0.12891998657936418, 'weights_13': 0.8915018417323217, 'weights_14': 0.4157048794082218, 'weights_15': 0.7186714993871774, 'weights_16': 0.1526492252534845, 'weights_17': 0.8445133806875365, 'weights_18': 0.20361020019223958, 'weights_19': 0.19110743613374317}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,442] Trial 32 finished with value: 2199.4181871491855 and parameters: {'weights_0': 0.4187636126468163, 'weights_1': 0.12712591843915294, 'weights_2': 0.3278046295719711, 'weights_3': 0.5773548588543894, 'weights_4': 0.3012319887773482, 'weights_5': 0.755786796836439, 'weights_6': 0.07669898701027997, 'weights_7': 0.9144665183964322, 'weights_8': 0.39263717443134943, 'weights_9': 0.9907137854066739, 'weights_10': 0.1737626288248194, 'weights_11': 0.7957791246798729, 'weights_12': 0.05883734315258112, 'weights_13': 0.8699700164040557, 'weights_14': 0.3580259172284088, 'weights_15': 0.6853854135029493, 'weights_16': 0.07124787416733643, 'weights_17': 0.8889837748918751, 'weights_18': 0.16453489488216066, 'weights_19': 0.26180587769060254}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,534] Trial 33 finished with value: 2344.073608867886 and parameters: {'weights_0': 0.5186243386097213, 'weights_1': 0.0010740637161693288, 'weights_2': 0.1467935789775802, 'weights_3': 0.8594207019460751, 'weights_4': 0.2312749182631899, 'weights_5': 0.843717314007978, 'weights_6': 0.2776409811048595, 'weights_7': 0.9988463756379083, 'weights_8': 0.3990375102901141, 'weights_9': 0.9091146908527183, 'weights_10': 0.013992529734575834, 'weights_11': 0.7046490052425178, 'weights_12': 0.0038671051168615205, 'weights_13': 0.9848966903659266, 'weights_14': 0.486869625155438, 'weights_15': 0.8170453134853216, 'weights_16': 0.3147142873366483, 'weights_17': 0.7637619676269733, 'weights_18': 0.2574433467910967, 'weights_19': 0.21846571824486277}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,638] Trial 34 finished with value: 2559.1947879595527 and parameters: {'weights_0': 0.003706942359694876, 'weights_1': 0.07873002496081993, 'weights_2': 0.8723167497416469, 'weights_3': 0.7027990115179163, 'weights_4': 0.1381580352309874, 'weights_5': 0.9188849963294018, 'weights_6': 0.9891454131575019, 'weights_7': 0.8750837466851435, 'weights_8': 0.36181925209803617, 'weights_9': 0.8206837006012344, 'weights_10': 0.09041291767991189, 'weights_11': 0.8775159646463919, 'weights_12': 0.1358953817600084, 'weights_13': 0.9119899469331958, 'weights_14': 0.7107282910558859, 'weights_15': 0.5637756343960092, 'weights_16': 0.15960346680208015, 'weights_17': 0.6856861118205662, 'weights_18': 0.1311053752452762, 'weights_19': 0.33912750350649234}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,743] Trial 35 finished with value: 2434.4960539722606 and parameters: {'weights_0': 0.2205979093481912, 'weights_1': 0.12453895985505388, 'weights_2': 0.375186984168303, 'weights_3': 0.3727841813634037, 'weights_4': 0.3848747178311329, 'weights_5': 0.6653394502131059, 'weights_6': 0.5756630024398426, 'weights_7': 0.9023225248350808, 'weights_8': 0.25697651900984486, 'weights_9': 0.37723923015519334, 'weights_10': 0.20042657960595703, 'weights_11': 0.7838043888572015, 'weights_12': 0.24155906265919955, 'weights_13': 0.8422246782172829, 'weights_14': 0.3943926288940049, 'weights_15': 0.913304623863223, 'weights_16': 0.08674954543856173, 'weights_17': 0.3745372307154965, 'weights_18': 0.07904814712523156, 'weights_19': 0.11852958534188165}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,854] Trial 36 finished with value: 2311.8534940773984 and parameters: {'weights_0': 0.2960337709741557, 'weights_1': 0.05371871027250298, 'weights_2': 0.060737962603768625, 'weights_3': 0.47612081581569954, 'weights_4': 0.49981640034920866, 'weights_5': 0.7703998836336525, 'weights_6': 0.06452308285648424, 'weights_7': 0.8504521736275326, 'weights_8': 0.15537602372820833, 'weights_9': 0.9489545600671325, 'weights_10': 0.45212084334080105, 'weights_11': 0.7366239559723877, 'weights_12': 0.05389248907085101, 'weights_13': 0.7320601200339056, 'weights_14': 0.27825652837954373, 'weights_15': 0.6491093152724404, 'weights_16': 0.2091959417200119, 'weights_17': 0.9940198848946599, 'weights_18': 0.3403638526590866, 'weights_19': 0.013692246379198858}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:25,966] Trial 37 finished with value: 2803.6639507180626 and parameters: {'weights_0': 0.6537098236236608, 'weights_1': 0.22819866331261496, 'weights_2': 0.48938092600998073, 'weights_3': 0.6410042102789522, 'weights_4': 0.29361141570839766, 'weights_5': 0.8495068180034452, 'weights_6': 0.24326100280450697, 'weights_7': 0.9445940035974434, 'weights_8': 0.5227832823136914, 'weights_9': 0.009031911245358848, 'weights_10': 0.3329960815968953, 'weights_11': 0.5730973003319897, 'weights_12': 0.40438479447611536, 'weights_13': 0.840534982106169, 'weights_14': 0.37349572606992565, 'weights_15': 0.7680097630730075, 'weights_16': 0.2643310297779409, 'weights_17': 0.8136666112080703, 'weights_18': 0.04942021398807003, 'weights_19': 0.06851830771334655}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:26,069] Trial 38 finished with value: 2580.5665751324523 and parameters: {'weights_0': 0.14658778554519566, 'weights_1': 0.13375272493334286, 'weights_2': 0.29565971615490094, 'weights_3': 0.2700898435701608, 'weights_4': 0.19216695529298697, 'weights_5': 0.5694810359102171, 'weights_6': 0.15232686941723095, 'weights_7': 0.9522309124060192, 'weights_8': 0.7250258855382153, 'weights_9': 0.8699441204379206, 'weights_10': 0.7042160313050914, 'weights_11': 0.664232571483981, 'weights_12': 0.12436262577122861, 'weights_13': 0.9978110760450988, 'weights_14': 0.5013131563044693, 'weights_15': 0.5560249845656731, 'weights_16': 0.30205927785304226, 'weights_17': 0.9314549439161564, 'weights_18': 0.26594288386099185, 'weights_19': 0.47297304900376924}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:26,158] Trial 39 finished with value: 2821.2225658745483 and parameters: {'weights_0': 0.5784307223425951, 'weights_1': 0.27524142711737226, 'weights_2': 0.1998484718500395, 'weights_3': 0.33494831186691143, 'weights_4': 0.057609821139282175, 'weights_5': 0.932855333019865, 'weights_6': 0.41851627202673924, 'weights_7': 0.657125347074235, 'weights_8': 0.47229629858448385, 'weights_9': 0.6621204139632686, 'weights_10': 0.07245306916948283, 'weights_11': 0.9208420876354689, 'weights_12': 0.1756225662031757, 'weights_13': 0.7624160747308414, 'weights_14': 0.8728613646403948, 'weights_15': 0.8725478723652128, 'weights_16': 0.4038795957199195, 'weights_17': 0.7259883216636985, 'weights_18': 0.48935085640712256, 'weights_19': 0.1729216273147191}. Best is trial 21 with value: 2065.577727881272.\n",
      "[I 2025-08-01 08:05:26,272] Trial 40 finished with value: 1946.5581416557823 and parameters: {'weights_0': 0.08036048775906829, 'weights_1': 0.17726075026807847, 'weights_2': 0.11942005749443933, 'weights_3': 0.18325806291773292, 'weights_4': 0.3258750215064772, 'weights_5': 0.7529423775896099, 'weights_6': 0.05873643293086637, 'weights_7': 0.8159963644848987, 'weights_8': 0.2921744403936133, 'weights_9': 0.8016256554414262, 'weights_10': 0.12544813744179584, 'weights_11': 0.8172365590367137, 'weights_12': 0.064146437166094, 'weights_13': 0.923369286933933, 'weights_14': 0.14859598985573017, 'weights_15': 0.7085431243069024, 'weights_16': 0.039369826899327734, 'weights_17': 0.5987006115596651, 'weights_18': 0.1955012598117365, 'weights_19': 0.30762658948710925}. Best is trial 40 with value: 1946.5581416557823.\n",
      "[I 2025-08-01 08:05:26,349] Trial 41 finished with value: 1864.351817499874 and parameters: {'weights_0': 0.05190760730836659, 'weights_1': 0.09059938870635634, 'weights_2': 0.11809696259847983, 'weights_3': 0.06871451147605871, 'weights_4': 0.3903998555159119, 'weights_5': 0.7572341631066443, 'weights_6': 0.07132467083600658, 'weights_7': 0.8828253106907543, 'weights_8': 0.2827473090094813, 'weights_9': 0.9925746105002125, 'weights_10': 0.13526678687418384, 'weights_11': 0.825437915825551, 'weights_12': 0.05254907885763101, 'weights_13': 0.9281810236734751, 'weights_14': 0.14362505563300607, 'weights_15': 0.7209475415072215, 'weights_16': 0.0011083776456277117, 'weights_17': 0.5177938419220464, 'weights_18': 0.19246181239522597, 'weights_19': 0.30429637959976763}. Best is trial 41 with value: 1864.351817499874.\n",
      "[I 2025-08-01 08:05:26,445] Trial 42 finished with value: 1829.2659326521634 and parameters: {'weights_0': 0.06664978971872365, 'weights_1': 0.08049121555985991, 'weights_2': 0.11147481008795758, 'weights_3': 0.09473439207833592, 'weights_4': 0.40247561948015315, 'weights_5': 0.8258137635455084, 'weights_6': 0.05296000265723674, 'weights_7': 0.8196149340111791, 'weights_8': 0.2800091022962418, 'weights_9': 0.8031942815487894, 'weights_10': 0.1362694792181795, 'weights_11': 0.8566734990904692, 'weights_12': 0.04793349266059892, 'weights_13': 0.948468151690412, 'weights_14': 0.06874564630358418, 'weights_15': 0.6022416323723419, 'weights_16': 0.033822136365896274, 'weights_17': 0.5103953386957562, 'weights_18': 0.09144096708567495, 'weights_19': 0.3089594012089365}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:26,555] Trial 43 finished with value: 1961.5851554766152 and parameters: {'weights_0': 0.04416503947552311, 'weights_1': 0.0734112316581081, 'weights_2': 0.09921362263891421, 'weights_3': 0.0655153597624124, 'weights_4': 0.3922065596989616, 'weights_5': 0.6747064284098102, 'weights_6': 0.04546586408650281, 'weights_7': 0.8320097559126409, 'weights_8': 0.9809357917062874, 'weights_9': 0.7104318384655799, 'weights_10': 0.1383730645298118, 'weights_11': 0.8408204370975512, 'weights_12': 0.036501741011446556, 'weights_13': 0.9370528407691745, 'weights_14': 0.08204538359574565, 'weights_15': 0.7047428660163325, 'weights_16': 0.03136623433206043, 'weights_17': 0.48545608786776395, 'weights_18': 0.07359553697775616, 'weights_19': 0.4053181408598373}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:26,632] Trial 44 finished with value: 1989.8425817633085 and parameters: {'weights_0': 0.029842938861906407, 'weights_1': 0.08713306570049767, 'weights_2': 0.10746183138386024, 'weights_3': 0.06932893175758803, 'weights_4': 0.48188314708020685, 'weights_5': 0.6846849374645299, 'weights_6': 0.031004213171969074, 'weights_7': 0.8078400342077658, 'weights_8': 0.8683714580747492, 'weights_9': 0.5275304474972746, 'weights_10': 0.2729755851299773, 'weights_11': 0.8451659992401829, 'weights_12': 0.052174305137289066, 'weights_13': 0.9410088126292515, 'weights_14': 0.07987008347629626, 'weights_15': 0.622647409612262, 'weights_16': 0.015452450002352743, 'weights_17': 0.5035564228066518, 'weights_18': 0.056506144586840765, 'weights_19': 0.41668463381296394}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:26,773] Trial 45 finished with value: 1976.1290397766008 and parameters: {'weights_0': 0.06175706225325461, 'weights_1': 0.0989126818725537, 'weights_2': 0.010551048844080313, 'weights_3': 0.060874684223747456, 'weights_4': 0.39648508415377437, 'weights_5': 0.6752434508377976, 'weights_6': 0.03955779679355869, 'weights_7': 0.7675820122735217, 'weights_8': 0.8824199714463755, 'weights_9': 0.5348108854428282, 'weights_10': 0.2548603945911938, 'weights_11': 0.8376519877145455, 'weights_12': 0.06056884183764143, 'weights_13': 0.9458326435647622, 'weights_14': 0.09009720581142204, 'weights_15': 0.6111250802055487, 'weights_16': 0.009679916289031452, 'weights_17': 0.5165199928036246, 'weights_18': 0.045569589878002414, 'weights_19': 0.5147559321292745}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:26,875] Trial 46 finished with value: 2015.51927139669 and parameters: {'weights_0': 0.07703731022476534, 'weights_1': 0.18178774424719973, 'weights_2': 9.9207723033512e-05, 'weights_3': 0.18522407406602348, 'weights_4': 0.39274219330016663, 'weights_5': 0.45261902861414355, 'weights_6': 0.05237179434938669, 'weights_7': 0.6599128530930738, 'weights_8': 0.9791870607328748, 'weights_9': 0.6141048823077534, 'weights_10': 0.1405577582943269, 'weights_11': 0.9987510555828303, 'weights_12': 0.09149101348016098, 'weights_13': 0.9357422786549561, 'weights_14': 0.09519306036430325, 'weights_15': 0.6041499126945128, 'weights_16': 0.04069036054062972, 'weights_17': 0.5036664798276524, 'weights_18': 0.028748476116399968, 'weights_19': 0.5035019468992972}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:26,993] Trial 47 finished with value: 2278.662693363424 and parameters: {'weights_0': 0.05731297327177099, 'weights_1': 0.28781634119044763, 'weights_2': 0.07208620383880854, 'weights_3': 0.003995117343245258, 'weights_4': 0.3403006306639159, 'weights_5': 0.6045036426587779, 'weights_6': 0.03806115852035551, 'weights_7': 0.7438235875704554, 'weights_8': 0.8406917083445603, 'weights_9': 0.7011901621241055, 'weights_10': 0.2506565221723204, 'weights_11': 0.9243336850584499, 'weights_12': 0.7029530199588236, 'weights_13': 0.2741247213266407, 'weights_14': 0.004651521036420941, 'weights_15': 0.691767377073526, 'weights_16': 0.18477532025841187, 'weights_17': 0.6149791475128785, 'weights_18': 0.10083809146048056, 'weights_19': 0.678861613467691}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,159] Trial 48 finished with value: 2824.8092591419972 and parameters: {'weights_0': 0.8071574678788853, 'weights_1': 0.11212218382320882, 'weights_2': 0.0423569946657035, 'weights_3': 0.09420770182748008, 'weights_4': 0.5265346751087595, 'weights_5': 0.5156889532727993, 'weights_6': 0.0005342660498684482, 'weights_7': 0.6188410555710927, 'weights_8': 0.9669326445920108, 'weights_9': 0.4553677206442228, 'weights_10': 0.4341879673259069, 'weights_11': 0.8835853727931456, 'weights_12': 0.9713711407469288, 'weights_13': 0.95148611434032, 'weights_14': 0.16361678689601536, 'weights_15': 0.5325273024302414, 'weights_16': 0.0038630690560711237, 'weights_17': 0.5514300209257106, 'weights_18': 0.08864102682635386, 'weights_19': 0.375367165807064}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,256] Trial 49 finished with value: 2147.252575072263 and parameters: {'weights_0': 0.0994064379861394, 'weights_1': 0.998812930038685, 'weights_2': 0.12399513186960225, 'weights_3': 0.1600524148705142, 'weights_4': 0.5581593415417476, 'weights_5': 0.3702333531400593, 'weights_6': 0.17553051801717479, 'weights_7': 0.862006339937781, 'weights_8': 0.7937382008022589, 'weights_9': 0.538873023531561, 'weights_10': 0.20224069265086841, 'weights_11': 0.8268733586129586, 'weights_12': 0.21402614485823873, 'weights_13': 0.3886395332240429, 'weights_14': 0.05073366286978359, 'weights_15': 0.6446730695390104, 'weights_16': 0.1006217630083762, 'weights_17': 0.3727277792579156, 'weights_18': 0.003959851570863107, 'weights_19': 0.5300403991377769}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,527] Trial 50 finished with value: 2289.1484215612186 and parameters: {'weights_0': 0.03643142381358355, 'weights_1': 0.181140168634859, 'weights_2': 0.02378903878467664, 'weights_3': 0.047817797072998984, 'weights_4': 0.42198612738436336, 'weights_5': 0.600252153049185, 'weights_6': 0.07541443116588495, 'weights_7': 0.78418464511064, 'weights_8': 0.9078410559636021, 'weights_9': 0.7921783719580057, 'weights_10': 0.9954782503932056, 'weights_11': 0.9370833770699388, 'weights_12': 0.05018820316774746, 'weights_13': 0.16351567536610845, 'weights_14': 0.10526184817138172, 'weights_15': 0.6064551318414353, 'weights_16': 0.05270024313210325, 'weights_17': 0.46565428308661794, 'weights_18': 0.12003859927950283, 'weights_19': 0.5935494175886007}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,631] Trial 51 finished with value: 1998.0529623723041 and parameters: {'weights_0': 0.02984897591019179, 'weights_1': 0.10142855927024474, 'weights_2': 0.11057380865753834, 'weights_3': 0.07818831041040422, 'weights_4': 0.47911800315404485, 'weights_5': 0.6826248837336888, 'weights_6': 0.03705100389271866, 'weights_7': 0.8037370362247682, 'weights_8': 0.8781221566515915, 'weights_9': 0.497018829474368, 'weights_10': 0.2676966271276588, 'weights_11': 0.8287411814932643, 'weights_12': 0.05864195043060325, 'weights_13': 0.9195304162611843, 'weights_14': 0.06419439485001494, 'weights_15': 0.6306878007651029, 'weights_16': 0.005069970170968309, 'weights_17': 0.5125706267366924, 'weights_18': 0.0659325946468586, 'weights_19': 0.40971894048214597}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,723] Trial 52 finished with value: 2099.8458336703416 and parameters: {'weights_0': 0.05254149753985961, 'weights_1': 0.06613500999513768, 'weights_2': 0.10416129141776334, 'weights_3': 0.12682984392987182, 'weights_4': 0.462652964948597, 'weights_5': 0.7314357475284393, 'weights_6': 0.030970235927609273, 'weights_7': 0.7412266916796186, 'weights_8': 0.8305755251626988, 'weights_9': 0.546641698300403, 'weights_10': 0.3378750934185516, 'weights_11': 0.8546217234281858, 'weights_12': 0.12041117280943668, 'weights_13': 0.9763216996661214, 'weights_14': 0.19760838497889177, 'weights_15': 0.6961395763298028, 'weights_16': 0.02964949695358758, 'weights_17': 0.5932161813993997, 'weights_18': 0.05990562172867666, 'weights_19': 0.43248605214503766}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,848] Trial 53 finished with value: 2123.0779148806987 and parameters: {'weights_0': 0.004085405450153984, 'weights_1': 0.08234116959638593, 'weights_2': 0.07035320641741885, 'weights_3': 0.05377394943902753, 'weights_4': 0.38471233831793783, 'weights_5': 0.6836367375380625, 'weights_6': 0.2305326309620086, 'weights_7': 0.6951847311310073, 'weights_8': 0.9971636919741551, 'weights_9': 0.41570009830497656, 'weights_10': 0.1310080638521011, 'weights_11': 0.9060169676771374, 'weights_12': 0.051305358336143136, 'weights_13': 0.9998894750999767, 'weights_14': 0.08054484321275866, 'weights_15': 0.8037178596464554, 'weights_16': 0.08941093555418925, 'weights_17': 0.3984544452530683, 'weights_18': 0.13588558364167388, 'weights_19': 0.3436042977873883}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:27,950] Trial 54 finished with value: 2163.8313949602752 and parameters: {'weights_0': 0.18053648461789787, 'weights_1': 0.15176391914157558, 'weights_2': 0.250397615885511, 'weights_3': 0.002643108276167816, 'weights_4': 0.3474556555578675, 'weights_5': 0.6465595018912311, 'weights_6': 0.07688608256469479, 'weights_7': 0.8333704557848997, 'weights_8': 0.7060355949757379, 'weights_9': 0.6084164224242775, 'weights_10': 0.17574965214951904, 'weights_11': 0.7483075196560217, 'weights_12': 0.2842408248033549, 'weights_13': 0.9428900809923446, 'weights_14': 0.0282011840908767, 'weights_15': 0.5881447314908431, 'weights_16': 0.16083235758831751, 'weights_17': 0.4692472270167809, 'weights_18': 0.05472169000818228, 'weights_19': 0.4969475436968594}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,078] Trial 55 finished with value: 2744.03061568566 and parameters: {'weights_0': 0.106401774706673, 'weights_1': 0.19737011657743703, 'weights_2': 0.11749083775153855, 'weights_3': 0.11779328491067606, 'weights_4': 0.6165460951751872, 'weights_5': 0.4403228905016098, 'weights_6': 0.5129018239921622, 'weights_7': 0.7886927017683972, 'weights_8': 0.9124721427020102, 'weights_9': 0.7364396829598167, 'weights_10': 0.23171327628665292, 'weights_11': 0.8167836631063521, 'weights_12': 0.09748552322260512, 'weights_13': 0.9126210359815573, 'weights_14': 0.13513533041348536, 'weights_15': 0.537189789139232, 'weights_16': 0.5974249069092541, 'weights_17': 0.3131773417924003, 'weights_18': 0.5969141383041736, 'weights_19': 0.3213991444059406}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,237] Trial 56 finished with value: 1986.7049913897918 and parameters: {'weights_0': 0.05356441454564714, 'weights_1': 0.360301021709984, 'weights_2': 0.045116824102587896, 'weights_3': 0.2189096814618265, 'weights_4': 0.4218814431789909, 'weights_5': 0.5376500026635973, 'weights_6': 0.004111108766713181, 'weights_7': 0.8881223463499861, 'weights_8': 0.8628868563341661, 'weights_9': 0.7044668717689206, 'weights_10': 0.29041952019763095, 'weights_11': 0.955028777226093, 'weights_12': 0.03515593898178088, 'weights_13': 0.8171230603760906, 'weights_14': 0.19635232355634813, 'weights_15': 0.44302989371476925, 'weights_16': 0.04445267374067415, 'weights_17': 0.647358251622266, 'weights_18': 0.028161817948990697, 'weights_19': 0.6332776990015399}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,329] Trial 57 finished with value: 2668.2169981839165 and parameters: {'weights_0': 0.9829606231036069, 'weights_1': 0.35216279756232416, 'weights_2': 0.02841557784707257, 'weights_3': 0.2125347236554359, 'weights_4': 0.42130514971069394, 'weights_5': 0.5907199256427036, 'weights_6': 0.002238561209230404, 'weights_7': 0.881720801627184, 'weights_8': 0.9471934731333376, 'weights_9': 0.7095049474653032, 'weights_10': 0.3058544446768167, 'weights_11': 0.9657311290647639, 'weights_12': 0.1439592515670869, 'weights_13': 0.8081222105757087, 'weights_14': 0.18463375542926602, 'weights_15': 0.44460604813345406, 'weights_16': 0.04885223428335436, 'weights_17': 0.6468560291779434, 'weights_18': 0.9395604016485188, 'weights_19': 0.6096563224830753}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,462] Trial 58 finished with value: 2585.318317594583 and parameters: {'weights_0': 0.12373420940651525, 'weights_1': 0.4444667193077154, 'weights_2': 0.04367009533798834, 'weights_3': 0.23985466431852978, 'weights_4': 0.3212250496316329, 'weights_5': 0.5259911651340081, 'weights_6': 0.11340353423779104, 'weights_7': 0.38256262090608617, 'weights_8': 0.2110751352066473, 'weights_9': 0.7718013995100035, 'weights_10': 0.19542201254366315, 'weights_11': 0.9549486725486847, 'weights_12': 0.21786718358855794, 'weights_13': 0.8671585080725216, 'weights_14': 0.23900879033886713, 'weights_15': 0.3764564583510859, 'weights_16': 0.9883663250694313, 'weights_17': 0.571338432610743, 'weights_18': 0.03291824949790671, 'weights_19': 0.6329794571839693}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,561] Trial 59 finished with value: 2245.4062659718256 and parameters: {'weights_0': 0.16376683202196696, 'weights_1': 0.6846539730284407, 'weights_2': 0.0029033685886593885, 'weights_3': 0.13371429660575102, 'weights_4': 0.2589970041998083, 'weights_5': 0.4275735623251427, 'weights_6': 0.7078038705541745, 'weights_7': 0.7115743559463372, 'weights_8': 0.753747511581918, 'weights_9': 0.7009280611833522, 'weights_10': 0.11692535948110505, 'weights_11': 0.8945107269686732, 'weights_12': 0.03203987741164964, 'weights_13': 0.8223625154803503, 'weights_14': 0.12449816452708362, 'weights_15': 0.33882208230866057, 'weights_16': 0.1258780466785996, 'weights_17': 0.5288549909190099, 'weights_18': 0.10106040683055223, 'weights_19': 0.7254857169554851}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,677] Trial 60 finished with value: 2152.8738278276737 and parameters: {'weights_0': 0.06710332276308106, 'weights_1': 0.3130672062636015, 'weights_2': 0.07861018297897732, 'weights_3': 0.20712330327787654, 'weights_4': 0.5291537574542465, 'weights_5': 0.7410297033099007, 'weights_6': 0.1549359274118807, 'weights_7': 0.5384531671383764, 'weights_8': 0.0981417940981204, 'weights_9': 0.7998126730705765, 'weights_10': 0.5067646815289486, 'weights_11': 0.8020499944331514, 'weights_12': 0.0932218908533695, 'weights_13': 0.5027552838784899, 'weights_14': 0.03580824321044339, 'weights_15': 0.28256880369732873, 'weights_16': 0.06708200142821832, 'weights_17': 0.44351071792589725, 'weights_18': 0.31716155250797196, 'weights_19': 0.7565195624521754}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,793] Trial 61 finished with value: 1987.0859082880302 and parameters: {'weights_0': 0.023893878293543436, 'weights_1': 0.056134536338124735, 'weights_2': 0.11760221161931787, 'weights_3': 0.07896082456109729, 'weights_4': 0.4844664865880251, 'weights_5': 0.6235179974742007, 'weights_6': 0.02839461209481886, 'weights_7': 0.8943654050977665, 'weights_8': 0.8800480976217664, 'weights_9': 0.6321139775630161, 'weights_10': 0.38082443644560837, 'weights_11': 0.8671728585442189, 'weights_12': 0.03943085051965664, 'weights_13': 0.9619247362529374, 'weights_14': 0.07972328446826793, 'weights_15': 0.667764586723564, 'weights_16': 0.030786352514527566, 'weights_17': 0.6178954033430353, 'weights_18': 0.02293970432330965, 'weights_19': 0.4435221132582715}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:28,901] Trial 62 finished with value: 2134.1598402165664 and parameters: {'weights_0': 0.001088642356748687, 'weights_1': 0.04564847833723734, 'weights_2': 0.13059956075879578, 'weights_3': 0.030010397197138765, 'weights_4': 0.37061199067780043, 'weights_5': 0.267939972639728, 'weights_6': 0.09642648096576031, 'weights_7': 0.8772186881348726, 'weights_8': 0.8223357902165116, 'weights_9': 0.6075813215676755, 'weights_10': 0.3855812335148043, 'weights_11': 0.8644357429758959, 'weights_12': 0.030936327606687387, 'weights_13': 0.9576602937910442, 'weights_14': 0.16481265341222912, 'weights_15': 0.7057287870272098, 'weights_16': 0.1096637436036737, 'weights_17': 0.6145367784647375, 'weights_18': 0.146779349495969, 'weights_19': 0.5536754981846789}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,013] Trial 63 finished with value: 2479.262213812306 and parameters: {'weights_0': 0.07324279438706745, 'weights_1': 0.5305302467457362, 'weights_2': 0.22111871054076904, 'weights_3': 0.15285000611437044, 'weights_4': 0.451338117061143, 'weights_5': 0.55282903398683, 'weights_6': 0.05337380187938334, 'weights_7': 0.9115087039807646, 'weights_8': 0.7856314489949592, 'weights_9': 0.6321719545387581, 'weights_10': 0.4197229042953213, 'weights_11': 0.9659148155811161, 'weights_12': 0.08153549050962358, 'weights_13': 0.9065523106882407, 'weights_14': 0.21734322500126518, 'weights_15': 0.7862578515436994, 'weights_16': 0.8801668429180208, 'weights_17': 0.6801865345746194, 'weights_18': 0.02282589907339333, 'weights_19': 0.37341824549064684}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,092] Trial 64 finished with value: 2169.967021589801 and parameters: {'weights_0': 0.11953740337256563, 'weights_1': 0.14968648782042474, 'weights_2': 0.183399115278878, 'weights_3': 0.09560711497788686, 'weights_4': 0.4022572896502633, 'weights_5': 0.6205086367833754, 'weights_6': 0.033510586404035446, 'weights_7': 0.7554261359137608, 'weights_8': 0.8808925938142348, 'weights_9': 0.5674304384513731, 'weights_10': 0.3483288822217963, 'weights_11': 0.9048569579138028, 'weights_12': 0.029113450314802832, 'weights_13': 0.901050549311406, 'weights_14': 0.11216525671059221, 'weights_15': 0.5212453173670953, 'weights_16': 0.037288946038907096, 'weights_17': 0.6375383395242268, 'weights_18': 0.22801722149432008, 'weights_19': 0.4630352701133713}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,207] Trial 65 finished with value: 2176.9421420195195 and parameters: {'weights_0': 0.21763973708414314, 'weights_1': 0.044927987549552635, 'weights_2': 0.5607682041867239, 'weights_3': 0.03623714043886545, 'weights_4': 0.591424187060868, 'weights_5': 0.48397318867844646, 'weights_6': 0.0948113489809144, 'weights_7': 0.8307608833988024, 'weights_8': 0.9505629989230922, 'weights_9': 0.6846620159570921, 'weights_10': 0.05386444317063942, 'weights_11': 0.7752385939566443, 'weights_12': 0.10671031592552206, 'weights_13': 0.8643283573555638, 'weights_14': 5.710921147825121e-05, 'weights_15': 0.6528207937953207, 'weights_16': 0.004612843375009331, 'weights_17': 0.5837504746217259, 'weights_18': 0.10996197529300501, 'weights_19': 0.30518818262801517}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,303] Trial 66 finished with value: 2288.391639544102 and parameters: {'weights_0': 0.03631313367377234, 'weights_1': 0.20989687698571075, 'weights_2': 0.08716947315507989, 'weights_3': 0.1991248617769964, 'weights_4': 0.36167882962609016, 'weights_5': 0.7069513823905462, 'weights_6': 0.0014254807181181203, 'weights_7': 0.010042753181062292, 'weights_8': 0.20140761011313452, 'weights_9': 0.5852020327525345, 'weights_10': 0.4769767542581733, 'weights_11': 0.7352072497325091, 'weights_12': 0.0075207821373375755, 'weights_13': 0.9682690846982445, 'weights_14': 0.04748963644369461, 'weights_15': 0.58029715864063, 'weights_16': 0.13469962337656716, 'weights_17': 0.0017398964607119316, 'weights_18': 0.08480171144294534, 'weights_19': 0.22704909385545158}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,415] Trial 67 finished with value: 2090.298894058663 and parameters: {'weights_0': 0.13738928064132627, 'weights_1': 0.11324327398880552, 'weights_2': 0.1452532439520539, 'weights_3': 0.09728154595129151, 'weights_4': 0.4388279635554925, 'weights_5': 0.8238187888674898, 'weights_6': 0.13601526195542518, 'weights_7': 0.7715436909470652, 'weights_8': 0.2797624289142103, 'weights_9': 0.7488210797049888, 'weights_10': 0.2266606533197844, 'weights_11': 0.05936317999161589, 'weights_12': 0.14827515821395454, 'weights_13': 0.7802763887180646, 'weights_14': 0.13437884743386158, 'weights_15': 0.4836336728880337, 'weights_16': 0.07021403375419094, 'weights_17': 0.5366995260206076, 'weights_18': 0.024784779234219963, 'weights_19': 0.6719613189642354}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,504] Trial 68 finished with value: 2433.184456568934 and parameters: {'weights_0': 0.0887671634976534, 'weights_1': 0.6033350158447548, 'weights_2': 0.7321419080002091, 'weights_3': 0.1484600562794681, 'weights_4': 0.509312613197447, 'weights_5': 0.04147517090659458, 'weights_6': 0.20112460777730162, 'weights_7': 0.95264733770245, 'weights_8': 0.9213828891376935, 'weights_9': 0.7318397495953186, 'weights_10': 0.2825726733625031, 'weights_11': 0.8410521355123677, 'weights_12': 0.19581654943549406, 'weights_13': 0.8781483576172142, 'weights_14': 0.2800902747221753, 'weights_15': 0.718152947035314, 'weights_16': 0.17336976434996837, 'weights_17': 0.4867627265709712, 'weights_18': 0.15153516860227634, 'weights_19': 0.8126622969778068}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,580] Trial 69 finished with value: 2461.5116519067806 and parameters: {'weights_0': 0.1878676858472823, 'weights_1': 0.4457799011780171, 'weights_2': 0.27533158307795613, 'weights_3': 0.26183827114305563, 'weights_4': 0.30681435040310445, 'weights_5': 0.6407777931030687, 'weights_6': 0.060450795826708564, 'weights_7': 0.8482716239297678, 'weights_8': 0.7033373912601975, 'weights_9': 0.6372838017090566, 'weights_10': 0.16061290307760756, 'weights_11': 0.706484416917766, 'weights_12': 0.4309642088367117, 'weights_13': 0.6782030865501267, 'weights_14': 0.17603882544837335, 'weights_15': 0.6749842042362929, 'weights_16': 0.038025208502436285, 'weights_17': 0.7110029119328497, 'weights_18': 0.6442003947962416, 'weights_19': 0.5179219878622103}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,700] Trial 70 finished with value: 2188.501961823555 and parameters: {'weights_0': 0.03590660116521148, 'weights_1': 0.03179473260709029, 'weights_2': 0.038368493798958236, 'weights_3': 0.07387247477288085, 'weights_4': 0.738448191678761, 'weights_5': 0.8575280506714582, 'weights_6': 0.09323694827194624, 'weights_7': 0.8912062823170038, 'weights_8': 0.307649680866583, 'weights_9': 0.7996481849194137, 'weights_10': 0.9384465026636437, 'weights_11': 0.6212571435487009, 'weights_12': 0.0002755955670650165, 'weights_13': 0.015812372107243178, 'weights_14': 0.07758366925906819, 'weights_15': 0.7657067610998667, 'weights_16': 0.10220388945099253, 'weights_17': 0.6125156114807057, 'weights_18': 0.1936510468920449, 'weights_19': 0.439560496599949}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,798] Trial 71 finished with value: 1960.263114827356 and parameters: {'weights_0': 0.026637321201313888, 'weights_1': 0.08803841687206257, 'weights_2': 0.11454316108242833, 'weights_3': 0.059026184856092206, 'weights_4': 0.48627938765044726, 'weights_5': 0.688436788781307, 'weights_6': 0.029110449322083065, 'weights_7': 0.8097349658103343, 'weights_8': 0.8706165891109322, 'weights_9': 0.5124523480850041, 'weights_10': 0.2660991564993145, 'weights_11': 0.8614599458631144, 'weights_12': 0.04063155309531356, 'weights_13': 0.9363117681218411, 'weights_14': 0.08369284222117832, 'weights_15': 0.6261555956213543, 'weights_16': 0.024038420154634366, 'weights_17': 0.42009431038789213, 'weights_18': 0.001290108800873442, 'weights_19': 0.41905146173538}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:29,882] Trial 72 finished with value: 2089.7810777066184 and parameters: {'weights_0': 0.06384522411828722, 'weights_1': 0.09872373548795653, 'weights_2': 0.18299153770374027, 'weights_3': 0.026658726808859376, 'weights_4': 0.5589182246223564, 'weights_5': 0.7517251476088233, 'weights_6': 0.024990379928574707, 'weights_7': 0.8277376849985514, 'weights_8': 0.8608302574689404, 'weights_9': 0.4898908064977273, 'weights_10': 0.3168090693675237, 'weights_11': 0.8095520005835043, 'weights_12': 0.07690726494422291, 'weights_13': 0.930790099240831, 'weights_14': 0.14481187396879636, 'weights_15': 0.6685887313429194, 'weights_16': 0.07172536905981228, 'weights_17': 0.41194857342472774, 'weights_18': 0.031756535214000826, 'weights_19': 0.3598847991851143}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,009] Trial 73 finished with value: 2121.852109371862 and parameters: {'weights_0': 0.09889278827453335, 'weights_1': 0.14908772713597612, 'weights_2': 0.14009170175461874, 'weights_3': 0.10760381506336567, 'weights_4': 0.4143081729235165, 'weights_5': 0.7040903102177466, 'weights_6': 0.06654271882164245, 'weights_7': 0.7326807520579645, 'weights_8': 0.8966136240263703, 'weights_9': 0.41275118896325075, 'weights_10': 0.3993295865115034, 'weights_11': 0.8788360557100168, 'weights_12': 0.03174914796581169, 'weights_13': 0.9733525533320487, 'weights_14': 0.104428294768226, 'weights_15': 0.5675043063598064, 'weights_16': 6.04159799272308e-07, 'weights_17': 0.4481134175411464, 'weights_18': 0.07977430514822825, 'weights_19': 0.4839583831293052}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,134] Trial 74 finished with value: 2130.481047944625 and parameters: {'weights_0': 0.0228482749248873, 'weights_1': 0.026196586201809126, 'weights_2': 0.0573669190816848, 'weights_3': 0.17545705903279424, 'weights_4': 0.47915624214910696, 'weights_5': 0.6722968339129565, 'weights_6': 0.11179940220456078, 'weights_7': 0.9237920572358348, 'weights_8': 0.8050844296867863, 'weights_9': 0.5123586973417517, 'weights_10': 0.10258837453328698, 'weights_11': 0.9388829104215721, 'weights_12': 0.6242453765107859, 'weights_13': 0.8583845617869293, 'weights_14': 0.2276712160746635, 'weights_15': 0.8484406332272258, 'weights_16': 0.03137078917678719, 'weights_17': 0.561739490341434, 'weights_18': 0.009561955287049095, 'weights_19': 0.5550936491221394}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,253] Trial 75 finished with value: 2148.0392055859074 and parameters: {'weights_0': 0.1547846680356963, 'weights_1': 0.8445537896457675, 'weights_2': 0.09375332569415383, 'weights_3': 0.13487948797570815, 'weights_4': 0.34983164761933266, 'weights_5': 0.7859217980154115, 'weights_6': 0.14645417530559088, 'weights_7': 0.8597673419922713, 'weights_8': 0.9446002074816301, 'weights_9': 0.6724100651818058, 'weights_10': 0.1389180736254587, 'weights_11': 0.9120789856775086, 'weights_12': 0.14758907522550752, 'weights_13': 0.9161055673292913, 'weights_14': 0.03224134694392686, 'weights_15': 0.6250260383321561, 'weights_16': 0.20414284637286748, 'weights_17': 0.4804596891986767, 'weights_18': 0.049474914398248394, 'weights_19': 0.3005877465094484}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,365] Trial 76 finished with value: 2271.9235600940447 and parameters: {'weights_0': 0.0678619269849481, 'weights_1': 0.06532640057195724, 'weights_2': 0.9185557211656359, 'weights_3': 0.06337954468562595, 'weights_4': 0.5043780205320031, 'weights_5': 0.9072149828454115, 'weights_6': 0.022437768333145435, 'weights_7': 0.799151933298258, 'weights_8': 0.8536787116297045, 'weights_9': 0.8449403858636936, 'weights_10': 0.2496923963782663, 'weights_11': 0.7542852729614826, 'weights_12': 0.10584219721324342, 'weights_13': 0.9629584129503659, 'weights_14': 0.07971847146861288, 'weights_15': 0.45844853721915413, 'weights_16': 0.13668840279712868, 'weights_17': 0.5251780116183983, 'weights_18': 0.11777154389362307, 'weights_19': 0.3963331351453735}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,481] Trial 77 finished with value: 2049.1128139216667 and parameters: {'weights_0': 0.001074758186808869, 'weights_1': 0.2780096309258845, 'weights_2': 0.017499920785979034, 'weights_3': 0.017275715988362937, 'weights_4': 0.4419111755424505, 'weights_5': 0.8185248235355104, 'weights_6': 0.17594046253961443, 'weights_7': 0.958249476146467, 'weights_8': 0.17465668026495856, 'weights_9': 0.5820446359255897, 'weights_10': 0.047066619273973556, 'weights_11': 0.9740985405339437, 'weights_12': 0.06935611068348928, 'weights_13': 0.8216846376408834, 'weights_14': 0.1964801223845185, 'weights_15': 0.7279299607046431, 'weights_16': 0.5287915255555671, 'weights_17': 0.3523967880259771, 'weights_18': 0.1714456439770297, 'weights_19': 0.44013839864671034}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,594] Trial 78 finished with value: 2130.279416720451 and parameters: {'weights_0': 0.1059340730076372, 'weights_1': 0.24873489855722755, 'weights_2': 0.6344283689562462, 'weights_3': 0.313115829681311, 'weights_4': 0.6313724648356027, 'weights_5': 0.5738220339207849, 'weights_6': 0.05237334908161207, 'weights_7': 0.9035512358634559, 'weights_8': 0.23210238348029755, 'weights_9': 0.4627892194340146, 'weights_10': 0.18514988436337776, 'weights_11': 0.8663226795154305, 'weights_12': 0.03645313076471539, 'weights_13': 0.9912440588001129, 'weights_14': 0.05471983764427303, 'weights_15': 0.5083201268654587, 'weights_16': 0.08544525665886321, 'weights_17': 0.6722679793051545, 'weights_18': 0.24354265898575178, 'weights_19': 0.3431764970333715}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,744] Trial 79 finished with value: 2775.041517877192 and parameters: {'weights_0': 0.7142984568972015, 'weights_1': 0.1680329099611103, 'weights_2': 0.23475685349904996, 'weights_3': 0.22740710935750783, 'weights_4': 0.27477791086746656, 'weights_5': 0.6353678336581432, 'weights_6': 0.7964345761784355, 'weights_7': 0.6841019680832534, 'weights_8': 0.6485507084326698, 'weights_9': 0.6408597678372052, 'weights_10': 0.35939775530741125, 'weights_11': 0.7875968860231854, 'weights_12': 0.15782342158448875, 'weights_13': 0.890012598093402, 'weights_14': 0.2610615756882596, 'weights_15': 0.049364443129449986, 'weights_16': 0.05892445352019331, 'weights_17': 0.4230110483197489, 'weights_18': 0.08467316290931798, 'weights_19': 0.24584046191199713}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,812] Trial 80 finished with value: 2122.1591962371613 and parameters: {'weights_0': 0.05138869521025788, 'weights_1': 0.12057250883936599, 'weights_2': 0.20057436487626923, 'weights_3': 0.08289510936558767, 'weights_4': 0.3760849893206752, 'weights_5': 0.5353993803417652, 'weights_6': 0.2488732709537061, 'weights_7': 0.963061623117044, 'weights_8': 0.7445767650587881, 'weights_9': 0.32231678774439787, 'weights_10': 0.2873758789712736, 'weights_11': 0.8320324836090972, 'weights_12': 0.07479277262436924, 'weights_13': 0.9295162725042303, 'weights_14': 0.15677355781644245, 'weights_15': 0.5911392085709717, 'weights_16': 0.030132009132240123, 'weights_17': 0.1882677610459681, 'weights_18': 0.006149929515315428, 'weights_19': 0.2818773603490245}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:30,925] Trial 81 finished with value: 1965.8686303755692 and parameters: {'weights_0': 0.02399091861892628, 'weights_1': 0.08429344685323567, 'weights_2': 0.1127018901536665, 'weights_3': 0.057813030251353745, 'weights_4': 0.49483623740076627, 'weights_5': 0.6970408728471807, 'weights_6': 0.023011338954175384, 'weights_7': 0.8104352863755743, 'weights_8': 0.8773466076735079, 'weights_9': 0.5423360856621425, 'weights_10': 0.22205898430518434, 'weights_11': 0.8423941484504044, 'weights_12': 0.037886515067782435, 'weights_13': 0.9493179677590133, 'weights_14': 0.09774056300475292, 'weights_15': 0.6153502814641657, 'weights_16': 0.017026352087049303, 'weights_17': 0.5831614762425877, 'weights_18': 0.04760669591843418, 'weights_19': 0.4142430236826571}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,017] Trial 82 finished with value: 2041.2855455187744 and parameters: {'weights_0': 0.08423873523546388, 'weights_1': 0.0896184005594922, 'weights_2': 0.1615937575305604, 'weights_3': 0.051466663801146006, 'weights_4': 0.4001113623421897, 'weights_5': 0.7227615645687316, 'weights_6': 0.08392337397324176, 'weights_7': 0.7708140210708352, 'weights_8': 0.9842680847236331, 'weights_9': 0.562617284213804, 'weights_10': 0.21962989091813548, 'weights_11': 0.8935024685116949, 'weights_12': 0.02743617941076948, 'weights_13': 0.9628563763769235, 'weights_14': 0.10533690955706586, 'weights_15': 0.6622784661026151, 'weights_16': 0.024145331182196396, 'weights_17': 0.5949351178817408, 'weights_18': 0.03967203880733403, 'weights_19': 0.41894900368581534}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,151] Trial 83 finished with value: 2020.7774521693555 and parameters: {'weights_0': 0.023088379076033477, 'weights_1': 0.02119765591917641, 'weights_2': 0.057199756203233025, 'weights_3': 0.11087195978500018, 'weights_4': 0.4628261669535113, 'weights_5': 0.6119012013438828, 'weights_6': 0.023584327958683877, 'weights_7': 0.8246707424775471, 'weights_8': 0.8897185802039979, 'weights_9': 0.5236517854751477, 'weights_10': 0.14784310371408793, 'weights_11': 0.8602644992480271, 'weights_12': 0.11423345740551988, 'weights_13': 0.897537526570116, 'weights_14': 0.017077706915159585, 'weights_15': 0.5448910769815531, 'weights_16': 0.1108368755942014, 'weights_17': 0.6422814715704334, 'weights_18': 0.14377992875040585, 'weights_19': 0.38784411864968593}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,289] Trial 84 finished with value: 2032.0970581293197 and parameters: {'weights_0': 0.1305497642991248, 'weights_1': 0.06655107016907152, 'weights_2': 0.09896690161018118, 'weights_3': 0.16297607108495926, 'weights_4': 0.5745836843684842, 'weights_5': 0.7506401436452724, 'weights_6': 0.056283301004663264, 'weights_7': 0.8641271600146975, 'weights_8': 0.932071034106233, 'weights_9': 0.5981859255879035, 'weights_10': 0.2076162879733592, 'weights_11': 0.809420417825309, 'weights_12': 0.05761739229759648, 'weights_13': 0.8459687322953117, 'weights_14': 0.07183750781509166, 'weights_15': 0.6353510802415409, 'weights_16': 0.059575813175496296, 'weights_17': 0.5512917339351227, 'weights_18': 0.059575875596417194, 'weights_19': 0.3602589836650765}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,433] Trial 85 finished with value: 2292.163900231749 and parameters: {'weights_0': 0.04247276048957881, 'weights_1': 0.12442523242236384, 'weights_2': 0.13369905906834734, 'weights_3': 0.04904122003463015, 'weights_4': 0.5315268049591652, 'weights_5': 0.6620793347247188, 'weights_6': 0.1279057388024991, 'weights_7': 0.2559792188186989, 'weights_8': 0.8183461947403844, 'weights_9': 0.7683663708485302, 'weights_10': 0.31541652131764575, 'weights_11': 0.9350783822472774, 'weights_12': 0.2563390522454458, 'weights_13': 0.9348943793686563, 'weights_14': 0.1242462467593726, 'weights_15': 0.7579769816427846, 'weights_16': 0.08433672195945632, 'weights_17': 0.5052990369504216, 'weights_18': 0.10242170840247211, 'weights_19': 0.32633961355238233}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,522] Trial 86 finished with value: 2346.9365387014177 and parameters: {'weights_0': 0.08738924731779277, 'weights_1': 0.1696307606423182, 'weights_2': 0.07677460109972367, 'weights_3': 0.0012222365755188008, 'weights_4': 0.32336636686963144, 'weights_5': 0.7711460295567385, 'weights_6': 0.3175741498842405, 'weights_7': 0.8871391327613998, 'weights_8': 0.8469645417708921, 'weights_9': 0.4251161051227889, 'weights_10': 0.17406888368869344, 'weights_11': 0.9968439963205294, 'weights_12': 0.1250771141559296, 'weights_13': 0.9941975677659227, 'weights_14': 0.09813089119473442, 'weights_15': 0.6953319980407, 'weights_16': 0.0012644363130140494, 'weights_17': 0.5797560639167072, 'weights_18': 0.8161127482713331, 'weights_19': 0.45741886200783355}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,648] Trial 87 finished with value: 2033.743405403185 and parameters: {'weights_0': 0.023189574805231095, 'weights_1': 0.04450731869326268, 'weights_2': 0.1247224375555135, 'weights_3': 0.07650175893031391, 'weights_4': 0.4239676319108144, 'weights_5': 0.7105102712896076, 'weights_6': 0.04482534336279256, 'weights_7': 0.8029788221175804, 'weights_8': 0.7829251150693681, 'weights_9': 0.7012417858938113, 'weights_10': 0.2538963508407207, 'weights_11': 0.7628010573615206, 'weights_12': 0.19253823864162467, 'weights_13': 0.8834583067629602, 'weights_14': 0.17918061731721616, 'weights_15': 0.6187770661656017, 'weights_16': 0.05010430376750631, 'weights_17': 0.4604672921191094, 'weights_18': 0.00343541095756595, 'weights_19': 0.5277027790528321}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,744] Trial 88 finished with value: 1905.1153062074375 and parameters: {'weights_0': 0.05792441691695979, 'weights_1': 0.09612140038734408, 'weights_2': 0.018773770759357183, 'weights_3': 0.1334393487862596, 'weights_4': 0.47965010571953015, 'weights_5': 0.5788353568138506, 'weights_6': 0.012775560001136988, 'weights_7': 0.7268364327072432, 'weights_8': 0.35794473582907954, 'weights_9': 0.5500571894340747, 'weights_10': 0.12312576037435527, 'weights_11': 0.7210866645121204, 'weights_12': 0.08647480467842585, 'weights_13': 0.6096512753080325, 'weights_14': 0.1416148150545395, 'weights_15': 0.735342408410646, 'weights_16': 0.1426486083313766, 'weights_17': 0.3927824616343535, 'weights_18': 0.06558804708303761, 'weights_19': 0.5772054616722179}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,840] Trial 89 finished with value: 1995.2528473099062 and parameters: {'weights_0': 0.1695751045916945, 'weights_1': 0.13895735463812553, 'weights_2': 0.01934218833644756, 'weights_3': 0.18648153440565077, 'weights_4': 0.36390285340124057, 'weights_5': 0.47835014821064437, 'weights_6': 0.005566161115738898, 'weights_7': 0.7150300604296516, 'weights_8': 0.26617789509724676, 'weights_9': 0.8946882662369261, 'weights_10': 0.12437169495830175, 'weights_11': 0.6868093914282003, 'weights_12': 0.002930903580029516, 'weights_13': 0.5327854078671518, 'weights_14': 0.15206461442997876, 'weights_15': 0.4057590371930096, 'weights_16': 0.1500210335930129, 'weights_17': 0.37807648976990693, 'weights_18': 0.2950510551475569, 'weights_19': 0.6187723721064984}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:31,926] Trial 90 finished with value: 1996.4023117057243 and parameters: {'weights_0': 0.12342261180623262, 'weights_1': 0.09814782543144043, 'weights_2': 0.05573836000288062, 'weights_3': 0.13447068408446947, 'weights_4': 0.4488708196890061, 'weights_5': 0.5843014995637449, 'weights_6': 0.10198927098767549, 'weights_7': 0.6224142534787193, 'weights_8': 0.43576026213611074, 'weights_9': 0.47445096246909524, 'weights_10': 0.10647044526221129, 'weights_11': 0.8451748429106005, 'weights_12': 0.07174053786385727, 'weights_13': 0.44446116924668333, 'weights_14': 0.20840614095668, 'weights_15': 0.7365153714252458, 'weights_16': 0.11308547446130922, 'weights_17': 0.30635439391450325, 'weights_18': 0.07286666790084464, 'weights_19': 0.5630690310473185}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,022] Trial 91 finished with value: 1846.88927932037 and parameters: {'weights_0': 0.0495602951345589, 'weights_1': 0.0823133282849128, 'weights_2': 0.0952865584938776, 'weights_3': 0.10659057725787992, 'weights_4': 0.5075044472988258, 'weights_5': 0.5486812836947148, 'weights_6': 0.06956625175387311, 'weights_7': 0.7698316565058752, 'weights_8': 0.23125704811417985, 'weights_9': 0.5379346783775698, 'weights_10': 0.1594031097572691, 'weights_11': 0.7228315624515114, 'weights_12': 0.04180935374382798, 'weights_13': 0.6102838284664661, 'weights_14': 0.05925930182160757, 'weights_15': 0.6754902191364002, 'weights_16': 0.028020358109316055, 'weights_17': 0.40109132032269335, 'weights_18': 0.12420164207639546, 'weights_19': 0.49950471189145174}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,148] Trial 92 finished with value: 1851.5864955728907 and parameters: {'weights_0': 0.054607472849398375, 'weights_1': 0.08524395742246907, 'weights_2': 0.0006046506896592724, 'weights_3': 0.11266946427015491, 'weights_4': 0.5175648437958289, 'weights_5': 0.5464072514528564, 'weights_6': 0.07223943833311874, 'weights_7': 0.7595338152508339, 'weights_8': 0.3680734840044754, 'weights_9': 0.3738212437767512, 'weights_10': 0.08140193612208607, 'weights_11': 0.6402269465399424, 'weights_12': 0.09835123311336513, 'weights_13': 0.71077989746575, 'weights_14': 0.039349799807170405, 'weights_15': 0.7757203267467001, 'weights_16': 0.021467645115553425, 'weights_17': 0.408007742969416, 'weights_18': 0.12718397739191892, 'weights_19': 0.6627842487082867}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,239] Trial 93 finished with value: 1861.1206364047882 and parameters: {'weights_0': 0.06792252205487288, 'weights_1': 0.08885756187542648, 'weights_2': 0.014030926130451774, 'weights_3': 0.11038118937329935, 'weights_4': 0.5456072584958793, 'weights_5': 0.8011085587139063, 'weights_6': 0.07700935678448459, 'weights_7': 0.7624279860876951, 'weights_8': 0.30985629291098193, 'weights_9': 0.376304700164579, 'weights_10': 0.06438938273244546, 'weights_11': 0.6488029315523524, 'weights_12': 0.09006995092161929, 'weights_13': 0.6020619693174081, 'weights_14': 0.05092516868293182, 'weights_15': 0.8301348024138195, 'weights_16': 0.02029867836561198, 'weights_17': 0.3941217281419567, 'weights_18': 0.2145284826828476, 'weights_19': 0.671246484115502}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,380] Trial 94 finished with value: 1946.1847367696364 and parameters: {'weights_0': 0.09824003998580098, 'weights_1': 0.0007631573200827663, 'weights_2': 0.08479137397084892, 'weights_3': 0.11251606297591205, 'weights_4': 0.5531787268039998, 'weights_5': 0.8034128016038993, 'weights_6': 0.06655539972259733, 'weights_7': 0.7320400223888673, 'weights_8': 0.36323834554500056, 'weights_9': 0.17852098008846248, 'weights_10': 0.0621004252091891, 'weights_11': 0.6351012909093157, 'weights_12': 0.09600768559743489, 'weights_13': 0.5971359519624363, 'weights_14': 0.029989995086583766, 'weights_15': 0.8398602713465786, 'weights_16': 0.08374877061292643, 'weights_17': 0.33565618956657567, 'weights_18': 0.21923069616535643, 'weights_19': 0.6663900047421201}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,480] Trial 95 finished with value: 1940.7751636243233 and parameters: {'weights_0': 0.10863106690352375, 'weights_1': 0.01509561628746399, 'weights_2': 5.6460929692706e-05, 'weights_3': 0.113129469941417, 'weights_4': 0.589487365712924, 'weights_5': 0.8389559752227869, 'weights_6': 0.07368233972339705, 'weights_7': 0.6480541807440792, 'weights_8': 0.36279751881957156, 'weights_9': 0.19166133300043522, 'weights_10': 0.04103089076897452, 'weights_11': 0.6305280407920054, 'weights_12': 0.09941801366098624, 'weights_13': 0.6242339856162856, 'weights_14': 0.024421191551471738, 'weights_15': 0.9019767680315932, 'weights_16': 0.08165461445657049, 'weights_17': 0.25739525817361436, 'weights_18': 0.2310904115734539, 'weights_19': 0.6695958593083648}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,582] Trial 96 finished with value: 1994.2908254108454 and parameters: {'weights_0': 0.10486160402263822, 'weights_1': 0.004259546977788797, 'weights_2': 0.0287538784818094, 'weights_3': 0.10955638586986607, 'weights_4': 0.6393273253081055, 'weights_5': 0.8673389956118183, 'weights_6': 0.0795886245860101, 'weights_7': 0.6376156389701442, 'weights_8': 0.36227968202201133, 'weights_9': 0.18101837233385346, 'weights_10': 0.055673994053560466, 'weights_11': 0.5344539213212043, 'weights_12': 0.1664429610404326, 'weights_13': 0.6070919273631089, 'weights_14': 0.022879010464779463, 'weights_15': 0.8964715942059407, 'weights_16': 0.07749082977612276, 'weights_17': 0.2650064249044075, 'weights_18': 0.21833762289226938, 'weights_19': 0.6982751231768103}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,695] Trial 97 finished with value: 1987.253881299462 and parameters: {'weights_0': 0.1407946242102489, 'weights_1': 0.022803672020402063, 'weights_2': 0.003262701297873677, 'weights_3': 0.14358387554900032, 'weights_4': 0.5476511505961438, 'weights_5': 0.8370261776382376, 'weights_6': 0.16966017081870116, 'weights_7': 0.7307045476761651, 'weights_8': 0.3119464744882984, 'weights_9': 0.17650472693228475, 'weights_10': 0.02987347806134715, 'weights_11': 0.6327295528556529, 'weights_12': 0.09448583319772606, 'weights_13': 0.6543781623516911, 'weights_14': 0.05230341800339179, 'weights_15': 0.9516223280804877, 'weights_16': 0.09508527770369696, 'weights_17': 0.3556980760441036, 'weights_18': 0.27216509617118667, 'weights_19': 0.733815665601318}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,788] Trial 98 finished with value: 2195.6662018849042 and parameters: {'weights_0': 0.21745883566860347, 'weights_1': 0.039987670045302064, 'weights_2': 0.07018406546166031, 'weights_3': 0.17160377414272024, 'weights_4': 0.5905374149525838, 'weights_5': 0.8017762412566847, 'weights_6': 0.126233953137926, 'weights_7': 0.5843921731447148, 'weights_8': 0.3809405619790753, 'weights_9': 0.2400647078448227, 'weights_10': 0.09485526620318231, 'weights_11': 0.5871868456911814, 'weights_12': 0.13206202319957894, 'weights_13': 0.579595121995135, 'weights_14': 0.03028648211777855, 'weights_15': 0.8468074005068119, 'weights_16': 0.2803020522973656, 'weights_17': 0.32059400259218374, 'weights_18': 0.21245883417638975, 'weights_19': 0.6683803346670639}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:32,882] Trial 99 finished with value: 2299.08867618571 and parameters: {'weights_0': 0.08092682211592092, 'weights_1': 0.13356882135122816, 'weights_2': 0.03260853984621833, 'weights_3': 0.12127501910380264, 'weights_4': 0.6496724221589114, 'weights_5': 0.8061607567424091, 'weights_6': 0.07227321868730846, 'weights_7': 0.6772545111243694, 'weights_8': 0.43425940316716705, 'weights_9': 0.35474635413153555, 'weights_10': 0.0019321328054832249, 'weights_11': 0.5529937729589091, 'weights_12': 0.9052831287750265, 'weights_13': 0.5573590007456033, 'weights_14': 0.010315279351444061, 'weights_15': 0.9194026898693608, 'weights_16': 0.13907831992030364, 'weights_17': 0.39939468956313273, 'weights_18': 0.17457502650011536, 'weights_19': 0.653947111074461}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,013] Trial 100 finished with value: 2104.8150612477184 and parameters: {'weights_0': 0.11331047219089678, 'weights_1': 0.19467728081940658, 'weights_2': 0.16159600669614055, 'weights_3': 0.2560642269671376, 'weights_4': 0.5862104125857933, 'weights_5': 0.8906030699172525, 'weights_6': 0.1068273949982107, 'weights_7': 0.7026502875279819, 'weights_8': 0.3487469018075437, 'weights_9': 0.24294984851260448, 'weights_10': 0.03319259452651516, 'weights_11': 0.6453491601863728, 'weights_12': 0.10322663136030369, 'weights_13': 0.6125488716392543, 'weights_14': 0.05417953583838348, 'weights_15': 0.782680330260114, 'weights_16': 0.22844429482558987, 'weights_17': 0.28624642985061716, 'weights_18': 0.24860763427375412, 'weights_19': 0.58529197924142}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,137] Trial 101 finished with value: 2090.7038242153535 and parameters: {'weights_0': 0.05562985882930856, 'weights_1': 0.07088749287885017, 'weights_2': 0.09110796163568596, 'weights_3': 0.09606447617907914, 'weights_4': 0.5141885665744098, 'weights_5': 0.77813023895229, 'weights_6': 0.14899840804888492, 'weights_7': 0.7879141048931674, 'weights_8': 0.40854189471853714, 'weights_9': 0.07347998291590652, 'weights_10': 0.07911957876730899, 'weights_11': 0.7216102449530057, 'weights_12': 0.3404667163949122, 'weights_13': 0.6446694490933054, 'weights_14': 0.12082227810384219, 'weights_15': 0.8271887813477169, 'weights_16': 0.05311509132853638, 'weights_17': 0.22822216642445708, 'weights_18': 0.19441034475824848, 'weights_19': 0.6998259377104277}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,222] Trial 102 finished with value: 1844.7454440563781 and parameters: {'weights_0': 0.07638329803454608, 'weights_1': 0.1128005855320232, 'weights_2': 0.05077779561869713, 'weights_3': 0.029735419216830802, 'weights_4': 0.6677920970053237, 'weights_5': 0.9430501370750024, 'weights_6': 0.06709212919742549, 'weights_7': 0.7561493950310337, 'weights_8': 0.2901878889302746, 'weights_9': 0.11822843374208322, 'weights_10': 0.07217645917014232, 'weights_11': 0.670865787347265, 'weights_12': 0.08275346637967952, 'weights_13': 0.503899237440865, 'weights_14': 0.05973055005125423, 'weights_15': 0.8671204196724918, 'weights_16': 0.021815811194778417, 'weights_17': 0.3373487943239993, 'weights_18': 0.12425323516768316, 'weights_19': 0.6036660203977485}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,353] Trial 103 finished with value: 1871.1023317507506 and parameters: {'weights_0': 0.07788793486663173, 'weights_1': 0.10899046376026321, 'weights_2': 0.05257403624309663, 'weights_3': 0.029912295319653642, 'weights_4': 0.6694741566161435, 'weights_5': 0.9768628336340731, 'weights_6': 0.08507422940000384, 'weights_7': 0.7563758812795437, 'weights_8': 0.2898699548056613, 'weights_9': 0.10806479931370044, 'weights_10': 0.06201903579178463, 'weights_11': 0.6060434966941708, 'weights_12': 0.08434393807286658, 'weights_13': 0.4895732347170984, 'weights_14': 0.04410458166777919, 'weights_15': 0.8720281019326367, 'weights_16': 0.06892916170231651, 'weights_17': 0.19484476382558566, 'weights_18': 0.13174679182290494, 'weights_19': 0.6001864971959421}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,454] Trial 104 finished with value: 2323.9503065603217 and parameters: {'weights_0': 0.1496664359435434, 'weights_1': 0.11836886284604858, 'weights_2': 0.04046086402244911, 'weights_3': 0.01625814842584636, 'weights_4': 0.6817384504436996, 'weights_5': 0.9608110386848255, 'weights_6': 0.09315067415899145, 'weights_7': 0.7469953101470822, 'weights_8': 0.23291863911958588, 'weights_9': 0.1063820349387466, 'weights_10': 0.06264977884332774, 'weights_11': 0.5988660430016176, 'weights_12': 0.11561404765275773, 'weights_13': 0.5201475792894632, 'weights_14': 0.9932939949456611, 'weights_15': 0.8637909460305508, 'weights_16': 0.07010460956857524, 'weights_17': 0.18758700501750128, 'weights_18': 0.13472412000292255, 'weights_19': 0.6072662094701602}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,563] Trial 105 finished with value: 2277.9971882557106 and parameters: {'weights_0': 0.2431662462610815, 'weights_1': 0.0557340972752309, 'weights_2': 0.000583504064057154, 'weights_3': 0.037023331652391925, 'weights_4': 0.7208560831720766, 'weights_5': 0.9699158680876059, 'weights_6': 0.20998493525189516, 'weights_7': 0.6535780205860435, 'weights_8': 0.2871128405555371, 'weights_9': 0.039487442362990816, 'weights_10': 0.08874028364342676, 'weights_11': 0.6763708590686228, 'weights_12': 0.08662935710980156, 'weights_13': 0.48387979535943604, 'weights_14': 0.03803028320106202, 'weights_15': 0.9425225469158331, 'weights_16': 0.4343000524497039, 'weights_17': 0.16040918820787545, 'weights_18': 0.3565639445455594, 'weights_19': 0.7587607738660623}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,691] Trial 106 finished with value: 2056.3303577648335 and parameters: {'weights_0': 0.17409085899840893, 'weights_1': 0.0009984586886237212, 'weights_2': 0.05353832871696174, 'weights_3': 0.18966389598959277, 'weights_4': 0.7272886707269758, 'weights_5': 0.9411738586820474, 'weights_6': 0.06783116508272591, 'weights_7': 0.7211216888038234, 'weights_8': 0.311002613605892, 'weights_9': 0.16349669595099578, 'weights_10': 0.03651253014664045, 'weights_11': 0.6502484165684932, 'weights_12': 0.20255824292049895, 'weights_13': 0.5566695946749096, 'weights_14': 0.06334474216630329, 'weights_15': 0.9815069348351657, 'weights_16': 0.11078426485962617, 'weights_17': 0.32846997106822395, 'weights_18': 0.29353655696629133, 'weights_19': 0.6427917588559708}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,777] Trial 107 finished with value: 2034.1228865817998 and parameters: {'weights_0': 0.07726722070463894, 'weights_1': 0.15818203136053455, 'weights_2': 0.02016358783416712, 'weights_3': 0.09070210693502032, 'weights_4': 0.796378214628359, 'weights_5': 0.9054512910322463, 'weights_6': 0.11835873281458142, 'weights_7': 0.4585551749961001, 'weights_8': 0.33248818690163634, 'weights_9': 0.1440518396050735, 'weights_10': 0.07461036385966653, 'weights_11': 0.47890713327197887, 'weights_12': 0.14253870869924642, 'weights_13': 0.41051471604620937, 'weights_14': 0.0002633067640330118, 'weights_15': 0.8008921931933733, 'weights_16': 0.09386476933776727, 'weights_17': 0.11266285813811266, 'weights_18': 0.17079745316762598, 'weights_19': 0.685764468287653}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:33,906] Trial 108 finished with value: 2292.925093147319 and parameters: {'weights_0': 0.19675984186904033, 'weights_1': 0.11039290202171669, 'weights_2': 0.0846322029364051, 'weights_3': 0.1492633196016493, 'weights_4': 0.6120323441867657, 'weights_5': 0.9793638156261916, 'weights_6': 0.13698596316681902, 'weights_7': 0.7610527897761968, 'weights_8': 0.2662471858199156, 'weights_9': 0.11968439965448191, 'weights_10': 0.12019109557472131, 'weights_11': 0.596873498685064, 'weights_12': 0.17586413548217056, 'weights_13': 0.5985030602394288, 'weights_14': 0.6289212589578684, 'weights_15': 0.8246074087701752, 'weights_16': 0.04681820535776156, 'weights_17': 0.24607977793734656, 'weights_18': 0.234410354448891, 'weights_19': 0.6571445869864457}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,008] Trial 109 finished with value: 2298.8941914331654 and parameters: {'weights_0': 0.09840970370364567, 'weights_1': 0.02605152794902229, 'weights_2': 0.05155200433538261, 'weights_3': 0.09536498813386488, 'weights_4': 0.7087625267923361, 'weights_5': 0.9239013678748664, 'weights_6': 0.1784740494834199, 'weights_7': 0.6920438264628905, 'weights_8': 0.22656013333430242, 'weights_9': 0.07482745457895745, 'weights_10': 0.14744025269888766, 'weights_11': 0.7090569575704276, 'weights_12': 0.13219245972858273, 'weights_13': 0.7166971878519366, 'weights_14': 0.8010040333889489, 'weights_15': 0.9041996416470535, 'weights_16': 0.02094122711492134, 'weights_17': 0.2922972678983453, 'weights_18': 0.2009025640152182, 'weights_19': 0.5749694697101184}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,101] Trial 110 finished with value: 2395.4905686402685 and parameters: {'weights_0': 0.13650524884284398, 'weights_1': 0.21164950859751597, 'weights_2': 0.8150451283914162, 'weights_3': 0.12406193286879297, 'weights_4': 0.550177313078846, 'weights_5': 0.881029557845858, 'weights_6': 0.07994188686121298, 'weights_7': 0.7774590567254731, 'weights_8': 0.3511267476864683, 'weights_9': 0.2175646513442157, 'weights_10': 0.6135345967064011, 'weights_11': 0.6182528564800358, 'weights_12': 0.06461142224075894, 'weights_13': 0.4751421043171482, 'weights_14': 0.02816730537701953, 'weights_15': 0.927273139120026, 'weights_16': 0.16391169938429712, 'weights_17': 0.3333384722036991, 'weights_18': 0.15953795007081242, 'weights_19': 0.5974057184933413}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,196] Trial 111 finished with value: 1888.1461052463237 and parameters: {'weights_0': 0.071769450571055, 'weights_1': 0.0861141844907794, 'weights_2': 0.07736729405158393, 'weights_3': 0.0402884195981143, 'weights_4': 0.6741282423738644, 'weights_5': 0.954449035951244, 'weights_6': 0.057502601648461424, 'weights_7': 0.7478889235095488, 'weights_8': 0.29657579265459444, 'weights_9': 0.20758152260859414, 'weights_10': 0.10142382100308195, 'weights_11': 0.6862620647226723, 'weights_12': 0.08617164338161303, 'weights_13': 0.6240356424388284, 'weights_14': 0.05748135581279428, 'weights_15': 0.8887066271151718, 'weights_16': 0.0641160018779722, 'weights_17': 0.3883769736227286, 'weights_18': 0.12448307634390678, 'weights_19': 0.5377325368663541}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,312] Trial 112 finished with value: 2101.7194305572916 and parameters: {'weights_0': 0.0694006358561425, 'weights_1': 0.06241269865445384, 'weights_2': 0.07620963099703032, 'weights_3': 0.03263010543539159, 'weights_4': 0.6545286093204858, 'weights_5': 0.9606796411496836, 'weights_6': 0.05268037905569804, 'weights_7': 0.7467063383827723, 'weights_8': 0.3234946634028127, 'weights_9': 0.21248794969847787, 'weights_10': 0.10157552761296901, 'weights_11': 0.6874246732375278, 'weights_12': 0.5394145005938731, 'weights_13': 0.3412645371864397, 'weights_14': 0.058012892601579324, 'weights_15': 0.8775903789559337, 'weights_16': 0.12395440259832817, 'weights_17': 0.3804701476539352, 'weights_18': 0.12369882699998799, 'weights_19': 0.6207459277515648}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,444] Trial 113 finished with value: 1953.638770368695 and parameters: {'weights_0': 0.11808827755328977, 'weights_1': 0.10161610693376297, 'weights_2': 0.025017229218486335, 'weights_3': 0.020290887832008837, 'weights_4': 0.7555053808927239, 'weights_5': 0.9950187324601524, 'weights_6': 0.0910854189264727, 'weights_7': 0.6708475041058435, 'weights_8': 0.2915270526363461, 'weights_9': 0.2960388614411404, 'weights_10': 0.060706458156997566, 'weights_11': 0.663808048886754, 'weights_12': 0.09014031415036589, 'weights_13': 0.628765418168214, 'weights_14': 0.13610949679727566, 'weights_15': 0.8788521537331316, 'weights_16': 0.06823661482349087, 'weights_17': 0.2500517434433967, 'weights_18': 0.18564638514198933, 'weights_19': 0.5424742359739929}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,550] Trial 114 finished with value: 1938.5808606247788 and parameters: {'weights_0': 0.05332198512612196, 'weights_1': 0.13823703651620184, 'weights_2': 0.06436712512462792, 'weights_3': 0.10771874485926974, 'weights_4': 0.674919084584867, 'weights_5': 0.8614374368819098, 'weights_6': 0.11128021459313331, 'weights_7': 0.5949410289257752, 'weights_8': 0.3694200524515797, 'weights_9': 0.0523442559497444, 'weights_10': 0.04387324593731337, 'weights_11': 0.5688270726362638, 'weights_12': 0.017474722989996458, 'weights_13': 0.6279559876310118, 'weights_14': 0.04031350871032742, 'weights_15': 0.7892033874526011, 'weights_16': 0.08530879578268041, 'weights_17': 0.3560150688332656, 'weights_18': 0.15014064536027658, 'weights_19': 0.7145060179660396}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,642] Trial 115 finished with value: 1889.3778507651866 and parameters: {'weights_0': 0.005196733065774561, 'weights_1': 0.037508605844324854, 'weights_2': 0.04204117135784785, 'weights_3': 0.07711672028233868, 'weights_4': 0.6827513007059107, 'weights_5': 0.8526310536001065, 'weights_6': 0.11545535312310291, 'weights_7': 0.5816562795821091, 'weights_8': 0.38519965616766166, 'weights_9': 0.09082891998463821, 'weights_10': 0.003780862684898398, 'weights_11': 0.5132568950933745, 'weights_12': 0.02461350668621294, 'weights_13': 0.7015708160438816, 'weights_14': 0.015403295406622889, 'weights_15': 0.7816909227889488, 'weights_16': 0.09795827171760092, 'weights_17': 0.35659120278577394, 'weights_18': 0.14664045315572485, 'weights_19': 0.7800362391881625}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,727] Trial 116 finished with value: 1976.2773561909355 and parameters: {'weights_0': 0.0119461678249616, 'weights_1': 0.13944243564945655, 'weights_2': 0.05976290480344335, 'weights_3': 0.0407626076551387, 'weights_4': 0.6843189019345357, 'weights_5': 0.8591705775160571, 'weights_6': 0.1067749677648034, 'weights_7': 0.5745756973827766, 'weights_8': 0.49189539699560497, 'weights_9': 0.029248342832296288, 'weights_10': 0.019757162568946704, 'weights_11': 0.5681592198116603, 'weights_12': 0.022498906181148665, 'weights_13': 0.6813879300278786, 'weights_14': 0.012678568477536532, 'weights_15': 0.8075721228205164, 'weights_16': 0.17784174744560866, 'weights_17': 0.39342801095273683, 'weights_18': 0.14936581109304142, 'weights_19': 0.753282164674898}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,839] Trial 117 finished with value: 2043.3564980042377 and parameters: {'weights_0': 0.04457291019216842, 'weights_1': 0.07664916614911423, 'weights_2': 0.03797368591683869, 'weights_3': 0.08193454269400971, 'weights_4': 0.6723494131368702, 'weights_5': 0.9413919873531674, 'weights_6': 0.48777807652209937, 'weights_7': 0.5957581082029391, 'weights_8': 0.4152848345401531, 'weights_9': 0.051805517255312246, 'weights_10': 0.0031454048857608233, 'weights_11': 0.5128761020239964, 'weights_12': 0.018729530613849826, 'weights_13': 0.7045381783673013, 'weights_14': 0.050041719035451016, 'weights_15': 0.7787063784690003, 'weights_16': 0.12391113290678644, 'weights_17': 0.36172101640814647, 'weights_18': 0.108190680917792, 'weights_19': 0.8089523048080675}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:34,940] Trial 118 finished with value: 1879.2951733014595 and parameters: {'weights_0': 0.0014392696185744902, 'weights_1': 0.03861167516388398, 'weights_2': 0.01637151232628707, 'weights_3': 0.0646499634446744, 'weights_4': 0.7007982384647201, 'weights_5': 0.900282191343753, 'weights_6': 0.1477004315101238, 'weights_7': 0.5280416801601675, 'weights_8': 0.4562475696747222, 'weights_9': 0.08958906633622132, 'weights_10': 0.03777249988835513, 'weights_11': 0.5587572520380448, 'weights_12': 0.048666331151802106, 'weights_13': 0.6269469181414726, 'weights_14': 0.000847345420193376, 'weights_15': 0.8569425712627479, 'weights_16': 0.05168627563976334, 'weights_17': 0.4259277558562399, 'weights_18': 0.1290236624094705, 'weights_19': 0.9346364623910052}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,064] Trial 119 finished with value: 2109.9312370120365 and parameters: {'weights_0': 0.003088658085344864, 'weights_1': 0.046667623209542604, 'weights_2': 0.09624938435782023, 'weights_3': 0.015195179070076892, 'weights_4': 0.8088553719581226, 'weights_5': 0.896493997340666, 'weights_6': 0.15800747610704768, 'weights_7': 0.5229457992221667, 'weights_8': 0.3850781118980677, 'weights_9': 0.09213365741484816, 'weights_10': 0.08685941908333591, 'weights_11': 0.5339178029664386, 'weights_12': 0.05357857264400434, 'weights_13': 0.6608278754724014, 'weights_14': 0.06701438331122642, 'weights_15': 0.749372015433464, 'weights_16': 0.34334507500919415, 'weights_17': 0.4397073218303937, 'weights_18': 0.13121340347566735, 'weights_19': 0.8884363049067431}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,156] Trial 120 finished with value: 2136.207771130235 and parameters: {'weights_0': 0.058082801411602186, 'weights_1': 0.10545795630815806, 'weights_2': 0.06732602924887635, 'weights_3': 0.05881170051471693, 'weights_4': 0.7003771740987444, 'weights_5': 0.9222926901703805, 'weights_6': 0.5632802210711457, 'weights_7': 0.4945142904699356, 'weights_8': 0.46005489821510764, 'weights_9': 0.14255312066790152, 'weights_10': 0.16126642537822672, 'weights_11': 0.5537797790394945, 'weights_12': 0.017893009986796892, 'weights_13': 0.7386272409326466, 'weights_14': 0.1093424322291342, 'weights_15': 0.8617042587133859, 'weights_16': 0.017409600262686002, 'weights_17': 0.40861741163678433, 'weights_18': 0.11335877461982288, 'weights_19': 0.795947881057712}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,263] Trial 121 finished with value: 1872.4774030207752 and parameters: {'weights_0': 0.04469566284098603, 'weights_1': 0.03150551530864908, 'weights_2': 0.025917112083609306, 'weights_3': 0.07450893084865483, 'weights_4': 0.756539762332453, 'weights_5': 0.8697919689907735, 'weights_6': 0.1230397754989131, 'weights_7': 0.6344121005921346, 'weights_8': 0.25545169968462644, 'weights_9': 0.05488150202122403, 'weights_10': 0.035356464198794846, 'weights_11': 0.5831304844298164, 'weights_12': 0.08308401680634431, 'weights_13': 0.5632938621637621, 'weights_14': 0.042966822590578616, 'weights_15': 0.890577887405387, 'weights_16': 0.05587765623135789, 'weights_17': 0.43013747499409005, 'weights_18': 0.15713580113756404, 'weights_19': 0.9583541210197594}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,387] Trial 122 finished with value: 1866.1318464041879 and parameters: {'weights_0': 0.046107162260254984, 'weights_1': 0.08224667302493077, 'weights_2': 0.02254674147080673, 'weights_3': 0.07673279354454862, 'weights_4': 0.753230786179214, 'weights_5': 0.9496561323469317, 'weights_6': 0.1284148357936951, 'weights_7': 0.5729230682332781, 'weights_8': 0.24373590858449584, 'weights_9': 0.06194263962345742, 'weights_10': 0.02646175892621727, 'weights_11': 0.581206305907026, 'weights_12': 0.07298976902556112, 'weights_13': 0.5757348589006042, 'weights_14': 0.00368106955973984, 'weights_15': 0.7999764166817758, 'weights_16': 0.04816480444918539, 'weights_17': 0.4551627125870975, 'weights_18': 0.15930047493862473, 'weights_19': 0.9214432002102567}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,524] Trial 123 finished with value: 1836.3825483197613 and parameters: {'weights_0': 0.01622526229229046, 'weights_1': 0.08538435046977101, 'weights_2': 0.02293903200247951, 'weights_3': 0.07327876106737358, 'weights_4': 0.7608274461007559, 'weights_5': 0.9615648006083652, 'weights_6': 0.13469630192730217, 'weights_7': 0.548730434060566, 'weights_8': 0.15870286954929363, 'weights_9': 0.0830481490296203, 'weights_10': 0.019082440099816043, 'weights_11': 0.4573786103007362, 'weights_12': 0.0690673621939033, 'weights_13': 0.5735701295575996, 'weights_14': 0.007488694893885699, 'weights_15': 0.8361007732399262, 'weights_16': 0.05170120895038044, 'weights_17': 0.4329731069681417, 'weights_18': 0.093383594714847, 'weights_19': 0.9360629510172841}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,645] Trial 124 finished with value: 1867.459153202172 and parameters: {'weights_0': 0.016210353911318684, 'weights_1': 0.04234042229073334, 'weights_2': 0.022057445190471793, 'weights_3': 0.03970280154414903, 'weights_4': 0.830571765178793, 'weights_5': 0.9460796479874102, 'weights_6': 0.19980824026362826, 'weights_7': 0.5481055152022879, 'weights_8': 0.1370729113477438, 'weights_9': 0.009415700066594958, 'weights_10': 0.023378071226531925, 'weights_11': 0.3805692499790877, 'weights_12': 0.0709671876584464, 'weights_13': 0.5714790327154362, 'weights_14': 0.0012433801353610718, 'weights_15': 0.8267168093768884, 'weights_16': 0.05205584397568007, 'weights_17': 0.4322376174325982, 'weights_18': 0.09613528374620928, 'weights_19': 0.9732129207007355}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,746] Trial 125 finished with value: 1865.6694108309596 and parameters: {'weights_0': 0.037960877931140724, 'weights_1': 0.07431807799745213, 'weights_2': 0.014884649058984, 'weights_3': 0.027012096892894633, 'weights_4': 0.8531278765729071, 'weights_5': 0.9609701451926047, 'weights_6': 0.13937502036624988, 'weights_7': 0.4996065999692417, 'weights_8': 0.1348551659341371, 'weights_9': 0.005444180123573519, 'weights_10': 0.03192819017390161, 'weights_11': 0.39582393739091015, 'weights_12': 0.0681455459689188, 'weights_13': 0.5701581142724423, 'weights_14': 0.0014699627576015566, 'weights_15': 0.8268032524205271, 'weights_16': 0.04730122736575835, 'weights_17': 0.43089879947598486, 'weights_18': 0.09538287014639628, 'weights_19': 0.9831528858642645}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,842] Trial 126 finished with value: 1847.0299518964632 and parameters: {'weights_0': 0.0337411522058116, 'weights_1': 0.05665115959870402, 'weights_2': 0.022956103026980007, 'weights_3': 0.011552908397954954, 'weights_4': 0.8897931521400917, 'weights_5': 0.987131568545987, 'weights_6': 0.20984891968174205, 'weights_7': 0.5569196206368779, 'weights_8': 0.11519899961647234, 'weights_9': 0.0032828335094399084, 'weights_10': 0.024368524795177666, 'weights_11': 0.38990034474639357, 'weights_12': 0.0664639224193059, 'weights_13': 0.5717531848081391, 'weights_14': 0.004712525534766669, 'weights_15': 0.8283121155064356, 'weights_16': 0.0005927516332464508, 'weights_17': 0.4685109723168289, 'weights_18': 0.09225924516129724, 'weights_19': 0.9819151367988586}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:35,931] Trial 127 finished with value: 2197.258815487223 and parameters: {'weights_0': 0.4795074056769475, 'weights_1': 0.06238603801744887, 'weights_2': 7.366075250224077e-05, 'weights_3': 0.007199275536536619, 'weights_4': 0.9189809381890799, 'weights_5': 0.9826017883633491, 'weights_6': 0.2074902228288533, 'weights_7': 0.555567583789032, 'weights_8': 0.11097560821322613, 'weights_9': 0.0063550475472948075, 'weights_10': 0.020191517028083042, 'weights_11': 0.37720815966950716, 'weights_12': 0.07235217948406786, 'weights_13': 0.515094556433552, 'weights_14': 0.003522356771059852, 'weights_15': 0.8265630563810626, 'weights_16': 0.0002722585445442474, 'weights_17': 0.45324424255668994, 'weights_18': 0.514062275362391, 'weights_19': 0.9645793201089166}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,059] Trial 128 finished with value: 1958.6895294211722 and parameters: {'weights_0': 0.038895351654473526, 'weights_1': 0.07744416480934851, 'weights_2': 0.0322920336666111, 'weights_3': 0.03559597296578203, 'weights_4': 0.8739082991042101, 'weights_5': 0.9987634030472625, 'weights_6': 0.19165265807731507, 'weights_7': 0.47642245938888955, 'weights_8': 0.05578330404249074, 'weights_9': 0.02228210771325025, 'weights_10': 0.07595311902037288, 'weights_11': 0.27144350111029997, 'weights_12': 0.11874797082846719, 'weights_13': 0.5401051159244513, 'weights_14': 0.04048200924059653, 'weights_15': 0.8356518009242032, 'weights_16': 0.026703422735145282, 'weights_17': 0.4749528007101631, 'weights_18': 0.10361569297454497, 'weights_19': 0.9967012992462594}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,180] Trial 129 finished with value: 1967.4170153666212 and parameters: {'weights_0': 0.03664620076167825, 'weights_1': 0.11664027506677108, 'weights_2': 0.047635967459505525, 'weights_3': 0.0009344579995448736, 'weights_4': 0.8353720262794465, 'weights_5': 0.9378185987409042, 'weights_6': 0.26584625877859, 'weights_7': 0.4251003427625593, 'weights_8': 0.1602451875280675, 'weights_9': 0.0011664102731466204, 'weights_10': 0.025156789073607334, 'weights_11': 0.44576418204555196, 'weights_12': 0.06219851288540461, 'weights_13': 0.5753022570949607, 'weights_14': 0.07836173213995631, 'weights_15': 0.8142919819110532, 'weights_16': 0.03979811840744732, 'weights_17': 0.44116845034474633, 'weights_18': 0.09611497105227747, 'weights_19': 0.8909067643957964}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,298] Trial 130 finished with value: 2320.4107038381553 and parameters: {'weights_0': 0.021202425345691965, 'weights_1': 0.16203341295922924, 'weights_2': 0.019876487398163688, 'weights_3': 0.024292717139165615, 'weights_4': 0.9088169088427304, 'weights_5': 0.9677188311205337, 'weights_6': 0.2216023802857367, 'weights_7': 0.5062434547118158, 'weights_8': 0.13880044735400088, 'weights_9': 0.05125553876079023, 'weights_10': 0.05530880770443053, 'weights_11': 0.31094086318573966, 'weights_12': 0.15776794340652664, 'weights_13': 0.5474251303992969, 'weights_14': 0.08728083164597009, 'weights_15': 0.8012012894776871, 'weights_16': 0.663580678228068, 'weights_17': 0.4957828033354523, 'weights_18': 0.08808908519085859, 'weights_19': 0.9701424509381396}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,410] Trial 131 finished with value: 1864.9848921967982 and parameters: {'weights_0': 0.0022877348851863314, 'weights_1': 0.03817069105003801, 'weights_2': 0.017869515373805753, 'weights_3': 0.06400044498410251, 'weights_4': 0.848884591182019, 'weights_5': 0.9112944506183688, 'weights_6': 0.14013864553749295, 'weights_7': 0.5600791821803278, 'weights_8': 0.06372028415698969, 'weights_9': 0.06524298884162513, 'weights_10': 0.03982023726306656, 'weights_11': 0.4125525800922332, 'weights_12': 0.05182732588198498, 'weights_13': 0.5656437378086231, 'weights_14': 0.007121141208049653, 'weights_15': 0.8679013123006952, 'weights_16': 0.04837005298745952, 'weights_17': 0.4220505326514414, 'weights_18': 0.17799715514291053, 'weights_19': 0.9305508416790514}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,518] Trial 132 finished with value: 1904.9030504552181 and parameters: {'weights_0': 0.021211924116894335, 'weights_1': 0.05552293762887508, 'weights_2': 0.041987452719651444, 'weights_3': 0.05063815463879415, 'weights_4': 0.8467162114352291, 'weights_5': 0.9472119678574642, 'weights_6': 0.1744349796255959, 'weights_7': 0.5468508661396798, 'weights_8': 0.1790243027547952, 'weights_9': 0.060749937333353335, 'weights_10': 0.07072459610299948, 'weights_11': 0.35179787855748385, 'weights_12': 0.048214436772545693, 'weights_13': 0.49033308848547263, 'weights_14': 0.0001498038939607496, 'weights_15': 0.8713108259725835, 'weights_16': 0.014918770034995442, 'weights_17': 0.4695824777001959, 'weights_18': 0.17887366971238589, 'weights_19': 0.9267626091874339}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,673] Trial 133 finished with value: 2163.8956887654454 and parameters: {'weights_0': 0.08174579172257093, 'weights_1': 0.02582746514521373, 'weights_2': 0.019099118624943852, 'weights_3': 0.07493499377130033, 'weights_4': 0.831794379764989, 'weights_5': 0.918312605541971, 'weights_6': 0.1348773993971374, 'weights_7': 0.5700128004889544, 'weights_8': 0.08433959270851105, 'weights_9': 0.03472436154507085, 'weights_10': 0.019612151195176702, 'weights_11': 0.38886400052084535, 'weights_12': 0.7403169985655287, 'weights_13': 0.566211537788832, 'weights_14': 0.036816245867649006, 'weights_15': 0.9330330382375341, 'weights_16': 0.04260079981858075, 'weights_17': 0.4154874491419258, 'weights_18': 0.08040116404045346, 'weights_19': 0.9692971642840342}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,800] Trial 134 finished with value: 1929.3743629643616 and parameters: {'weights_0': 0.04065567560191677, 'weights_1': 0.07850679878111567, 'weights_2': 0.06021290761134047, 'weights_3': 0.09166106293837452, 'weights_4': 0.7557982382465835, 'weights_5': 0.8769031491772944, 'weights_6': 0.16104261956274044, 'weights_7': 0.5170524453903215, 'weights_8': 0.0736874698823811, 'weights_9': 0.12158400709507518, 'weights_10': 0.04962131914978125, 'weights_11': 0.4378226629840809, 'weights_12': 0.11479289467586147, 'weights_13': 0.510442303394114, 'weights_14': 0.023903651209844987, 'weights_15': 0.7656182768951232, 'weights_16': 0.02021358434003522, 'weights_17': 0.4303044491815112, 'weights_18': 0.16872812401717807, 'weights_19': 0.8596415851704651}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:36,877] Trial 135 finished with value: 2444.6003978358012 and parameters: {'weights_0': 0.04714216161228161, 'weights_1': 0.1174572812436687, 'weights_2': 0.10074441288342378, 'weights_3': 0.05171559066342333, 'weights_4': 0.9633652353767317, 'weights_5': 0.9808451971018263, 'weights_6': 0.2988591004519214, 'weights_7': 0.4898602438666424, 'weights_8': 0.02122113962531938, 'weights_9': 0.013265903840625367, 'weights_10': 0.7306781379246097, 'weights_11': 0.39021133852176776, 'weights_12': 0.07337168104322211, 'weights_13': 0.5283800509475863, 'weights_14': 0.06886112518979784, 'weights_15': 0.8461262522585522, 'weights_16': 0.05739451780037509, 'weights_17': 0.4564978191652833, 'weights_18': 0.4554717483137747, 'weights_19': 0.948064701823456}. Best is trial 42 with value: 1829.2659326521634.\n",
      "[I 2025-08-01 08:05:37,012] Trial 136 finished with value: 1821.1721801310314 and parameters: {'weights_0': 0.06647589289227662, 'weights_1': 0.05884790536587698, 'weights_2': 0.0022453773943179947, 'weights_3': 0.026823207446590554, 'weights_4': 0.7862063740002977, 'weights_5': 0.919817390166635, 'weights_6': 0.13153892774165604, 'weights_7': 0.6122812122040415, 'weights_8': 0.11890070267333228, 'weights_9': 0.06704567247512076, 'weights_10': 0.0017385469623884126, 'weights_11': 0.41655740310485234, 'weights_12': 0.04829008834406183, 'weights_13': 0.46369497094159723, 'weights_14': 0.04554078309637763, 'weights_15': 0.890737733884013, 'weights_16': 0.032581540546195394, 'weights_17': 0.5211086933150331, 'weights_18': 0.11422917482545936, 'weights_19': 0.9996955218107731}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:37,127] Trial 137 finished with value: 1834.6060663232427 and parameters: {'weights_0': 0.08687101307586459, 'weights_1': 0.0569448853574368, 'weights_2': 0.04360822047494528, 'weights_3': 0.02184965369660903, 'weights_4': 0.8609361805410378, 'weights_5': 0.9272180317800807, 'weights_6': 0.18757353467644156, 'weights_7': 0.4429469438012646, 'weights_8': 0.12977038486182582, 'weights_9': 0.11066851462973264, 'weights_10': 0.007505072208062258, 'weights_11': 0.4637313487788144, 'weights_12': 0.0006296246373374836, 'weights_13': 0.4570509512523135, 'weights_14': 0.016212707138853158, 'weights_15': 0.8160495068664986, 'weights_16': 0.0021128259767715547, 'weights_17': 0.5138776256630957, 'weights_18': 0.0965182441010622, 'weights_19': 0.999157825366534}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:37,246] Trial 138 finished with value: 1952.937367982086 and parameters: {'weights_0': 0.018734044551629584, 'weights_1': 0.06146696481062763, 'weights_2': 0.4114748664456262, 'weights_3': 0.019406203332432634, 'weights_4': 0.8654610392159315, 'weights_5': 0.9198931207573742, 'weights_6': 0.24484780627346478, 'weights_7': 0.4350156343995288, 'weights_8': 0.1225955931500319, 'weights_9': 0.029493755644845174, 'weights_10': 0.0018301051471569726, 'weights_11': 0.4156916057931689, 'weights_12': 0.009304098343426825, 'weights_13': 0.45700683871107983, 'weights_14': 0.016442398851475533, 'weights_15': 0.8231193298122221, 'weights_16': 0.0050732039353784605, 'weights_17': 0.5241935115761746, 'weights_18': 0.09087134758276497, 'weights_19': 0.9937411919684987}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:37,433] Trial 139 finished with value: 1851.0931502703663 and parameters: {'weights_0': 0.09262865213216853, 'weights_1': 0.088501029315711, 'weights_2': 0.00015263248657454952, 'weights_3': 0.0013835984616300534, 'weights_4': 0.7810326577526175, 'weights_5': 0.95335724418902, 'weights_6': 0.19755964819171146, 'weights_7': 0.5569189712836911, 'weights_8': 0.15618364755054404, 'weights_9': 0.07886835191526644, 'weights_10': 0.02177046461294302, 'weights_11': 0.48378788115261634, 'weights_12': 0.0003392374187476465, 'weights_13': 0.5860717792952879, 'weights_14': 0.09427991201877882, 'weights_15': 0.7563905532471424, 'weights_16': 0.033352326795789866, 'weights_17': 0.5027321490103497, 'weights_18': 0.06709477208139163, 'weights_19': 0.9844093872714483}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:37,610] Trial 140 finished with value: 2468.8684614839913 and parameters: {'weights_0': 0.09066859724113834, 'weights_1': 0.08467748271863129, 'weights_2': 0.004694551562639966, 'weights_3': 0.007810937453416572, 'weights_4': 0.7823328389513908, 'weights_5': 0.26268663235471346, 'weights_6': 0.22466580399582922, 'weights_7': 0.37136828435222796, 'weights_8': 0.20780672977924458, 'weights_9': 0.08099230445063568, 'weights_10': 0.08842679442057302, 'weights_11': 0.4853893738605114, 'weights_12': 0.0002737012101085151, 'weights_13': 0.4243381460076393, 'weights_14': 0.09201968989690756, 'weights_15': 0.757310998388245, 'weights_16': 0.7442466180073701, 'weights_17': 0.5391296542051132, 'weights_18': 0.06693635053190056, 'weights_19': 0.8922568336083458}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:37,767] Trial 141 finished with value: 1861.0797658487909 and parameters: {'weights_0': 0.06550345494676718, 'weights_1': 0.053794529806371415, 'weights_2': 0.0020607607133829656, 'weights_3': 0.04616928368325571, 'weights_4': 0.8240591034687972, 'weights_5': 0.9447566445896305, 'weights_6': 0.17299008378971029, 'weights_7': 0.5552517098055509, 'weights_8': 0.15912491586394611, 'weights_9': 0.06669380237823108, 'weights_10': 0.023309567189176705, 'weights_11': 0.46650629783919173, 'weights_12': 0.04415653398884896, 'weights_13': 0.5831456912366174, 'weights_14': 0.058493357126033665, 'weights_15': 0.8106483855237476, 'weights_16': 0.03233872516619267, 'weights_17': 0.47619724146319165, 'weights_18': 0.10395783297043677, 'weights_19': 0.9879023995479395}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:37,882] Trial 142 finished with value: 1896.619037653634 and parameters: {'weights_0': 0.06573536841066807, 'weights_1': 0.09356102069850163, 'weights_2': 0.03867989188891784, 'weights_3': 0.06130976360290729, 'weights_4': 0.8100402391347811, 'weights_5': 0.9577943303879882, 'weights_6': 0.19078115720939381, 'weights_7': 0.46035776178378446, 'weights_8': 0.15249484893941354, 'weights_9': 0.13160682327540246, 'weights_10': 0.002848353940678186, 'weights_11': 0.40544644508406313, 'weights_12': 0.03934506511993679, 'weights_13': 0.36687889763049786, 'weights_14': 0.06808108152864703, 'weights_15': 0.7944472891409634, 'weights_16': 0.02850646265345724, 'weights_17': 0.492703436882664, 'weights_18': 0.1150109874743169, 'weights_19': 0.9082420706956842}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,025] Trial 143 finished with value: 2091.5721355301102 and parameters: {'weights_0': 0.8718205018598726, 'weights_1': 0.05423882499819954, 'weights_2': 0.0049788651638602716, 'weights_3': 0.0288346353083891, 'weights_4': 0.8920070680961476, 'weights_5': 0.927721681481261, 'weights_6': 0.14434507943129055, 'weights_7': 0.6115373609950387, 'weights_8': 0.17715837413002333, 'weights_9': 0.37073608705188904, 'weights_10': 0.03383052671997763, 'weights_11': 0.47527449222383583, 'weights_12': 0.049436874610433064, 'weights_13': 0.5897955805113605, 'weights_14': 0.11210976852700842, 'weights_15': 0.7165474670872142, 'weights_16': 0.0030144233377078083, 'weights_17': 0.5100858278957754, 'weights_18': 0.05306170697899556, 'weights_19': 0.9851499223281922}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,150] Trial 144 finished with value: 2019.4878385297525 and parameters: {'weights_0': 0.09382074017872646, 'weights_1': 0.13161839597132172, 'weights_2': 0.49841224244827104, 'weights_3': 0.0015772414749564653, 'weights_4': 0.7730008959474672, 'weights_5': 0.9990353174292769, 'weights_6': 0.17719020313164519, 'weights_7': 0.4867255711726255, 'weights_8': 0.07952730301590324, 'weights_9': 0.07209963068996444, 'weights_10': 0.05475552450370501, 'weights_11': 0.4578052970179239, 'weights_12': 0.043780674171691375, 'weights_13': 0.5250140589382842, 'weights_14': 0.06351304637798152, 'weights_15': 0.7729064486821381, 'weights_16': 0.029902015122054083, 'weights_17': 0.4532899919411241, 'weights_18': 0.07198165766677021, 'weights_19': 0.9447601512546372}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,283] Trial 145 finished with value: 1946.7144762028145 and parameters: {'weights_0': 0.1214713542199409, 'weights_1': 0.07156990370389005, 'weights_2': 0.00021449597915434776, 'weights_3': 0.08928623878179437, 'weights_4': 0.814464357476982, 'weights_5': 0.8940679557602277, 'weights_6': 0.36086590365935495, 'weights_7': 0.5606817564268266, 'weights_8': 0.09633550028732185, 'weights_9': 0.10807839368024702, 'weights_10': 0.10878901659711758, 'weights_11': 0.46063499929327556, 'weights_12': 0.013718787884268899, 'weights_13': 0.5430451431004997, 'weights_14': 0.02363967462455227, 'weights_15': 0.8494849758892317, 'weights_16': 0.0023041159074590617, 'weights_17': 0.48474102412721154, 'weights_18': 0.11847786805390921, 'weights_19': 0.909594777300072}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,414] Trial 146 finished with value: 2023.090886225129 and parameters: {'weights_0': 0.06427256142658828, 'weights_1': 0.024977121549880202, 'weights_2': 0.07695097428524135, 'weights_3': 0.7651466159140248, 'weights_4': 0.8627333659651905, 'weights_5': 0.91430693022815, 'weights_6': 0.1351061382596458, 'weights_7': 0.5094445835706186, 'weights_8': 0.19349599560434333, 'weights_9': 0.10077799179358532, 'weights_10': 0.07802809166185842, 'weights_11': 0.42544539641775714, 'weights_12': 0.05863789330303296, 'weights_13': 0.5885653187366245, 'weights_14': 0.04918529288099411, 'weights_15': 0.8131157613236643, 'weights_16': 0.03869653550275544, 'weights_17': 0.5552630090436985, 'weights_18': 0.14349236412788646, 'weights_19': 0.8420190811485188}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,539] Trial 147 finished with value: 1919.4931430797526 and parameters: {'weights_0': 0.03672574758850954, 'weights_1': 0.09743307722208691, 'weights_2': 0.037176815272792395, 'weights_3': 0.050185049822601954, 'weights_4': 0.9286334395117368, 'weights_5': 0.18892686461938168, 'weights_6': 0.1571527493064275, 'weights_7': 0.5334439514197669, 'weights_8': 0.12368543094253384, 'weights_9': 0.14981763371354845, 'weights_10': 0.02177624812421318, 'weights_11': 0.35401548345356054, 'weights_12': 0.03390089463198161, 'weights_13': 0.46071085497394454, 'weights_14': 0.0959653696172757, 'weights_15': 0.7388571190404813, 'weights_16': 0.02478286513444105, 'weights_17': 0.4767681918751709, 'weights_18': 0.10171419095602982, 'weights_19': 0.9281584783437771}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,655] Trial 148 finished with value: 2003.8523091144189 and parameters: {'weights_0': 0.41846599296531684, 'weights_1': 0.06155374353316601, 'weights_2': 0.13984702571638308, 'weights_3': 0.0650597535677688, 'weights_4': 0.7826298587896092, 'weights_5': 0.9339190936275775, 'weights_6': 0.0977555670962874, 'weights_7': 0.47082838395788684, 'weights_8': 0.04982330473724732, 'weights_9': 0.9608208820077371, 'weights_10': 0.047474347744529584, 'weights_11': 0.4061346667460025, 'weights_12': 0.10848922319971974, 'weights_13': 0.5032051132405759, 'weights_14': 0.029828670586113867, 'weights_15': 0.9127503516135003, 'weights_16': 0.07495842069147549, 'weights_17': 0.5183198961980213, 'weights_18': 0.19205020586714439, 'weights_19': 0.9848816638217418}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,761] Trial 149 finished with value: 1869.1439693599705 and parameters: {'weights_0': 0.10638832524510627, 'weights_1': 0.12146400354936562, 'weights_2': 0.05813848101463087, 'weights_3': 0.10062944109887408, 'weights_4': 0.8954918210666847, 'weights_5': 0.9657118312679992, 'weights_6': 0.19203545281855525, 'weights_7': 0.605811927365371, 'weights_8': 0.1564338601945116, 'weights_9': 0.07036828017539197, 'weights_10': 0.004837442497114423, 'weights_11': 0.47201635133928993, 'weights_12': 0.002083703686955092, 'weights_13': 0.6482034478218994, 'weights_14': 0.08112183334010627, 'weights_15': 0.7923774492240668, 'weights_16': 0.03819663852785597, 'weights_17': 0.497215831911101, 'weights_18': 0.04458841047307953, 'weights_19': 0.9480423403755565}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:38,951] Trial 150 finished with value: 2162.3892293088325 and parameters: {'weights_0': 0.0787358977141358, 'weights_1': 0.7764473209748778, 'weights_2': 0.023309564484524918, 'weights_3': 0.031106297511702234, 'weights_4': 0.85242371575998, 'weights_5': 0.8853287012727451, 'weights_6': 0.43580140623914, 'weights_7': 0.39811307557090625, 'weights_8': 0.21631965292221395, 'weights_9': 0.03970713310531066, 'weights_10': 0.06746878355308891, 'weights_11': 0.3349324813092021, 'weights_12': 0.061256054567828795, 'weights_13': 0.5814133589217002, 'weights_14': 0.12010175970590611, 'weights_15': 0.8440968211858609, 'weights_16': 0.01254985669445809, 'weights_17': 0.40492878679922895, 'weights_18': 0.16201063275997224, 'weights_19': 0.9912491215564387}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:39,073] Trial 151 finished with value: 1903.8501054499793 and parameters: {'weights_0': 0.0012077470644021315, 'weights_1': 0.04594422894328414, 'weights_2': 0.02020918470457887, 'weights_3': 0.04169400912739054, 'weights_4': 0.827174191043859, 'weights_5': 0.9517397276748301, 'weights_6': 0.25450992286527724, 'weights_7': 0.5513440033288063, 'weights_8': 0.24047996370966002, 'weights_9': 0.005150270983862956, 'weights_10': 0.02949763521328946, 'weights_11': 0.36955611715344644, 'weights_12': 0.06933259765389486, 'weights_13': 0.5671285392101688, 'weights_14': 0.01280274047515961, 'weights_15': 0.8246026297636697, 'weights_16': 0.05207963860185097, 'weights_17': 0.46469819022303, 'weights_18': 0.09692703419154772, 'weights_19': 0.9645442506360589}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:39,206] Trial 152 finished with value: 1920.212638356086 and parameters: {'weights_0': 0.02575476725819862, 'weights_1': 0.08587377613762563, 'weights_2': 0.0004884364339188851, 'weights_3': 0.5204298986200451, 'weights_4': 0.8772466617698952, 'weights_5': 0.9379057864963822, 'weights_6': 0.20510182070486097, 'weights_7': 0.5426771414510991, 'weights_8': 0.14005949779506247, 'weights_9': 0.05856015387766202, 'weights_10': 0.040436822576888035, 'weights_11': 0.44171087941280324, 'weights_12': 0.04623400203758097, 'weights_13': 0.5499682428715668, 'weights_14': 0.04283711659574568, 'weights_15': 0.7666653156751496, 'weights_16': 0.04779059010478798, 'weights_17': 0.43816549379335173, 'weights_18': 0.07435415629548872, 'weights_19': 0.9208820131598384}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:39,354] Trial 153 finished with value: 1844.962747685041 and parameters: {'weights_0': 0.058518819494127655, 'weights_1': 0.011535695416991024, 'weights_2': 0.038017366523796024, 'weights_3': 0.0002241497789504058, 'weights_4': 0.7925744105522955, 'weights_5': 0.9771088091239442, 'weights_6': 0.23053258436831053, 'weights_7': 0.5724789555770023, 'weights_8': 0.0034483262814794108, 'weights_9': 0.024284617322036538, 'weights_10': 0.01988105443547774, 'weights_11': 0.3888088657673672, 'weights_12': 0.02407531362224951, 'weights_13': 0.6046822511479913, 'weights_14': 0.005682782322526683, 'weights_15': 0.8067037117925034, 'weights_16': 6.651290695502922e-05, 'weights_17': 0.5388917464963583, 'weights_18': 0.13477682275468789, 'weights_19': 0.9994682464967131}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:39,554] Trial 154 finished with value: 1873.3241277052944 and parameters: {'weights_0': 0.05947216006968499, 'weights_1': 0.009094968101457164, 'weights_2': 0.08542159476907396, 'weights_3': 0.001037666366967279, 'weights_4': 0.7978777762793746, 'weights_5': 0.9745188358356652, 'weights_6': 0.16356038187670885, 'weights_7': 0.5665962657433095, 'weights_8': 0.06427858695196292, 'weights_9': 0.3345673407839731, 'weights_10': 0.09327401561892099, 'weights_11': 0.4222413535852108, 'weights_12': 0.026081127230738924, 'weights_13': 0.611979862131988, 'weights_14': 0.06527855752334814, 'weights_15': 0.8607825310230058, 'weights_16': 0.02566813815496935, 'weights_17': 0.5367199543049127, 'weights_18': 0.13370071787870924, 'weights_19': 0.9996651439766788}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:39,676] Trial 155 finished with value: 1821.460159666823 and parameters: {'weights_0': 0.09756686458679405, 'weights_1': 0.026394517582535915, 'weights_2': 0.047026589924531056, 'weights_3': 0.022269709026492265, 'weights_4': 0.738385244692862, 'weights_5': 0.9063016796830238, 'weights_6': 0.11987770015196246, 'weights_7': 0.5874205354662503, 'weights_8': 0.1081965078156129, 'weights_9': 0.025094197047027682, 'weights_10': 0.0005893894289241003, 'weights_11': 0.49737464030537615, 'weights_12': 0.02497738787896056, 'weights_13': 0.44157029379587853, 'weights_14': 0.02302098607266175, 'weights_15': 0.8029816768297845, 'weights_16': 0.002027542051435738, 'weights_17': 0.5150951559966181, 'weights_18': 0.17053967558019642, 'weights_19': 0.9479454108041044}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:39,856] Trial 156 finished with value: 2005.5518871677823 and parameters: {'weights_0': 0.31935676058631995, 'weights_1': 0.017645841778149665, 'weights_2': 0.06241367393432432, 'weights_3': 0.02061784191446101, 'weights_4': 0.7931897127462546, 'weights_5': 0.8281630981754521, 'weights_6': 0.21962467104208638, 'weights_7': 0.4406597196100883, 'weights_8': 0.013598410223678317, 'weights_9': 0.032818668348714206, 'weights_10': 0.04902982219894072, 'weights_11': 0.49370548987913093, 'weights_12': 0.0008250387341233179, 'weights_13': 0.4075001605427224, 'weights_14': 0.02507724582654739, 'weights_15': 0.6847489889443672, 'weights_16': 0.0017365462298025887, 'weights_17': 0.5253937918578842, 'weights_18': 0.2092837970554226, 'weights_19': 0.977520017780475}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,008] Trial 157 finished with value: 1958.1120289786031 and parameters: {'weights_0': 0.13617344941716747, 'weights_1': 0.03475058129085228, 'weights_2': 0.04485389695392147, 'weights_3': 0.9947822451142542, 'weights_4': 0.7736184420911201, 'weights_5': 0.9192687223463895, 'weights_6': 0.09654119012873273, 'weights_7': 0.6286287863645725, 'weights_8': 0.0023119918527040664, 'weights_9': 0.01990681004687883, 'weights_10': 0.0024982267266125367, 'weights_11': 0.5041847801511322, 'weights_12': 0.02249346082785373, 'weights_13': 0.4448145576696311, 'weights_14': 0.05732317080893565, 'weights_15': 0.7489654693080007, 'weights_16': 0.020878995352218228, 'weights_17': 0.5623665321612662, 'weights_18': 0.1789016925992994, 'weights_19': 0.9450476613758847}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,173] Trial 158 finished with value: 1906.2052986948102 and parameters: {'weights_0': 0.09606496637066915, 'weights_1': 0.0021452952041368933, 'weights_2': 0.1027063371692109, 'weights_3': 0.05348217995775608, 'weights_4': 0.8509352599024573, 'weights_5': 0.999577060487451, 'weights_6': 0.17569364553808547, 'weights_7': 0.5970603372030816, 'weights_8': 0.040061840206472535, 'weights_9': 0.4425697673981823, 'weights_10': 0.1285516268510277, 'weights_11': 0.4597328481849686, 'weights_12': 0.028902622425727956, 'weights_13': 0.4635357329843348, 'weights_14': 0.08941846218309486, 'weights_15': 0.7257671196951856, 'weights_16': 0.06935774507894207, 'weights_17': 0.5079368392787286, 'weights_18': 0.12449960489719775, 'weights_19': 0.9545566548257838}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,333] Trial 159 finished with value: 2429.6331699035723 and parameters: {'weights_0': 0.07077520629969411, 'weights_1': 0.05712285958541964, 'weights_2': 0.06821448943431394, 'weights_3': 0.0015564001358457234, 'weights_4': 0.7300707933707701, 'weights_5': 0.9016925898860781, 'weights_6': 0.22877968404845847, 'weights_7': 0.5241458204042075, 'weights_8': 0.1113376848057895, 'weights_9': 0.08895013959578446, 'weights_10': 0.07862671941053795, 'weights_11': 0.43400247301539885, 'weights_12': 0.10467646675921724, 'weights_13': 0.3843980665718088, 'weights_14': 0.0359749883348707, 'weights_15': 0.8085320905683803, 'weights_16': 0.8882975142359674, 'weights_17': 0.4893227116375362, 'weights_18': 0.11126984900461268, 'weights_19': 0.9750615112870746}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,551] Trial 160 finished with value: 1859.3984558563905 and parameters: {'weights_0': 0.11495908804135872, 'weights_1': 0.022256404925955, 'weights_2': 0.04439283431165624, 'weights_3': 0.022994256172827535, 'weights_4': 0.9284044035330733, 'weights_5': 0.49792928294298316, 'weights_6': 0.11537332764198191, 'weights_7': 0.4988862320266386, 'weights_8': 0.08875795686867922, 'weights_9': 0.12160790745796884, 'weights_10': 0.017461461425779753, 'weights_11': 0.39703057135231234, 'weights_12': 0.045015455526563025, 'weights_13': 0.4988014183169469, 'weights_14': 0.021770515298330212, 'weights_15': 0.8880339192753337, 'weights_16': 0.020233572221421314, 'weights_17': 0.3785423963779482, 'weights_18': 0.07817533343726304, 'weights_19': 0.9404655049232818}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,660] Trial 161 finished with value: 1866.4620645723583 and parameters: {'weights_0': 0.11189995823210545, 'weights_1': 0.02484949065148888, 'weights_2': 0.04539733339527336, 'weights_3': 0.020188599179678825, 'weights_4': 0.8217323620457658, 'weights_5': 0.40214730523184294, 'weights_6': 0.11208829864176999, 'weights_7': 0.5089439863500396, 'weights_8': 0.09510267473159209, 'weights_9': 0.12287101439110876, 'weights_10': 0.00030406446937925047, 'weights_11': 0.3222903483840853, 'weights_12': 0.05408677748878452, 'weights_13': 0.48008939399037526, 'weights_14': 0.02126360817613944, 'weights_15': 0.8890344221496868, 'weights_16': 0.028988616897070038, 'weights_17': 0.3758812441163828, 'weights_18': 0.062458681851623135, 'weights_19': 0.8662603190343139}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,801] Trial 162 finished with value: 1854.4395924520816 and parameters: {'weights_0': 0.09019250785825461, 'weights_1': 0.04028283252114326, 'weights_2': 0.037801557324412566, 'weights_3': 0.04254333867017871, 'weights_4': 0.9392451929299217, 'weights_5': 0.5275228842131993, 'weights_6': 0.1418228346192023, 'weights_7': 0.5859520833270342, 'weights_8': 0.11272053420844541, 'weights_9': 0.08492884266285596, 'weights_10': 0.020736363078608547, 'weights_11': 0.3942261294975631, 'weights_12': 0.03168149896915927, 'weights_13': 0.5020879352527126, 'weights_14': 0.05097263740717805, 'weights_15': 0.8372335901273594, 'weights_16': 0.017212486376656677, 'weights_17': 0.40230911600761665, 'weights_18': 0.08350413797004624, 'weights_19': 0.9475665669316474}. Best is trial 136 with value: 1821.1721801310314.\n",
      "[I 2025-08-01 08:05:40,918] Trial 163 finished with value: 1799.8727674869642 and parameters: {'weights_0': 0.1489907438587703, 'weights_1': 0.03763912168303796, 'weights_2': 0.04026831186904108, 'weights_3': 0.06277999257237149, 'weights_4': 0.9346296533377593, 'weights_5': 0.49676549281135485, 'weights_6': 0.04345986931003366, 'weights_7': 0.6069514649976238, 'weights_8': 0.10818809865680343, 'weights_9': 0.39985267037667577, 'weights_10': 0.0637584835305475, 'weights_11': 0.5295043557704797, 'weights_12': 0.03187571661295663, 'weights_13': 0.44567552660747967, 'weights_14': 0.05175652328424744, 'weights_15': 0.8603751875794198, 'weights_16': 0.0017597568431822596, 'weights_17': 0.40434232533488157, 'weights_18': 0.08315217003472905, 'weights_19': 0.9044485999678158}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,029] Trial 164 finished with value: 1974.6788453679815 and parameters: {'weights_0': 0.5878876910454273, 'weights_1': 0.052038375967151156, 'weights_2': 0.08479906346753247, 'weights_3': 0.04463649599121002, 'weights_4': 0.9459219322284054, 'weights_5': 0.49761012887226314, 'weights_6': 0.03412862680414989, 'weights_7': 0.6204110369462048, 'weights_8': 0.1746062109371201, 'weights_9': 0.4128209397617518, 'weights_10': 0.05948453677051249, 'weights_11': 0.5237653222922312, 'weights_12': 0.025078380378588862, 'weights_13': 0.4350712998772176, 'weights_14': 0.059731720582204835, 'weights_15': 0.8456363221630087, 'weights_16': 0.0012223088276757388, 'weights_17': 0.39151612031799343, 'weights_18': 0.08173590079334299, 'weights_19': 0.9553321606315979}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,175] Trial 165 finished with value: 2049.103373213711 and parameters: {'weights_0': 0.09084473783688361, 'weights_1': 0.019599781142267556, 'weights_2': 0.04036182643020038, 'weights_3': 0.08709784927264196, 'weights_4': 0.9512864930660907, 'weights_5': 0.45759840924565265, 'weights_6': 0.08278398359353875, 'weights_7': 0.6011027722954825, 'weights_8': 0.10697199736043506, 'weights_9': 0.2757859020024884, 'weights_10': 0.546088029165947, 'weights_11': 0.4490482726807624, 'weights_12': 0.03930755925982825, 'weights_13': 0.5033727253784455, 'weights_14': 0.07837732429356632, 'weights_15': 0.9654898517800488, 'weights_16': 0.018667478079424163, 'weights_17': 0.5449337090708729, 'weights_18': 0.023822477779742987, 'weights_19': 0.9997190314295243}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,302] Trial 166 finished with value: 1958.7364377148947 and parameters: {'weights_0': 0.14645631525326255, 'weights_1': 0.10172404822346107, 'weights_2': 0.12186584082279125, 'weights_3': 0.9413493636709265, 'weights_4': 0.9689497005970508, 'weights_5': 0.5084370650811061, 'weights_6': 0.04540398415507445, 'weights_7': 0.5820894011242476, 'weights_8': 0.15845174965333866, 'weights_9': 0.39679524703289437, 'weights_10': 0.11042346494813662, 'weights_11': 0.5053339543519947, 'weights_12': 0.004051733435749627, 'weights_13': 0.4175845676138553, 'weights_14': 0.10318417402319521, 'weights_15': 0.7791292845666564, 'weights_16': 0.002979133430939508, 'weights_17': 0.3687520470517155, 'weights_18': 0.052828562907011045, 'weights_19': 0.9051598872879472}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,512] Trial 167 finished with value: 2365.986636588002 and parameters: {'weights_0': 0.12565144811681817, 'weights_1': 0.0684843286056529, 'weights_2': 0.05922809708198764, 'weights_3': 0.1238628875055298, 'weights_4': 0.9839958011710711, 'weights_5': 0.4784785877163779, 'weights_6': 0.9649158873079006, 'weights_7': 0.6486556205158686, 'weights_8': 0.18943351815653137, 'weights_9': 0.1585725877479835, 'weights_10': 0.018393472065821596, 'weights_11': 0.4951996479951989, 'weights_12': 0.024023638244109524, 'weights_13': 0.4638430663373449, 'weights_14': 0.5512863767651416, 'weights_15': 0.8848433395133465, 'weights_16': 0.02385819435526505, 'weights_17': 0.40670096174615367, 'weights_18': 0.13915682727592338, 'weights_19': 0.9374165581328154}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,641] Trial 168 finished with value: 1923.141468321206 and parameters: {'weights_0': 0.15825424649488562, 'weights_1': 0.003572079225488309, 'weights_2': 0.10218660667835801, 'weights_3': 0.040869470459105224, 'weights_4': 0.8864713622812981, 'weights_5': 0.5315483895489587, 'weights_6': 0.07561274558951228, 'weights_7': 0.5894752176692389, 'weights_8': 0.12013429680358788, 'weights_9': 0.3422128285996542, 'weights_10': 0.06562434822790847, 'weights_11': 0.2808520676032133, 'weights_12': 0.08999183381401654, 'weights_13': 0.44785484009983934, 'weights_14': 0.04566820745020946, 'weights_15': 0.9107851803375495, 'weights_16': 0.07188253458220174, 'weights_17': 0.3362889544844796, 'weights_18': 0.07351421569626629, 'weights_19': 0.9590926951920608}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,763] Trial 169 finished with value: 2003.932403720169 and parameters: {'weights_0': 0.0861206295399653, 'weights_1': 0.041741857768445995, 'weights_2': 0.06923905446737308, 'weights_3': 0.07402010056882734, 'weights_4': 0.927725410773661, 'weights_5': 0.41796385836520905, 'weights_6': 0.05446857874846696, 'weights_7': 0.5339189855111725, 'weights_8': 0.08549453401967197, 'weights_9': 0.10897710903096139, 'weights_10': 0.017866819557652635, 'weights_11': 0.37011121442113415, 'weights_12': 0.04145953923929835, 'weights_13': 0.47885607113828843, 'weights_14': 0.07166295490152935, 'weights_15': 0.8552298977001469, 'weights_16': 0.0001367705567481281, 'weights_17': 0.5095260912361319, 'weights_18': 0.1151028612043471, 'weights_19': 0.062165765277628626}. Best is trial 163 with value: 1799.8727674869642.\n",
      "[I 2025-08-01 08:05:41,890] Trial 170 finished with value: 1780.0363280993686 and parameters: {'weights_0': 0.11322520754969785, 'weights_1': 0.09479196329350459, 'weights_2': 0.036507950681302845, 'weights_3': 0.022522336572106005, 'weights_4': 0.9376315865441907, 'weights_5': 0.5418567839480226, 'weights_6': 0.10629416901416244, 'weights_7': 0.8431692551397257, 'weights_8': 0.2674303744107398, 'weights_9': 0.3881336338279784, 'weights_10': 0.09316827611563544, 'weights_11': 0.46758769505286857, 'weights_12': 0.02182328262042244, 'weights_13': 0.3254605922474693, 'weights_14': 0.04375282021322888, 'weights_15': 0.811684851875242, 'weights_16': 0.028649755437502082, 'weights_17': 0.4730229914310835, 'weights_18': 0.03616039797367736, 'weights_19': 0.8868544587828687}. Best is trial 170 with value: 1780.0363280993686.\n",
      "[I 2025-08-01 08:05:42,011] Trial 171 finished with value: 1759.7607581148661 and parameters: {'weights_0': 0.10616414755435721, 'weights_1': 0.09683972715465668, 'weights_2': 0.034399297448267856, 'weights_3': 0.025404269428430677, 'weights_4': 0.9407003896065576, 'weights_5': 0.5543705468775729, 'weights_6': 0.12029737078409607, 'weights_7': 0.7936903760863879, 'weights_8': 0.14197720705499142, 'weights_9': 0.3709246066430575, 'weights_10': 0.09375609143569201, 'weights_11': 0.4673898095305928, 'weights_12': 0.002046529825354415, 'weights_13': 0.26631500303605615, 'weights_14': 0.04366030407335953, 'weights_15': 0.8084038417861974, 'weights_16': 0.03336137640429815, 'weights_17': 0.4665821779190332, 'weights_18': 0.03205444769100102, 'weights_19': 0.910029907979341}. Best is trial 171 with value: 1759.7607581148661.\n",
      "[I 2025-08-01 08:05:42,145] Trial 172 finished with value: 2012.008865609224 and parameters: {'weights_0': 0.11924000026972188, 'weights_1': 0.06757489212806292, 'weights_2': 0.03879580644039615, 'weights_3': 0.014020478329219939, 'weights_4': 0.9950506328834358, 'weights_5': 0.5615729783870017, 'weights_6': 0.15830635830248735, 'weights_7': 0.783559744545086, 'weights_8': 0.26572870405211346, 'weights_9': 0.3670017081605927, 'weights_10': 0.09310383458005082, 'weights_11': 0.4794474286684909, 'weights_12': 0.46398153299475764, 'weights_13': 0.20560984368054963, 'weights_14': 0.044518451458140845, 'weights_15': 0.8096546149932268, 'weights_16': 0.03351710083008447, 'weights_17': 0.4730839052188326, 'weights_18': 0.02941727997350166, 'weights_19': 0.8693161757273667}. Best is trial 171 with value: 1759.7607581148661.\n",
      "[I 2025-08-01 08:05:42,270] Trial 173 finished with value: 1743.5074819995584 and parameters: {'weights_0': 0.10779165947726219, 'weights_1': 0.10500180882126378, 'weights_2': 0.0331170958705573, 'weights_3': 0.000400416409077019, 'weights_4': 0.9417489198694975, 'weights_5': 0.5130949751438623, 'weights_6': 0.11616071004550858, 'weights_7': 0.8385125811628231, 'weights_8': 0.14571916215038602, 'weights_9': 0.32442450415126184, 'weights_10': 0.05028889132632468, 'weights_11': 0.468019761701656, 'weights_12': 0.013235509750596227, 'weights_13': 0.32374686609472486, 'weights_14': 0.036295221354976724, 'weights_15': 0.8369151154217338, 'weights_16': 0.03423802940929531, 'weights_17': 0.46739688060950113, 'weights_18': 0.03642672036666811, 'weights_19': 0.8994041296958617}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:42,429] Trial 174 finished with value: 2053.513213913277 and parameters: {'weights_0': 0.16618842802720282, 'weights_1': 0.10592632838496939, 'weights_2': 0.036720541421512806, 'weights_3': 0.00011346465977737918, 'weights_4': 0.9021545784879894, 'weights_5': 0.5561748006510947, 'weights_6': 0.11074228971275209, 'weights_7': 0.8350823928249758, 'weights_8': 0.1474267274480373, 'weights_9': 0.4415048903294931, 'weights_10': 0.04814338517274199, 'weights_11': 0.4660249774530237, 'weights_12': 0.0016324027300111468, 'weights_13': 0.2998660777856441, 'weights_14': 0.6975664255598439, 'weights_15': 0.7915825070083637, 'weights_16': 0.09325403016234998, 'weights_17': 0.47966947551765654, 'weights_18': 0.04449749766229999, 'weights_19': 0.8923708990485886}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:42,555] Trial 175 finished with value: 1755.4001310901674 and parameters: {'weights_0': 0.1071271896924572, 'weights_1': 0.14382469627708577, 'weights_2': 0.05530759110801919, 'weights_3': 0.02731981983270587, 'weights_4': 0.9524124525702906, 'weights_5': 0.49845129803491, 'weights_6': 0.12240544568583665, 'weights_7': 0.8496866795525027, 'weights_8': 0.10872209958063604, 'weights_9': 0.3415281949493849, 'weights_10': 0.01966251385642836, 'weights_11': 0.44244241296814785, 'weights_12': 0.01897204829717737, 'weights_13': 0.31795208584759604, 'weights_14': 0.028117957692720304, 'weights_15': 0.8359891680044654, 'weights_16': 0.06603184211138294, 'weights_17': 0.460284288945961, 'weights_18': 0.029635360354162477, 'weights_19': 0.8768989539504928}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:42,706] Trial 176 finished with value: 1793.1652944967157 and parameters: {'weights_0': 0.13324872320665176, 'weights_1': 0.13774958738699739, 'weights_2': 0.08011368780464885, 'weights_3': 0.023387682653237894, 'weights_4': 0.9422294166425927, 'weights_5': 0.5204309058158955, 'weights_6': 0.11876691570446898, 'weights_7': 0.8482945895115295, 'weights_8': 0.11040722809157477, 'weights_9': 0.4011460118034798, 'weights_10': 0.07943700387902458, 'weights_11': 0.4351067611070878, 'weights_12': 0.01775630268873539, 'weights_13': 0.30144138541748555, 'weights_14': 0.0316379654395143, 'weights_15': 0.8725859737668641, 'weights_16': 0.06588616015672416, 'weights_17': 0.4512652144171852, 'weights_18': 0.03427443967896166, 'weights_19': 0.8841848910883063}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:42,837] Trial 177 finished with value: 2192.7307751654553 and parameters: {'weights_0': 0.1347282989982953, 'weights_1': 0.15092913133185812, 'weights_2': 0.07636359590570499, 'weights_3': 0.026361424957260765, 'weights_4': 0.960873066777348, 'weights_5': 0.5207969547755608, 'weights_6': 0.09395966459056986, 'weights_7': 0.8400801115561706, 'weights_8': 0.12430818882204996, 'weights_9': 0.3129094204899894, 'weights_10': 0.875154950102532, 'weights_11': 0.4368408618072347, 'weights_12': 0.017068423884525633, 'weights_13': 0.3255284210005897, 'weights_14': 0.029273834250071046, 'weights_15': 0.8338086721273958, 'weights_16': 0.0697495986406556, 'weights_17': 0.4975030262220655, 'weights_18': 0.034981637070797725, 'weights_19': 0.8465463448039562}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:43,005] Trial 178 finished with value: 1829.2197170669579 and parameters: {'weights_0': 0.15168535755478652, 'weights_1': 0.13542880913072103, 'weights_2': 0.09445739498242739, 'weights_3': 0.00030059096054512943, 'weights_4': 0.9700619974240594, 'weights_5': 0.5457398148059582, 'weights_6': 0.1259061021008836, 'weights_7': 0.8478959571825597, 'weights_8': 0.11396476590816401, 'weights_9': 0.40595516281828325, 'weights_10': 0.1126885959705874, 'weights_11': 0.4303959739898603, 'weights_12': 0.01946806191281388, 'weights_13': 0.24558640058094217, 'weights_14': 0.03523942850491818, 'weights_15': 0.8663356657582355, 'weights_16': 0.09514967971303617, 'weights_17': 0.4458467917711178, 'weights_18': 0.013714002881170598, 'weights_19': 0.8196427792705295}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:43,318] Trial 179 finished with value: 1999.5881508996606 and parameters: {'weights_0': 0.16103035377835903, 'weights_1': 0.13687021970941743, 'weights_2': 0.09342039198649478, 'weights_3': 0.0019184073137958142, 'weights_4': 0.9800330264400575, 'weights_5': 0.5435149345105699, 'weights_6': 0.6536377530743236, 'weights_7': 0.8613477225293392, 'weights_8': 0.1970377629812361, 'weights_9': 0.38954738957009566, 'weights_10': 0.11689464777885172, 'weights_11': 0.5342959721362833, 'weights_12': 0.0002454156915974316, 'weights_13': 0.24411794033979428, 'weights_14': 0.029740932922017748, 'weights_15': 0.8684229235678591, 'weights_16': 0.10358622688269667, 'weights_17': 0.45009364906180566, 'weights_18': 0.012629673348394363, 'weights_19': 0.8233732737584627}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:43,443] Trial 180 finished with value: 1856.6244973237692 and parameters: {'weights_0': 0.18348548394688527, 'weights_1': 0.17895610115026214, 'weights_2': 0.06351085718261736, 'weights_3': 0.022363377425927852, 'weights_4': 0.9549580274302286, 'weights_5': 0.4795990368330702, 'weights_6': 0.12535503111308172, 'weights_7': 0.7953190607300694, 'weights_8': 0.13378294609684815, 'weights_9': 0.4003043369311746, 'weights_10': 0.13686059765417283, 'weights_11': 0.44721336520510063, 'weights_12': 0.01775291652107504, 'weights_13': 0.25575616323916217, 'weights_14': 0.07772368589044265, 'weights_15': 0.8697979500699632, 'weights_16': 0.06314149707096484, 'weights_17': 0.4510476924609513, 'weights_18': 0.0014588244480140816, 'weights_19': 0.8765365131286385}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:43,589] Trial 181 finished with value: 1812.4295986679722 and parameters: {'weights_0': 0.1466101348930512, 'weights_1': 0.12394758896911012, 'weights_2': 0.05771532154104008, 'weights_3': 0.040646040741863496, 'weights_4': 0.9361933427586479, 'weights_5': 0.5244467249162784, 'weights_6': 0.15103688475064114, 'weights_7': 0.845813263335289, 'weights_8': 0.10863902182965346, 'weights_9': 0.3588338068802436, 'weights_10': 0.0824106873007935, 'weights_11': 0.4228990305215322, 'weights_12': 0.02269902316786259, 'weights_13': 0.3028657461234389, 'weights_14': 0.0481601247443629, 'weights_15': 0.8430443382214141, 'weights_16': 0.04463674765769892, 'weights_17': 0.46322134768365175, 'weights_18': 0.03370443329880466, 'weights_19': 0.836874476383564}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:43,729] Trial 182 finished with value: 1809.2974454751998 and parameters: {'weights_0': 0.1471927248221615, 'weights_1': 0.14732955963729735, 'weights_2': 0.08756650261840221, 'weights_3': 0.0007279165319141812, 'weights_4': 0.9233511554603566, 'weights_5': 0.5961344386610107, 'weights_6': 0.09614966821903925, 'weights_7': 0.849876563863578, 'weights_8': 0.10361360128252868, 'weights_9': 0.3620889917967729, 'weights_10': 0.09357609438074264, 'weights_11': 0.42754258895735286, 'weights_12': 0.015435126424845708, 'weights_13': 0.2988334781029503, 'weights_14': 0.039505209365393, 'weights_15': 0.853495153190775, 'weights_16': 0.0866269750007001, 'weights_17': 0.5276616019604773, 'weights_18': 0.021337844914853403, 'weights_19': 0.8785012400337161}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:43,880] Trial 183 finished with value: 1875.6384162910788 and parameters: {'weights_0': 0.20380073717316555, 'weights_1': 0.15712673640496705, 'weights_2': 0.11598969438457181, 'weights_3': 0.013100082623222115, 'weights_4': 0.9199170330407672, 'weights_5': 0.5934164842259142, 'weights_6': 0.09927826135654608, 'weights_7': 0.8487702418729832, 'weights_8': 0.10591466766181151, 'weights_9': 0.35218060982826493, 'weights_10': 0.15401330478849923, 'weights_11': 0.4233987055091677, 'weights_12': 0.016114914431220265, 'weights_13': 0.3118988601752253, 'weights_14': 0.02796796176921106, 'weights_15': 0.852715296597716, 'weights_16': 0.0848644407572187, 'weights_17': 0.5358557582102886, 'weights_18': 0.03369786175666291, 'weights_19': 0.843296619320052}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,076] Trial 184 finished with value: 1797.0959345668502 and parameters: {'weights_0': 0.13326860114601524, 'weights_1': 0.19052555500770652, 'weights_2': 0.09005156606300752, 'weights_3': 0.023454371151606968, 'weights_4': 0.9400006920559006, 'weights_5': 0.5117211429945879, 'weights_6': 0.11820637399881426, 'weights_7': 0.8188507225060925, 'weights_8': 0.06241955136870883, 'weights_9': 0.31499398000802126, 'weights_10': 0.09997487837513258, 'weights_11': 0.49098655747534603, 'weights_12': 0.02378095761466184, 'weights_13': 0.26285831050592645, 'weights_14': 0.000944515110262549, 'weights_15': 0.8984381229468108, 'weights_16': 0.05158923529051258, 'weights_17': 0.5128300506458541, 'weights_18': 0.019875819733409256, 'weights_19': 0.8280237592551708}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,301] Trial 185 finished with value: 1863.9677652960302 and parameters: {'weights_0': 0.15130913865032652, 'weights_1': 0.12776885589109968, 'weights_2': 0.13514260277065177, 'weights_3': 0.03438187197879761, 'weights_4': 0.9417144934519778, 'weights_5': 0.5089813177042749, 'weights_6': 0.12343257565883459, 'weights_7': 0.8234948408329181, 'weights_8': 0.06940282427105438, 'weights_9': 0.31107020835200566, 'weights_10': 0.10366137071774999, 'weights_11': 0.4188801292437402, 'weights_12': 0.028251407871038543, 'weights_13': 0.28206464242343693, 'weights_14': 0.015633279921153695, 'weights_15': 0.9284070209724968, 'weights_16': 0.11135821072543428, 'weights_17': 0.5215023129004625, 'weights_18': 0.01969080032481015, 'weights_19': 0.8255071065223019}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,457] Trial 186 finished with value: 1805.6187456055864 and parameters: {'weights_0': 0.13432267871047537, 'weights_1': 0.1556861723219768, 'weights_2': 0.09214079033755054, 'weights_3': 0.05743866893872534, 'weights_4': 0.9748944386775235, 'weights_5': 0.46381665193522353, 'weights_6': 0.10106059054511879, 'weights_7': 0.8800645346778612, 'weights_8': 0.022470791523912348, 'weights_9': 0.33635238751022567, 'weights_10': 0.11802641457344631, 'weights_11': 0.4497639933356728, 'weights_12': 0.023253124496821154, 'weights_13': 0.2253920281768786, 'weights_14': 0.0004354117262653813, 'weights_15': 0.8955869562080965, 'weights_16': 0.08416109372394817, 'weights_17': 0.4652564497391684, 'weights_18': 0.04270998353347785, 'weights_19': 0.8745876982452588}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,584] Trial 187 finished with value: 1829.0072445090518 and parameters: {'weights_0': 0.1387787242538198, 'weights_1': 0.18955125931834405, 'weights_2': 0.09788103588817917, 'weights_3': 0.06165310490329649, 'weights_4': 0.9729195685435285, 'weights_5': 0.4584832201630985, 'weights_6': 0.09961412368538913, 'weights_7': 0.9096803184436812, 'weights_8': 0.03964600912607846, 'weights_9': 0.28755684544812854, 'weights_10': 0.1228651418225607, 'weights_11': 0.43232465318306496, 'weights_12': 0.020070920958158395, 'weights_13': 0.23075665659904365, 'weights_14': 0.0438071203202086, 'weights_15': 0.8967418117674196, 'weights_16': 0.0888016875414902, 'weights_17': 0.4899809721522998, 'weights_18': 0.022363731110005974, 'weights_19': 0.876271552351944}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,728] Trial 188 finished with value: 1858.4901159665585 and parameters: {'weights_0': 0.19249808637175445, 'weights_1': 0.18232903195787634, 'weights_2': 0.11359667607565263, 'weights_3': 0.06038237951910442, 'weights_4': 0.9981336143955427, 'weights_5': 0.49277010250712416, 'weights_6': 0.10154566168631418, 'weights_7': 0.8757159275346396, 'weights_8': 0.03172147934046895, 'weights_9': 0.2824376647436136, 'weights_10': 0.1186450447794207, 'weights_11': 0.4524512691668033, 'weights_12': 0.021540722688153824, 'weights_13': 0.21759355202776776, 'weights_14': 0.03642004407560704, 'weights_15': 0.9076262955883941, 'weights_16': 0.09936581606114622, 'weights_17': 0.5705706171017907, 'weights_18': 0.013387688511803839, 'weights_19': 0.8721698071011392}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,872] Trial 189 finished with value: 1826.6352898852206 and parameters: {'weights_0': 0.1715881448274446, 'weights_1': 0.17001169729735444, 'weights_2': 0.15675728039372636, 'weights_3': 0.05657314428795919, 'weights_4': 0.9781974214122295, 'weights_5': 0.43467720867664805, 'weights_6': 0.12204861596977426, 'weights_7': 0.9051978807574994, 'weights_8': 0.045555779894405624, 'weights_9': 0.3296116200811261, 'weights_10': 0.08986781848848978, 'weights_11': 0.437746289570976, 'weights_12': 0.00011508573832387514, 'weights_13': 0.21861182774327403, 'weights_14': 0.00018781467645955646, 'weights_15': 0.9670208928143972, 'weights_16': 0.0795350615125533, 'weights_17': 0.5436230486114657, 'weights_18': 0.03978791256981578, 'weights_19': 0.853162950091679}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:44,999] Trial 190 finished with value: 1849.6897142442378 and parameters: {'weights_0': 0.15021495997573134, 'weights_1': 0.1818372751252489, 'weights_2': 0.15184438535455103, 'weights_3': 0.05749475513119545, 'weights_4': 0.9755463631918285, 'weights_5': 0.4467968264473542, 'weights_6': 0.1272052828513605, 'weights_7': 0.9050689677699424, 'weights_8': 0.04532516528122289, 'weights_9': 0.33393703739124336, 'weights_10': 0.09321451832336518, 'weights_11': 0.4325730070099538, 'weights_12': 0.000304591105236892, 'weights_13': 0.16529978355728628, 'weights_14': 0.023052794802410376, 'weights_15': 0.958566021546507, 'weights_16': 0.13019393528802753, 'weights_17': 0.49302277316891807, 'weights_18': 0.04106817759789194, 'weights_19': 0.8554142935149381}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:45,158] Trial 191 finished with value: 1833.0875036939544 and parameters: {'weights_0': 0.1761277015226887, 'weights_1': 0.20765807312797363, 'weights_2': 0.08668646006618438, 'weights_3': 0.03881778385981356, 'weights_4': 0.9689314234853165, 'weights_5': 0.4703963954568634, 'weights_6': 0.1486568068797527, 'weights_7': 0.9302260807937065, 'weights_8': 0.018994940080429894, 'weights_9': 0.3504668811453422, 'weights_10': 0.1384466149093409, 'weights_11': 0.4865866302215994, 'weights_12': 0.02159561967241367, 'weights_13': 0.26941025373456334, 'weights_14': 0.00356548021850151, 'weights_15': 0.8987395689023017, 'weights_16': 0.07748455538302933, 'weights_17': 0.5521744673079028, 'weights_18': 0.024328933627301666, 'weights_19': 0.8285253828082187}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:45,335] Trial 192 finished with value: 1842.9108236378922 and parameters: {'weights_0': 0.17358201641052023, 'weights_1': 0.22794780854575758, 'weights_2': 0.08720242594710907, 'weights_3': 0.03847250632840775, 'weights_4': 0.9659190867530013, 'weights_5': 0.4568078847744979, 'weights_6': 0.14494555462404224, 'weights_7': 0.9301729335109501, 'weights_8': 0.027283043869042047, 'weights_9': 0.35856466583243957, 'weights_10': 0.13931031229386875, 'weights_11': 0.4964484560030776, 'weights_12': 0.03497975073683873, 'weights_13': 0.23608366359652813, 'weights_14': 0.04416141886034859, 'weights_15': 0.9904888615533863, 'weights_16': 0.08381354927780166, 'weights_17': 0.5589430995545945, 'weights_18': 0.0025688825408333987, 'weights_19': 0.8836925579785293}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:45,450] Trial 193 finished with value: 1832.53013913248 and parameters: {'weights_0': 0.1783019150815882, 'weights_1': 0.22872257964037454, 'weights_2': 0.12757328953037658, 'weights_3': 0.047173968558012244, 'weights_4': 0.9691951352255214, 'weights_5': 0.46187061795313783, 'weights_6': 0.14933989597368455, 'weights_7': 0.9144736128441856, 'weights_8': 0.029413154150434995, 'weights_9': 0.35909540660411093, 'weights_10': 0.13655668757873654, 'weights_11': 0.5099164552319173, 'weights_12': 9.884260636848865e-05, 'weights_13': 0.22664628412182342, 'weights_14': 5.1769517559540484e-05, 'weights_15': 0.9656362965814067, 'weights_16': 0.09147808869977898, 'weights_17': 0.5586142665861318, 'weights_18': 0.0014339268272440253, 'weights_19': 0.8343845339633646}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:45,593] Trial 194 finished with value: 1874.1857547440202 and parameters: {'weights_0': 0.21253995761365446, 'weights_1': 0.24187477663920554, 'weights_2': 0.1324358674233946, 'weights_3': 0.06566843594437695, 'weights_4': 0.9440980258867433, 'weights_5': 0.3904242187537677, 'weights_6': 0.11717156149231074, 'weights_7': 0.967412405470567, 'weights_8': 0.05160871793308397, 'weights_9': 0.32347380141536347, 'weights_10': 0.12972491427533475, 'weights_11': 0.46344485765122656, 'weights_12': 0.015991472642198988, 'weights_13': 0.27333560693782205, 'weights_14': 0.019623675093149124, 'weights_15': 0.9696521562452999, 'weights_16': 0.11439991876434194, 'weights_17': 0.5134797271332092, 'weights_18': 0.02416026763973761, 'weights_19': 0.8318695112074765}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:45,699] Trial 195 finished with value: 1871.7277822865037 and parameters: {'weights_0': 0.1766584902759576, 'weights_1': 0.20498100008589776, 'weights_2': 0.11030497978352446, 'weights_3': 0.050758078028224504, 'weights_4': 0.97961177685569, 'weights_5': 0.472036971252993, 'weights_6': 0.1416064472553934, 'weights_7': 0.9166667878148899, 'weights_8': 0.07114417026520642, 'weights_9': 0.30311661075254126, 'weights_10': 0.177759671969564, 'weights_11': 0.5197826928018522, 'weights_12': 0.0011232136160248556, 'weights_13': 0.2652394913891883, 'weights_14': 0.0035487297636991183, 'weights_15': 0.9409881048498975, 'weights_16': 0.08629293740135136, 'weights_17': 0.5807987932165725, 'weights_18': 0.0450216479192982, 'weights_19': 0.7904758281631381}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:45,847] Trial 196 finished with value: 1863.8378785215932 and parameters: {'weights_0': 0.14668690763032063, 'weights_1': 0.19716184792225883, 'weights_2': 0.15801372088018087, 'weights_3': 0.07407010474769266, 'weights_4': 0.9160094061944811, 'weights_5': 0.43130075457086736, 'weights_6': 0.1526998193982791, 'weights_7': 0.8672202208547967, 'weights_8': 0.02582802083687705, 'weights_9': 0.38224352207975815, 'weights_10': 0.15656206911277096, 'weights_11': 0.4813481296345511, 'weights_12': 0.03867145465559417, 'weights_13': 0.19859237592954695, 'weights_14': 0.0025011339274311375, 'weights_15': 0.9248682416396911, 'weights_16': 0.06530305671779464, 'weights_17': 0.5470729544703977, 'weights_18': 0.02737109711507924, 'weights_19': 0.8129234802080574}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,049] Trial 197 finished with value: 1893.8176253003023 and parameters: {'weights_0': 0.22784636098137603, 'weights_1': 0.22041290269418762, 'weights_2': 0.1730727589284317, 'weights_3': 0.02983809407701348, 'weights_4': 0.9984795327331095, 'weights_5': 0.4620429333241732, 'weights_6': 0.09403107654187663, 'weights_7': 0.89127403215292, 'weights_8': 0.08818011267263916, 'weights_9': 0.34625491730911884, 'weights_10': 0.102111514852594, 'weights_11': 0.44196567958007416, 'weights_12': 0.020981823204703154, 'weights_13': 0.2984566139681944, 'weights_14': 0.03580365778212189, 'weights_15': 0.8955882328435335, 'weights_16': 0.10260588917193718, 'weights_17': 0.5246154697380098, 'weights_18': 0.05116514459395906, 'weights_19': 0.9039611531033815}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,179] Trial 198 finished with value: 1818.5845142243409 and parameters: {'weights_0': 0.13158078774580437, 'weights_1': 0.2606891096849126, 'weights_2': 0.10096371061464912, 'weights_3': 0.0492456076253517, 'weights_4': 0.9575739667009301, 'weights_5': 0.5130476176084808, 'weights_6': 0.11938769217147024, 'weights_7': 0.8496829489823106, 'weights_8': 0.04693023239800037, 'weights_9': 0.43097634670171736, 'weights_10': 0.11193645397316, 'weights_11': 0.4982861006056046, 'weights_12': 0.052638988804190275, 'weights_13': 0.3457887389405978, 'weights_14': 0.00027262738103406547, 'weights_15': 0.9064512149638336, 'weights_16': 0.059211868829222414, 'weights_17': 0.6013640868796013, 'weights_18': 0.002808038600669579, 'weights_19': 0.8574660123706981}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,290] Trial 199 finished with value: 1907.9485897244333 and parameters: {'weights_0': 0.1337907145933993, 'weights_1': 0.2697907732374959, 'weights_2': 0.1292118985396252, 'weights_3': 0.04736528910408598, 'weights_4': 0.9619482741129289, 'weights_5': 0.5199132714785738, 'weights_6': 0.1110423417979761, 'weights_7': 0.8437006782960035, 'weights_8': 0.040747428706338046, 'weights_9': 0.392651904724549, 'weights_10': 0.19244918751014572, 'weights_11': 0.18212712616420068, 'weights_12': 0.00018429614585586593, 'weights_13': 0.3436702084493973, 'weights_14': 0.02417714531847365, 'weights_15': 0.9109819513879902, 'weights_16': 0.07976717551752109, 'weights_17': 0.6129608242467628, 'weights_18': 0.00011406690038274006, 'weights_19': 0.8538302968828811}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,432] Trial 200 finished with value: 1893.611652491667 and parameters: {'weights_0': 0.19636111229912012, 'weights_1': 0.1611534024133117, 'weights_2': 0.09835599532491471, 'weights_3': 0.023944005181039566, 'weights_4': 0.9387530843936434, 'weights_5': 0.3493190276210386, 'weights_6': 0.16113336008799273, 'weights_7': 0.8599043549739811, 'weights_8': 0.05573979180266498, 'weights_9': 0.41881014588620263, 'weights_10': 0.11987462635476885, 'weights_11': 0.4970955100440369, 'weights_12': 0.05172111893066514, 'weights_13': 0.2895068086229967, 'weights_14': 0.0003189073396433935, 'weights_15': 0.9984030760069119, 'weights_16': 0.15250624301828594, 'weights_17': 0.5884074816648878, 'weights_18': 0.02057143370371375, 'weights_19': 0.8658476569004527}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,562] Trial 201 finished with value: 2058.1626724924654 and parameters: {'weights_0': 0.17009593832431327, 'weights_1': 0.1850275659441807, 'weights_2': 0.08151509635264069, 'weights_3': 0.06486785515712438, 'weights_4': 0.9098768960777636, 'weights_5': 0.49330234867635275, 'weights_6': 0.1276720915379901, 'weights_7': 0.9364816098373868, 'weights_8': 0.018286684205014433, 'weights_9': 0.36772540065632014, 'weights_10': 0.1438247999514913, 'weights_11': 0.4753414752859995, 'weights_12': 0.03453472798545608, 'weights_13': 0.2303908913469087, 'weights_14': 0.041937023586295655, 'weights_15': 0.94640766296675, 'weights_16': 0.5150227381110029, 'weights_17': 0.47047665618280315, 'weights_18': 0.037470795248153936, 'weights_19': 0.8837379075416733}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,662] Trial 202 finished with value: 1794.271064969812 and parameters: {'weights_0': 0.13344056739186266, 'weights_1': 0.21313795697939758, 'weights_2': 0.10976113605862667, 'weights_3': 0.04309865175049756, 'weights_4': 0.9530590206940551, 'weights_5': 0.4381893574893908, 'weights_6': 0.09122820162897632, 'weights_7': 0.8784790262693594, 'weights_8': 0.07058943330567591, 'weights_9': 0.25101062937739693, 'weights_10': 0.09188171948569271, 'weights_11': 0.4615209722874867, 'weights_12': 0.02091594009374577, 'weights_13': 0.18643390224211967, 'weights_14': 0.0003708658398251562, 'weights_15': 0.8818183079769998, 'weights_16': 0.061018455286070146, 'weights_17': 0.5622329569004042, 'weights_18': 0.018052668044429045, 'weights_19': 0.8354872815515857}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,812] Trial 203 finished with value: 1797.6834642677231 and parameters: {'weights_0': 0.13309022258989936, 'weights_1': 0.21776223027542907, 'weights_2': 0.14282594949324265, 'weights_3': 0.032599809000198196, 'weights_4': 0.9538069832465923, 'weights_5': 0.4046152120136381, 'weights_6': 0.0874021120638053, 'weights_7': 0.8839923630350703, 'weights_8': 0.062404988532743795, 'weights_9': 0.25887023442470464, 'weights_10': 0.08892884004354662, 'weights_11': 0.421228456473291, 'weights_12': 0.019886227614659226, 'weights_13': 0.1815135294337152, 'weights_14': 8.755548034478414e-06, 'weights_15': 0.8959168948033747, 'weights_16': 0.061525230937878234, 'weights_17': 0.5712015116812826, 'weights_18': 0.0016119190567414217, 'weights_19': 0.8336196766321577}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:46,934] Trial 204 finished with value: 1862.1677935483713 and parameters: {'weights_0': 0.13600523469684142, 'weights_1': 0.23258261361584104, 'weights_2': 0.18445656690230128, 'weights_3': 0.04535120429465111, 'weights_4': 0.9740304103406093, 'weights_5': 0.4261127253537059, 'weights_6': 0.09320971036607592, 'weights_7': 0.9030970604842701, 'weights_8': 0.07812699713126843, 'weights_9': 0.24897654712403025, 'weights_10': 0.11118350726907116, 'weights_11': 0.410612634301466, 'weights_12': 0.05417432487172527, 'weights_13': 0.1779608538020633, 'weights_14': 0.023356094213496353, 'weights_15': 0.9014173329798465, 'weights_16': 0.0667557791662051, 'weights_17': 0.6011620403765209, 'weights_18': 0.01840635061891508, 'weights_19': 0.8409441821744018}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,054] Trial 205 finished with value: 2142.538113290852 and parameters: {'weights_0': 0.15828525310757224, 'weights_1': 0.19927328823500404, 'weights_2': 0.14051028624260922, 'weights_3': 0.036775139308711124, 'weights_4': 0.9553305838253789, 'weights_5': 0.39881587053121614, 'weights_6': 0.08474177742485134, 'weights_7': 0.8798517042682714, 'weights_8': 0.05899592752348399, 'weights_9': 0.2918215322898976, 'weights_10': 0.08590179300027126, 'weights_11': 0.5169981520842444, 'weights_12': 0.6640725150060321, 'weights_13': 0.14274266093290341, 'weights_14': 0.05368108485200343, 'weights_15': 0.942852186207999, 'weights_16': 0.12298677822091329, 'weights_17': 0.5662254186834269, 'weights_18': 0.018254141609084264, 'weights_19': 0.8018469666826734}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,191] Trial 206 finished with value: 1853.4057704047088 and parameters: {'weights_0': 0.12465914353000244, 'weights_1': 0.1683251141066659, 'weights_2': 0.11361503360494168, 'weights_3': 0.08228505723789906, 'weights_4': 0.9357953779405758, 'weights_5': 0.44607467391081723, 'weights_6': 0.11068552821779357, 'weights_7': 0.8512976619583644, 'weights_8': 0.03687934539243158, 'weights_9': 0.26092575202626855, 'weights_10': 0.09752493634664981, 'weights_11': 0.4273467329290871, 'weights_12': 0.020419958844994777, 'weights_13': 0.12794691974798544, 'weights_14': 0.036624279499161125, 'weights_15': 0.8818716708083687, 'weights_16': 0.09384366743705361, 'weights_17': 0.6272641958038943, 'weights_18': 0.05379586778962947, 'weights_19': 0.8269385702984211}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,337] Trial 207 finished with value: 1820.8569981337644 and parameters: {'weights_0': 0.1833526114929172, 'weights_1': 0.20629013175782657, 'weights_2': 0.10118761556935052, 'weights_3': 0.05484062632477655, 'weights_4': 0.9805597003333536, 'weights_5': 0.4705490944263007, 'weights_6': 0.05459508524226674, 'weights_7': 0.8269244293874649, 'weights_8': 0.09426320126235543, 'weights_9': 0.32593571772690577, 'weights_10': 0.13248302465516107, 'weights_11': 0.5431380697739773, 'weights_12': 0.03622942940418441, 'weights_13': 0.3184122252247136, 'weights_14': 0.002483731820895889, 'weights_15': 0.9242370325013374, 'weights_16': 0.05956872883703965, 'weights_17': 0.554752712899663, 'weights_18': 0.0010016681310562534, 'weights_19': 0.8633018787947634}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,450] Trial 208 finished with value: 1860.0185390487434 and parameters: {'weights_0': 0.13625654721018166, 'weights_1': 0.25270116976996654, 'weights_2': 0.14969876909817323, 'weights_3': 0.06080069515872638, 'weights_4': 0.9999295170102138, 'weights_5': 0.5146343829040713, 'weights_6': 0.05556951500991962, 'weights_7': 0.8203092266372367, 'weights_8': 0.08845279230796123, 'weights_9': 0.32440824346366554, 'weights_10': 0.16476277280616236, 'weights_11': 0.5438109858338905, 'weights_12': 0.043200369825761455, 'weights_13': 0.31523218902463473, 'weights_14': 0.05627309299555327, 'weights_15': 0.9344501949148192, 'weights_16': 0.05484949697506365, 'weights_17': 0.5668805584922578, 'weights_18': 0.0015097387688779648, 'weights_19': 0.8588928575647734}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,639] Trial 209 finished with value: 1819.6962244460124 and parameters: {'weights_0': 0.11055093711086393, 'weights_1': 0.15168291168239317, 'weights_2': 0.1295692069826057, 'weights_3': 0.01926804610898524, 'weights_4': 0.9492608315768184, 'weights_5': 0.5708557530804018, 'weights_6': 0.07737313707757901, 'weights_7': 0.8094760023053845, 'weights_8': 0.1017610022769963, 'weights_9': 0.43166814528868985, 'weights_10': 0.12043839266897706, 'weights_11': 0.4432185210222225, 'weights_12': 0.05469529608567625, 'weights_13': 0.3328394139330971, 'weights_14': 0.0003648261563741987, 'weights_15': 0.9684028659991025, 'weights_16': 0.05297557209466317, 'weights_17': 0.595887435708591, 'weights_18': 0.041546171169218035, 'weights_19': 0.8978057413661473}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,788] Trial 210 finished with value: 1801.2434110558834 and parameters: {'weights_0': 0.11535183607082067, 'weights_1': 0.14341455518317578, 'weights_2': 0.10436171909923816, 'weights_3': 0.02205601705247028, 'weights_4': 0.9153113015426301, 'weights_5': 0.5758090447946502, 'weights_6': 0.04201911066652496, 'weights_7': 0.8104308177917703, 'weights_8': 0.09530742591273421, 'weights_9': 0.4302968053294089, 'weights_10': 0.11246942352389847, 'weights_11': 0.44208447665635897, 'weights_12': 0.05395826189532382, 'weights_13': 0.35928880414972136, 'weights_14': 0.022304604692493322, 'weights_15': 0.9178016127681398, 'weights_16': 0.05575168192227545, 'weights_17': 0.4883489086766378, 'weights_18': 0.04351136180659691, 'weights_19': 0.907017003568877}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:47,914] Trial 211 finished with value: 1925.983938938925 and parameters: {'weights_0': 0.11434139402994101, 'weights_1': 0.15294431525194105, 'weights_2': 0.11058087493132743, 'weights_3': 0.019144834133184595, 'weights_4': 0.9184110061249782, 'weights_5': 0.5595403640650561, 'weights_6': 0.04242511159087108, 'weights_7': 0.8209208720663483, 'weights_8': 0.10406759386466989, 'weights_9': 0.4258709598457308, 'weights_10': 0.11038263805431676, 'weights_11': 0.43762775092926554, 'weights_12': 0.06301241086343913, 'weights_13': 0.35753744143067223, 'weights_14': 0.33047432960165757, 'weights_15': 0.925525040168426, 'weights_16': 0.05086171542429491, 'weights_17': 0.49266743824786624, 'weights_18': 0.0448779875374512, 'weights_19': 0.9011392692994362}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,032] Trial 212 finished with value: 1819.8861604578422 and parameters: {'weights_0': 0.15154312594846492, 'weights_1': 0.142256334753597, 'weights_2': 0.10312998408786252, 'weights_3': 0.016006418725310546, 'weights_4': 0.9427791896419085, 'weights_5': 0.5785766265362791, 'weights_6': 0.07559248378913033, 'weights_7': 0.8037254805937273, 'weights_8': 0.0780020189740151, 'weights_9': 0.4515269647635101, 'weights_10': 0.08264388974122895, 'weights_11': 0.41591614254133846, 'weights_12': 0.03900220731828723, 'weights_13': 0.32590088424418034, 'weights_14': 0.03373184138243601, 'weights_15': 0.9153364688304837, 'weights_16': 0.06287192868508445, 'weights_17': 0.45923248572805137, 'weights_18': 0.05993490296996819, 'weights_19': 0.8760143155769978}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,193] Trial 213 finished with value: 1807.80283654889 and parameters: {'weights_0': 0.14367261353749308, 'weights_1': 0.17111445570014583, 'weights_2': 0.09443509264188701, 'weights_3': 0.016478971576118558, 'weights_4': 0.9419531844516733, 'weights_5': 0.5398723098930244, 'weights_6': 0.07844152786175432, 'weights_7': 0.8397529900774535, 'weights_8': 0.07715897701809665, 'weights_9': 0.45692937202534156, 'weights_10': 0.07853299511049143, 'weights_11': 0.41424025633686157, 'weights_12': 0.037697659068510345, 'weights_13': 0.32970675883449246, 'weights_14': 0.02534099085211042, 'weights_15': 0.9175236428030873, 'weights_16': 0.06488761259843959, 'weights_17': 0.6035611484195695, 'weights_18': 0.03767678054824222, 'weights_19': 0.8776910026867866}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,320] Trial 214 finished with value: 2147.9167248186664 and parameters: {'weights_0': 0.12641861605494975, 'weights_1': 0.17945610001293205, 'weights_2': 0.07485161020542738, 'weights_3': 0.02071428402985316, 'weights_4': 0.9446732407344743, 'weights_5': 0.5769396945772244, 'weights_6': 0.06907843824451165, 'weights_7': 0.8049145492010243, 'weights_8': 0.07382850387905085, 'weights_9': 0.4736361637851244, 'weights_10': 0.08055874148105942, 'weights_11': 0.40824138949597905, 'weights_12': 0.8385444429133488, 'weights_13': 0.32733165564961314, 'weights_14': 0.017616911822154312, 'weights_15': 0.9149419693103118, 'weights_16': 0.060207563942883985, 'weights_17': 0.6557661131538746, 'weights_18': 0.05706311755187439, 'weights_19': 0.8786706373897499}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,457] Trial 215 finished with value: 1801.688991452721 and parameters: {'weights_0': 0.1506010715793228, 'weights_1': 0.1584807314398901, 'weights_2': 0.12676681417644117, 'weights_3': 0.020774245764253452, 'weights_4': 0.9037172895189056, 'weights_5': 0.5722956316538467, 'weights_6': 0.07957535606029215, 'weights_7': 0.8705187250060191, 'weights_8': 0.059772695434166974, 'weights_9': 0.443315505739154, 'weights_10': 0.07909042209361675, 'weights_11': 0.45448984006904686, 'weights_12': 0.059378926197684034, 'weights_13': 0.33912662890389755, 'weights_14': 0.00020959595305745926, 'weights_15': 0.9768051590406092, 'weights_16': 0.06635907856349323, 'weights_17': 0.602126296272922, 'weights_18': 0.0350426283133462, 'weights_19': 0.9125711117311097}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,629] Trial 216 finished with value: 1780.364649794487 and parameters: {'weights_0': 0.11025326465834959, 'weights_1': 0.14986485779630768, 'weights_2': 0.1596336451454769, 'weights_3': 0.020091712565094736, 'weights_4': 0.9022487775426548, 'weights_5': 0.6136724099419955, 'weights_6': 0.03200939386816244, 'weights_7': 0.8346648083405006, 'weights_8': 0.09703668080542364, 'weights_9': 0.44547710666729134, 'weights_10': 0.07619474921356008, 'weights_11': 0.4555494724253554, 'weights_12': 0.05674556270639976, 'weights_13': 0.3397057011414809, 'weights_14': 0.0008347345293868219, 'weights_15': 0.9810841146902428, 'weights_16': 0.046810186254203905, 'weights_17': 0.5947321752298946, 'weights_18': 0.039784688861014564, 'weights_19': 0.9068467131228146}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,734] Trial 217 finished with value: 1790.9170459942386 and parameters: {'weights_0': 0.10994670622356463, 'weights_1': 0.1532443543702144, 'weights_2': 0.13276156679816736, 'weights_3': 0.016329538077877355, 'weights_4': 0.904950759935731, 'weights_5': 0.6081898005018651, 'weights_6': 0.03799448754155266, 'weights_7': 0.828949676481264, 'weights_8': 0.09408042299553895, 'weights_9': 0.45770999896187425, 'weights_10': 0.06891882228778123, 'weights_11': 0.454411195478957, 'weights_12': 0.05776870164797368, 'weights_13': 0.37715134230895275, 'weights_14': 0.020940179772609195, 'weights_15': 0.9836710560748101, 'weights_16': 0.045746677176599734, 'weights_17': 0.5978971769444181, 'weights_18': 0.061149669223315085, 'weights_19': 0.918480202924401}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:48,882] Trial 218 finished with value: 1812.9907039134794 and parameters: {'weights_0': 0.1476051670357404, 'weights_1': 0.13848326872531036, 'weights_2': 0.18988542279061466, 'weights_3': 0.0002291333500348408, 'weights_4': 0.8986252404772731, 'weights_5': 0.6060150617786204, 'weights_6': 0.0206864523077713, 'weights_7': 0.8321061455969957, 'weights_8': 0.08831414857874931, 'weights_9': 0.45378329110686566, 'weights_10': 0.07103260153282613, 'weights_11': 0.47028986325515576, 'weights_12': 0.06515239615751486, 'weights_13': 0.3838067831169768, 'weights_14': 0.025482749407558958, 'weights_15': 0.986598989301772, 'weights_16': 0.046454950405451195, 'weights_17': 0.606584072503727, 'weights_18': 0.059323848169575644, 'weights_19': 0.910831978419995}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,007] Trial 219 finished with value: 1856.884384112023 and parameters: {'weights_0': 0.11362788908153484, 'weights_1': 0.15037199869712506, 'weights_2': 0.16680406168064377, 'weights_3': 0.4566865580356593, 'weights_4': 0.904302272929358, 'weights_5': 0.5721337575798106, 'weights_6': 0.016963903757274783, 'weights_7': 0.8349209320514452, 'weights_8': 0.0914275789820091, 'weights_9': 0.45319100929124456, 'weights_10': 0.08074839848743975, 'weights_11': 0.454770912902952, 'weights_12': 0.07125517795444844, 'weights_13': 0.37264225039138665, 'weights_14': 0.022303036698517725, 'weights_15': 0.9720694773549431, 'weights_16': 0.056845453216204475, 'weights_17': 0.6001447200953148, 'weights_18': 0.05408623682789402, 'weights_19': 0.9117818724291041}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,157] Trial 220 finished with value: 1801.9945316173437 and parameters: {'weights_0': 0.1549149357158114, 'weights_1': 0.1458174977761263, 'weights_2': 0.18385350129494923, 'weights_3': 0.016594753731050807, 'weights_4': 0.9236773937348328, 'weights_5': 0.613166780699181, 'weights_6': 0.02651616559473244, 'weights_7': 0.8066772212543949, 'weights_8': 0.07161936496562696, 'weights_9': 0.4804136022770571, 'weights_10': 0.06592606648561919, 'weights_11': 0.4697094532187916, 'weights_12': 0.06375165307803589, 'weights_13': 0.35108432898742553, 'weights_14': 0.00011882445963240854, 'weights_15': 0.9939322384677398, 'weights_16': 0.04873355260240156, 'weights_17': 0.6241325287500019, 'weights_18': 0.03915845565883749, 'weights_19': 0.8971063305502738}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,304] Trial 221 finished with value: 1800.4311449635693 and parameters: {'weights_0': 0.15182601248947963, 'weights_1': 0.1520384873576197, 'weights_2': 0.19216120633985173, 'weights_3': 0.0022643222865802934, 'weights_4': 0.9205373560546519, 'weights_5': 0.6145146091535921, 'weights_6': 0.018016515257668307, 'weights_7': 0.8013723308207933, 'weights_8': 0.06660197448155794, 'weights_9': 0.43090313883585474, 'weights_10': 0.0682606204868049, 'weights_11': 0.46596158352292055, 'weights_12': 0.059863000309306, 'weights_13': 0.34214321599844655, 'weights_14': 5.211718664625831e-05, 'weights_15': 0.9970703129739455, 'weights_16': 0.044988597927329045, 'weights_17': 0.6254811339365072, 'weights_18': 0.036799696539806526, 'weights_19': 0.9021990080644258}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,462] Trial 222 finished with value: 1821.4424711007716 and parameters: {'weights_0': 0.1561514550052155, 'weights_1': 0.14311091325677458, 'weights_2': 0.19060061064644798, 'weights_3': 0.012143039036943474, 'weights_4': 0.9038494140318076, 'weights_5': 0.6058501661017217, 'weights_6': 0.020826781786821874, 'weights_7': 0.8011111448320114, 'weights_8': 0.06845560840813766, 'weights_9': 0.43716933328751856, 'weights_10': 0.07289642673721283, 'weights_11': 0.4693892024042983, 'weights_12': 0.0619466562901838, 'weights_13': 0.34274798202681506, 'weights_14': 0.022083344426920025, 'weights_15': 0.9700798575593199, 'weights_16': 0.046685426264886545, 'weights_17': 0.633231359327875, 'weights_18': 0.06044429435416896, 'weights_19': 0.910754237594448}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,586] Trial 223 finished with value: 1797.3217981035405 and parameters: {'weights_0': 0.12879346841882164, 'weights_1': 0.15988720406285697, 'weights_2': 0.24470033217921242, 'weights_3': 0.002176906784173996, 'weights_4': 0.9258955106473808, 'weights_5': 0.6287381496278173, 'weights_6': 0.0005689852517972126, 'weights_7': 0.8741714975027401, 'weights_8': 0.062484845432009745, 'weights_9': 0.49594341916293466, 'weights_10': 0.06184678988910751, 'weights_11': 0.4549871404405521, 'weights_12': 0.079735354748294, 'weights_13': 0.39059312747441927, 'weights_14': 0.02038304804141599, 'weights_15': 0.9918370356138744, 'weights_16': 0.04465487439199565, 'weights_17': 0.6131404922600572, 'weights_18': 0.032901188428296924, 'weights_19': 0.8955191529899021}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,724] Trial 224 finished with value: 2183.1811604185186 and parameters: {'weights_0': 0.12200914862511673, 'weights_1': 0.165017064760814, 'weights_2': 0.20312737839110828, 'weights_3': 0.0006620024026650015, 'weights_4': 0.9225340708670323, 'weights_5': 0.629529282377611, 'weights_6': 0.012209816186416728, 'weights_7': 0.8486967702174757, 'weights_8': 0.06531376532073688, 'weights_9': 0.49642018099765706, 'weights_10': 0.05973727097221862, 'weights_11': 0.4560112737530332, 'weights_12': 0.08207110688884023, 'weights_13': 0.37391294923266893, 'weights_14': 0.0222562583472695, 'weights_15': 0.9884231382799699, 'weights_16': 0.03929531590397577, 'weights_17': 0.6193240927651193, 'weights_18': 0.9986456124955042, 'weights_19': 0.9006303165813688}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:49,922] Trial 225 finished with value: 1776.6682113614968 and parameters: {'weights_0': 0.11197376940913974, 'weights_1': 0.12751431903920027, 'weights_2': 0.2287662378549877, 'weights_3': 0.0017088426070098932, 'weights_4': 0.8884654256924525, 'weights_5': 0.6199762827538607, 'weights_6': 0.0028794275505088732, 'weights_7': 0.8706257273935258, 'weights_8': 0.09396731880845188, 'weights_9': 0.4297897450165389, 'weights_10': 0.06493756843780511, 'weights_11': 0.47897090999884895, 'weights_12': 0.06364725157953455, 'weights_13': 0.39355738114465416, 'weights_14': 0.0033090128543426384, 'weights_15': 0.9816188949210873, 'weights_16': 0.04247588350164927, 'weights_17': 0.6433285340134112, 'weights_18': 0.03500199424003972, 'weights_19': 0.9166101398918735}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:50,067] Trial 226 finished with value: 1799.5108915815351 and parameters: {'weights_0': 0.1419405177481331, 'weights_1': 0.12564519777384744, 'weights_2': 0.21093829018656396, 'weights_3': 0.0291130087567325, 'weights_4': 0.8867894903384255, 'weights_5': 0.6133441779303536, 'weights_6': 0.03461324426240429, 'weights_7': 0.8720860938130803, 'weights_8': 0.07438912580236798, 'weights_9': 0.4755098371430457, 'weights_10': 0.061434073799080544, 'weights_11': 0.4820109936704928, 'weights_12': 0.07373365475051546, 'weights_13': 0.3924778566673618, 'weights_14': 0.022256473639793706, 'weights_15': 0.9856375169806897, 'weights_16': 0.042479021063477104, 'weights_17': 0.6717666016593234, 'weights_18': 0.03347039344911011, 'weights_19': 0.9200628768272945}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:50,228] Trial 227 finished with value: 1805.3091461154143 and parameters: {'weights_0': 0.1432243178288546, 'weights_1': 0.12169233947229541, 'weights_2': 0.2271881331426356, 'weights_3': 0.00046244098341752417, 'weights_4': 0.8883054246905078, 'weights_5': 0.6495427060294677, 'weights_6': 0.008039545427069476, 'weights_7': 0.8791659835884477, 'weights_8': 0.07851170371639438, 'weights_9': 0.4805925854441027, 'weights_10': 0.059747236906268514, 'weights_11': 0.4778311800533777, 'weights_12': 0.0791167358526357, 'weights_13': 0.3947651788470893, 'weights_14': 0.05926597302533565, 'weights_15': 0.9990542224452689, 'weights_16': 0.040531126420963945, 'weights_17': 0.6734925902992613, 'weights_18': 0.03452128725655433, 'weights_19': 0.9224421854603383}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:50,369] Trial 228 finished with value: 1815.3046894510717 and parameters: {'weights_0': 0.10975855085691502, 'weights_1': 0.12322582335603294, 'weights_2': 0.2278604906059386, 'weights_3': 0.029011553593237045, 'weights_4': 0.8750789745035842, 'weights_5': 0.6483043078934221, 'weights_6': 0.008208225187580864, 'weights_7': 0.8761124652070642, 'weights_8': 0.07007549526196258, 'weights_9': 0.48175704781442896, 'weights_10': 0.057233696096980265, 'weights_11': 0.47772985746098673, 'weights_12': 0.08231193679107537, 'weights_13': 0.38974045117716255, 'weights_14': 0.06609072650129882, 'weights_15': 0.9910090512612808, 'weights_16': 0.0727836554406494, 'weights_17': 0.7071720025080819, 'weights_18': 0.03441760205702402, 'weights_19': 0.9218783595229342}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:50,603] Trial 229 finished with value: 1827.5036973344113 and parameters: {'weights_0': 0.12993047683557216, 'weights_1': 0.12065919374224868, 'weights_2': 0.2697749183133829, 'weights_3': 0.0027940796420516546, 'weights_4': 0.8857025277408784, 'weights_5': 0.6378889590966706, 'weights_6': 0.037480650026560716, 'weights_7': 0.8748969711949098, 'weights_8': 0.06873248390222611, 'weights_9': 0.4761784236734774, 'weights_10': 0.056573182341285194, 'weights_11': 0.46187244167622715, 'weights_12': 0.10032525241688901, 'weights_13': 0.40446592519485386, 'weights_14': 0.04999559608703896, 'weights_15': 0.9984896239916468, 'weights_16': 0.03810185286282371, 'weights_17': 0.6691250439342702, 'weights_18': 0.03785723876380279, 'weights_19': 0.9204933003341844}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:50,739] Trial 230 finished with value: 1846.609769391313 and parameters: {'weights_0': 0.1431770224524927, 'weights_1': 0.170532068302074, 'weights_2': 0.24501535691462273, 'weights_3': 0.03266686779719471, 'weights_4': 0.9237170816695802, 'weights_5': 0.6180303297288117, 'weights_6': 0.03429118337267292, 'weights_7': 0.8852571678054436, 'weights_8': 0.09452959941515228, 'weights_9': 0.49787965887443164, 'weights_10': 0.06881531988863845, 'weights_11': 0.4842082836268001, 'weights_12': 0.08315434887940443, 'weights_13': 0.3578122710728479, 'weights_14': 0.0662854655698356, 'weights_15': 0.9556320281295977, 'weights_16': 0.07222631295361434, 'weights_17': 0.6906832515350982, 'weights_18': 0.02979852458657823, 'weights_19': 0.8887671960706206}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:50,871] Trial 231 finished with value: 1812.6573377016189 and parameters: {'weights_0': 0.1583323701413881, 'weights_1': 0.13416088026030104, 'weights_2': 0.20919578068425668, 'weights_3': 0.0011987739716099524, 'weights_4': 0.8981907676306619, 'weights_5': 0.597480635219644, 'weights_6': 0.0025828197186852564, 'weights_7': 0.8623524072051064, 'weights_8': 0.08810244418905139, 'weights_9': 0.45888211199819906, 'weights_10': 0.07124766659469724, 'weights_11': 0.47005525956690436, 'weights_12': 0.06856592187755427, 'weights_13': 0.3943318481253337, 'weights_14': 0.021979348197133652, 'weights_15': 0.9818089001509428, 'weights_16': 0.03798271348259929, 'weights_17': 0.6572938615159237, 'weights_18': 0.0674124238076553, 'weights_19': 0.9114799066324544}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,029] Trial 232 finished with value: 1803.6336694825768 and parameters: {'weights_0': 0.1594748347105469, 'weights_1': 0.12624091737949314, 'weights_2': 0.20907371526979426, 'weights_3': 0.001097246544538514, 'weights_4': 0.9085603016620264, 'weights_5': 0.6032361222880784, 'weights_6': 0.029839237446445274, 'weights_7': 0.865324165872902, 'weights_8': 0.05890113795097124, 'weights_9': 0.4658587351275797, 'weights_10': 0.089657753496939, 'weights_11': 0.45053854842732766, 'weights_12': 0.0531728949169094, 'weights_13': 0.30380762586014454, 'weights_14': 0.02081683439285799, 'weights_15': 0.9968157178784933, 'weights_16': 0.03899736238650239, 'weights_17': 0.6626357906311814, 'weights_18': 0.03492166253879554, 'weights_19': 0.8900635253895961}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,190] Trial 233 finished with value: 1802.777527458098 and parameters: {'weights_0': 0.11368690376864425, 'weights_1': 0.1623962651874774, 'weights_2': 0.21696589868523813, 'weights_3': 0.021490511378862775, 'weights_4': 0.9225097297921142, 'weights_5': 0.5936875829589238, 'weights_6': 0.030176034220190023, 'weights_7': 0.8646541756431435, 'weights_8': 0.060712167353859904, 'weights_9': 0.5052315039027144, 'weights_10': 0.09683275097420782, 'weights_11': 0.44915237263431057, 'weights_12': 0.050716146690785786, 'weights_13': 0.3074540759075307, 'weights_14': 0.04049217819402849, 'weights_15': 0.9973047213413044, 'weights_16': 0.040670875766743886, 'weights_17': 0.6265021316011321, 'weights_18': 0.03365491424036751, 'weights_19': 0.8897991925825371}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,327] Trial 234 finished with value: 1793.7040800147422 and parameters: {'weights_0': 0.11175319820364865, 'weights_1': 0.1571326757391918, 'weights_2': 0.22125191302954608, 'weights_3': 0.01858103411979649, 'weights_4': 0.9153980578008577, 'weights_5': 0.624660147561236, 'weights_6': 0.03199352136764706, 'weights_7': 0.8670083101464662, 'weights_8': 0.0562968884663402, 'weights_9': 0.47123434679358056, 'weights_10': 0.09501512344873393, 'weights_11': 0.45075050066319977, 'weights_12': 0.05464375476415979, 'weights_13': 0.35738511299010445, 'weights_14': 0.019056257691554484, 'weights_15': 0.9941189589788104, 'weights_16': 0.03480996749200854, 'weights_17': 0.6414907927157576, 'weights_18': 0.02089051190713061, 'weights_19': 0.8889833003550892}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,441] Trial 235 finished with value: 1793.8993585493959 and parameters: {'weights_0': 0.1270537849878795, 'weights_1': 0.16407124142498214, 'weights_2': 0.22279969492205862, 'weights_3': 0.021996180667132766, 'weights_4': 0.8810259957144374, 'weights_5': 0.6413551999299707, 'weights_6': 0.02572334318643579, 'weights_7': 0.8684142826884754, 'weights_8': 0.0547681061801201, 'weights_9': 0.50473900557667, 'weights_10': 0.05496709264730381, 'weights_11': 0.4506801140455574, 'weights_12': 0.06363279136885283, 'weights_13': 0.3700067071596634, 'weights_14': 0.01929345340660522, 'weights_15': 0.9999866410123203, 'weights_16': 0.0426891796501275, 'weights_17': 0.6405334228977907, 'weights_18': 0.04381159435866673, 'weights_19': 0.8954143694781987}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,603] Trial 236 finished with value: 1785.3093524761591 and parameters: {'weights_0': 0.11108379950952324, 'weights_1': 0.16045184380392763, 'weights_2': 0.21968604278826773, 'weights_3': 0.026848338005502143, 'weights_4': 0.8853495553495462, 'weights_5': 0.6592586573800789, 'weights_6': 0.03224010693814858, 'weights_7': 0.8695041323440491, 'weights_8': 0.05628923879847799, 'weights_9': 0.5118809615720745, 'weights_10': 0.04852847733400479, 'weights_11': 0.45194689926202786, 'weights_12': 0.07959321759712176, 'weights_13': 0.3587742178155906, 'weights_14': 0.000816123377495377, 'weights_15': 0.9847746348866803, 'weights_16': 0.03666805606700416, 'weights_17': 0.6331904078769621, 'weights_18': 0.054103422827007905, 'weights_19': 0.8977897345485233}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,733] Trial 237 finished with value: 1794.9304749240662 and parameters: {'weights_0': 0.10706789472370927, 'weights_1': 0.1626322959243624, 'weights_2': 0.261385244184152, 'weights_3': 0.025067264606851918, 'weights_4': 0.8747296859994351, 'weights_5': 0.6541449315932993, 'weights_6': 0.0018173136757512383, 'weights_7': 0.8680919276269852, 'weights_8': 0.04755601129149656, 'weights_9': 0.5236481494140968, 'weights_10': 0.046992851272578615, 'weights_11': 0.48638897436880835, 'weights_12': 0.10324495767959013, 'weights_13': 0.35759889683525814, 'weights_14': 0.01760812948118937, 'weights_15': 0.9940799470717524, 'weights_16': 0.03336848430474307, 'weights_17': 0.6502846244141596, 'weights_18': 0.06105309437286181, 'weights_19': 0.9237783556731836}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:51,840] Trial 238 finished with value: 1995.4753977241996 and parameters: {'weights_0': 0.10536636321784358, 'weights_1': 0.18535647266480573, 'weights_2': 0.2616224136507599, 'weights_3': 0.018892565906338775, 'weights_4': 0.9027473546415478, 'weights_5': 0.6266241243020022, 'weights_6': 0.033583058781340755, 'weights_7': 0.8946151033904237, 'weights_8': 0.05249380372286945, 'weights_9': 0.5163692196390047, 'weights_10': 0.04421456086608144, 'weights_11': 0.5130716837897534, 'weights_12': 0.106974211940149, 'weights_13': 0.3586396552657331, 'weights_14': 0.01513703756067469, 'weights_15': 0.9835507020178833, 'weights_16': 0.03584343711123117, 'weights_17': 0.6447317038757993, 'weights_18': 0.5588450356748553, 'weights_19': 0.8965092322899303}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,024] Trial 239 finished with value: 1798.873376139466 and parameters: {'weights_0': 0.10554771709981241, 'weights_1': 0.16533548429106015, 'weights_2': 0.24110262447770023, 'weights_3': 0.029383374084182113, 'weights_4': 0.8743114611965473, 'weights_5': 0.6603755471591038, 'weights_6': 0.027831391244875683, 'weights_7': 0.8653947215358432, 'weights_8': 0.06204324533063956, 'weights_9': 0.5247046876608121, 'weights_10': 0.04386874011444283, 'weights_11': 0.45816039125946606, 'weights_12': 0.09668878128851924, 'weights_13': 0.36548407943512357, 'weights_14': 0.019014334736896822, 'weights_15': 0.9974811236129005, 'weights_16': 0.027037042804230266, 'weights_17': 0.64021896129072, 'weights_18': 0.06728800352936837, 'weights_19': 0.9258859994349128}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,134] Trial 240 finished with value: 1780.1206999393733 and parameters: {'weights_0': 0.10210334520284728, 'weights_1': 0.1647868326257076, 'weights_2': 0.29233861149459717, 'weights_3': 0.03455848100549681, 'weights_4': 0.8747898818844806, 'weights_5': 0.6677410424667528, 'weights_6': 0.0012455942790485508, 'weights_7': 0.8666835402851824, 'weights_8': 0.05001737855891722, 'weights_9': 0.5292232647576265, 'weights_10': 0.044807583483124726, 'weights_11': 0.4949469363289746, 'weights_12': 0.12396502560500691, 'weights_13': 0.10376629078415395, 'weights_14': 0.00042356943679897367, 'weights_15': 0.9587184620751671, 'weights_16': 0.020063767113490366, 'weights_17': 0.633770951134829, 'weights_18': 0.0758873800295434, 'weights_19': 0.92923056846359}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,251] Trial 241 finished with value: 1791.0343778244467 and parameters: {'weights_0': 0.10449060414786987, 'weights_1': 0.16295702352522234, 'weights_2': 0.2560552753224109, 'weights_3': 0.028723840151490963, 'weights_4': 0.8805586660852356, 'weights_5': 0.6490071822021878, 'weights_6': 0.006267115904727932, 'weights_7': 0.8754988042023407, 'weights_8': 0.05394969567726181, 'weights_9': 0.5156363089697498, 'weights_10': 0.04664074219266008, 'weights_11': 0.48297042283527203, 'weights_12': 0.1024764988373923, 'weights_13': 0.37066192597245673, 'weights_14': 0.01728488818848349, 'weights_15': 0.9554455543673899, 'weights_16': 0.020622501557084276, 'weights_17': 0.6363868232701672, 'weights_18': 0.06885388272105811, 'weights_19': 0.9236798954014634}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,390] Trial 242 finished with value: 1788.0337761668181 and parameters: {'weights_0': 0.10572262252287397, 'weights_1': 0.19442024174877742, 'weights_2': 0.3142118544639926, 'weights_3': 0.03289969783857325, 'weights_4': 0.8749627580877166, 'weights_5': 0.6676280784843934, 'weights_6': 0.008163540571018979, 'weights_7': 0.8931218126408421, 'weights_8': 0.04661585353820427, 'weights_9': 0.5275187766853662, 'weights_10': 0.04152628422900181, 'weights_11': 0.4913988135670796, 'weights_12': 0.12995142046169744, 'weights_13': 0.10485364965741795, 'weights_14': 2.1020463963958465e-05, 'weights_15': 0.9528736494918525, 'weights_16': 0.02202862838947288, 'weights_17': 0.6386954785905303, 'weights_18': 0.0708609592804097, 'weights_19': 0.9266910439671278}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,513] Trial 243 finished with value: 1802.4241075722862 and parameters: {'weights_0': 0.1018300972776887, 'weights_1': 0.19251721887636608, 'weights_2': 0.3163245097988279, 'weights_3': 0.0378537819204504, 'weights_4': 0.8675057916260612, 'weights_5': 0.682601236314721, 'weights_6': 0.0018362752093891849, 'weights_7': 0.8947856591867307, 'weights_8': 0.046696667924836566, 'weights_9': 0.5545579938203008, 'weights_10': 0.04491578748029598, 'weights_11': 0.49980684269948256, 'weights_12': 0.12164138534005142, 'weights_13': 0.36444349953126004, 'weights_14': 0.017442020137003876, 'weights_15': 0.9582162457844975, 'weights_16': 0.013168235052212839, 'weights_17': 0.6409007851371961, 'weights_18': 0.07187862768881445, 'weights_19': 0.9251586517565857}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,629] Trial 244 finished with value: 1852.8791976632444 and parameters: {'weights_0': 0.10226099896653647, 'weights_1': 0.4128197001768051, 'weights_2': 0.28251480637001775, 'weights_3': 0.03548013352054412, 'weights_4': 0.8753992127838135, 'weights_5': 0.6608410310423753, 'weights_6': 0.04582206434105788, 'weights_7': 0.8641363040134246, 'weights_8': 0.033647434647642305, 'weights_9': 0.5291931146503189, 'weights_10': 0.04529832773879659, 'weights_11': 0.4889135183562624, 'weights_12': 0.13540725555469657, 'weights_13': 0.3742500238541767, 'weights_14': 0.020009395478750074, 'weights_15': 0.9539939164726017, 'weights_16': 0.024111727706090862, 'weights_17': 0.647670473553954, 'weights_18': 0.06872365485095774, 'weights_19': 0.9332699885816282}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,751] Trial 245 finished with value: 1764.7690745561458 and parameters: {'weights_0': 0.10397223241946081, 'weights_1': 0.17057068264050346, 'weights_2': 0.2915670221545251, 'weights_3': 0.03383367136159019, 'weights_4': 0.8799977283210325, 'weights_5': 0.660283567076461, 'weights_6': 0.002120723512195743, 'weights_7': 0.8895369957614871, 'weights_8': 0.05161684383156679, 'weights_9': 0.5282063505846627, 'weights_10': 0.04429630461569064, 'weights_11': 0.5153943927744191, 'weights_12': 0.10408402797612472, 'weights_13': 0.09219935229225217, 'weights_14': 0.0013110634256678698, 'weights_15': 0.9752682404993087, 'weights_16': 0.020305135150944436, 'weights_17': 0.6771389645986242, 'weights_18': 0.062130451569449754, 'weights_19': 0.919151103681106}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:52,884] Trial 246 finished with value: 1782.7409406300615 and parameters: {'weights_0': 0.09949451993191168, 'weights_1': 0.21112949497733421, 'weights_2': 0.2525228366592263, 'weights_3': 0.039573022713815645, 'weights_4': 0.8831791939973764, 'weights_5': 0.6625209341348293, 'weights_6': 0.0009975181312340264, 'weights_7': 0.8839367717989683, 'weights_8': 0.04854585817530966, 'weights_9': 0.527393230922749, 'weights_10': 0.04682643511170385, 'weights_11': 0.5294964675002829, 'weights_12': 0.12660078674992525, 'weights_13': 0.1390050285921512, 'weights_14': 0.019877601381865975, 'weights_15': 0.9542497102963349, 'weights_16': 0.02188326238978018, 'weights_17': 0.694427225172292, 'weights_18': 0.07037289316912711, 'weights_19': 0.9250719378496547}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,016] Trial 247 finished with value: 1789.5702337917935 and parameters: {'weights_0': 0.09561312183269807, 'weights_1': 0.20697272785551218, 'weights_2': 0.29102995278079946, 'weights_3': 0.0428357062785428, 'weights_4': 0.8695165397829904, 'weights_5': 0.6657087776541596, 'weights_6': 0.0023119985462531807, 'weights_7': 0.8899693445735096, 'weights_8': 0.0025228241958751493, 'weights_9': 0.5259417358398015, 'weights_10': 0.046804167684321156, 'weights_11': 0.5176543515597607, 'weights_12': 0.1276909640142997, 'weights_13': 0.08861710037641152, 'weights_14': 0.038491841063358075, 'weights_15': 0.9517289003185321, 'weights_16': 0.017413716684899067, 'weights_17': 0.705311847301292, 'weights_18': 0.0711771827715183, 'weights_19': 0.9333104408653639}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,166] Trial 248 finished with value: 1796.3041636409014 and parameters: {'weights_0': 0.09199492117953374, 'weights_1': 0.21325027624828052, 'weights_2': 0.3022144389979032, 'weights_3': 0.03946539643333774, 'weights_4': 0.8741991854863704, 'weights_5': 0.6699860566955957, 'weights_6': 0.0022391587099596932, 'weights_7': 0.897196239173305, 'weights_8': 0.00787744329453434, 'weights_9': 0.5355351450201282, 'weights_10': 0.04771596939087969, 'weights_11': 0.5203675508183494, 'weights_12': 0.13167594534307053, 'weights_13': 0.10566448283441322, 'weights_14': 0.037784137459127586, 'weights_15': 0.9572230455450177, 'weights_16': 0.021047164689191017, 'weights_17': 0.7233815158991358, 'weights_18': 0.07397155428654499, 'weights_19': 0.933953911464382}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,316] Trial 249 finished with value: 2065.935235199181 and parameters: {'weights_0': 0.09149799087847328, 'weights_1': 0.21336579551868748, 'weights_2': 0.29998643039622624, 'weights_3': 0.04066013055997677, 'weights_4': 0.8708587368916804, 'weights_5': 0.6675023078954941, 'weights_6': 0.0009573528607519114, 'weights_7': 0.8968534256373741, 'weights_8': 0.0012949608153275316, 'weights_9': 0.5382178883359957, 'weights_10': 0.03805428017939582, 'weights_11': 0.5304968920641197, 'weights_12': 0.13208929966982455, 'weights_13': 0.08762607287237639, 'weights_14': 0.8148522129357397, 'weights_15': 0.9501742266650728, 'weights_16': 0.02488235455652587, 'weights_17': 0.7280749087045619, 'weights_18': 0.0645494298045533, 'weights_19': 0.9345222009158527}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,462] Trial 250 finished with value: 2082.8660564917154 and parameters: {'weights_0': 0.0951798131671023, 'weights_1': 0.2966262918055921, 'weights_2': 0.34899838512524334, 'weights_3': 0.03779552253988681, 'weights_4': 0.8809112272092603, 'weights_5': 0.6902240228427989, 'weights_6': 0.0003838968388526834, 'weights_7': 0.917662636586544, 'weights_8': 0.028698121528668217, 'weights_9': 0.5700293776297006, 'weights_10': 0.044369432237454834, 'weights_11': 0.4933604140248536, 'weights_12': 0.1574940213854564, 'weights_13': 0.10378853129679877, 'weights_14': 0.036392272560243584, 'weights_15': 0.9685613722794346, 'weights_16': 0.020438298356443965, 'weights_17': 0.7816267594801298, 'weights_18': 0.7416460785765366, 'weights_19': 0.9319449366308439}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,596] Trial 251 finished with value: 1789.6510061795077 and parameters: {'weights_0': 0.0847313597947161, 'weights_1': 0.2004553239549681, 'weights_2': 0.2485611643076748, 'weights_3': 0.04087716043442941, 'weights_4': 0.8477170489079132, 'weights_5': 0.6575880435645659, 'weights_6': 0.01792002568948006, 'weights_7': 0.8861394032963333, 'weights_8': 0.024488925873021747, 'weights_9': 0.520980961040859, 'weights_10': 0.05093674216893756, 'weights_11': 0.5106705415605328, 'weights_12': 0.14357565449081894, 'weights_13': 0.05344330667903368, 'weights_14': 0.03673724393665795, 'weights_15': 0.9480150317635534, 'weights_16': 0.021211727742547117, 'weights_17': 0.7453573570414873, 'weights_18': 0.06884623370824001, 'weights_19': 0.9360679722074526}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,782] Trial 252 finished with value: 1784.0753263726772 and parameters: {'weights_0': 0.09147126867203045, 'weights_1': 0.21848572097644536, 'weights_2': 0.2817901611247008, 'weights_3': 0.04597909552423321, 'weights_4': 0.8489308281477367, 'weights_5': 0.6500253462455233, 'weights_6': 0.003247481739475769, 'weights_7': 0.8906625346399611, 'weights_8': 0.012791506004729052, 'weights_9': 0.5176970127886926, 'weights_10': 0.03674595226374848, 'weights_11': 0.5196077627131529, 'weights_12': 0.12826315075608713, 'weights_13': 0.0570614833462878, 'weights_14': 0.039809370506863104, 'weights_15': 0.9437965342747333, 'weights_16': 0.019575028564243428, 'weights_17': 0.7008035596986764, 'weights_18': 0.07562681791792228, 'weights_19': 0.9432560720802292}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:53,971] Trial 253 finished with value: 1795.6893440650015 and parameters: {'weights_0': 0.08923498036674689, 'weights_1': 0.2152279820746347, 'weights_2': 0.28192302903698585, 'weights_3': 0.048530531930312246, 'weights_4': 0.8519007329862052, 'weights_5': 0.6428742089263857, 'weights_6': 0.008663784138708837, 'weights_7': 0.8938205383853629, 'weights_8': 0.01496699544421868, 'weights_9': 0.5129935260247865, 'weights_10': 0.03820552070262648, 'weights_11': 0.5202030799040636, 'weights_12': 0.1425373279012793, 'weights_13': 0.05845601516456756, 'weights_14': 0.040927482109145916, 'weights_15': 0.939488662119057, 'weights_16': 0.02407697217349955, 'weights_17': 0.7095537556386532, 'weights_18': 0.08071907485679967, 'weights_19': 0.9506276697922584}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,071] Trial 254 finished with value: 1803.0918762293793 and parameters: {'weights_0': 0.08093775242698009, 'weights_1': 0.2326501197496672, 'weights_2': 0.2870537015281445, 'weights_3': 0.051356815439893636, 'weights_4': 0.8545388844784587, 'weights_5': 0.6445172062846976, 'weights_6': 0.00025656053851863536, 'weights_7': 0.8975402130095065, 'weights_8': 0.0023746391171560674, 'weights_9': 0.5132208209511417, 'weights_10': 0.039798747144142985, 'weights_11': 0.522695164445522, 'weights_12': 0.17167766625960965, 'weights_13': 0.0609850865989202, 'weights_14': 0.042706424277836115, 'weights_15': 0.9433151299846749, 'weights_16': 0.01676288067773987, 'weights_17': 0.7467747850935897, 'weights_18': 0.07615729851612223, 'weights_19': 0.9517055312186881}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,191] Trial 255 finished with value: 2057.069281783826 and parameters: {'weights_0': 0.08861057418326043, 'weights_1': 0.2019246368040376, 'weights_2': 0.2675537608814716, 'weights_3': 0.07071022096190072, 'weights_4': 0.8367982079888323, 'weights_5': 0.6776007776183439, 'weights_6': 0.014794777149902587, 'weights_7': 0.945432620624755, 'weights_8': 0.01057886258330013, 'weights_9': 0.505757349640603, 'weights_10': 0.03679330902506388, 'weights_11': 0.5120639412419911, 'weights_12': 0.1497069085732913, 'weights_13': 0.056736335521602725, 'weights_14': 0.06999777928605025, 'weights_15': 0.9508697781586186, 'weights_16': 0.5781335574013544, 'weights_17': 0.7120548620050562, 'weights_18': 0.07370511547119017, 'weights_19': 0.950204365416723}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,312] Trial 256 finished with value: 1791.3405501551279 and parameters: {'weights_0': 0.07903903845987242, 'weights_1': 0.1871502352815794, 'weights_2': 0.3155793751666039, 'weights_3': 0.046993747240253285, 'weights_4': 0.8620776675413172, 'weights_5': 0.7068924831008621, 'weights_6': 0.002076269677142189, 'weights_7': 0.9061399987207736, 'weights_8': 0.01719364753705724, 'weights_9': 0.5531145153650967, 'weights_10': 0.04955140729369796, 'weights_11': 0.5491761008601878, 'weights_12': 0.1367005626472778, 'weights_13': 0.0886774993253886, 'weights_14': 0.042131269287714185, 'weights_15': 0.943857475449565, 'weights_16': 0.019511168192766583, 'weights_17': 0.7029076416505647, 'weights_18': 0.0881147539110356, 'weights_19': 0.9370289800043561}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,470] Trial 257 finished with value: 1798.5551644343097 and parameters: {'weights_0': 0.08069322656391244, 'weights_1': 0.1972743408728382, 'weights_2': 0.3321980090389803, 'weights_3': 0.08628829518397549, 'weights_4': 0.8493432217673004, 'weights_5': 0.706400673018176, 'weights_6': 0.021934135010665545, 'weights_7': 0.924724385156573, 'weights_8': 0.005135888381027666, 'weights_9': 0.5480541024812843, 'weights_10': 0.03518096759231946, 'weights_11': 0.5568504689004186, 'weights_12': 0.13972859579302113, 'weights_13': 0.09023262254478828, 'weights_14': 0.04560623665546886, 'weights_15': 0.946842295929113, 'weights_16': 0.024052914584513897, 'weights_17': 0.6909743924490904, 'weights_18': 0.08444676525061114, 'weights_19': 0.9371225208719997}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,562] Trial 258 finished with value: 1800.17908496443 and parameters: {'weights_0': 0.10106843628242068, 'weights_1': 0.21376558899944192, 'weights_2': 0.30347801661969187, 'weights_3': 0.04548457060428527, 'weights_4': 0.8547199853803873, 'weights_5': 0.6639063999653633, 'weights_6': 0.0008826138123658562, 'weights_7': 0.9004431479139468, 'weights_8': 0.022681209496943654, 'weights_9': 0.531346958476518, 'weights_10': 0.049801591635166086, 'weights_11': 0.5360743775255151, 'weights_12': 0.1231091746959485, 'weights_13': 0.03303251171325354, 'weights_14': 0.06500726147856808, 'weights_15': 0.9602657704008889, 'weights_16': 0.018417576321294874, 'weights_17': 0.706833069982419, 'weights_18': 0.0849337406027638, 'weights_19': 0.9590188084263229}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,722] Trial 259 finished with value: 1799.3228095898137 and parameters: {'weights_0': 0.07709674917766304, 'weights_1': 0.18694182128178824, 'weights_2': 0.3200826398487493, 'weights_3': 0.054429750662319525, 'weights_4': 0.865904750988783, 'weights_5': 0.6928861398510202, 'weights_6': 0.019558152409243294, 'weights_7': 0.9152555771402695, 'weights_8': 0.03044490012789282, 'weights_9': 0.5693365505979433, 'weights_10': 0.03132648912768103, 'weights_11': 0.5484644488328074, 'weights_12': 0.18307005207916555, 'weights_13': 0.11149922364094823, 'weights_14': 0.03905824146888295, 'weights_15': 0.9380536317063585, 'weights_16': 0.014124245309699843, 'weights_17': 0.7668433655570421, 'weights_18': 0.0625478932568513, 'weights_19': 0.9420624867044848}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:54,889] Trial 260 finished with value: 1806.7611540268556 and parameters: {'weights_0': 0.09659493707811674, 'weights_1': 0.23831663249982152, 'weights_2': 0.28094628675763395, 'weights_3': 0.07319311459598837, 'weights_4': 0.8378855754464002, 'weights_5': 0.7225014972929652, 'weights_6': 0.021098774412929445, 'weights_7': 0.8911109006998423, 'weights_8': 0.016825698712247712, 'weights_9': 0.5508368600899409, 'weights_10': 0.04817972722823294, 'weights_11': 0.5118200723201723, 'weights_12': 0.15014058862856502, 'weights_13': 0.08657264015552676, 'weights_14': 0.038550783966164195, 'weights_15': 0.9735543865248422, 'weights_16': 0.017570049296733677, 'weights_17': 0.7354710860769117, 'weights_18': 0.06419691096213381, 'weights_19': 0.9305580660860284}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,037] Trial 261 finished with value: 2005.1816779135665 and parameters: {'weights_0': 0.07807377591659789, 'weights_1': 0.1889663318289462, 'weights_2': 0.2613570339679095, 'weights_3': 0.042441783246900434, 'weights_4': 0.8904590146722494, 'weights_5': 0.6550991072937042, 'weights_6': 0.019687016402839094, 'weights_7': 0.8393007090506084, 'weights_8': 0.0018313948098853741, 'weights_9': 0.5841977401483734, 'weights_10': 0.03481762331910614, 'weights_11': 0.5237160722160905, 'weights_12': 0.12161628698021389, 'weights_13': 0.06978669724202885, 'weights_14': 0.057140155563466515, 'weights_15': 0.9401161421308631, 'weights_16': 0.025074680152655786, 'weights_17': 0.6790730998810851, 'weights_18': 0.6279317570177796, 'weights_19': 0.9607531958996687}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,169] Trial 262 finished with value: 1807.6826705487579 and parameters: {'weights_0': 0.11261671517923122, 'weights_1': 0.2248181389138274, 'weights_2': 0.29564887254306166, 'weights_3': 0.05256638519777111, 'weights_4': 0.8667473395924976, 'weights_5': 0.6417672121456508, 'weights_6': 0.04923704831223184, 'weights_7': 0.9284070373062474, 'weights_8': 0.038505157570377285, 'weights_9': 0.5217814203513886, 'weights_10': 0.05135068056311392, 'weights_11': 0.5704874455273474, 'weights_12': 0.13407826589200622, 'weights_13': 0.008314347305872466, 'weights_14': 0.08244527331237479, 'weights_15': 0.9612653931412883, 'weights_16': 0.0016513286664136297, 'weights_17': 0.7225116424453941, 'weights_18': 0.05861021371801102, 'weights_19': 0.9193041723649081}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,291] Trial 263 finished with value: 1785.2794113498048 and parameters: {'weights_0': 0.10212527032404603, 'weights_1': 0.21203739494508547, 'weights_2': 0.2514785878128906, 'weights_3': 0.07353528882338571, 'weights_4': 0.8861133264378289, 'weights_5': 0.6771850444178773, 'weights_6': 0.0009220723692528916, 'weights_7': 0.8917044627786938, 'weights_8': 0.02978377527063859, 'weights_9': 0.5398861660125277, 'weights_10': 0.02795837575075346, 'weights_11': 0.5056294817554906, 'weights_12': 0.11016581161012005, 'weights_13': 0.12178876913297426, 'weights_14': 0.03643597196669195, 'weights_15': 0.9736267523877191, 'weights_16': 0.030632071336028854, 'weights_17': 0.70563863393098, 'weights_18': 0.08299540739450115, 'weights_19': 0.9423594918199157}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,420] Trial 264 finished with value: 1805.7076266129593 and parameters: {'weights_0': 0.09158340273247, 'weights_1': 0.2458676367870012, 'weights_2': 0.25259811412035416, 'weights_3': 0.06769375473266928, 'weights_4': 0.8802620034044734, 'weights_5': 0.6714293752056288, 'weights_6': 0.0017618469493534093, 'weights_7': 0.8911982586969851, 'weights_8': 0.033738468707065164, 'weights_9': 0.5304873814155595, 'weights_10': 0.028673086319352892, 'weights_11': 0.5133227900324342, 'weights_12': 0.16280190884275617, 'weights_13': 0.10591479472314255, 'weights_14': 0.038317699206126835, 'weights_15': 0.9736268779589353, 'weights_16': 0.027013501220850777, 'weights_17': 0.7037519598228124, 'weights_18': 0.08960951407643934, 'weights_19': 0.9648733199570174}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,555] Trial 265 finished with value: 1781.4453078612587 and parameters: {'weights_0': 0.07216806689226087, 'weights_1': 0.21665396737636225, 'weights_2': 0.2801996058108562, 'weights_3': 0.08100281977342631, 'weights_4': 0.8427116384135133, 'weights_5': 0.7011515814221762, 'weights_6': 9.210548225134247e-05, 'weights_7': 0.9114998711840744, 'weights_8': 0.015809657717325704, 'weights_9': 0.5087995230302939, 'weights_10': 0.022109268645132688, 'weights_11': 0.544160969459034, 'weights_12': 0.10465328744086856, 'weights_13': 0.1306196169061972, 'weights_14': 0.07776726229614295, 'weights_15': 0.9562459616828545, 'weights_16': 0.017563469046248545, 'weights_17': 0.6930845776051692, 'weights_18': 0.08988891372021493, 'weights_19': 0.9308502004424155}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,689] Trial 266 finished with value: 1774.7039592426179 and parameters: {'weights_0': 0.07124323966952704, 'weights_1': 0.17697943203644106, 'weights_2': 0.2782158627657836, 'weights_3': 0.08760596736838824, 'weights_4': 0.846916332317592, 'weights_5': 0.7089195440238284, 'weights_6': 0.04100810065857768, 'weights_7': 0.9720542449304668, 'weights_8': 0.04155759732073212, 'weights_9': 0.5079752000178621, 'weights_10': 0.017914770464811602, 'weights_11': 0.5474818903070373, 'weights_12': 0.10749733605691393, 'weights_13': 0.1372438926587015, 'weights_14': 0.07511731154005392, 'weights_15': 0.972774945845146, 'weights_16': 0.0004998480633669616, 'weights_17': 0.6880015540299401, 'weights_18': 0.09942069744864279, 'weights_19': 0.9151734695255158}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,862] Trial 267 finished with value: 1862.359372843133 and parameters: {'weights_0': 0.06622077002852772, 'weights_1': 0.181874228709425, 'weights_2': 0.34026884724547146, 'weights_3': 0.6721019596661568, 'weights_4': 0.8322198035384222, 'weights_5': 0.7332496648763001, 'weights_6': 0.044035520900080005, 'weights_7': 0.9414793978229263, 'weights_8': 0.04154985137144203, 'weights_9': 0.5605332879580548, 'weights_10': 0.017591012682628648, 'weights_11': 0.5408671561527181, 'weights_12': 0.10856104623207444, 'weights_13': 0.14003625742408055, 'weights_14': 0.07428188666010611, 'weights_15': 0.9756958530460276, 'weights_16': 0.0163422406105228, 'weights_17': 0.6860383206079236, 'weights_18': 0.1010601985517525, 'weights_19': 0.9245994527084248}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:55,995] Trial 268 finished with value: 1820.730513362811 and parameters: {'weights_0': 0.11433566515996336, 'weights_1': 0.17321429281150477, 'weights_2': 0.26214414846593187, 'weights_3': 0.3596033807390321, 'weights_4': 0.8932639415055128, 'weights_5': 0.713257055480769, 'weights_6': 0.02957438959270236, 'weights_7': 0.8530276126407863, 'weights_8': 0.04379281257951188, 'weights_9': 0.49690538959197716, 'weights_10': 0.01388068501229249, 'weights_11': 0.5704687646947337, 'weights_12': 0.11174671864920606, 'weights_13': 0.1560701417050061, 'weights_14': 0.0819822527891644, 'weights_15': 0.9656401299316153, 'weights_16': 0.0015647255372356651, 'weights_17': 0.6578666691600812, 'weights_18': 0.05655643799434264, 'weights_19': 0.9140594148360635}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:56,141] Trial 269 finished with value: 2216.5343402325075 and parameters: {'weights_0': 0.6935743444040401, 'weights_1': 0.200373039093545, 'weights_2': 0.2323041337450037, 'weights_3': 0.09214574728682903, 'weights_4': 0.8438419304866995, 'weights_5': 0.6910861773492204, 'weights_6': 0.0563688185439694, 'weights_7': 0.9730980805370404, 'weights_8': 0.6091942858769837, 'weights_9': 0.508034758803, 'weights_10': 0.022259337513686455, 'weights_11': 0.5529151901551691, 'weights_12': 0.10991650660359631, 'weights_13': 0.13064721805262391, 'weights_14': 0.42976325139267013, 'weights_15': 0.9746888228285935, 'weights_16': 0.03311815461754802, 'weights_17': 0.6760707081106422, 'weights_18': 0.09600949076691193, 'weights_19': 0.9049113818482394}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:56,272] Trial 270 finished with value: 1782.6271945890717 and parameters: {'weights_0': 0.07177316770629166, 'weights_1': 0.1762899986650529, 'weights_2': 0.2517074093021313, 'weights_3': 0.09226607288944048, 'weights_4': 0.8607967998213815, 'weights_5': 0.6949841499929286, 'weights_6': 0.024472107494032273, 'weights_7': 0.9166867799362304, 'weights_8': 0.02653824723255177, 'weights_9': 0.5404169361834035, 'weights_10': 0.058814837532718586, 'weights_11': 0.49418766379372886, 'weights_12': 0.10207251475093122, 'weights_13': 0.12339666181251573, 'weights_14': 0.05855192102925631, 'weights_15': 0.9508817997459875, 'weights_16': 0.03666516739403104, 'weights_17': 0.6898248554428303, 'weights_18': 0.05451091996742107, 'weights_19': 0.9373301956917118}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:56,401] Trial 271 finished with value: 1973.195941815688 and parameters: {'weights_0': 0.07194999972114666, 'weights_1': 0.18496282284736465, 'weights_2': 0.3137063584748906, 'weights_3': 0.08818106080804203, 'weights_4': 0.8561919385524586, 'weights_5': 0.7004165125847256, 'weights_6': 0.04220141458119648, 'weights_7': 0.9416634914637472, 'weights_8': 0.02406574015013019, 'weights_9': 0.5944848650796722, 'weights_10': 0.05993607195289703, 'weights_11': 0.5007714160106896, 'weights_12': 0.11945153166258529, 'weights_13': 0.12642553881637747, 'weights_14': 0.06607598888634342, 'weights_15': 0.9359326087979722, 'weights_16': 0.38410393311057867, 'weights_17': 0.7501448971640711, 'weights_18': 0.0841456637632806, 'weights_19': 0.9414043174226172}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:56,545] Trial 272 finished with value: 1787.486032591631 and parameters: {'weights_0': 0.06992283688369685, 'weights_1': 0.20719045949865894, 'weights_2': 0.24752553445997932, 'weights_3': 0.07700404718319084, 'weights_4': 0.8938365468438524, 'weights_5': 0.6799587373461566, 'weights_6': 0.025867219696867505, 'weights_7': 0.9215687516235798, 'weights_8': 0.027169312865626145, 'weights_9': 0.5418264544965968, 'weights_10': 0.0675748316050617, 'weights_11': 0.537528782576421, 'weights_12': 0.15011125763239075, 'weights_13': 0.03617607370895397, 'weights_14': 0.07946519252879879, 'weights_15': 0.9519213167016202, 'weights_16': 0.003931651109598439, 'weights_17': 0.7057275246428311, 'weights_18': 0.054941707315327576, 'weights_19': 0.9653813820603134}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:56,670] Trial 273 finished with value: 2183.348360558708 and parameters: {'weights_0': 0.06852763909397058, 'weights_1': 0.1769194189462309, 'weights_2': 0.3648493879726564, 'weights_3': 0.09291239324191032, 'weights_4': 0.8249796781084305, 'weights_5': 0.7205357012997473, 'weights_6': 0.023571621237895954, 'weights_7': 0.9548675720041614, 'weights_8': 0.022801435146838106, 'weights_9': 0.5481185982435722, 'weights_10': 0.658936881597012, 'weights_11': 0.5839335423189859, 'weights_12': 0.19010289432096691, 'weights_13': 0.03776007848602771, 'weights_14': 0.09515799972019179, 'weights_15': 0.9522746912146067, 'weights_16': 0.004848360617182432, 'weights_17': 0.6949202050783784, 'weights_18': 0.3906895295346887, 'weights_19': 0.9620318518377887}. Best is trial 173 with value: 1743.5074819995584.\n",
      "[I 2025-08-01 08:05:56,820] Trial 274 finished with value: 1742.8116808767434 and parameters: {'weights_0': 0.07501798690226275, 'weights_1': 0.19841355621792317, 'weights_2': 0.22821543673538347, 'weights_3': 0.0794112013572683, 'weights_4': 0.8943404033295833, 'weights_5': 0.6926024201426149, 'weights_6': 0.023585877422855214, 'weights_7': 0.9859810619341368, 'weights_8': 0.02926184802667048, 'weights_9': 0.5605215921331718, 'weights_10': 0.028816761253984472, 'weights_11': 0.5490412200796472, 'weights_12': 0.15261109758063895, 'weights_13': 0.07712031875639498, 'weights_14': 0.08746224820430289, 'weights_15': 0.22064580609547368, 'weights_16': 0.004536391620765981, 'weights_17': 0.696375847485945, 'weights_18': 0.05440979795790858, 'weights_19': 0.9405164472341888}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:56,946] Trial 275 finished with value: 2113.5547754577015 and parameters: {'weights_0': 0.05571970315983752, 'weights_1': 0.25941642183770897, 'weights_2': 0.24494387782840948, 'weights_3': 0.08926357558431314, 'weights_4': 0.8989168813810903, 'weights_5': 0.6884674549192125, 'weights_6': 0.05645341375041373, 'weights_7': 0.990511334330602, 'weights_8': 0.028639917374933575, 'weights_9': 0.564181685063157, 'weights_10': 0.019824958150140157, 'weights_11': 0.553070871046745, 'weights_12': 0.1618964465087348, 'weights_13': 0.026875421540776243, 'weights_14': 0.0988544313723399, 'weights_15': 0.37418333957765043, 'weights_16': 0.004185016551482578, 'weights_17': 0.6864224740131262, 'weights_18': 0.874611793136245, 'weights_19': 0.962935494272668}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:57,078] Trial 276 finished with value: 1844.1897010680411 and parameters: {'weights_0': 0.07773377749451701, 'weights_1': 0.23001660917728584, 'weights_2': 0.27533445523687666, 'weights_3': 0.5827573573011329, 'weights_4': 0.894295934285667, 'weights_5': 0.6823465287075079, 'weights_6': 0.038241634660073395, 'weights_7': 0.9688326060435821, 'weights_8': 0.004717654987323052, 'weights_9': 0.5428085676946449, 'weights_10': 0.02740422027048776, 'weights_11': 0.5417727218038431, 'weights_12': 0.14528895150784396, 'weights_13': 0.08435538844718732, 'weights_14': 0.08385073886283523, 'weights_15': 0.11199247057864896, 'weights_16': 0.0009738499935495262, 'weights_17': 0.7365603085182496, 'weights_18': 0.09345948474001745, 'weights_19': 0.9372304970101754}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:57,234] Trial 277 finished with value: 1789.3316517653363 and parameters: {'weights_0': 0.05637666373379176, 'weights_1': 0.6002739290640291, 'weights_2': 0.24604551169348957, 'weights_3': 0.07811785481617545, 'weights_4': 0.86168734246017, 'weights_5': 0.7032054762434009, 'weights_6': 0.020814025034762575, 'weights_7': 0.9764642458078371, 'weights_8': 0.00027493078036756186, 'weights_9': 0.5796184670861706, 'weights_10': 0.003163653372923427, 'weights_11': 0.5313682042608637, 'weights_12': 0.12771298056456099, 'weights_13': 0.07458652299275215, 'weights_14': 0.06339150224008686, 'weights_15': 0.9401586861466329, 'weights_16': 0.019440519977290748, 'weights_17': 0.7089809051652359, 'weights_18': 0.058053022743215395, 'weights_19': 0.9511960937748513}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:57,359] Trial 278 finished with value: 1835.2582468546354 and parameters: {'weights_0': 0.04800190987157729, 'weights_1': 0.5482838269481899, 'weights_2': 0.2905268051287474, 'weights_3': 0.12197684130394706, 'weights_4': 0.8595787246496608, 'weights_5': 0.7410347658829607, 'weights_6': 0.01908022756501087, 'weights_7': 0.9570318547042458, 'weights_8': 0.02627167750251574, 'weights_9': 0.6041267165817055, 'weights_10': 0.012934349191184837, 'weights_11': 0.5444163496147577, 'weights_12': 0.1713412345924554, 'weights_13': 0.0771491802025908, 'weights_14': 0.08708977344267695, 'weights_15': 0.9309204944509958, 'weights_16': 0.017121692461646795, 'weights_17': 0.699196259437211, 'weights_18': 0.10499046174634667, 'weights_19': 0.9718343699025073}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:57,510] Trial 279 finished with value: 1776.9481961735676 and parameters: {'weights_0': 0.057651516027008534, 'weights_1': 0.6018001965702626, 'weights_2': 0.2563785128708359, 'weights_3': 0.11160774898809761, 'weights_4': 0.8152237107790843, 'weights_5': 0.7063423566862409, 'weights_6': 0.0007986950647806967, 'weights_7': 0.9995089665418119, 'weights_8': 0.0040377103653711464, 'weights_9': 0.5715314741150688, 'weights_10': 0.0007757299073685511, 'weights_11': 0.5648996177401707, 'weights_12': 0.12383490395210364, 'weights_13': 0.11630137937817894, 'weights_14': 0.06593497521714592, 'weights_15': 0.9487779471529153, 'weights_16': 0.000717771522293336, 'weights_17': 0.7109950558561526, 'weights_18': 0.056961044729269134, 'weights_19': 0.9468895140009562}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:57,651] Trial 280 finished with value: 1810.2969743110823 and parameters: {'weights_0': 0.05822340212255991, 'weights_1': 0.6308000613745929, 'weights_2': 0.24873833928388087, 'weights_3': 0.1059940851376912, 'weights_4': 0.8149251303886577, 'weights_5': 0.7078552068216828, 'weights_6': 0.052768752016874206, 'weights_7': 0.9614691764882072, 'weights_8': 9.564299166867074e-05, 'weights_9': 0.5769354962406426, 'weights_10': 0.0018840225457752331, 'weights_11': 0.5636923055873063, 'weights_12': 0.1286949198243016, 'weights_13': 0.048043805949535875, 'weights_14': 0.06983629228867091, 'weights_15': 0.9486677200615582, 'weights_16': 0.014699509044038949, 'weights_17': 0.7164122921383386, 'weights_18': 0.08042293887352152, 'weights_19': 0.9499752892072564}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:57,914] Trial 281 finished with value: 1798.031918698888 and parameters: {'weights_0': 0.0731341528888782, 'weights_1': 0.6019077989163361, 'weights_2': 0.2710484638878008, 'weights_3': 0.07758438383006643, 'weights_4': 0.8394421307694072, 'weights_5': 0.7290920535062249, 'weights_6': 0.018826089112836075, 'weights_7': 0.989085255668816, 'weights_8': 0.0004033940768222166, 'weights_9': 0.5858075735523275, 'weights_10': 0.0037805314262866693, 'weights_11': 0.595148609690837, 'weights_12': 0.1562439253348514, 'weights_13': 0.1140149463962716, 'weights_14': 0.06118745303164397, 'weights_15': 0.9606495234729272, 'weights_16': 0.0027154532460550193, 'weights_17': 0.7668002587121779, 'weights_18': 0.05983947050815276, 'weights_19': 0.9690501094884661}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,055] Trial 282 finished with value: 1827.553777059538 and parameters: {'weights_0': 0.05855889421546982, 'weights_1': 0.5735625224976849, 'weights_2': 0.24030956459332578, 'weights_3': 0.08440864971437667, 'weights_4': 0.8611814963952611, 'weights_5': 0.7077600838893032, 'weights_6': 0.013870259793078064, 'weights_7': 0.9932383581410672, 'weights_8': 0.023600680746484744, 'weights_9': 0.6206327370226431, 'weights_10': 0.0017138909867056708, 'weights_11': 0.532747393894802, 'weights_12': 0.20550073594323146, 'weights_13': 0.07327542420286656, 'weights_14': 0.12692429830063595, 'weights_15': 0.9348257171779714, 'weights_16': 0.000864332328994858, 'weights_17': 0.7395833293605858, 'weights_18': 0.07326024242503451, 'weights_19': 0.9437156835800921}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,196] Trial 283 finished with value: 1799.0623194725802 and parameters: {'weights_0': 0.07964711284556553, 'weights_1': 0.2033638800558862, 'weights_2': 0.29225991621381425, 'weights_3': 0.10583289563826462, 'weights_4': 0.8193215586822238, 'weights_5': 0.6709687603201893, 'weights_6': 0.03863858325107676, 'weights_7': 0.9690641759179728, 'weights_8': 0.04238718825939933, 'weights_9': 0.5588299435078558, 'weights_10': 0.029514558328350426, 'weights_11': 0.5660714688879072, 'weights_12': 0.11987580146798567, 'weights_13': 0.12008278991125859, 'weights_14': 0.1177165439416859, 'weights_15': 0.9535283194355756, 'weights_16': 0.030445833353491766, 'weights_17': 0.6912980079316552, 'weights_18': 0.05497212314443105, 'weights_19': 0.9183937803306099}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,298] Trial 284 finished with value: 1824.393572719598 and parameters: {'weights_0': 0.04937546282859856, 'weights_1': 0.6670726025884423, 'weights_2': 0.256639587891818, 'weights_3': 0.0682824072617661, 'weights_4': 0.841747911672561, 'weights_5': 0.6942612078868963, 'weights_6': 0.0007257332611863409, 'weights_7': 0.9844618866448139, 'weights_8': 0.017204709154403957, 'weights_9': 0.5412297381809108, 'weights_10': 0.029835860534983397, 'weights_11': 0.5296895896909013, 'weights_12': 0.13779111251410708, 'weights_13': 0.15462542882673103, 'weights_14': 0.0952518081473826, 'weights_15': 0.2447453348721631, 'weights_16': 0.019668218311529474, 'weights_17': 0.6700814473421692, 'weights_18': 0.10038404120122692, 'weights_19': 0.9733693445182545}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,420] Trial 285 finished with value: 1828.7524176173188 and parameters: {'weights_0': 0.09096901470897316, 'weights_1': 0.6496489109557086, 'weights_2': 0.28237103478266085, 'weights_3': 0.10407994570174499, 'weights_4': 0.8859912648165201, 'weights_5': 0.6784821462763875, 'weights_6': 0.02036098883883034, 'weights_7': 0.9217185527130195, 'weights_8': 0.03733701277710391, 'weights_9': 0.5675942251938043, 'weights_10': 0.0006618934034631173, 'weights_11': 0.502126196584594, 'weights_12': 0.1102126735432683, 'weights_13': 0.10062116484189576, 'weights_14': 0.07234294784344389, 'weights_15': 0.16545009315801507, 'weights_16': 0.03405666378465026, 'weights_17': 0.7181257948308076, 'weights_18': 0.05572046926291561, 'weights_19': 0.9422194827031192}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,592] Trial 286 finished with value: 1801.570416471222 and parameters: {'weights_0': 0.07463251231887522, 'weights_1': 0.24658174060793248, 'weights_2': 0.3309849582268578, 'weights_3': 0.1359792992058948, 'weights_4': 0.8621547714473728, 'weights_5': 0.7569839364740066, 'weights_6': 0.0544722682062803, 'weights_7': 0.9093100876575325, 'weights_8': 0.02324747467810659, 'weights_9': 0.5202492124628171, 'weights_10': 0.03024619035962908, 'weights_11': 0.5872458303065551, 'weights_12': 0.09673569476386668, 'weights_13': 0.04306487032933294, 'weights_14': 0.059621403852790814, 'weights_15': 0.9333788511331624, 'weights_16': 0.0020205598708637057, 'weights_17': 0.6974670018600995, 'weights_18': 0.10687266616035263, 'weights_19': 0.9246111540049293}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,783] Trial 287 finished with value: 1845.5170426331927 and parameters: {'weights_0': 0.040006418307340266, 'weights_1': 0.5598720922976597, 'weights_2': 0.2333028054744108, 'weights_3': 0.07514347676575428, 'weights_4': 0.8857226114035024, 'weights_5': 0.657020646100424, 'weights_6': 0.0011385706759178896, 'weights_7': 0.9489223994515252, 'weights_8': 0.040556054213320675, 'weights_9': 0.5470781200657558, 'weights_10': 0.05605749999235664, 'weights_11': 0.5070953667206227, 'weights_12': 0.14795166719100544, 'weights_13': 0.07152888119320863, 'weights_14': 0.1084292735595323, 'weights_15': 0.9674845916606044, 'weights_16': 0.03736448339724749, 'weights_17': 0.7261626317719765, 'weights_18': 0.08766007478264248, 'weights_19': 0.9526215239873409}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:58,968] Trial 288 finished with value: 2446.4089657675327 and parameters: {'weights_0': 0.09972082776309711, 'weights_1': 0.5161414749400576, 'weights_2': 0.31444637401758263, 'weights_3': 0.07006493645250489, 'weights_4': 0.8442695312177557, 'weights_5': 0.705743012179596, 'weights_6': 0.8024031117388607, 'weights_7': 0.1444304729078284, 'weights_8': 0.0016755175024043972, 'weights_9': 0.5287147040895762, 'weights_10': 0.019884113212587408, 'weights_11': 0.5554271781307139, 'weights_12': 0.12152823534756607, 'weights_13': 0.09377247149779974, 'weights_14': 0.05630588358142992, 'weights_15': 0.9736289528794458, 'weights_16': 0.4860200981145375, 'weights_17': 0.671639469260551, 'weights_18': 0.05201041670543695, 'weights_19': 0.9107885600222908}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:59,111] Trial 289 finished with value: 1907.8100716668046 and parameters: {'weights_0': 0.062265589865706024, 'weights_1': 0.4777872396866635, 'weights_2': 0.2560682770723015, 'weights_3': 0.10238251867808397, 'weights_4': 0.8695739892213246, 'weights_5': 0.6772313301028421, 'weights_6': 0.04066744929770011, 'weights_7': 0.9995300914129355, 'weights_8': 0.01761310310775921, 'weights_9': 0.5838517574414801, 'weights_10': 0.04016531700379696, 'weights_11': 0.5269781375419285, 'weights_12': 0.36516738529395776, 'weights_13': 0.13603948927805148, 'weights_14': 0.0854551365368433, 'weights_15': 0.01940351118156411, 'weights_16': 0.02073743433428996, 'weights_17': 0.6966918232333896, 'weights_18': 0.07787394828402056, 'weights_19': 0.9360460393153762}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:59,366] Trial 290 finished with value: 2118.5713072118456 and parameters: {'weights_0': 0.08443591508862272, 'weights_1': 0.6056950678711868, 'weights_2': 0.3925198214013588, 'weights_3': 0.08111262643689623, 'weights_4': 0.8068493232074645, 'weights_5': 0.725787568478471, 'weights_6': 0.022928376147088626, 'weights_7': 0.9401123605175615, 'weights_8': 0.0434814209236849, 'weights_9': 0.4902525152568921, 'weights_10': 0.0662677961547592, 'weights_11': 0.5366119813606536, 'weights_12': 0.09930099793808764, 'weights_13': 0.11624327342897192, 'weights_14': 0.051535457361775505, 'weights_15': 0.9239230472448338, 'weights_16': 0.6271728678067338, 'weights_17': 0.6668901428259998, 'weights_18': 0.0560233192195488, 'weights_19': 0.9687185057192921}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:59,523] Trial 291 finished with value: 1902.706512514156 and parameters: {'weights_0': 0.09874114325018644, 'weights_1': 0.7021748611004025, 'weights_2': 0.46564824249542536, 'weights_3': 0.06184245138456207, 'weights_4': 0.9053700037130737, 'weights_5': 0.6923219953716682, 'weights_6': 0.02223987799446612, 'weights_7': 0.9271001060126225, 'weights_8': 0.019891043370783696, 'weights_9': 0.5560917270282396, 'weights_10': 0.019847448551597636, 'weights_11': 0.5020468377052043, 'weights_12': 0.13197459280820345, 'weights_13': 0.021001068682085608, 'weights_14': 0.05947428757444066, 'weights_15': 0.9486669066487651, 'weights_16': 0.04009691204500976, 'weights_17': 0.7579499368005648, 'weights_18': 0.07866859794524016, 'weights_19': 0.916425649424516}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:59,675] Trial 292 finished with value: 1956.9545317962309 and parameters: {'weights_0': 0.37888475557939094, 'weights_1': 0.5946211507366952, 'weights_2': 0.27432858895145296, 'weights_3': 0.06244687564518502, 'weights_4': 0.8947823921516138, 'weights_5': 0.6587217685164052, 'weights_6': 0.0009227380234247068, 'weights_7': 0.9343615838754961, 'weights_8': 0.04350132531403958, 'weights_9': 0.519925263219277, 'weights_10': 0.04594873372734631, 'weights_11': 0.5584531369517232, 'weights_12': 0.1680737077558494, 'weights_13': 0.07647217381355415, 'weights_14': 0.07579049355001366, 'weights_15': 0.966859947397091, 'weights_16': 0.019588513166808687, 'weights_17': 0.7926777242772302, 'weights_18': 0.10981171369853267, 'weights_19': 0.9528500819736409}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:05:59,848] Trial 293 finished with value: 1983.318616472024 and parameters: {'weights_0': 0.05748449702376042, 'weights_1': 0.20283170739470363, 'weights_2': 0.22876577733145934, 'weights_3': 0.09831614155876509, 'weights_4': 0.865520155475133, 'weights_5': 0.6365863411843083, 'weights_6': 0.05335315063436297, 'weights_7': 0.9150584188914347, 'weights_8': 0.03652094592506762, 'weights_9': 0.4948060413240157, 'weights_10': 0.06594773825776966, 'weights_11': 0.5143651260933234, 'weights_12': 0.14673554760251273, 'weights_13': 0.09183639653632995, 'weights_14': 0.5850045643293867, 'weights_15': 0.9324169339960149, 'weights_16': 0.0012785890774475693, 'weights_17': 0.7109787672652119, 'weights_18': 0.05214231730147803, 'weights_19': 0.9267288599738319}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:06:00,011] Trial 294 finished with value: 1999.1836520337447 and parameters: {'weights_0': 0.10703469792432545, 'weights_1': 0.6321711360503903, 'weights_2': 0.3053096004300903, 'weights_3': 0.1207448864077485, 'weights_4': 0.8281336128953447, 'weights_5': 0.6721071519380756, 'weights_6': 0.033771224551896184, 'weights_7': 0.9777115845830162, 'weights_8': 0.018779825501605726, 'weights_9': 0.5359142226934412, 'weights_10': 0.03685166658713443, 'weights_11': 0.607313158494249, 'weights_12': 0.09830486869095569, 'weights_13': 0.049788366078251864, 'weights_14': 0.10550096117165471, 'weights_15': 0.9760644389723282, 'weights_16': 0.04481196792918617, 'weights_17': 0.6837078136571202, 'weights_18': 0.4788521027649465, 'weights_19': 0.9051336573757489}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:06:00,170] Trial 295 finished with value: 1920.1039623594054 and parameters: {'weights_0': 0.514334776660089, 'weights_1': 0.22054501677238708, 'weights_2': 0.2496860252179444, 'weights_3': 0.0828891006000378, 'weights_4': 0.8814676805515607, 'weights_5': 0.7133203459857265, 'weights_6': 0.0009619904749402913, 'weights_7': 0.9177351552761488, 'weights_8': 0.002091997158323968, 'weights_9': 0.5115926959288316, 'weights_10': 0.0008824487712799567, 'weights_11': 0.574064373989916, 'weights_12': 0.18191859444844916, 'weights_13': 0.1520620889896219, 'weights_14': 0.04942886724031205, 'weights_15': 0.9480071219184167, 'weights_16': 0.02276228180108631, 'weights_17': 0.7391675609042995, 'weights_18': 0.06932500512482913, 'weights_19': 0.9741151024236706}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:06:00,295] Trial 296 finished with value: 1801.977558217887 and parameters: {'weights_0': 0.0757756048562758, 'weights_1': 0.18979496668955376, 'weights_2': 0.2705137819463725, 'weights_3': 0.05719154731341928, 'weights_4': 0.9051218846637419, 'weights_5': 0.6913537186025607, 'weights_6': 0.06119855112399366, 'weights_7': 0.9732164576041503, 'weights_8': 0.051035440028722026, 'weights_9': 0.6052001898065861, 'weights_10': 0.056293131715193026, 'weights_11': 0.4969010284784675, 'weights_12': 0.12022468371779912, 'weights_13': 0.12797465122994534, 'weights_14': 0.04250368069709774, 'weights_15': 0.9755914740628692, 'weights_16': 0.04792572099737607, 'weights_17': 0.6611929701716851, 'weights_18': 0.08855980285354732, 'weights_19': 0.9380114172777069}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:06:00,423] Trial 297 finished with value: 1751.5528737895559 and parameters: {'weights_0': 0.03605451178210821, 'weights_1': 0.1787154242884148, 'weights_2': 0.2894416664510341, 'weights_3': 0.053079756277718534, 'weights_4': 0.8475648954562813, 'weights_5': 0.6496632118938422, 'weights_6': 0.02025165315967826, 'weights_7': 0.9092261998948374, 'weights_8': 0.03245633040205952, 'weights_9': 0.5746949883323925, 'weights_10': 0.031302243573345295, 'weights_11': 0.536718753661966, 'weights_12': 0.0921135807928453, 'weights_13': 0.06236498959983152, 'weights_14': 0.07756771475800804, 'weights_15': 0.9534438399445457, 'weights_16': 0.021754113950496853, 'weights_17': 0.7179025687260936, 'weights_18': 0.05677339368544802, 'weights_19': 0.9518618122801807}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:06:00,766] Trial 298 finished with value: 1775.2743359274273 and parameters: {'weights_0': 0.03246205891534511, 'weights_1': 0.23747653534385782, 'weights_2': 0.24069715071209694, 'weights_3': 0.3020925840265946, 'weights_4': 0.8378124437262152, 'weights_5': 0.6477477360156655, 'weights_6': 0.03811332465417186, 'weights_7': 0.9463715153521138, 'weights_8': 0.04490339679492296, 'weights_9': 0.5827860080067688, 'weights_10': 0.022076377166294472, 'weights_11': 0.5259935870963466, 'weights_12': 0.09451334919821114, 'weights_13': 0.006882980149051865, 'weights_14': 0.08062098464925957, 'weights_15': 0.9603909989186015, 'weights_16': 0.03805618526188791, 'weights_17': 0.7290542026612676, 'weights_18': 0.052715361559059724, 'weights_19': 0.9566854061257382}. Best is trial 274 with value: 1742.8116808767434.\n",
      "[I 2025-08-01 08:06:01,044] Trial 299 finished with value: 1791.448124223199 and parameters: {'weights_0': 0.031127766801107376, 'weights_1': 0.2377757391379327, 'weights_2': 0.23712175582304698, 'weights_3': 0.3807483955703728, 'weights_4': 0.8422475219622741, 'weights_5': 0.631422493481505, 'weights_6': 0.04188730936550281, 'weights_7': 0.9571731197845561, 'weights_8': 0.00024625388699799593, 'weights_9': 0.5803170153769055, 'weights_10': 0.020542568235081715, 'weights_11': 0.5291066008764097, 'weights_12': 0.09100570333118907, 'weights_13': 0.004667475681038036, 'weights_14': 0.11614730309742903, 'weights_15': 0.9241161060465192, 'weights_16': 0.049341464039180286, 'weights_17': 0.7270525140366786, 'weights_18': 0.04833807463770114, 'weights_19': 0.9700581719763057}. Best is trial 274 with value: 1742.8116808767434.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "voting_study = optuna.create_study(direction='minimize')\n",
    "voting_study.optimize(voting_objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/voting_optuna_study.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(voting_study.best_params, f\"../../split_year_models/ensemble/voting_best_params.pkl\")\n",
    "joblib.dump(voting_study, f\"../../split_year_models/ensemble/voting_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights_0': 0.01140283808613561,\n",
       " 'weights_1': 0.030159135816254498,\n",
       " 'weights_2': 0.03468906300086026,\n",
       " 'weights_3': 0.012070612778268649,\n",
       " 'weights_4': 0.13594098207864408,\n",
       " 'weights_5': 0.10527652875091603,\n",
       " 'weights_6': 0.0035850860903886414,\n",
       " 'weights_7': 0.14987048932516597,\n",
       " 'weights_8': 0.004447841496785966,\n",
       " 'weights_9': 0.08520005964975735,\n",
       " 'weights_10': 0.004380187689841886,\n",
       " 'weights_11': 0.08345502717020692,\n",
       " 'weights_12': 0.02319709855886547,\n",
       " 'weights_13': 0.011722395444655878,\n",
       " 'weights_14': 0.013294383068722269,\n",
       " 'weights_15': 0.033538468641787444,\n",
       " 'weights_16': 0.0006895378199669675,\n",
       " 'weights_17': 0.10585009494220626,\n",
       " 'weights_18': 0.0082703647756065,\n",
       " 'weights_19': 0.14295980481496337}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = voting_study.best_params\n",
    "normalised_bp = {k: v / sum(bp.values()) for k, v in bp.items()}\n",
    "normalised_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/voting_normalised_best_params.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(normalised_bp, f\"../../split_year_models/ensemble/voting_normalised_best_params.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression -> Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_linreg(trial):\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 1.0)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "    \n",
    "    #to get the predictions of the base models \n",
    "    #fit_intercept=True\n",
    "    elastic_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True, random_state=42)\n",
    "    elastic_model.fit(X_meta_train, y_meta_train)\n",
    "    elastic_predictions = elastic_model.predict(X_meta_val)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, elastic_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:06:01,734] A new study created in memory with name: no-name-25313670-d044-41cc-bcc9-783a90bc1aba\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.794e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:01,985] Trial 0 finished with value: 467.2018752397538 and parameters: {'alpha': 0.5378771604387992, 'l1_ratio': 0.8701990447549647}. Best is trial 0 with value: 467.2018752397538.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.846e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,161] Trial 1 finished with value: 467.3544682453146 and parameters: {'alpha': 0.8757484694864872, 'l1_ratio': 0.39719016588575384}. Best is trial 0 with value: 467.2018752397538.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,351] Trial 2 finished with value: 467.0505711460748 and parameters: {'alpha': 0.8748844508863194, 'l1_ratio': 0.21003999785843885}. Best is trial 2 with value: 467.0505711460748.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.865e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,602] Trial 3 finished with value: 467.3376910786846 and parameters: {'alpha': 0.934729954502963, 'l1_ratio': 0.32492597280674695}. Best is trial 2 with value: 467.0505711460748.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,782] Trial 4 finished with value: 466.0221349100704 and parameters: {'alpha': 0.20307488398571594, 'l1_ratio': 0.16158521373875334}. Best is trial 4 with value: 466.0221349100704.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,950] Trial 5 finished with value: 466.0160218634485 and parameters: {'alpha': 0.2496723811801009, 'l1_ratio': 0.014038743801862874}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.922e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,081] Trial 6 finished with value: 466.13209828903524 and parameters: {'alpha': 0.15133485645630054, 'l1_ratio': 0.7849569018039189}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.949e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,220] Trial 7 finished with value: 466.7897779297875 and parameters: {'alpha': 0.8048555592046266, 'l1_ratio': 0.10851480395690127}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.936e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,381] Trial 8 finished with value: 466.0858009384236 and parameters: {'alpha': 0.16775204619120598, 'l1_ratio': 0.5096793581809249}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.850e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,563] Trial 9 finished with value: 467.01888984647485 and parameters: {'alpha': 0.6073613346148281, 'l1_ratio': 0.5342036940270961}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.975e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,719] Trial 10 finished with value: 466.143469646961 and parameters: {'alpha': 0.3710340229331496, 'l1_ratio': 0.000873687269891477}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,898] Trial 11 finished with value: 466.0981638865583 and parameters: {'alpha': 0.29918209385897454, 'l1_ratio': 0.05877055960504453}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.945e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,078] Trial 12 finished with value: 466.25543657029135 and parameters: {'alpha': 0.3461865894333226, 'l1_ratio': 0.2073435200966381}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.845e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,235] Trial 13 finished with value: 466.8978444831948 and parameters: {'alpha': 0.4848592188130607, 'l1_ratio': 0.684560104445935}. Best is trial 5 with value: 466.0160218634485.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,403] Trial 14 finished with value: 465.89245228671825 and parameters: {'alpha': 0.1055547572898155, 'l1_ratio': 0.20281378943660477}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.954e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,561] Trial 15 finished with value: 465.94292527350393 and parameters: {'alpha': 0.11937486590034549, 'l1_ratio': 0.330389239156454}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.954e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,730] Trial 16 finished with value: 465.9215530966975 and parameters: {'alpha': 0.10431575318309841, 'l1_ratio': 0.35476812678979364}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,902] Trial 17 finished with value: 466.96403530204765 and parameters: {'alpha': 0.6596182181308412, 'l1_ratio': 0.4001429664113981}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.879e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,090] Trial 18 finished with value: 466.64568795981626 and parameters: {'alpha': 0.4080391672335146, 'l1_ratio': 0.5915415853146239}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,256] Trial 19 finished with value: 465.89953703031597 and parameters: {'alpha': 0.10048149179015481, 'l1_ratio': 0.27743189772130633}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,464] Trial 20 finished with value: 466.87355672725624 and parameters: {'alpha': 0.7146949869048433, 'l1_ratio': 0.2563526261575663}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.950e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,640] Trial 21 finished with value: 465.9540366126654 and parameters: {'alpha': 0.11560454307088779, 'l1_ratio': 0.4083963748548203}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.941e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,836] Trial 22 finished with value: 466.1516416610567 and parameters: {'alpha': 0.24279892528708405, 'l1_ratio': 0.3167734168081515}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,964] Trial 23 finished with value: 466.0943307448612 and parameters: {'alpha': 0.26440302982664665, 'l1_ratio': 0.1330056919886817}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.929e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,127] Trial 24 finished with value: 466.0410989119538 and parameters: {'alpha': 0.10108638732036374, 'l1_ratio': 0.9921900536148318}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.950e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,262] Trial 25 finished with value: 466.0527732555894 and parameters: {'alpha': 0.19643842367278397, 'l1_ratio': 0.2658462363590284}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.896e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,421] Trial 26 finished with value: 466.59094055088286 and parameters: {'alpha': 0.42986569977913197, 'l1_ratio': 0.4633747527727673}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.888e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,639] Trial 27 finished with value: 466.51500368091183 and parameters: {'alpha': 0.33448561314885084, 'l1_ratio': 0.6412587056102719}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.949e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,778] Trial 28 finished with value: 466.0809243548129 and parameters: {'alpha': 0.21578458719758636, 'l1_ratio': 0.25852279089477426}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,945] Trial 29 finished with value: 466.408130000531 and parameters: {'alpha': 0.5209774807590253, 'l1_ratio': 0.09841758816328183}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.919e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,242] Trial 30 finished with value: 466.3237688327517 and parameters: {'alpha': 0.29657421386236016, 'l1_ratio': 0.45645198504865786}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,422] Trial 31 finished with value: 465.9136713275383 and parameters: {'alpha': 0.102656783247221, 'l1_ratio': 0.33036015729570667}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.948e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,584] Trial 32 finished with value: 466.0248443897726 and parameters: {'alpha': 0.1633231862425843, 'l1_ratio': 0.3467094296107396}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,881] Trial 33 finished with value: 465.8988528689078 and parameters: {'alpha': 0.10437051162365261, 'l1_ratio': 0.24277169009403615}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,045] Trial 34 finished with value: 465.9883182730639 and parameters: {'alpha': 0.1713199333726902, 'l1_ratio': 0.19478044140227846}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.950e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,199] Trial 35 finished with value: 466.07415012667076 and parameters: {'alpha': 0.2132597498893669, 'l1_ratio': 0.2519666135227794}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.909e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,372] Trial 36 finished with value: 467.19058189597433 and parameters: {'alpha': 0.9827511571331415, 'l1_ratio': 0.19919885926707012}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,635] Trial 37 finished with value: 466.2029986971848 and parameters: {'alpha': 0.2812198813079445, 'l1_ratio': 0.28991115383679084}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,758] Trial 38 finished with value: 465.90111654528727 and parameters: {'alpha': 0.1365854613822112, 'l1_ratio': 0.06171320570055572}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,927] Trial 39 finished with value: 465.92449566679636 and parameters: {'alpha': 0.15420703973345004, 'l1_ratio': 0.06769148918770294}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,086] Trial 40 finished with value: 466.0516495631146 and parameters: {'alpha': 0.2308134373609716, 'l1_ratio': 0.139910924202019}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.960e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,236] Trial 41 finished with value: 465.9386502344695 and parameters: {'alpha': 0.14247331198206498, 'l1_ratio': 0.17039680101659455}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,391] Trial 42 finished with value: 465.9638526434653 and parameters: {'alpha': 0.19093678728977045, 'l1_ratio': 0.05182125495069938}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,553] Trial 43 finished with value: 465.9514208699096 and parameters: {'alpha': 0.14175101960911782, 'l1_ratio': 0.22007037574949928}. Best is trial 14 with value: 465.89245228671825.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,689] Trial 44 finished with value: 465.8741669833733 and parameters: {'alpha': 0.10032231800443474, 'l1_ratio': 0.14988454187780098}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,903] Trial 45 finished with value: 465.97226051028264 and parameters: {'alpha': 0.18345778355591072, 'l1_ratio': 0.10011331881986141}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.958e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,076] Trial 46 finished with value: 466.0688545435013 and parameters: {'alpha': 0.24263788702192424, 'l1_ratio': 0.14182304888379793}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.984e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,188] Trial 47 finished with value: 466.6811246079791 and parameters: {'alpha': 0.8530297764328783, 'l1_ratio': 0.004468053921011288}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,407] Trial 48 finished with value: 465.91520457437093 and parameters: {'alpha': 0.1443751278028301, 'l1_ratio': 0.07774179511646737}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.952e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,564] Trial 49 finished with value: 466.2031668545815 and parameters: {'alpha': 0.32772105656757033, 'l1_ratio': 0.16865811976743497}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,778] Trial 50 finished with value: 466.6187315898955 and parameters: {'alpha': 0.7464576144456254, 'l1_ratio': 0.04284815554897292}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.953e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,986] Trial 51 finished with value: 465.92565573630156 and parameters: {'alpha': 0.10328495029181375, 'l1_ratio': 0.3841378359285273}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.953e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,132] Trial 52 finished with value: 465.9668052699455 and parameters: {'alpha': 0.13818698932870666, 'l1_ratio': 0.2968865555774338}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,307] Trial 53 finished with value: 465.89557749655825 and parameters: {'alpha': 0.10175814510403373, 'l1_ratio': 0.24703721093130016}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.954e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,480] Trial 54 finished with value: 466.0201637992504 and parameters: {'alpha': 0.18449248027924003, 'l1_ratio': 0.22925836774419928}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.949e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,670] Trial 55 finished with value: 466.53077300602513 and parameters: {'alpha': 0.5886547603851127, 'l1_ratio': 0.1295413817248181}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,863] Trial 56 finished with value: 465.9255072974295 and parameters: {'alpha': 0.12729404116480816, 'l1_ratio': 0.20504723846512696}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,053] Trial 57 finished with value: 466.27109665816147 and parameters: {'alpha': 0.2093368144284139, 'l1_ratio': 0.7554313113686436}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.951e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,215] Trial 58 finished with value: 466.01760839586836 and parameters: {'alpha': 0.17054835171635613, 'l1_ratio': 0.28654782501355464}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.956e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,385] Trial 59 finished with value: 466.0910046407877 and parameters: {'alpha': 0.2508236265870689, 'l1_ratio': 0.16387061525523094}. Best is trial 44 with value: 465.8741669833733.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,544] Trial 60 finished with value: 465.85189081246546 and parameters: {'alpha': 0.10150739509875141, 'l1_ratio': 0.030052663523711498}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,714] Trial 61 finished with value: 465.8773614042826 and parameters: {'alpha': 0.12460332127353504, 'l1_ratio': 0.024592444388221557}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,895] Trial 62 finished with value: 465.8532894070185 and parameters: {'alpha': 0.10296792425794672, 'l1_ratio': 0.028586706086098895}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,073] Trial 63 finished with value: 465.8788242007601 and parameters: {'alpha': 0.12463676263200353, 'l1_ratio': 0.03039843104663817}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,228] Trial 64 finished with value: 465.88708840176906 and parameters: {'alpha': 0.1337072665173485, 'l1_ratio': 0.02175905294930903}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,396] Trial 65 finished with value: 465.93864026517497 and parameters: {'alpha': 0.17719451442396572, 'l1_ratio': 0.02684964130099625}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,573] Trial 66 finished with value: 465.9829062852793 and parameters: {'alpha': 0.219617263198364, 'l1_ratio': 0.01596610753339181}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,742] Trial 67 finished with value: 466.08948366964097 and parameters: {'alpha': 0.27706642506512513, 'l1_ratio': 0.09234120043005925}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,861] Trial 68 finished with value: 465.8868163614558 and parameters: {'alpha': 0.13084996903801172, 'l1_ratio': 0.033401055771443706}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.975e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,027] Trial 69 finished with value: 466.18544541550665 and parameters: {'alpha': 0.4058790267030205, 'l1_ratio': 0.005303265887611014}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,206] Trial 70 finished with value: 465.9179157453345 and parameters: {'alpha': 0.15543957171975387, 'l1_ratio': 0.04121718811745691}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,360] Trial 71 finished with value: 465.90315575239873 and parameters: {'alpha': 0.12890817076545114, 'l1_ratio': 0.10677787602025393}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,534] Trial 72 finished with value: 465.97955162974296 and parameters: {'alpha': 0.19723545598418657, 'l1_ratio': 0.07275008870249969}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,690] Trial 73 finished with value: 465.8827011194755 and parameters: {'alpha': 0.1270171016825886, 'l1_ratio': 0.034843324029728895}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,855] Trial 74 finished with value: 465.924263217458 and parameters: {'alpha': 0.16335503347232855, 'l1_ratio': 0.03183253379325723}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,977] Trial 75 finished with value: 465.8694669839887 and parameters: {'alpha': 0.12266321745535438, 'l1_ratio': 0.0011339124703104546}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,153] Trial 76 finished with value: 465.8742788433565 and parameters: {'alpha': 0.1269007555060564, 'l1_ratio': 0.001668290584074958}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,303] Trial 77 finished with value: 466.04112708870264 and parameters: {'alpha': 0.2282790011738734, 'l1_ratio': 0.12413020736601445}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,478] Trial 78 finished with value: 465.9371195452344 and parameters: {'alpha': 0.1617494396990366, 'l1_ratio': 0.0782116819398854}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,658] Trial 79 finished with value: 465.86825001238407 and parameters: {'alpha': 0.12122361523805947, 'l1_ratio': 0.002695253462460121}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.972e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,769] Trial 80 finished with value: 465.9543681908492 and parameters: {'alpha': 0.19996395599265637, 'l1_ratio': 1.5136459938766555e-05}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,911] Trial 81 finished with value: 465.8832799697328 and parameters: {'alpha': 0.12178122949383371, 'l1_ratio': 0.06282480693524477}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,070] Trial 82 finished with value: 465.87434205440076 and parameters: {'alpha': 0.11645175028528137, 'l1_ratio': 0.05233375412444141}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,285] Trial 83 finished with value: 465.93774107786703 and parameters: {'alpha': 0.1561338935780431, 'l1_ratio': 0.10329258449266596}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,426] Trial 84 finished with value: 465.874255387185 and parameters: {'alpha': 0.11578336046917832, 'l1_ratio': 0.055487857505934726}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,569] Trial 85 finished with value: 465.952889627701 and parameters: {'alpha': 0.1799996175905465, 'l1_ratio': 0.05805913182625377}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,747] Trial 86 finished with value: 465.86563759549443 and parameters: {'alpha': 0.10359523361519138, 'l1_ratio': 0.08563345510131902}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,923] Trial 87 finished with value: 465.8645807092745 and parameters: {'alpha': 0.10274798747987804, 'l1_ratio': 0.08573119970412316}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.954e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,078] Trial 88 finished with value: 466.36166061903793 and parameters: {'alpha': 0.4698131932354265, 'l1_ratio': 0.12002240052685273}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,224] Trial 89 finished with value: 466.2114972436246 and parameters: {'alpha': 0.16176371228487038, 'l1_ratio': 0.9532758166550264}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,433] Trial 90 finished with value: 465.92008312041355 and parameters: {'alpha': 0.14708881823163575, 'l1_ratio': 0.082823065070655}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,606] Trial 91 finished with value: 465.8799891613126 and parameters: {'alpha': 0.104160441868699, 'l1_ratio': 0.1521158731736308}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,747] Trial 92 finished with value: 465.85690142727816 and parameters: {'alpha': 0.1014837634274525, 'l1_ratio': 0.05532255556914006}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,890] Trial 93 finished with value: 465.86668860620443 and parameters: {'alpha': 0.10301026108050712, 'l1_ratio': 0.09448389865222719}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,047] Trial 94 finished with value: 466.01068500436566 and parameters: {'alpha': 0.18800144222215803, 'l1_ratio': 0.18842944614083723}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.945e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,196] Trial 95 finished with value: 465.9660303260354 and parameters: {'alpha': 0.10494050917759189, 'l1_ratio': 0.5665167474647606}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,352] Trial 96 finished with value: 465.92650373592824 and parameters: {'alpha': 0.14877173557025147, 'l1_ratio': 0.09746743509225887}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,502] Trial 97 finished with value: 466.0103576064735 and parameters: {'alpha': 0.2058957997391496, 'l1_ratio': 0.12229298668664754}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,673] Trial 98 finished with value: 465.8659485644838 and parameters: {'alpha': 0.10463334966462241, 'l1_ratio': 0.08073757200344432}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,761] Trial 99 finished with value: 465.95034298580305 and parameters: {'alpha': 0.1720678757940003, 'l1_ratio': 0.07906537963460138}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.960e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,970] Trial 100 finished with value: 465.9453836367936 and parameters: {'alpha': 0.14548259349688886, 'l1_ratio': 0.17882040041160197}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,104] Trial 101 finished with value: 465.85666950975343 and parameters: {'alpha': 0.10204861703131252, 'l1_ratio': 0.050760829102431695}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,292] Trial 102 finished with value: 465.88041178477727 and parameters: {'alpha': 0.10541524357927934, 'l1_ratio': 0.14567665996713522}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,452] Trial 103 finished with value: 465.8673578743964 and parameters: {'alpha': 0.10034203564430548, 'l1_ratio': 0.11527653639965499}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,628] Trial 104 finished with value: 465.9194401631656 and parameters: {'alpha': 0.13971230480352567, 'l1_ratio': 0.11441571323998156}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,800] Trial 105 finished with value: 465.86023798592356 and parameters: {'alpha': 0.10038782179388549, 'l1_ratio': 0.07893262062896163}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,006] Trial 106 finished with value: 465.8612705329456 and parameters: {'alpha': 0.10047932458378045, 'l1_ratio': 0.08357263661426437}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,197] Trial 107 finished with value: 465.9263307376466 and parameters: {'alpha': 0.14963903644957882, 'l1_ratio': 0.09307143517296523}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,399] Trial 108 finished with value: 465.9529963618609 and parameters: {'alpha': 0.1763810877233436, 'l1_ratio': 0.07106810265252109}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,701] Trial 109 finished with value: 465.8874895436521 and parameters: {'alpha': 0.1123347905705737, 'l1_ratio': 0.13431812900702814}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,856] Trial 110 finished with value: 466.53019270920686 and parameters: {'alpha': 0.6665472985922561, 'l1_ratio': 0.047579694293102145}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,997] Trial 111 finished with value: 465.86245008258516 and parameters: {'alpha': 0.10091621510973503, 'l1_ratio': 0.08672544210662775}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.964e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,169] Trial 112 finished with value: 465.9201692815179 and parameters: {'alpha': 0.14179574534824757, 'l1_ratio': 0.10712001202304805}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.962e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,336] Trial 113 finished with value: 465.893932771521 and parameters: {'alpha': 0.11350518116762598, 'l1_ratio': 0.15599745559353068}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,483] Trial 114 finished with value: 465.86259827806845 and parameters: {'alpha': 0.1010245662347998, 'l1_ratio': 0.08677712295477912}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.965e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,623] Trial 115 finished with value: 465.9441493252875 and parameters: {'alpha': 0.16498987797209244, 'l1_ratio': 0.08742222724344605}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,802] Trial 116 finished with value: 465.90321599910646 and parameters: {'alpha': 0.14147514564234875, 'l1_ratio': 0.047765216745901506}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,973] Trial 117 finished with value: 465.85947086811063 and parameters: {'alpha': 0.10136598709567139, 'l1_ratio': 0.0689202131564399}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,177] Trial 118 finished with value: 465.96639496838134 and parameters: {'alpha': 0.18816574796559005, 'l1_ratio': 0.0677190740919596}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,333] Trial 119 finished with value: 465.87989959509474 and parameters: {'alpha': 0.12602781764098128, 'l1_ratio': 0.02821855971509284}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.924e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,517] Trial 120 finished with value: 466.14007473893935 and parameters: {'alpha': 0.16296106888291295, 'l1_ratio': 0.7135973023411575}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,690] Trial 121 finished with value: 465.8621240328759 and parameters: {'alpha': 0.10016459664743424, 'l1_ratio': 0.08992489350945379}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,823] Trial 122 finished with value: 465.858510378558 and parameters: {'alpha': 0.10083269990529825, 'l1_ratio': 0.06740611239245597}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,002] Trial 123 finished with value: 465.89413753617026 and parameters: {'alpha': 0.13379088285395194, 'l1_ratio': 0.04819340410096617}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,168] Trial 124 finished with value: 465.8730831599211 and parameters: {'alpha': 0.1215876611471388, 'l1_ratio': 0.02121112402845539}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,311] Trial 125 finished with value: 465.93776548204323 and parameters: {'alpha': 0.15017026935896083, 'l1_ratio': 0.1297915617904562}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,520] Trial 126 finished with value: 465.8970202826663 and parameters: {'alpha': 0.13145836348045437, 'l1_ratio': 0.0701302017238351}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,687] Trial 127 finished with value: 465.87448058200954 and parameters: {'alpha': 0.11678858774117791, 'l1_ratio': 0.05117053966818256}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.947e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,851] Trial 128 finished with value: 466.89881670178806 and parameters: {'alpha': 0.8901876897149074, 'l1_ratio': 0.10714874270242505}. Best is trial 60 with value: 465.85189081246546.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,010] Trial 129 finished with value: 465.8511182446265 and parameters: {'alpha': 0.10003587820292169, 'l1_ratio': 0.034804047144054454}. Best is trial 129 with value: 465.8511182446265.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,160] Trial 130 finished with value: 465.91675166111935 and parameters: {'alpha': 0.15857445832330141, 'l1_ratio': 0.02560616586907454}. Best is trial 129 with value: 465.8511182446265.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,319] Trial 131 finished with value: 465.8529763602932 and parameters: {'alpha': 0.10111889946766754, 'l1_ratio': 0.03781325407462719}. Best is trial 129 with value: 465.8511182446265.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,486] Trial 132 finished with value: 465.89524515164754 and parameters: {'alpha': 0.1313263529804108, 'l1_ratio': 0.06389510784424907}. Best is trial 129 with value: 465.8511182446265.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,682] Trial 133 finished with value: 465.8506232923116 and parameters: {'alpha': 0.10202255465133687, 'l1_ratio': 0.020766942134265675}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,802] Trial 134 finished with value: 465.87005329963625 and parameters: {'alpha': 0.12011060850422718, 'l1_ratio': 0.015539242674144683}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,961] Trial 135 finished with value: 465.89702191940563 and parameters: {'alpha': 0.1400546274343564, 'l1_ratio': 0.03145553301035618}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.947e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,140] Trial 136 finished with value: 465.97502095465273 and parameters: {'alpha': 0.11845655986554127, 'l1_ratio': 0.47633916260579423}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.934e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,341] Trial 137 finished with value: 466.0144878671255 and parameters: {'alpha': 0.10072759967983257, 'l1_ratio': 0.8615694715663341}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,533] Trial 138 finished with value: 466.40899284487347 and parameters: {'alpha': 0.5661294068232753, 'l1_ratio': 0.046300422556282285}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,674] Trial 139 finished with value: 465.94128115908956 and parameters: {'alpha': 0.17462517167603253, 'l1_ratio': 0.043161095017003326}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,861] Trial 140 finished with value: 465.9075192560076 and parameters: {'alpha': 0.15156398181845937, 'l1_ratio': 0.021738433101078595}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,017] Trial 141 finished with value: 465.8601457801951 and parameters: {'alpha': 0.10234584916894217, 'l1_ratio': 0.06624920587025722}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,180] Trial 142 finished with value: 465.8585881472381 and parameters: {'alpha': 0.10135353519044353, 'l1_ratio': 0.06457135626409355}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,312] Trial 143 finished with value: 465.89804609268015 and parameters: {'alpha': 0.13388086227772855, 'l1_ratio': 0.06262041864110515}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,479] Trial 144 finished with value: 465.869472570249 and parameters: {'alpha': 0.12070058823032226, 'l1_ratio': 0.010281118215670668}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,689] Trial 145 finished with value: 465.89761966064447 and parameters: {'alpha': 0.13872829986427815, 'l1_ratio': 0.03930058541660122}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,842] Trial 146 finished with value: 465.85844263081486 and parameters: {'alpha': 0.10043525363047347, 'l1_ratio': 0.06954656381559002}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,980] Trial 147 finished with value: 465.8835900050791 and parameters: {'alpha': 0.12118891002569845, 'l1_ratio': 0.067167407081186}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.963e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,130] Trial 148 finished with value: 465.9437282738176 and parameters: {'alpha': 0.15817780180558905, 'l1_ratio': 0.11399913736315764}. Best is trial 133 with value: 465.8506232923116.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,304] Trial 149 finished with value: 465.8485010984513 and parameters: {'alpha': 0.10080964806565328, 'l1_ratio': 0.017059014609397447}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,469] Trial 150 finished with value: 465.9492102498548 and parameters: {'alpha': 0.1940664463516678, 'l1_ratio': 0.003522010602211134}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,671] Trial 151 finished with value: 465.8536050120455 and parameters: {'alpha': 0.10060123282692654, 'l1_ratio': 0.04406683651190328}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,918] Trial 152 finished with value: 465.8740473579989 and parameters: {'alpha': 0.11942460131903401, 'l1_ratio': 0.03583915990909958}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,125] Trial 153 finished with value: 465.89443315847234 and parameters: {'alpha': 0.13159884475014866, 'l1_ratio': 0.05946748784949621}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,347] Trial 154 finished with value: 465.9001100033569 and parameters: {'alpha': 0.14493773905957263, 'l1_ratio': 0.022355434135979894}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,519] Trial 155 finished with value: 466.9232548223743 and parameters: {'alpha': 0.9987197256930516, 'l1_ratio': 0.04607124698649906}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,642] Trial 156 finished with value: 465.86808644231945 and parameters: {'alpha': 0.118430374040076, 'l1_ratio': 0.015264416921106451}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,781] Trial 157 finished with value: 465.8575419591177 and parameters: {'alpha': 0.10177121061013256, 'l1_ratio': 0.056783077964030815}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.927e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,958] Trial 158 finished with value: 466.1344436835859 and parameters: {'alpha': 0.1714631145541409, 'l1_ratio': 0.6333737061909499}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,100] Trial 159 finished with value: 465.87793950239393 and parameters: {'alpha': 0.11820591288913611, 'l1_ratio': 0.05870929437914991}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,261] Trial 160 finished with value: 465.8978226034588 and parameters: {'alpha': 0.13946181026740403, 'l1_ratio': 0.036887718727076815}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,464] Trial 161 finished with value: 465.8773077088157 and parameters: {'alpha': 0.11484136711827646, 'l1_ratio': 0.07403771637438995}. Best is trial 149 with value: 465.8485010984513.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,675] Trial 162 finished with value: 465.84735946930255 and parameters: {'alpha': 0.10254391501741289, 'l1_ratio': 0.00165222115104211}. Best is trial 162 with value: 465.84735946930255.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,857] Trial 163 finished with value: 465.84595050316005 and parameters: {'alpha': 0.1001433613433653, 'l1_ratio': 0.00795815463305758}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,026] Trial 164 finished with value: 465.8819103263721 and parameters: {'alpha': 0.13208491597520464, 'l1_ratio': 0.008986459007593713}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.975e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,210] Trial 165 finished with value: 466.1447383586682 and parameters: {'alpha': 0.37111556002846546, 'l1_ratio': 0.0024902393771322404}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,399] Trial 166 finished with value: 465.8512369235039 and parameters: {'alpha': 0.10047964463522006, 'l1_ratio': 0.032778868094306884}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,731] Trial 167 finished with value: 465.90551144008344 and parameters: {'alpha': 0.15545373714570812, 'l1_ratio': 0.0006200780051819343}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,869] Trial 168 finished with value: 465.87748492110796 and parameters: {'alpha': 0.12365654180487429, 'l1_ratio': 0.02957508559677142}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,065] Trial 169 finished with value: 465.90555614997595 and parameters: {'alpha': 0.14492689283328142, 'l1_ratio': 0.04149484687081245}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.976e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,250] Trial 170 finished with value: 466.6212721209088 and parameters: {'alpha': 0.7736308868436435, 'l1_ratio': 0.023171765695965074}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,484] Trial 171 finished with value: 465.8586666852817 and parameters: {'alpha': 0.10222774090777627, 'l1_ratio': 0.05961977293523118}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,625] Trial 172 finished with value: 465.8537324165335 and parameters: {'alpha': 0.10014988746580131, 'l1_ratio': 0.047436601924800426}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,803] Trial 173 finished with value: 465.87676419586 and parameters: {'alpha': 0.11945189127723553, 'l1_ratio': 0.047258489501631584}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,943] Trial 174 finished with value: 465.87042624960503 and parameters: {'alpha': 0.11853928354829993, 'l1_ratio': 0.02476673946167446}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,097] Trial 175 finished with value: 465.8529689177921 and parameters: {'alpha': 0.10026788686977534, 'l1_ratio': 0.04285092380130977}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,262] Trial 176 finished with value: 465.84834718940095 and parameters: {'alpha': 0.10012291110287798, 'l1_ratio': 0.02023345779740371}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,425] Trial 177 finished with value: 465.8901995511015 and parameters: {'alpha': 0.13649266676166108, 'l1_ratio': 0.02147062887835795}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,592] Trial 178 finished with value: 465.88026829973387 and parameters: {'alpha': 0.1324601055086384, 'l1_ratio': 0.0010770251877548487}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,779] Trial 179 finished with value: 465.9135581119776 and parameters: {'alpha': 0.1529216857948863, 'l1_ratio': 0.03663821143298101}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,970] Trial 180 finished with value: 465.87379044239736 and parameters: {'alpha': 0.11806660715863446, 'l1_ratio': 0.04158594310645567}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,177] Trial 181 finished with value: 465.849738392892 and parameters: {'alpha': 0.10139652758407122, 'l1_ratio': 0.019918204541046793}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,328] Trial 182 finished with value: 465.8489644852966 and parameters: {'alpha': 0.10134501305977876, 'l1_ratio': 0.016334895046667408}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,483] Trial 183 finished with value: 465.86804803590485 and parameters: {'alpha': 0.11746228815844836, 'l1_ratio': 0.019839293515355266}. Best is trial 163 with value: 465.84595050316005.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,650] Trial 184 finished with value: 465.84518851887606 and parameters: {'alpha': 0.10042203916947606, 'l1_ratio': 0.002531294705115393}. Best is trial 184 with value: 465.84518851887606.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,784] Trial 185 finished with value: 465.8835411086799 and parameters: {'alpha': 0.13210424478423477, 'l1_ratio': 0.01517481980449963}. Best is trial 184 with value: 465.84518851887606.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,917] Trial 186 finished with value: 465.8650621865207 and parameters: {'alpha': 0.11882730720890888, 'l1_ratio': 0.0004076131938011915}. Best is trial 184 with value: 465.84518851887606.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,077] Trial 187 finished with value: 465.904170708865 and parameters: {'alpha': 0.14512144932000123, 'l1_ratio': 0.03583763632756863}. Best is trial 184 with value: 465.84518851887606.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,210] Trial 188 finished with value: 465.8445012304901 and parameters: {'alpha': 0.10021971679801349, 'l1_ratio': 0.00018388304058678667}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,348] Trial 189 finished with value: 465.92124777253736 and parameters: {'alpha': 0.16423690439499986, 'l1_ratio': 0.019330015768614345}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,514] Trial 190 finished with value: 465.84820779139267 and parameters: {'alpha': 0.1000834219594535, 'l1_ratio': 0.01975492137252792}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,672] Trial 191 finished with value: 465.86157117802543 and parameters: {'alpha': 0.11524574719850848, 'l1_ratio': 0.002427928963972266}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,830] Trial 192 finished with value: 465.88706796245185 and parameters: {'alpha': 0.1315506900893999, 'l1_ratio': 0.031213039524045326}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,991] Trial 193 finished with value: 465.8495666475653 and parameters: {'alpha': 0.10114418725552445, 'l1_ratio': 0.02050164111403532}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,138] Trial 194 finished with value: 465.86608138758606 and parameters: {'alpha': 0.11963939181469173, 'l1_ratio': 0.0009335130850290779}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,324] Trial 195 finished with value: 465.88845274368435 and parameters: {'alpha': 0.1347590202433029, 'l1_ratio': 0.022363358662451142}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,497] Trial 196 finished with value: 465.8519282933353 and parameters: {'alpha': 0.1001519573443807, 'l1_ratio': 0.03822200433293646}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,664] Trial 197 finished with value: 465.87079857116356 and parameters: {'alpha': 0.11682309335657914, 'l1_ratio': 0.034976140934789846}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,794] Trial 198 finished with value: 465.90160144112946 and parameters: {'alpha': 0.14751641760194664, 'l1_ratio': 0.017313404786577724}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,003] Trial 199 finished with value: 466.3218240811142 and parameters: {'alpha': 0.4972973202378245, 'l1_ratio': 0.040934829518687654}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,161] Trial 200 finished with value: 465.84813723061643 and parameters: {'alpha': 0.10056586733258943, 'l1_ratio': 0.016619389436118633}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,255] Trial 201 finished with value: 465.8498611743868 and parameters: {'alpha': 0.10160424982468448, 'l1_ratio': 0.019347165011518116}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,413] Trial 202 finished with value: 465.8733628867226 and parameters: {'alpha': 0.12208173904656869, 'l1_ratio': 0.020023497824899584}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,580] Trial 203 finished with value: 465.8623969932009 and parameters: {'alpha': 0.11608912576223349, 'l1_ratio': 0.001957399714540599}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,738] Trial 204 finished with value: 465.878617469507 and parameters: {'alpha': 0.13110311853308734, 'l1_ratio': 0.0004847493962693919}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,920] Trial 205 finished with value: 465.85014103124877 and parameters: {'alpha': 0.10038953455705503, 'l1_ratio': 0.02776745591547106}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,069] Trial 206 finished with value: 465.850534845196 and parameters: {'alpha': 0.10170665214074204, 'l1_ratio': 0.02212780784265746}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,293] Trial 207 finished with value: 465.8488672664577 and parameters: {'alpha': 0.10083032485323706, 'l1_ratio': 0.018784942340872475}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,473] Trial 208 finished with value: 465.88327841921614 and parameters: {'alpha': 0.13090128907906012, 'l1_ratio': 0.019439141626781273}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,626] Trial 209 finished with value: 465.86527565269506 and parameters: {'alpha': 0.11519424579770374, 'l1_ratio': 0.019024601370773116}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,788] Trial 210 finished with value: 465.90039145569096 and parameters: {'alpha': 0.14536583522044116, 'l1_ratio': 0.021624335851437703}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,947] Trial 211 finished with value: 465.8457075282504 and parameters: {'alpha': 0.1012875541037498, 'l1_ratio': 0.00033104034745126644}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,089] Trial 212 finished with value: 465.8616505758821 and parameters: {'alpha': 0.11506122214809904, 'l1_ratio': 0.003680762417827622}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,279] Trial 213 finished with value: 465.8445106917684 and parameters: {'alpha': 0.10008176732996142, 'l1_ratio': 0.0010032211803857362}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,414] Trial 214 finished with value: 465.87794975869144 and parameters: {'alpha': 0.13043354380333544, 'l1_ratio': 0.0007600432032513673}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,695] Trial 215 finished with value: 465.85063634422613 and parameters: {'alpha': 0.1011227532656454, 'l1_ratio': 0.02599616171883517}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,885] Trial 216 finished with value: 466.93756358466715 and parameters: {'alpha': 0.625024361943451, 'l1_ratio': 0.43161374432021027}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,047] Trial 217 finished with value: 465.87140643509144 and parameters: {'alpha': 0.11980724687816835, 'l1_ratio': 0.022735815557637734}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,189] Trial 218 finished with value: 465.8637790574455 and parameters: {'alpha': 0.11754134091482218, 'l1_ratio': 0.000990480737654939}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,355] Trial 219 finished with value: 465.84891668859996 and parameters: {'alpha': 0.10009277746319994, 'l1_ratio': 0.023297340904079013}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,524] Trial 220 finished with value: 465.8905126353523 and parameters: {'alpha': 0.14200011808288363, 'l1_ratio': 4.9932190638372204e-05}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,685] Trial 221 finished with value: 465.8488079811247 and parameters: {'alpha': 0.10005135347858309, 'l1_ratio': 0.022986917367574716}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,871] Trial 222 finished with value: 465.8666089547749 and parameters: {'alpha': 0.11652691126189003, 'l1_ratio': 0.01821748694882857}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,013] Trial 223 finished with value: 465.86822431683186 and parameters: {'alpha': 0.11568548358151559, 'l1_ratio': 0.029519196769586142}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,178] Trial 224 finished with value: 465.8552541829191 and parameters: {'alpha': 0.10065936319319259, 'l1_ratio': 0.05204567499964896}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.948e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,346] Trial 225 finished with value: 465.9479626392006 and parameters: {'alpha': 0.10036300675340115, 'l1_ratio': 0.5252763431047246}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,488] Trial 226 finished with value: 465.8837887584528 and parameters: {'alpha': 0.1302931204641708, 'l1_ratio': 0.024132586430537683}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,615] Trial 227 finished with value: 465.883090786654 and parameters: {'alpha': 0.1305829695929827, 'l1_ratio': 0.020121165368844618}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,809] Trial 228 finished with value: 465.85466597877974 and parameters: {'alpha': 0.10082712279040959, 'l1_ratio': 0.0480618314234324}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,967] Trial 229 finished with value: 465.9078030980176 and parameters: {'alpha': 0.1488860727585002, 'l1_ratio': 0.03316927482743454}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,152] Trial 230 finished with value: 465.8451831159571 and parameters: {'alpha': 0.10073644039837693, 'l1_ratio': 0.0007502236180852301}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,321] Trial 231 finished with value: 465.8620270253512 and parameters: {'alpha': 0.11581193400552331, 'l1_ratio': 0.0016787538749482248}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,470] Trial 232 finished with value: 465.84943979423673 and parameters: {'alpha': 0.10146476979541028, 'l1_ratio': 0.01803404023792339}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,642] Trial 233 finished with value: 465.8482906336655 and parameters: {'alpha': 0.10033757067958943, 'l1_ratio': 0.01870679792972017}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,800] Trial 234 finished with value: 465.87036774927253 and parameters: {'alpha': 0.11992465149620325, 'l1_ratio': 0.01776409740323625}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,993] Trial 235 finished with value: 465.8479159379546 and parameters: {'alpha': 0.1001885465276943, 'l1_ratio': 0.017667721730586537}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,167] Trial 236 finished with value: 465.8829550655459 and parameters: {'alpha': 0.13449740818411554, 'l1_ratio': 0.0027305865789898597}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,458] Trial 237 finished with value: 465.8679053085972 and parameters: {'alpha': 0.1180929605113003, 'l1_ratio': 0.016128522319631508}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,632] Trial 238 finished with value: 465.8793460389878 and parameters: {'alpha': 0.13179703528332576, 'l1_ratio': 0.0003434498255436985}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,796] Trial 239 finished with value: 465.8770168158879 and parameters: {'alpha': 0.11864782522195458, 'l1_ratio': 0.05245472171505889}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,910] Trial 240 finished with value: 465.8654707126135 and parameters: {'alpha': 0.11567359342050505, 'l1_ratio': 0.017482080058424394}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,107] Trial 241 finished with value: 465.8653525594029 and parameters: {'alpha': 0.11213917723586518, 'l1_ratio': 0.03514848396567635}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,236] Trial 242 finished with value: 465.848837888557 and parameters: {'alpha': 0.10091984235890641, 'l1_ratio': 0.018124108728372668}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,396] Trial 243 finished with value: 465.84763219393164 and parameters: {'alpha': 0.10024397299658865, 'l1_ratio': 0.015911105767199445}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,588] Trial 244 finished with value: 465.85623466051436 and parameters: {'alpha': 0.10210860017552668, 'l1_ratio': 0.04823739236649743}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,729] Trial 245 finished with value: 465.8825436425695 and parameters: {'alpha': 0.1346258831316407, 'l1_ratio': 0.000641086021481517}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,822] Trial 246 finished with value: 465.86836812900435 and parameters: {'alpha': 0.1177156636595168, 'l1_ratio': 0.019973139026537415}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,887] Trial 247 finished with value: 465.8510357199501 and parameters: {'alpha': 0.10002177334732819, 'l1_ratio': 0.03446892192280428}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,958] Trial 248 finished with value: 465.8475845559693 and parameters: {'alpha': 0.10004372071386562, 'l1_ratio': 0.01682121977677277}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,257] Trial 249 finished with value: 465.8924812455616 and parameters: {'alpha': 0.13109681285394434, 'l1_ratio': 0.054230443507243035}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,451] Trial 250 finished with value: 465.86802918998455 and parameters: {'alpha': 0.1182741097944665, 'l1_ratio': 0.015778437548725526}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,531] Trial 251 finished with value: 465.9005860796985 and parameters: {'alpha': 0.15084025036287788, 'l1_ratio': 0.0011706248678915766}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,610] Trial 252 finished with value: 465.8523627791602 and parameters: {'alpha': 0.1002368072583569, 'l1_ratio': 0.03995102120816469}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,703] Trial 253 finished with value: 465.8918699773597 and parameters: {'alpha': 0.13497239714010348, 'l1_ratio': 0.0343024900598607}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,787] Trial 254 finished with value: 465.84468688558263 and parameters: {'alpha': 0.10015743757648934, 'l1_ratio': 0.0014729887672715646}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.974e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,860] Trial 255 finished with value: 466.0764570131195 and parameters: {'alpha': 0.31044999958748215, 'l1_ratio': 0.0006039703114348308}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:44,940] Trial 256 finished with value: 465.8664234026367 and parameters: {'alpha': 0.12010247700610505, 'l1_ratio': 0.0002180437816301263}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,033] Trial 257 finished with value: 465.877314535675 and parameters: {'alpha': 0.11857580966199391, 'l1_ratio': 0.054102136598491266}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.973e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,108] Trial 258 finished with value: 466.2472587231985 and parameters: {'alpha': 0.45037431667965994, 'l1_ratio': 0.019303148632905134}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,200] Trial 259 finished with value: 465.8476717471636 and parameters: {'alpha': 0.10003043589947573, 'l1_ratio': 0.017340424855963432}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.949e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,284] Trial 260 finished with value: 466.00246635232594 and parameters: {'alpha': 0.1501853383145361, 'l1_ratio': 0.3502665251508184}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,374] Trial 261 finished with value: 465.892618650985 and parameters: {'alpha': 0.13452160947667113, 'l1_ratio': 0.03911947160058971}. Best is trial 188 with value: 465.8445012304901.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,460] Trial 262 finished with value: 465.84448449172174 and parameters: {'alpha': 0.10014764345653215, 'l1_ratio': 0.0005017516169458121}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,537] Trial 263 finished with value: 465.86668953310374 and parameters: {'alpha': 0.12032602108261119, 'l1_ratio': 0.0003013953071114164}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,619] Trial 264 finished with value: 465.8558740964737 and parameters: {'alpha': 0.10012902135182836, 'l1_ratio': 0.058435000962104085}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,686] Trial 265 finished with value: 465.89205343293827 and parameters: {'alpha': 0.13423131033298794, 'l1_ratio': 0.038276007854784126}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.929e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,759] Trial 266 finished with value: 466.0613796951569 and parameters: {'alpha': 0.11970352018241617, 'l1_ratio': 0.8365083171519494}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,824] Trial 267 finished with value: 465.9031300531391 and parameters: {'alpha': 0.15325918247942735, 'l1_ratio': 0.000750204872190071}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:45,942] Trial 268 finished with value: 465.8672828461999 and parameters: {'alpha': 0.11669429671932278, 'l1_ratio': 0.020322926966661478}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,074] Trial 269 finished with value: 465.88757134062206 and parameters: {'alpha': 0.13527992420997292, 'l1_ratio': 0.01681239809258334}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,185] Trial 270 finished with value: 466.5473477100839 and parameters: {'alpha': 0.6864457559903098, 'l1_ratio': 0.042630170522616445}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,254] Trial 271 finished with value: 465.8665591564703 and parameters: {'alpha': 0.11660798779454307, 'l1_ratio': 0.017598414843906795}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,329] Trial 272 finished with value: 465.8577993665841 and parameters: {'alpha': 0.10113664767139713, 'l1_ratio': 0.061947292713838545}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,402] Trial 273 finished with value: 465.8914936137813 and parameters: {'alpha': 0.13463560712412234, 'l1_ratio': 0.034368625382677945}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,483] Trial 274 finished with value: 465.9156755593624 and parameters: {'alpha': 0.16436972436900416, 'l1_ratio': 0.0016391731461929322}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,617] Trial 275 finished with value: 465.86946298933344 and parameters: {'alpha': 0.11584946729602191, 'l1_ratio': 0.03411805224096713}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.957e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,685] Trial 276 finished with value: 465.905632116132 and parameters: {'alpha': 0.10017754647767951, 'l1_ratio': 0.3114698632988554}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,757] Trial 277 finished with value: 465.8968069522265 and parameters: {'alpha': 0.14326909292715534, 'l1_ratio': 0.017407373041652453}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.985e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,827] Trial 278 finished with value: 466.67183883812817 and parameters: {'alpha': 0.8505833628333084, 'l1_ratio': 0.0005116527932344053}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,909] Trial 279 finished with value: 465.876322180136 and parameters: {'alpha': 0.11737812965927692, 'l1_ratio': 0.05607212883368384}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:46,992] Trial 280 finished with value: 465.8808195781894 and parameters: {'alpha': 0.12869518620370435, 'l1_ratio': 0.019662265682199285}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,056] Trial 281 finished with value: 465.8528312174163 and parameters: {'alpha': 0.10096519852092409, 'l1_ratio': 0.03799283102676694}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,127] Trial 282 finished with value: 465.8445757427285 and parameters: {'alpha': 0.10021151734373109, 'l1_ratio': 0.0006071910920800007}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.966e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,324] Trial 283 finished with value: 465.88153094692854 and parameters: {'alpha': 0.11828752675719734, 'l1_ratio': 0.07370500811979648}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,423] Trial 284 finished with value: 465.90777446872465 and parameters: {'alpha': 0.15228243417868817, 'l1_ratio': 0.019845757060461912}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,507] Trial 285 finished with value: 465.87769078050815 and parameters: {'alpha': 0.13034554617395572, 'l1_ratio': 0.00012894522973849742}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.952e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,579] Trial 286 finished with value: 465.94806503266005 and parameters: {'alpha': 0.11578786811941387, 'l1_ratio': 0.38061977972129923}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,657] Trial 287 finished with value: 465.84477020799613 and parameters: {'alpha': 0.10048149866673993, 'l1_ratio': 8.509257799184378e-05}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,737] Trial 288 finished with value: 465.88712571720276 and parameters: {'alpha': 0.13892482411617335, 'l1_ratio': 5.625990173292885e-05}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,807] Trial 289 finished with value: 465.8731785675293 and parameters: {'alpha': 0.1169453276341563, 'l1_ratio': 0.044694940141386114}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,877] Trial 290 finished with value: 465.851579345185 and parameters: {'alpha': 0.10038290217834289, 'l1_ratio': 0.03508175378856458}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:47,963] Trial 291 finished with value: 465.87592274418586 and parameters: {'alpha': 0.12863798146203712, 'l1_ratio': 0.0005784500809340037}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.937e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,042] Trial 292 finished with value: 466.0533761984261 and parameters: {'alpha': 0.144206525323864, 'l1_ratio': 0.5699649191625645}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,116] Trial 293 finished with value: 465.93172999572346 and parameters: {'alpha': 0.16361059822127366, 'l1_ratio': 0.0540870378767941}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.969e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,197] Trial 294 finished with value: 465.86892920285896 and parameters: {'alpha': 0.11728067830322986, 'l1_ratio': 0.02455531280137116}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.930e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,272] Trial 295 finished with value: 466.0345345069363 and parameters: {'alpha': 0.10067861029457928, 'l1_ratio': 0.9652130795653721}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.988e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,340] Trial 296 finished with value: 466.78726412996383 and parameters: {'alpha': 0.9560220073538666, 'l1_ratio': 0.00010656094365436852}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.968e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,423] Trial 297 finished with value: 465.8819825445466 and parameters: {'alpha': 0.12675758908727758, 'l1_ratio': 0.03318102533163212}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.973e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,500] Trial 298 finished with value: 466.17337635099113 and parameters: {'alpha': 0.3866417301297488, 'l1_ratio': 0.017589878600766093}. Best is trial 262 with value: 465.84448449172174.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e+05, tolerance: 5.877e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:48,576] Trial 299 finished with value: 465.88696758110814 and parameters: {'alpha': 0.1242483943383238, 'l1_ratio': 0.06553514152771422}. Best is trial 262 with value: 465.84448449172174.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "linreg_stacking_study = optuna.create_study(direction='minimize')\n",
    "linreg_stacking_study.optimize(stacked_objective_linreg, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.10014764345653215, 'l1_ratio': 0.0005017516169458121}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/linreg_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linreg_stacking_study.best_params, f\"../../split_year_models/ensemble/linreg_stacking_best_params.pkl\")\n",
    "joblib.dump(linreg_stacking_study, f\"../../split_year_models/ensemble/linreg_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.922e+05, tolerance: 7.040e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/linreg_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_linreg_model = ElasticNet(**linreg_stacking_study.best_params)\n",
    "best_linreg_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_linreg_model, \"../../split_year_models/ensemble/linreg_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_rf(trial):\n",
    "\n",
    "    n_trees = trial.suggest_int(\"n_estimators\", 10, 300)\n",
    "\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 25)\n",
    "\n",
    "    min_sample_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "\n",
    "    bootstrapping = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    if bootstrapping == False:\n",
    "        max_samples = None\n",
    "    else:\n",
    "        max_samples = trial.suggest_float(\"max_samples\", 0.01, 1.0)\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42, min_samples_split=min_sample_split, bootstrap=bootstrapping, max_samples=max_samples, n_estimators=n_trees, max_depth=max_depth)\n",
    "    \n",
    "    rf.fit(X_meta_train, y_meta_train)\n",
    "    rf_predictions = rf.predict(X_meta_val)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:06:48,766] A new study created in memory with name: no-name-fce37c69-94fc-40c1-9cc0-44e194b2fbd1\n",
      "[I 2025-08-01 08:06:49,403] Trial 0 finished with value: 1280.3705010761005 and parameters: {'n_estimators': 117, 'max_depth': 4, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.40225765024624605}. Best is trial 0 with value: 1280.3705010761005.\n",
      "[I 2025-08-01 08:06:49,924] Trial 1 finished with value: 1380.5477802778432 and parameters: {'n_estimators': 103, 'max_depth': 6, 'min_samples_split': 10, 'bootstrap': True, 'max_samples': 0.3246539847972197}. Best is trial 0 with value: 1280.3705010761005.\n",
      "[I 2025-08-01 08:06:51,311] Trial 2 finished with value: 1192.0060581818439 and parameters: {'n_estimators': 243, 'max_depth': 5, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.40750863686001826}. Best is trial 2 with value: 1192.0060581818439.\n",
      "[I 2025-08-01 08:06:55,762] Trial 3 finished with value: 1359.584784718719 and parameters: {'n_estimators': 123, 'max_depth': 24, 'min_samples_split': 9, 'bootstrap': False}. Best is trial 2 with value: 1192.0060581818439.\n",
      "[I 2025-08-01 08:06:58,830] Trial 4 finished with value: 1078.91523781851 and parameters: {'n_estimators': 229, 'max_depth': 7, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.8966086157566564}. Best is trial 4 with value: 1078.91523781851.\n",
      "[I 2025-08-01 08:06:58,990] Trial 5 finished with value: 3110.8066398346846 and parameters: {'n_estimators': 15, 'max_depth': 3, 'min_samples_split': 10, 'bootstrap': False}. Best is trial 4 with value: 1078.91523781851.\n",
      "[I 2025-08-01 08:07:09,014] Trial 6 finished with value: 1372.6114681598492 and parameters: {'n_estimators': 263, 'max_depth': 20, 'min_samples_split': 6, 'bootstrap': False}. Best is trial 4 with value: 1078.91523781851.\n",
      "[I 2025-08-01 08:07:12,109] Trial 7 finished with value: 1106.5756842387595 and parameters: {'n_estimators': 277, 'max_depth': 20, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.5355571596892761}. Best is trial 4 with value: 1078.91523781851.\n",
      "[I 2025-08-01 08:07:12,304] Trial 8 finished with value: 3110.806639834684 and parameters: {'n_estimators': 21, 'max_depth': 3, 'min_samples_split': 6, 'bootstrap': False}. Best is trial 4 with value: 1078.91523781851.\n",
      "[I 2025-08-01 08:07:14,296] Trial 9 finished with value: 1250.7301140520335 and parameters: {'n_estimators': 159, 'max_depth': 16, 'min_samples_split': 10, 'bootstrap': True, 'max_samples': 0.6229977122904984}. Best is trial 4 with value: 1078.91523781851.\n",
      "[I 2025-08-01 08:07:17,290] Trial 10 finished with value: 1009.3137185092255 and parameters: {'n_estimators': 208, 'max_depth': 10, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.9926319824376715}. Best is trial 10 with value: 1009.3137185092255.\n",
      "[I 2025-08-01 08:07:20,375] Trial 11 finished with value: 959.5297197652428 and parameters: {'n_estimators': 203, 'max_depth': 11, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.9640878112243749}. Best is trial 11 with value: 959.5297197652428.\n",
      "[I 2025-08-01 08:07:23,200] Trial 12 finished with value: 987.0317485894308 and parameters: {'n_estimators': 194, 'max_depth': 11, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.9549930791265364}. Best is trial 11 with value: 959.5297197652428.\n",
      "[I 2025-08-01 08:07:23,296] Trial 13 finished with value: 5328.248677282465 and parameters: {'n_estimators': 185, 'max_depth': 12, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.014342854411731665}. Best is trial 11 with value: 959.5297197652428.\n",
      "[I 2025-08-01 08:07:25,792] Trial 14 finished with value: 1083.9056040813766 and parameters: {'n_estimators': 177, 'max_depth': 15, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7903626669654407}. Best is trial 11 with value: 959.5297197652428.\n",
      "[I 2025-08-01 08:07:29,348] Trial 15 finished with value: 1095.995928988788 and parameters: {'n_estimators': 293, 'max_depth': 10, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.7613912753696946}. Best is trial 11 with value: 959.5297197652428.\n",
      "[I 2025-08-01 08:07:30,317] Trial 16 finished with value: 869.4380043548123 and parameters: {'n_estimators': 63, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.960407376418442}. Best is trial 16 with value: 869.4380043548123.\n",
      "[I 2025-08-01 08:07:31,709] Trial 17 finished with value: 907.1148366217072 and parameters: {'n_estimators': 84, 'max_depth': 17, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7639322516641376}. Best is trial 16 with value: 869.4380043548123.\n",
      "[I 2025-08-01 08:07:33,737] Trial 18 finished with value: 1052.2670200726398 and parameters: {'n_estimators': 62, 'max_depth': 18, 'min_samples_split': 2, 'bootstrap': False}. Best is trial 16 with value: 869.4380043548123.\n",
      "[I 2025-08-01 08:07:34,622] Trial 19 finished with value: 870.2059799680078 and parameters: {'n_estimators': 67, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7365334281920342}. Best is trial 16 with value: 869.4380043548123.\n",
      "[I 2025-08-01 08:07:35,226] Trial 20 finished with value: 927.9291520957796 and parameters: {'n_estimators': 54, 'max_depth': 13, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.6290065030157399}. Best is trial 16 with value: 869.4380043548123.\n",
      "[I 2025-08-01 08:07:36,383] Trial 21 finished with value: 846.0883121241108 and parameters: {'n_estimators': 79, 'max_depth': 17, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7704201178804506}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:36,943] Trial 22 finished with value: 958.9249857841218 and parameters: {'n_estimators': 48, 'max_depth': 8, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8462407773390139}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:38,368] Trial 23 finished with value: 1041.0607261426744 and parameters: {'n_estimators': 92, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.6647699707870347}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:40,412] Trial 24 finished with value: 1034.7465408878782 and parameters: {'n_estimators': 133, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7175679059644768}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:41,570] Trial 25 finished with value: 901.0327494124391 and parameters: {'n_estimators': 73, 'max_depth': 24, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.8303007247127754}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:42,723] Trial 26 finished with value: 1371.9789343242267 and parameters: {'n_estimators': 37, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:43,276] Trial 27 finished with value: 957.9959332418508 and parameters: {'n_estimators': 34, 'max_depth': 15, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8879997327049022}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:44,985] Trial 28 finished with value: 1162.080698877748 and parameters: {'n_estimators': 147, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.5295433393681266}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:46,558] Trial 29 finished with value: 1188.9938003995615 and parameters: {'n_estimators': 102, 'max_depth': 17, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.6949713717007074}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:47,407] Trial 30 finished with value: 849.4392424494708 and parameters: {'n_estimators': 69, 'max_depth': 9, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8902085598318624}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:48,363] Trial 31 finished with value: 1027.6227794751185 and parameters: {'n_estimators': 76, 'max_depth': 9, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8965629692628699}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:50,109] Trial 32 finished with value: 1087.160772506068 and parameters: {'n_estimators': 116, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.8451394394526797}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:51,067] Trial 33 finished with value: 891.7031314473306 and parameters: {'n_estimators': 65, 'max_depth': 9, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9057347218767619}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:51,854] Trial 34 finished with value: 1021.8955809328995 and parameters: {'n_estimators': 103, 'max_depth': 5, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7773758153864654}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:52,295] Trial 35 finished with value: 870.6314321999055 and parameters: {'n_estimators': 36, 'max_depth': 7, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9959988883190419}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:52,492] Trial 36 finished with value: 1980.7312096942062 and parameters: {'n_estimators': 119, 'max_depth': 15, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.07891716224258588}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:52,783] Trial 37 finished with value: 1373.3702823745336 and parameters: {'n_estimators': 11, 'max_depth': 12, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:53,375] Trial 38 finished with value: 1027.1958958626592 and parameters: {'n_estimators': 88, 'max_depth': 6, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.6075881445690368}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:54,942] Trial 39 finished with value: 1371.3550492785532 and parameters: {'n_estimators': 48, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:55,747] Trial 40 finished with value: 1266.3927503366776 and parameters: {'n_estimators': 131, 'max_depth': 22, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.271213049368612}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:56,122] Trial 41 finished with value: 909.4428606370468 and parameters: {'n_estimators': 32, 'max_depth': 7, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9794410812316849}. Best is trial 21 with value: 846.0883121241108.\n",
      "[I 2025-08-01 08:07:56,481] Trial 42 finished with value: 682.8567386814518 and parameters: {'n_estimators': 26, 'max_depth': 8, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9349571327993542}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:07:57,471] Trial 43 finished with value: 929.2313523757626 and parameters: {'n_estimators': 72, 'max_depth': 10, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9230060925842846}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:07:57,733] Trial 44 finished with value: 918.2338915087778 and parameters: {'n_estimators': 25, 'max_depth': 8, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.8275668605216036}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:07:58,101] Trial 45 finished with value: 1000.7168114596047 and parameters: {'n_estimators': 56, 'max_depth': 5, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7288043617641772}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:07:58,493] Trial 46 finished with value: 1022.2696194287793 and parameters: {'n_estimators': 48, 'max_depth': 11, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.4102305822408666}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:01,913] Trial 47 finished with value: 1123.1534472847125 and parameters: {'n_estimators': 103, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': False}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:02,222] Trial 48 finished with value: 995.4531918088086 and parameters: {'n_estimators': 21, 'max_depth': 12, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.8608648326712407}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:03,410] Trial 49 finished with value: 999.2040923677883 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.9229138397671447}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:07,850] Trial 50 finished with value: 1003.652938387464 and parameters: {'n_estimators': 242, 'max_depth': 16, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9419658549704133}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:08,334] Trial 51 finished with value: 962.0501196063947 and parameters: {'n_estimators': 43, 'max_depth': 7, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9943146344310673}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:08,446] Trial 52 finished with value: 849.4920732411766 and parameters: {'n_estimators': 10, 'max_depth': 6, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9528945178514802}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:08,523] Trial 53 finished with value: 1011.6376356697373 and parameters: {'n_estimators': 10, 'max_depth': 4, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8090891928363855}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:09,137] Trial 54 finished with value: 950.6804307164128 and parameters: {'n_estimators': 63, 'max_depth': 6, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.937215180102413}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:09,413] Trial 55 finished with value: 1191.7727180206116 and parameters: {'n_estimators': 24, 'max_depth': 8, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8784056710506142}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:09,700] Trial 56 finished with value: 1018.2404309878058 and parameters: {'n_estimators': 56, 'max_depth': 4, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5823898307868381}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:11,015] Trial 57 finished with value: 964.7454622482873 and parameters: {'n_estimators': 95, 'max_depth': 11, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7546962907033126}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:13,914] Trial 58 finished with value: 1374.5458904815323 and parameters: {'n_estimators': 77, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:14,312] Trial 59 finished with value: 829.8593365991337 and parameters: {'n_estimators': 23, 'max_depth': 14, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9611486028575649}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:14,667] Trial 60 finished with value: 1045.4370101738266 and parameters: {'n_estimators': 21, 'max_depth': 16, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9595452374652604}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:15,361] Trial 61 finished with value: 815.9033324459181 and parameters: {'n_estimators': 41, 'max_depth': 12, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.882784459962326}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:15,778] Trial 62 finished with value: 880.8908883422644 and parameters: {'n_estimators': 30, 'max_depth': 12, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8770232929194965}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:16,412] Trial 63 finished with value: 854.7257264958359 and parameters: {'n_estimators': 43, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.9468459128119021}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:16,951] Trial 64 finished with value: 852.6780785182677 and parameters: {'n_estimators': 41, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.8014346618025158}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:17,156] Trial 65 finished with value: 1162.916657846587 and parameters: {'n_estimators': 16, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.8357349760949215}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:17,486] Trial 66 finished with value: 931.366063100258 and parameters: {'n_estimators': 39, 'max_depth': 6, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.8147489834147273}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:17,780] Trial 67 finished with value: 1159.8460579817108 and parameters: {'n_estimators': 29, 'max_depth': 8, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.7934046809890813}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:18,427] Trial 68 finished with value: 962.0617099229933 and parameters: {'n_estimators': 53, 'max_depth': 9, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9016700007152972}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:18,671] Trial 69 finished with value: 1011.9217693895592 and parameters: {'n_estimators': 17, 'max_depth': 11, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.8704199180313775}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:23,054] Trial 70 finished with value: 1360.7576169144022 and parameters: {'n_estimators': 157, 'max_depth': 14, 'min_samples_split': 9, 'bootstrap': False}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:23,638] Trial 71 finished with value: 910.3612050936473 and parameters: {'n_estimators': 43, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.9570132459720416}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:24,260] Trial 72 finished with value: 968.5177468205501 and parameters: {'n_estimators': 42, 'max_depth': 13, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9258158083709569}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:26,535] Trial 73 finished with value: 1025.4177505376977 and parameters: {'n_estimators': 171, 'max_depth': 9, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.9630393757229632}. Best is trial 42 with value: 682.8567386814518.\n",
      "[I 2025-08-01 08:08:26,664] Trial 74 finished with value: 642.5517954150213 and parameters: {'n_estimators': 10, 'max_depth': 8, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.999158959072722}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:26,802] Trial 75 finished with value: 772.4549932118666 and parameters: {'n_estimators': 11, 'max_depth': 8, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9996434808310706}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:26,908] Trial 76 finished with value: 990.5964822204736 and parameters: {'n_estimators': 12, 'max_depth': 5, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9918697935452793}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:27,210] Trial 77 finished with value: 849.5917594221746 and parameters: {'n_estimators': 27, 'max_depth': 8, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8989770461849899}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:27,563] Trial 78 finished with value: 791.602123309948 and parameters: {'n_estimators': 33, 'max_depth': 7, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9941192489029038}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:27,924] Trial 79 finished with value: 921.1106033962025 and parameters: {'n_estimators': 34, 'max_depth': 7, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9759873295837486}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:28,242] Trial 80 finished with value: 914.4968335799698 and parameters: {'n_estimators': 19, 'max_depth': 15, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9973941949921649}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:28,482] Trial 81 finished with value: 947.9886244293158 and parameters: {'n_estimators': 26, 'max_depth': 6, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9258276095505953}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:29,024] Trial 82 finished with value: 954.524398781515 and parameters: {'n_estimators': 54, 'max_depth': 7, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9072071418449466}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:29,096] Trial 83 finished with value: 1344.453579237775 and parameters: {'n_estimators': 12, 'max_depth': 3, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9648092228615046}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:29,316] Trial 84 finished with value: 1060.5140043223232 and parameters: {'n_estimators': 33, 'max_depth': 8, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.4471197563289167}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:29,359] Trial 85 finished with value: 1059.985350816288 and parameters: {'n_estimators': 10, 'max_depth': 5, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.3105302528143918}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:29,569] Trial 86 finished with value: 873.0478293000097 and parameters: {'n_estimators': 21, 'max_depth': 7, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8745814276231614}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:33,063] Trial 87 finished with value: 1515.0914536487487 and parameters: {'n_estimators': 215, 'max_depth': 6, 'min_samples_split': 6, 'bootstrap': False}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:33,727] Trial 88 finished with value: 826.5442113604133 and parameters: {'n_estimators': 48, 'max_depth': 9, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.8581001388265864}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:34,507] Trial 89 finished with value: 938.8968550797772 and parameters: {'n_estimators': 69, 'max_depth': 9, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.8392373976200684}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:35,336] Trial 90 finished with value: 1062.7605193097058 and parameters: {'n_estimators': 62, 'max_depth': 18, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.6856844834998167}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:36,129] Trial 91 finished with value: 881.8711578215277 and parameters: {'n_estimators': 51, 'max_depth': 8, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9380243864362349}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:36,455] Trial 92 finished with value: 1017.5537511334193 and parameters: {'n_estimators': 29, 'max_depth': 7, 'min_samples_split': 10, 'bootstrap': True, 'max_samples': 0.8599210513994076}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:36,753] Trial 93 finished with value: 1040.669319054111 and parameters: {'n_estimators': 19, 'max_depth': 9, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9077824740197383}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:37,343] Trial 94 finished with value: 943.4735008709796 and parameters: {'n_estimators': 34, 'max_depth': 11, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9842119318295655}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:38,333] Trial 95 finished with value: 802.8918589010586 and parameters: {'n_estimators': 57, 'max_depth': 21, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.9432505146558421}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:40,122] Trial 96 finished with value: 1036.3312056273187 and parameters: {'n_estimators': 82, 'max_depth': 21, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.9218748478956651}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:41,628] Trial 97 finished with value: 964.6235248093603 and parameters: {'n_estimators': 60, 'max_depth': 25, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9999031827886017}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:42,924] Trial 98 finished with value: 752.8992652037177 and parameters: {'n_estimators': 70, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8546769753309397}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:43,757] Trial 99 finished with value: 967.8332663886404 and parameters: {'n_estimators': 50, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8521155810605286}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:44,427] Trial 100 finished with value: 740.9785029515704 and parameters: {'n_estimators': 46, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7583543078241508}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:45,154] Trial 101 finished with value: 804.1963637985826 and parameters: {'n_estimators': 47, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7728580020624046}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:45,739] Trial 102 finished with value: 725.470505221876 and parameters: {'n_estimators': 37, 'max_depth': 24, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7781143501151548}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:46,699] Trial 103 finished with value: 874.3402978863419 and parameters: {'n_estimators': 48, 'max_depth': 24, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7424274210238665}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:47,256] Trial 104 finished with value: 919.5630922981212 and parameters: {'n_estimators': 39, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.70527654948197}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:48,138] Trial 105 finished with value: 900.3114592038876 and parameters: {'n_estimators': 57, 'max_depth': 25, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7738324229693216}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:52,959] Trial 106 finished with value: 1078.1226276013258 and parameters: {'n_estimators': 281, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8160313029979808}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:54,396] Trial 107 finished with value: 1376.5148776113424 and parameters: {'n_estimators': 46, 'max_depth': 22, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:54,946] Trial 108 finished with value: 769.207145413849 and parameters: {'n_estimators': 36, 'max_depth': 21, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7764814831401221}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:55,513] Trial 109 finished with value: 1031.1581469806736 and parameters: {'n_estimators': 34, 'max_depth': 21, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.655886233114994}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:56,562] Trial 110 finished with value: 876.2440238628774 and parameters: {'n_estimators': 68, 'max_depth': 21, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7874626154755318}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:57,128] Trial 111 finished with value: 813.6941456027938 and parameters: {'n_estimators': 39, 'max_depth': 22, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7411584812239425}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:57,662] Trial 112 finished with value: 770.865600878692 and parameters: {'n_estimators': 36, 'max_depth': 24, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7535348602139448}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:58,067] Trial 113 finished with value: 978.4760372850808 and parameters: {'n_estimators': 29, 'max_depth': 24, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.714073779708286}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:58,629] Trial 114 finished with value: 1000.2921894691167 and parameters: {'n_estimators': 37, 'max_depth': 22, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7560880797118716}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:58,978] Trial 115 finished with value: 981.3507338341778 and parameters: {'n_estimators': 25, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.6757449045704016}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:59,233] Trial 116 finished with value: 983.0945286341569 and parameters: {'n_estimators': 17, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7500201414384895}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:08:59,979] Trial 117 finished with value: 800.4080986242984 and parameters: {'n_estimators': 59, 'max_depth': 24, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.6442055351716843}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:00,938] Trial 118 finished with value: 999.2886602210539 and parameters: {'n_estimators': 73, 'max_depth': 24, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.5646343229075923}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:01,776] Trial 119 finished with value: 978.0037418990238 and parameters: {'n_estimators': 66, 'max_depth': 25, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.6484130458884596}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:02,280] Trial 120 finished with value: 1417.8648127499011 and parameters: {'n_estimators': 146, 'max_depth': 24, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.15863369658660992}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:03,167] Trial 121 finished with value: 900.5552309027398 and parameters: {'n_estimators': 58, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7244416627165331}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:03,737] Trial 122 finished with value: 821.1981593980281 and parameters: {'n_estimators': 37, 'max_depth': 22, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7731411595738117}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:04,511] Trial 123 finished with value: 937.572360873612 and parameters: {'n_estimators': 44, 'max_depth': 21, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.6255952107383886}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:05,337] Trial 124 finished with value: 918.262196234405 and parameters: {'n_estimators': 53, 'max_depth': 23, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7322885927387174}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:05,726] Trial 125 finished with value: 1002.7677745498643 and parameters: {'n_estimators': 25, 'max_depth': 24, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7967597740385619}. Best is trial 74 with value: 642.5517954150213.\n",
      "[I 2025-08-01 08:09:05,897] Trial 126 finished with value: 642.3538786499706 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.496283421632939}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:06,871] Trial 127 finished with value: 1375.8017148218964 and parameters: {'n_estimators': 30, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:07,899] Trial 128 finished with value: 1190.144712705878 and parameters: {'n_estimators': 90, 'max_depth': 23, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.5324362274642492}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:08,105] Trial 129 finished with value: 918.8444079846349 and parameters: {'n_estimators': 23, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.43626131236866067}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:08,254] Trial 130 finished with value: 698.3486909294867 and parameters: {'n_estimators': 15, 'max_depth': 24, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.486763038294622}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:08,420] Trial 131 finished with value: 955.7915461293801 and parameters: {'n_estimators': 18, 'max_depth': 24, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.46148309999495835}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:08,601] Trial 132 finished with value: 843.5274206795648 and parameters: {'n_estimators': 12, 'max_depth': 24, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.8142967190052306}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:08,768] Trial 133 finished with value: 834.6414180659627 and parameters: {'n_estimators': 16, 'max_depth': 25, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.5152397898636516}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:09,033] Trial 134 finished with value: 927.3826993470191 and parameters: {'n_estimators': 32, 'max_depth': 22, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.41942006721445263}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:09,272] Trial 135 finished with value: 779.2948866415016 and parameters: {'n_estimators': 22, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4877444361293365}. Best is trial 126 with value: 642.3538786499706.\n",
      "[I 2025-08-01 08:09:09,435] Trial 136 finished with value: 639.4884546828436 and parameters: {'n_estimators': 15, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4816711906771636}. Best is trial 136 with value: 639.4884546828436.\n",
      "[I 2025-08-01 08:09:09,558] Trial 137 finished with value: 859.8682450430845 and parameters: {'n_estimators': 10, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5580144936951835}. Best is trial 136 with value: 639.4884546828436.\n",
      "[I 2025-08-01 08:09:09,748] Trial 138 finished with value: 733.7298713874519 and parameters: {'n_estimators': 17, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4869352493364671}. Best is trial 136 with value: 639.4884546828436.\n",
      "[I 2025-08-01 08:09:09,924] Trial 139 finished with value: 594.5636396671175 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4833771654374403}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:10,092] Trial 140 finished with value: 645.7059323692334 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.48252510614548194}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:10,254] Trial 141 finished with value: 657.6286344418612 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4684666504736611}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:10,421] Trial 142 finished with value: 753.5900895829026 and parameters: {'n_estimators': 16, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.488340226174408}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:10,593] Trial 143 finished with value: 676.7314403499939 and parameters: {'n_estimators': 17, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4860843361719592}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:10,872] Trial 144 finished with value: 699.0548241536206 and parameters: {'n_estimators': 16, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4784411127364879}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:11,035] Trial 145 finished with value: 612.8376507213061 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.48372108122621876}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:11,199] Trial 146 finished with value: 804.6188896291959 and parameters: {'n_estimators': 16, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.47549922406352163}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:11,377] Trial 147 finished with value: 782.7451305683518 and parameters: {'n_estimators': 22, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.37396586123880715}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:11,490] Trial 148 finished with value: 600.2381012918268 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5097013171052688}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:11,791] Trial 149 finished with value: 1376.5361817505843 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:12,068] Trial 150 finished with value: 792.2615287800728 and parameters: {'n_estimators': 27, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5090781083721799}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:12,232] Trial 151 finished with value: 860.0213336824352 and parameters: {'n_estimators': 17, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.45936582028255457}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:12,447] Trial 152 finished with value: 919.7410846997175 and parameters: {'n_estimators': 21, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4983815245684682}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:12,584] Trial 153 finished with value: 1173.3497384160323 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.42967961815522115}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:12,795] Trial 154 finished with value: 1145.2631372600076 and parameters: {'n_estimators': 26, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.39328572923823657}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:12,926] Trial 155 finished with value: 948.6101921021886 and parameters: {'n_estimators': 10, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5449670419388185}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:13,169] Trial 156 finished with value: 734.2853592818807 and parameters: {'n_estimators': 20, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4754111000311676}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:13,403] Trial 157 finished with value: 666.8607958296391 and parameters: {'n_estimators': 19, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4711498028103766}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:13,604] Trial 158 finished with value: 768.7685600815452 and parameters: {'n_estimators': 19, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.46811750368399613}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:13,865] Trial 159 finished with value: 869.0839935079356 and parameters: {'n_estimators': 22, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5141271142169176}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:14,108] Trial 160 finished with value: 747.0920497979837 and parameters: {'n_estimators': 16, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5935305730139607}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:14,608] Trial 161 finished with value: 864.1043406065196 and parameters: {'n_estimators': 29, 'max_depth': 25, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4844243634932714}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:14,878] Trial 162 finished with value: 1024.2173253479752 and parameters: {'n_estimators': 25, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.45332318415749806}. Best is trial 139 with value: 594.5636396671175.\n",
      "[I 2025-08-01 08:09:14,997] Trial 163 finished with value: 570.6687297617511 and parameters: {'n_estimators': 10, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.523950365235999}. Best is trial 163 with value: 570.6687297617511.\n",
      "[I 2025-08-01 08:09:15,115] Trial 164 finished with value: 996.8294712285183 and parameters: {'n_estimators': 13, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.3950952615491947}. Best is trial 163 with value: 570.6687297617511.\n",
      "[I 2025-08-01 08:09:15,323] Trial 165 finished with value: 568.4507112827582 and parameters: {'n_estimators': 19, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5237794740137184}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:15,437] Trial 166 finished with value: 597.6496024387858 and parameters: {'n_estimators': 10, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5231423116878514}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:15,548] Trial 167 finished with value: 810.0927998609116 and parameters: {'n_estimators': 10, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5104378395508957}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:15,847] Trial 168 finished with value: 877.444535089169 and parameters: {'n_estimators': 27, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5368038151916192}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:15,971] Trial 169 finished with value: 867.2403977241171 and parameters: {'n_estimators': 10, 'max_depth': 21, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.57386270945266}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:16,134] Trial 170 finished with value: 1016.8844868253158 and parameters: {'n_estimators': 16, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4421206073062661}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:16,370] Trial 171 finished with value: 586.5362119207608 and parameters: {'n_estimators': 21, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5263356667410996}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:16,602] Trial 172 finished with value: 586.5362119207608 and parameters: {'n_estimators': 21, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5261441226228487}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:16,845] Trial 173 finished with value: 689.5154126596134 and parameters: {'n_estimators': 21, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.547866176947622}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:17,093] Trial 174 finished with value: 833.5113187174637 and parameters: {'n_estimators': 22, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5454784696879055}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:17,338] Trial 175 finished with value: 581.9796526845718 and parameters: {'n_estimators': 23, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5270280388261512}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:17,699] Trial 176 finished with value: 634.3065329095256 and parameters: {'n_estimators': 30, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5259466898086764}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:18,138] Trial 177 finished with value: 825.5737753653325 and parameters: {'n_estimators': 30, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.523511767025651}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:21,087] Trial 178 finished with value: 1123.2155151485158 and parameters: {'n_estimators': 257, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5950677588923677}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:24,585] Trial 179 finished with value: 1368.8961252352212 and parameters: {'n_estimators': 112, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:24,842] Trial 180 finished with value: 631.2710979726969 and parameters: {'n_estimators': 25, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5050266426186114}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:25,136] Trial 181 finished with value: 685.4444313497327 and parameters: {'n_estimators': 25, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5263240995945945}. Best is trial 165 with value: 568.4507112827582.\n",
      "[I 2025-08-01 08:09:25,251] Trial 182 finished with value: 557.7435632194318 and parameters: {'n_estimators': 10, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5052117644814353}. Best is trial 182 with value: 557.7435632194318.\n",
      "[I 2025-08-01 08:09:25,364] Trial 183 finished with value: 816.3823252460543 and parameters: {'n_estimators': 10, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5029189475855438}. Best is trial 182 with value: 557.7435632194318.\n",
      "[I 2025-08-01 08:09:25,592] Trial 184 finished with value: 556.4013557752346 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5273939523624588}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:25,896] Trial 185 finished with value: 664.9666798225084 and parameters: {'n_estimators': 22, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5245202986038402}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:26,261] Trial 186 finished with value: 723.3365261044545 and parameters: {'n_estimators': 29, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5764988029473144}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:26,720] Trial 187 finished with value: 729.618831494129 and parameters: {'n_estimators': 23, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5288874350228462}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:26,914] Trial 188 finished with value: 814.3351269576295 and parameters: {'n_estimators': 14, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5568578594979838}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:27,291] Trial 189 finished with value: 923.9723577276602 and parameters: {'n_estimators': 31, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5041053498295447}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:27,409] Trial 190 finished with value: 717.1578519573933 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5249842075504041}. Best is trial 184 with value: 556.4013557752346.\n",
      "[I 2025-08-01 08:09:27,623] Trial 191 finished with value: 540.179172988232 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5046886380652243}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:27,841] Trial 192 finished with value: 630.4341052876622 and parameters: {'n_estimators': 21, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5067363910759806}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:28,015] Trial 193 finished with value: 577.7018458368823 and parameters: {'n_estimators': 17, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4964501117782071}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:28,423] Trial 194 finished with value: 812.0297316854159 and parameters: {'n_estimators': 27, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5034313602223683}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:28,665] Trial 195 finished with value: 677.2873554119193 and parameters: {'n_estimators': 20, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5557928832883959}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:28,781] Trial 196 finished with value: 930.8988821343212 and parameters: {'n_estimators': 10, 'max_depth': 21, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5034766016255703}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:29,150] Trial 197 finished with value: 823.1347575621104 and parameters: {'n_estimators': 31, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5408127358600128}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:31,224] Trial 198 finished with value: 1255.917021912947 and parameters: {'n_estimators': 195, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4555870992757754}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:31,405] Trial 199 finished with value: 755.7699835782852 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.49791397959890193}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:31,686] Trial 200 finished with value: 646.0645039120495 and parameters: {'n_estimators': 23, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5200848617688197}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:31,944] Trial 201 finished with value: 636.9802044798125 and parameters: {'n_estimators': 23, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5267746036081314}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:32,130] Trial 202 finished with value: 800.4777635447231 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5441769622158911}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:32,372] Trial 203 finished with value: 541.4768699874705 and parameters: {'n_estimators': 21, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.510023986090763}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:32,403] Trial 204 finished with value: 4302.266277741433 and parameters: {'n_estimators': 23, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.030790490259673897}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:32,527] Trial 205 finished with value: 1268.3538335747808 and parameters: {'n_estimators': 27, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.1858648665064151}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:32,782] Trial 206 finished with value: 895.0715185537151 and parameters: {'n_estimators': 20, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5698097597252691}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:33,159] Trial 207 finished with value: 832.1051501922776 and parameters: {'n_estimators': 35, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5121360092268794}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:33,281] Trial 208 finished with value: 832.775379458763 and parameters: {'n_estimators': 10, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5313358379524404}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:33,555] Trial 209 finished with value: 872.2517244124526 and parameters: {'n_estimators': 26, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4980298278064537}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:33,785] Trial 210 finished with value: 840.0249373216061 and parameters: {'n_estimators': 19, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5614908310044197}. Best is trial 191 with value: 540.179172988232.\n",
      "[I 2025-08-01 08:09:34,060] Trial 211 finished with value: 536.3058843938924 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.48761837150165177}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:34,233] Trial 212 finished with value: 693.203694760238 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5144943763221129}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:34,426] Trial 213 finished with value: 947.6083642540368 and parameters: {'n_estimators': 20, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.45059558736519334}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:34,595] Trial 214 finished with value: 656.8282919226675 and parameters: {'n_estimators': 14, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4965539216576854}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:34,716] Trial 215 finished with value: 1005.9149719240258 and parameters: {'n_estimators': 10, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5390391099551262}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:35,065] Trial 216 finished with value: 910.4136723523637 and parameters: {'n_estimators': 31, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.46792315673273116}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:35,830] Trial 217 finished with value: 1371.8015369027805 and parameters: {'n_estimators': 24, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:36,041] Trial 218 finished with value: 754.2121236326692 and parameters: {'n_estimators': 19, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5207865242810944}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:36,198] Trial 219 finished with value: 645.1055981838429 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4888344094394039}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:36,696] Trial 220 finished with value: 966.8073321329589 and parameters: {'n_estimators': 27, 'max_depth': 21, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5913386285698287}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:36,921] Trial 221 finished with value: 629.78422935335 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4827625966846629}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:37,132] Trial 222 finished with value: 811.509870795345 and parameters: {'n_estimators': 20, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.47312872401517697}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:37,248] Trial 223 finished with value: 565.0496453363834 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5047995949303128}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:37,370] Trial 224 finished with value: 674.5909656490797 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5075544408128736}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:37,567] Trial 225 finished with value: 633.4895713559802 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.540184091576637}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:37,845] Trial 226 finished with value: 769.2274741041383 and parameters: {'n_estimators': 23, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5432087314583417}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:38,207] Trial 227 finished with value: 755.4203880438542 and parameters: {'n_estimators': 32, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5230856023111233}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:38,420] Trial 228 finished with value: 698.6818883130815 and parameters: {'n_estimators': 17, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5607848292667897}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:38,716] Trial 229 finished with value: 776.2818983980569 and parameters: {'n_estimators': 25, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5281824446482222}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:38,886] Trial 230 finished with value: 618.2223055642646 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.48409378635557593}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:39,048] Trial 231 finished with value: 710.7809577738785 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.48674209619975767}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:39,265] Trial 232 finished with value: 684.126861187029 and parameters: {'n_estimators': 20, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5111999080918651}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:39,370] Trial 233 finished with value: 1085.8614738772965 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4543600888290891}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:39,564] Trial 234 finished with value: 762.7315071812451 and parameters: {'n_estimators': 16, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5387959932324176}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:39,777] Trial 235 finished with value: 782.8802460436045 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.48382170570969774}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:40,053] Trial 236 finished with value: 920.0239313491646 and parameters: {'n_estimators': 26, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5029097628206841}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:40,208] Trial 237 finished with value: 637.4736037653188 and parameters: {'n_estimators': 15, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4684788550445353}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:40,405] Trial 238 finished with value: 878.3404442131896 and parameters: {'n_estimators': 22, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4207189886299476}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:40,510] Trial 239 finished with value: 1051.234315390723 and parameters: {'n_estimators': 10, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.46417583262286705}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:40,808] Trial 240 finished with value: 889.8371913876506 and parameters: {'n_estimators': 32, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4375594682338193}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:40,988] Trial 241 finished with value: 752.4523653310608 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5185067347006247}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:41,157] Trial 242 finished with value: 645.1055981838429 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4891328353638895}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:41,394] Trial 243 finished with value: 846.9619970789141 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5424506717685444}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:41,696] Trial 244 finished with value: 638.3263979753474 and parameters: {'n_estimators': 26, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5053569763700407}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:42,020] Trial 245 finished with value: 647.0596235375573 and parameters: {'n_estimators': 27, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5102917094744386}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:42,296] Trial 246 finished with value: 836.6747357645277 and parameters: {'n_estimators': 24, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5286674005203611}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:42,517] Trial 247 finished with value: 667.2296483527756 and parameters: {'n_estimators': 19, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5537633033533503}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:42,826] Trial 248 finished with value: 806.1498383312089 and parameters: {'n_estimators': 30, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5016865169283099}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:42,944] Trial 249 finished with value: 780.6568134545594 and parameters: {'n_estimators': 10, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4685853774138699}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:45,254] Trial 250 finished with value: 1077.5386150365748 and parameters: {'n_estimators': 171, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5255672305758636}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:45,461] Trial 251 finished with value: 860.2499499462868 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.5718908507439078}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:46,238] Trial 252 finished with value: 1371.8015369027805 and parameters: {'n_estimators': 24, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:46,464] Trial 253 finished with value: 656.5816214781795 and parameters: {'n_estimators': 19, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.49563432788708506}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:46,881] Trial 254 finished with value: 650.6553163355157 and parameters: {'n_estimators': 37, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5106205656981518}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:47,012] Trial 255 finished with value: 931.4093420703757 and parameters: {'n_estimators': 10, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5501007016077191}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:47,310] Trial 256 finished with value: 765.6891837467494 and parameters: {'n_estimators': 28, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4714802145774568}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:47,558] Trial 257 finished with value: 951.6550474371259 and parameters: {'n_estimators': 21, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5334699030588977}. Best is trial 211 with value: 536.3058843938924.\n",
      "[I 2025-08-01 08:09:47,733] Trial 258 finished with value: 500.1398151756764 and parameters: {'n_estimators': 15, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.488176275277811}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:47,887] Trial 259 finished with value: 779.2296401215297 and parameters: {'n_estimators': 15, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.447280565911316}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:48,063] Trial 260 finished with value: 672.1112721744781 and parameters: {'n_estimators': 15, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.48115047547820994}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:49,677] Trial 261 finished with value: 1088.2559385058669 and parameters: {'n_estimators': 131, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4927730633718953}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:49,828] Trial 262 finished with value: 712.5271270539348 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5227415154304424}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:50,051] Trial 263 finished with value: 909.6634646632255 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.45799989432131355}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:50,214] Trial 264 finished with value: 710.3533382368125 and parameters: {'n_estimators': 15, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.47860144255199605}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:50,491] Trial 265 finished with value: 815.6479417519209 and parameters: {'n_estimators': 22, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5420352622211413}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:50,863] Trial 266 finished with value: 951.1354212241878 and parameters: {'n_estimators': 33, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5139204045617376}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:50,993] Trial 267 finished with value: 823.1592417675485 and parameters: {'n_estimators': 10, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5732540311657536}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:51,193] Trial 268 finished with value: 716.7616867968164 and parameters: {'n_estimators': 18, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.49404901241859545}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:51,482] Trial 269 finished with value: 777.0442697009447 and parameters: {'n_estimators': 26, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5338004190249699}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:51,939] Trial 270 finished with value: 1377.937170408139 and parameters: {'n_estimators': 15, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:52,175] Trial 271 finished with value: 906.1227783058469 and parameters: {'n_estimators': 21, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5586463068963452}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:52,473] Trial 272 finished with value: 1025.5647300916414 and parameters: {'n_estimators': 29, 'max_depth': 22, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.5175683206388562}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:54,501] Trial 273 finished with value: 1223.168154013788 and parameters: {'n_estimators': 238, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.43671299729880036}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:54,656] Trial 274 finished with value: 635.1574366381043 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.4741891837663567}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:54,874] Trial 275 finished with value: 761.3514701988796 and parameters: {'n_estimators': 21, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.49533581585700837}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:55,033] Trial 276 finished with value: 761.4054562844613 and parameters: {'n_estimators': 14, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5081613375953915}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:55,156] Trial 277 finished with value: 1032.2464743985026 and parameters: {'n_estimators': 10, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5324280648530761}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:55,494] Trial 278 finished with value: 878.0045716034947 and parameters: {'n_estimators': 33, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.4799386535186092}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:55,791] Trial 279 finished with value: 932.3927689246106 and parameters: {'n_estimators': 25, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5459993644458119}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:58,056] Trial 280 finished with value: 1236.2304881776934 and parameters: {'n_estimators': 215, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5036240709232905}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:58,241] Trial 281 finished with value: 1001.682342578713 and parameters: {'n_estimators': 19, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.46277236863027055}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:58,359] Trial 282 finished with value: 644.2984402348874 and parameters: {'n_estimators': 10, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5213363105912086}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:58,661] Trial 283 finished with value: 1180.1318516355118 and parameters: {'n_estimators': 25, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6065744701748023}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:58,846] Trial 284 finished with value: 733.7380806078048 and parameters: {'n_estimators': 18, 'max_depth': 22, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.4870778426538631}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:59,327] Trial 285 finished with value: 854.6849330599712 and parameters: {'n_estimators': 40, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5666310327304918}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:59,657] Trial 286 finished with value: 787.7785865917222 and parameters: {'n_estimators': 30, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5167505788481496}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:09:59,815] Trial 287 finished with value: 809.7627813856856 and parameters: {'n_estimators': 16, 'max_depth': 21, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.44704700591606317}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:00,109] Trial 288 finished with value: 687.122779831881 and parameters: {'n_estimators': 22, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5407362746975035}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:00,281] Trial 289 finished with value: 704.8914864631624 and parameters: {'n_estimators': 15, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.49883017285865033}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:01,041] Trial 290 finished with value: 1371.8015369027805 and parameters: {'n_estimators': 24, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:01,230] Trial 291 finished with value: 857.0620008165415 and parameters: {'n_estimators': 18, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.4798364951011944}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:01,368] Trial 292 finished with value: 800.8686749877305 and parameters: {'n_estimators': 10, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5522844722046802}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:01,767] Trial 293 finished with value: 566.3278388393596 and parameters: {'n_estimators': 33, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5254643609179058}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:02,172] Trial 294 finished with value: 983.3359350518457 and parameters: {'n_estimators': 38, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.49878332657088603}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:02,460] Trial 295 finished with value: 989.5374798623645 and parameters: {'n_estimators': 29, 'max_depth': 23, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.46613965514120814}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:02,798] Trial 296 finished with value: 704.5954993614263 and parameters: {'n_estimators': 31, 'max_depth': 22, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5115948529812626}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:02,974] Trial 297 finished with value: 565.1264992785301 and parameters: {'n_estimators': 15, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5297507655033756}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:03,213] Trial 298 finished with value: 786.5547182068043 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5356591755291222}. Best is trial 258 with value: 500.1398151756764.\n",
      "[I 2025-08-01 08:10:03,521] Trial 299 finished with value: 720.5186196980095 and parameters: {'n_estimators': 26, 'max_depth': 23, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.5597793503585298}. Best is trial 258 with value: 500.1398151756764.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "rf_stacking_study = optuna.create_study(direction='minimize')\n",
    "rf_stacking_study.optimize(stacked_objective_rf, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 15,\n",
       " 'max_depth': 19,\n",
       " 'min_samples_split': 4,\n",
       " 'bootstrap': True,\n",
       " 'max_samples': 0.488176275277811}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/rf_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_stacking_study.best_params, f\"../../split_year_models/ensemble/rf_stacking_best_params.pkl\")\n",
    "joblib.dump(rf_stacking_study, f\"../../split_year_models/ensemble/rf_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/rf_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = RandomForestRegressor(**rf_stacking_study.best_params)\n",
    "best_rf_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_rf_model, \"../../split_year_models/ensemble/rf_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_svm(trial):\n",
    "\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"poly\", \"rbf\"])\n",
    "\n",
    "    if kernel == \"poly\":\n",
    "        degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "\n",
    "    C = trial.suggest_float(\"C\", 0.1, 1)\n",
    "    epsilon = trial.suggest_float(\"epsilon\", 0.05, 1.0)\n",
    "\n",
    "    svm = SVR(kernel=kernel, degree=degree if kernel == \"poly\" else 0, C=C, epsilon=epsilon)\n",
    "    \n",
    "    svm.fit(X_meta_train, y_meta_train)\n",
    "    svm_predictions = svm.predict(X_meta_val)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, svm_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:10:03,775] A new study created in memory with name: no-name-8c2ae7fe-e940-4d21-bad1-8dd6555a2878\n",
      "[I 2025-08-01 08:10:03,919] Trial 0 finished with value: 21104.521691472353 and parameters: {'kernel': 'rbf', 'C': 0.1899040434093136, 'epsilon': 0.4729479485751279}. Best is trial 0 with value: 21104.521691472353.\n",
      "[I 2025-08-01 08:10:04,049] Trial 1 finished with value: 18068.731325418696 and parameters: {'kernel': 'rbf', 'C': 0.6618688263082609, 'epsilon': 0.9816005465902056}. Best is trial 1 with value: 18068.731325418696.\n",
      "[I 2025-08-01 08:10:04,254] Trial 2 finished with value: 6505.28827556611 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9514305168113537, 'epsilon': 0.5663679811837096}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:04,375] Trial 3 finished with value: 20035.00819242468 and parameters: {'kernel': 'rbf', 'C': 0.3291134246511636, 'epsilon': 0.5674350133408897}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:04,496] Trial 4 finished with value: 19571.143842076766 and parameters: {'kernel': 'rbf', 'C': 0.3914720334735032, 'epsilon': 0.39731305045222687}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:04,617] Trial 5 finished with value: 20825.268517266177 and parameters: {'kernel': 'rbf', 'C': 0.22615761185470715, 'epsilon': 0.6316595281327362}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:04,738] Trial 6 finished with value: 20819.08467822422 and parameters: {'kernel': 'rbf', 'C': 0.2266849942003032, 'epsilon': 0.4187782317308078}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:04,858] Trial 7 finished with value: 18318.09977123399 and parameters: {'kernel': 'rbf', 'C': 0.6086450504372908, 'epsilon': 0.5744451159415513}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:04,986] Trial 8 finished with value: 17704.95872024832 and parameters: {'kernel': 'rbf', 'C': 0.757001921149352, 'epsilon': 0.18249861750081384}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:05,111] Trial 9 finished with value: 20420.7740271184 and parameters: {'kernel': 'rbf', 'C': 0.27290667432320004, 'epsilon': 0.5749447502126551}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:05,374] Trial 10 finished with value: 6514.88772472468 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9805067519400258, 'epsilon': 0.8393191370391595}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:05,668] Trial 11 finished with value: 6515.915692404573 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9933322026872304, 'epsilon': 0.8350539437603917}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:05,926] Trial 12 finished with value: 6512.899523675743 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9735963069840413, 'epsilon': 0.7691989797835845}. Best is trial 2 with value: 6505.28827556611.\n",
      "[I 2025-08-01 08:10:06,234] Trial 13 finished with value: 6504.331059515733 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.8390050225008197, 'epsilon': 0.7255078975595922}. Best is trial 13 with value: 6504.331059515733.\n",
      "[I 2025-08-01 08:10:06,326] Trial 14 finished with value: 2074.3098734173313 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8028740890259722, 'epsilon': 0.3013028217469453}. Best is trial 14 with value: 2074.3098734173313.\n",
      "[I 2025-08-01 08:10:06,416] Trial 15 finished with value: 2073.0121647820383 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8074527497290347, 'epsilon': 0.24112884875852275}. Best is trial 15 with value: 2073.0121647820383.\n",
      "[I 2025-08-01 08:10:06,506] Trial 16 finished with value: 2223.319226729953 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5065357736671656, 'epsilon': 0.14979620867780274}. Best is trial 15 with value: 2073.0121647820383.\n",
      "[I 2025-08-01 08:10:06,602] Trial 17 finished with value: 2080.619482672501 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7868029771679719, 'epsilon': 0.25027815702659617}. Best is trial 15 with value: 2073.0121647820383.\n",
      "[I 2025-08-01 08:10:06,695] Trial 18 finished with value: 2039.0395289892103 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8660773763021, 'epsilon': 0.298401696578549}. Best is trial 18 with value: 2039.0395289892103.\n",
      "[I 2025-08-01 08:10:06,817] Trial 19 finished with value: 4061.239013171242 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.6915792925224047, 'epsilon': 0.07205485935451694}. Best is trial 18 with value: 2039.0395289892103.\n",
      "[I 2025-08-01 08:10:06,921] Trial 20 finished with value: 3988.2926405198577 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.8687044720950123, 'epsilon': 0.3375165121774675}. Best is trial 18 with value: 2039.0395289892103.\n",
      "[I 2025-08-01 08:10:07,010] Trial 21 finished with value: 2028.6090317704486 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8888506810264475, 'epsilon': 0.29512391613705}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:07,107] Trial 22 finished with value: 2031.2969802246175 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8834462651366934, 'epsilon': 0.22507483262467196}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:07,219] Trial 23 finished with value: 3976.141982331332 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9058502703740006, 'epsilon': 0.06083333195528229}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:07,777] Trial 24 finished with value: 19775.40818736113 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.5001391454435062, 'epsilon': 0.3550348182433207}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:07,864] Trial 25 finished with value: 2099.332409528252 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7197961686024921, 'epsilon': 0.21687269829060044}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:07,982] Trial 26 finished with value: 3979.004943474876 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.8991167009733975, 'epsilon': 0.13796312818233072}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:08,071] Trial 27 finished with value: 2161.651549858589 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5900454827074033, 'epsilon': 0.47816519192200446}. Best is trial 21 with value: 2028.6090317704486.\n",
      "[I 2025-08-01 08:10:08,162] Trial 28 finished with value: 2028.2289851056137 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8910877079216477, 'epsilon': 0.29951607755632803}. Best is trial 28 with value: 2028.2289851056137.\n",
      "[I 2025-08-01 08:10:08,265] Trial 29 finished with value: 4024.7269127758213 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.7463359782945457, 'epsilon': 0.4600397223730269}. Best is trial 28 with value: 2028.2289851056137.\n",
      "[I 2025-08-01 08:10:08,501] Trial 30 finished with value: 2018.364022463642 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9228491236989145, 'epsilon': 0.12445897078254176}. Best is trial 30 with value: 2018.364022463642.\n",
      "[I 2025-08-01 08:10:08,623] Trial 31 finished with value: 2015.1981404468333 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9307016329959308, 'epsilon': 0.11887350519540554}. Best is trial 31 with value: 2015.1981404468333.\n",
      "[I 2025-08-01 08:10:08,725] Trial 32 finished with value: 2014.336081934449 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9325337503991551, 'epsilon': 0.11270251874841943}. Best is trial 32 with value: 2014.336081934449.\n",
      "[I 2025-08-01 08:10:08,818] Trial 33 finished with value: 2462.0088042134576 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.1108859880293448, 'epsilon': 0.09841153481070836}. Best is trial 32 with value: 2014.336081934449.\n",
      "[I 2025-08-01 08:10:08,970] Trial 34 finished with value: 3966.723977619935 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9388268649696115, 'epsilon': 0.12782219677355527}. Best is trial 32 with value: 2014.336081934449.\n",
      "[I 2025-08-01 08:10:09,088] Trial 35 finished with value: 2013.4192917112637 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.935735812094889, 'epsilon': 0.18511228543637237}. Best is trial 35 with value: 2013.4192917112637.\n",
      "[I 2025-08-01 08:10:09,199] Trial 36 finished with value: 2012.0379971267796 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9428163970986209, 'epsilon': 0.1682865089531943}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:09,323] Trial 37 finished with value: 4089.8147419778297 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.6481022941630212, 'epsilon': 0.1859498895280438}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:09,459] Trial 38 finished with value: 17369.893123511025 and parameters: {'kernel': 'rbf', 'C': 0.8284720031293465, 'epsilon': 0.06073870657829816}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:09,557] Trial 39 finished with value: 2294.0946408805253 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.3916351141233846, 'epsilon': 0.17231885102144545}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:09,700] Trial 40 finished with value: 16746.88565891447 and parameters: {'kernel': 'rbf', 'C': 0.9972037512470954, 'epsilon': 0.4066305203156485}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:09,795] Trial 41 finished with value: 2016.9845503008119 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9259951512462894, 'epsilon': 0.115415600101572}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:10,806] Trial 42 finished with value: 38451.40818497127 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.9528101479240546, 'epsilon': 0.19043498969982736}. Best is trial 36 with value: 2012.0379971267796.\n",
      "[I 2025-08-01 08:10:10,904] Trial 43 finished with value: 2007.948993445037 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9232957443020459, 'epsilon': 0.9844572849308778}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,001] Trial 44 finished with value: 2056.7905318460207 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.839258908713036, 'epsilon': 0.94561150309409}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,132] Trial 45 finished with value: 16902.53691349188 and parameters: {'kernel': 'rbf', 'C': 0.9571873459267531, 'epsilon': 0.665809063447381}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,226] Trial 46 finished with value: 2085.738846020407 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7701230759976444, 'epsilon': 0.5125544687336382}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,326] Trial 47 finished with value: 2051.56340433418 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8516991365835392, 'epsilon': 0.6315411820130967}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,433] Trial 48 finished with value: 3946.6859240958224 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.999872339819989, 'epsilon': 0.9357224327283624}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,592] Trial 49 finished with value: 16954.604917413326 and parameters: {'kernel': 'rbf', 'C': 0.9472864712201818, 'epsilon': 0.1024155104285971}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,684] Trial 50 finished with value: 2064.4050516652615 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8198825285482052, 'epsilon': 0.8449356057307118}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,782] Trial 51 finished with value: 2012.992239384972 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9332890798450011, 'epsilon': 0.2508630075080062}. Best is trial 43 with value: 2007.948993445037.\n",
      "[I 2025-08-01 08:10:11,882] Trial 52 finished with value: 2004.7992972751001 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9637206291903376, 'epsilon': 0.2552976046067411}. Best is trial 52 with value: 2004.7992972751001.\n",
      "[I 2025-08-01 08:10:11,979] Trial 53 finished with value: 2003.445233560915 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9679041415973211, 'epsilon': 0.2613597240542773}. Best is trial 53 with value: 2003.445233560915.\n",
      "[I 2025-08-01 08:10:12,074] Trial 54 finished with value: 2004.6835678241052 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9637324532813726, 'epsilon': 0.2607549695713772}. Best is trial 53 with value: 2003.445233560915.\n",
      "[I 2025-08-01 08:10:12,167] Trial 55 finished with value: 2003.0554373137454 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9625078161839654, 'epsilon': 0.3655436943951106}. Best is trial 55 with value: 2003.0554373137454.\n",
      "[I 2025-08-01 08:10:12,261] Trial 56 finished with value: 1999.9704657722775 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9731733236444741, 'epsilon': 0.36213646215081474}. Best is trial 56 with value: 1999.9704657722775.\n",
      "[I 2025-08-01 08:10:12,356] Trial 57 finished with value: 1999.7766391407122 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9740042042689837, 'epsilon': 0.3538294051214516}. Best is trial 57 with value: 1999.7766391407122.\n",
      "[I 2025-08-01 08:10:12,660] Trial 58 finished with value: 6510.200284042176 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9691590302586961, 'epsilon': 0.38010120709342954}. Best is trial 57 with value: 1999.7766391407122.\n",
      "[I 2025-08-01 08:10:12,756] Trial 59 finished with value: 1997.9322250820026 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9769575434033821, 'epsilon': 0.4378861148625473}. Best is trial 59 with value: 1997.9322250820026.\n",
      "[I 2025-08-01 08:10:12,891] Trial 60 finished with value: 16768.669766366926 and parameters: {'kernel': 'rbf', 'C': 0.9925855618671536, 'epsilon': 0.44045968154978954}. Best is trial 59 with value: 1997.9322250820026.\n",
      "[I 2025-08-01 08:10:12,987] Trial 61 finished with value: 2001.9875082176216 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9686061616835988, 'epsilon': 0.33604294744980334}. Best is trial 59 with value: 1997.9322250820026.\n",
      "[I 2025-08-01 08:10:13,085] Trial 62 finished with value: 2032.1362071370495 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8766859387738658, 'epsilon': 0.36478629360748616}. Best is trial 59 with value: 1997.9322250820026.\n",
      "[I 2025-08-01 08:10:13,184] Trial 63 finished with value: 1999.469910971884 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9761071503447165, 'epsilon': 0.32570249444182153}. Best is trial 59 with value: 1997.9322250820026.\n",
      "[I 2025-08-01 08:10:13,279] Trial 64 finished with value: 2023.1324204094174 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9049295300657222, 'epsilon': 0.32737560228951695}. Best is trial 59 with value: 1997.9322250820026.\n",
      "[I 2025-08-01 08:10:13,383] Trial 65 finished with value: 1994.1034497027454 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999577376473956, 'epsilon': 0.5011910487947802}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:13,512] Trial 66 finished with value: 3947.6798596901126 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9976188771612837, 'epsilon': 0.5006627750519401}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:13,604] Trial 67 finished with value: 2039.2190833219356 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8641837203875459, 'epsilon': 0.4282536945428359}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:13,694] Trial 68 finished with value: 2251.49353084035 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.45900038519448827, 'epsilon': 0.38608353006462115}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:13,783] Trial 69 finished with value: 2023.25060934414 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9026252864359029, 'epsilon': 0.5637554874773257}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:13,894] Trial 70 finished with value: 4044.037148048338 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.28870959279131814, 'epsilon': 0.32623444445939975}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:13,989] Trial 71 finished with value: 1997.2075533054601 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9788455245769436, 'epsilon': 0.46285380003792437}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,083] Trial 72 finished with value: 1997.3074792408693 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9786536494416368, 'epsilon': 0.5465905640491425}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,192] Trial 73 finished with value: 1997.0842819654572 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.97886995328311, 'epsilon': 0.4733098053522}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,291] Trial 74 finished with value: 1996.028873028488 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9825165334215573, 'epsilon': 0.46483126495602817}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,382] Trial 75 finished with value: 2020.5521091853855 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9078627982740588, 'epsilon': 0.530452540282735}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,471] Trial 76 finished with value: 2029.6018763946247 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.883176601202247, 'epsilon': 0.46009172818341953}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,567] Trial 77 finished with value: 1995.512061434113 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9870937963498382, 'epsilon': 0.5978152952724074}. Best is trial 65 with value: 1994.1034497027454.\n",
      "[I 2025-08-01 08:10:14,664] Trial 78 finished with value: 1993.3194463332147 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9968457810695055, 'epsilon': 0.6058605437919586}. Best is trial 78 with value: 1993.3194463332147.\n",
      "[I 2025-08-01 08:10:14,758] Trial 79 finished with value: 1992.706397576536 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9984146829034422, 'epsilon': 0.609565566276379}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:14,877] Trial 80 finished with value: 16740.060614584076 and parameters: {'kernel': 'rbf', 'C': 0.9984939462378621, 'epsilon': 0.5999317328973957}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:14,967] Trial 81 finished with value: 2017.722391587837 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9147966587300022, 'epsilon': 0.55066217319654}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:15,058] Trial 82 finished with value: 2007.7942439335498 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.944955642427796, 'epsilon': 0.5917388905000326}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:15,150] Trial 83 finished with value: 1993.4360837194158 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9855550766123106, 'epsilon': 0.6920326836266857}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:15,242] Trial 84 finished with value: 2004.6282983448527 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9435777112412329, 'epsilon': 0.6886847771069976}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:16,268] Trial 85 finished with value: 39669.25097072847 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.9930588756405294, 'epsilon': 0.6312358328046218}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:16,555] Trial 86 finished with value: 6502.045136531176 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9213395424964897, 'epsilon': 0.4842495863669101}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:16,643] Trial 87 finished with value: 2029.1169829952635 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8839858917544501, 'epsilon': 0.7076677417277335}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:16,735] Trial 88 finished with value: 2003.0444721110873 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9498435570468091, 'epsilon': 0.7408972930183149}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:16,827] Trial 89 finished with value: 2075.449813078606 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7984145519722708, 'epsilon': 0.5304863774545103}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:16,920] Trial 90 finished with value: 2050.7942525186927 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8537679251010855, 'epsilon': 0.6046020771925432}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:17,014] Trial 91 finished with value: 1996.2922863690867 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9874760807328483, 'epsilon': 0.5549609328431575}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:17,108] Trial 92 finished with value: 1996.5459590933813 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9847527951901336, 'epsilon': 0.5483567250078474}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:17,207] Trial 93 finished with value: 1994.3806510113245 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9966221469337856, 'epsilon': 0.5760697225382319}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:17,298] Trial 94 finished with value: 2005.9161982300138 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9492691192358584, 'epsilon': 0.617571662026788}. Best is trial 79 with value: 1992.706397576536.\n",
      "[I 2025-08-01 08:10:17,393] Trial 95 finished with value: 1991.3602441276894 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999873887210261, 'epsilon': 0.6517142884096606}. Best is trial 95 with value: 1991.3602441276894.\n",
      "[I 2025-08-01 08:10:17,486] Trial 96 finished with value: 1990.8832128262077 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996722679530201, 'epsilon': 0.6693353584181425}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:17,601] Trial 97 finished with value: 3970.4843814520605 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9244834287434475, 'epsilon': 0.6582464048255126}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:17,717] Trial 98 finished with value: 16916.37130075496 and parameters: {'kernel': 'rbf', 'C': 0.9534016683142722, 'epsilon': 0.6616356494055451}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:17,804] Trial 99 finished with value: 2021.057602078739 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.89971575691691, 'epsilon': 0.7832854403924114}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:17,898] Trial 100 finished with value: 1994.4937396861815 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9951816007619336, 'epsilon': 0.5832188109912451}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:17,992] Trial 101 finished with value: 1993.7268903035988 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997121959931626, 'epsilon': 0.5727494630971758}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,086] Trial 102 finished with value: 1991.4193574013916 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9991207282140294, 'epsilon': 0.6460053941189197}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,179] Trial 103 finished with value: 1993.5517379810262 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998534065409502, 'epsilon': 0.5783064162834234}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,273] Trial 104 finished with value: 1993.719610210732 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9986315724320457, 'epsilon': 0.5832596590551399}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,360] Trial 105 finished with value: 2392.8589598793965 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.15978241625475254, 'epsilon': 0.6936571267237315}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,448] Trial 106 finished with value: 2173.821081397357 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5776261214097703, 'epsilon': 0.645410503426592}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,539] Trial 107 finished with value: 2002.2412147586158 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9525337360598373, 'epsilon': 0.7321274858308844}. Best is trial 96 with value: 1990.8832128262077.\n",
      "[I 2025-08-01 08:10:18,633] Trial 108 finished with value: 1990.855802936432 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990011479984616, 'epsilon': 0.676297345606849}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:18,725] Trial 109 finished with value: 2009.5589886296962 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9283547062818883, 'epsilon': 0.7583348772135516}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:18,815] Trial 110 finished with value: 2129.3409360650076 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6469875002084743, 'epsilon': 0.6840237221784543}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:18,908] Trial 111 finished with value: 2001.3999714713873 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9619581831523256, 'epsilon': 0.6233449301788283}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:19,000] Trial 112 finished with value: 2000.7132992659779 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9624718911457695, 'epsilon': 0.6461594252257792}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:19,195] Trial 113 finished with value: 2011.007309446634 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.929267585156859, 'epsilon': 0.6749425925772831}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:19,295] Trial 114 finished with value: 1993.8558059871298 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9991526414245618, 'epsilon': 0.5729762024778067}. Best is trial 108 with value: 1990.855802936432.\n",
      "[I 2025-08-01 08:10:19,391] Trial 115 finished with value: 1990.178234293226 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997091038873948, 'epsilon': 0.7104555623353217}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:19,484] Trial 116 finished with value: 1997.9262796081161 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9654853359850194, 'epsilon': 0.7196942982001335}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:19,602] Trial 117 finished with value: 16960.577236339373 and parameters: {'kernel': 'rbf', 'C': 0.9414213210453373, 'epsilon': 0.7837726547280083}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:19,695] Trial 118 finished with value: 1992.2454213981273 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9994280969106887, 'epsilon': 0.6154632721408027}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:19,788] Trial 119 finished with value: 1998.9547987273702 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9684644105074504, 'epsilon': 0.6444981047227469}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:19,876] Trial 120 finished with value: 2015.8576187277258 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9131787262023184, 'epsilon': 0.7023661914152045}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:19,969] Trial 121 finished with value: 1996.782563477742 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9779003811802747, 'epsilon': 0.6099013544952301}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,062] Trial 122 finished with value: 1993.7234385694267 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997641854079417, 'epsilon': 0.5723890735223257}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,154] Trial 123 finished with value: 2001.1593848798123 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.955837825004739, 'epsilon': 0.6743898208484717}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,248] Trial 124 finished with value: 1996.0380189141674 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9812318617308962, 'epsilon': 0.6189780959887125}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,342] Trial 125 finished with value: 1991.2276041041546 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997538514946142, 'epsilon': 0.6415496389078853}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,433] Trial 126 finished with value: 2008.8659087972926 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9368928548947186, 'epsilon': 0.6321125160597493}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,527] Trial 127 finished with value: 1994.2444581218685 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9761589740301181, 'epsilon': 0.7148717772126937}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,621] Trial 128 finished with value: 2001.265742190387 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9603567871867807, 'epsilon': 0.6496175975902516}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,715] Trial 129 finished with value: 1990.8059446298905 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999927296665359, 'epsilon': 0.670126783399371}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,807] Trial 130 finished with value: 2005.4441587839697 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9402902622781316, 'epsilon': 0.7429529528070122}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,901] Trial 131 finished with value: 1994.6855874033142 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9787781105636371, 'epsilon': 0.6683102905705238}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:20,990] Trial 132 finished with value: 2275.55932651248 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.41900291577934357, 'epsilon': 0.5909098458793254}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,083] Trial 133 finished with value: 1990.4616252623978 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.99933430071415, 'epsilon': 0.6889744617085609}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,176] Trial 134 finished with value: 1993.845340922478 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9810665961497466, 'epsilon': 0.7019172739111631}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,269] Trial 135 finished with value: 1998.645500078264 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.964045768381006, 'epsilon': 0.6730815615118758}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,364] Trial 136 finished with value: 1991.6931080226611 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9987595836179803, 'epsilon': 0.6355567439493939}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,462] Trial 137 finished with value: 2005.2848031733192 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9497378704783406, 'epsilon': 0.6370338852510377}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,581] Trial 138 finished with value: 16811.65640904274 and parameters: {'kernel': 'rbf', 'C': 0.9806788865142418, 'epsilon': 0.6163378031098288}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,670] Trial 139 finished with value: 2283.1852579350425 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.32826652568601566, 'epsilon': 0.8139931951912306}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,760] Trial 140 finished with value: 2013.4921148802352 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9208692258121723, 'epsilon': 0.6899869043524329}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,855] Trial 141 finished with value: 1993.8879703289338 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9870768019794985, 'epsilon': 0.6565080902345481}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:21,950] Trial 142 finished with value: 1990.3604772170524 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999636585054776, 'epsilon': 0.7257014900653449}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:22,042] Trial 143 finished with value: 2096.3665824471877 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7266242794310178, 'epsilon': 0.7240440105910985}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:22,135] Trial 144 finished with value: 1998.42892240036 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9620977991688882, 'epsilon': 0.7539752559344881}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:22,229] Trial 145 finished with value: 1994.061294803373 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9756734987229081, 'epsilon': 0.7095365922006477}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:22,333] Trial 146 finished with value: 1990.7148294215692 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.998339244348322, 'epsilon': 0.6877148767102519}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:22,440] Trial 147 finished with value: 1990.3776202315912 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999205920205135, 'epsilon': 0.6934464163170553}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:23,479] Trial 148 finished with value: 39879.28024155643 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.9997098356636543, 'epsilon': 0.6689329758091401}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:23,614] Trial 149 finished with value: 3966.5451427018115 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9442116697103905, 'epsilon': 0.7382880158792926}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:23,711] Trial 150 finished with value: 1999.4008234030175 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9584475845975968, 'epsilon': 0.7763097660401335}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:23,810] Trial 151 finished with value: 1994.056376682746 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9795906864442572, 'epsilon': 0.6912172024420002}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:23,910] Trial 152 finished with value: 1993.8677740399821 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9808333024430068, 'epsilon': 0.6854973411487701}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,008] Trial 153 finished with value: 1999.7894853477355 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9653556934048088, 'epsilon': 0.6486593161921256}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,108] Trial 154 finished with value: 1992.9094844233543 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9888023360729475, 'epsilon': 0.7215449372381739}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,204] Trial 155 finished with value: 2204.2058883066106 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5283281416306834, 'epsilon': 0.7264161164949587}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,300] Trial 156 finished with value: 2004.1862613019239 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9442342710738738, 'epsilon': 0.7578275138092307}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,396] Trial 157 finished with value: 2000.0271510393047 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9662291902556015, 'epsilon': 0.6272759573141503}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,731] Trial 158 finished with value: 6515.9360400555815 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9997395543100264, 'epsilon': 0.8016816589666924}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,822] Trial 159 finished with value: 2010.0423788704177 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9327613048138796, 'epsilon': 0.6555926110278207}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:24,917] Trial 160 finished with value: 1993.477467748858 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9857598577755156, 'epsilon': 0.7124966516557352}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,011] Trial 161 finished with value: 1990.5863592332596 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999758479378931, 'epsilon': 0.6784348676808852}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,104] Trial 162 finished with value: 1993.5524397044796 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9840107718358235, 'epsilon': 0.6813664015052252}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,197] Trial 163 finished with value: 2000.2376928850172 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9671928037930814, 'epsilon': 0.6060085928643602}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,293] Trial 164 finished with value: 1991.0296375860198 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9992857441730875, 'epsilon': 0.6669142946130621}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,393] Trial 165 finished with value: 2000.3111009613513 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.959311950645139, 'epsilon': 0.6653526707247561}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,495] Trial 166 finished with value: 1991.1206069502045 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9952320099091949, 'epsilon': 0.7042349119240092}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,622] Trial 167 finished with value: 16741.287471916552 and parameters: {'kernel': 'rbf', 'C': 0.9981164439055566, 'epsilon': 0.6434642865384681}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,722] Trial 168 finished with value: 2002.2961364312034 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9515606904086159, 'epsilon': 0.7079938652953897}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,825] Trial 169 finished with value: 1994.383576939035 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9775154956979105, 'epsilon': 0.6776641245268624}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:25,925] Trial 170 finished with value: 1995.7016372932826 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9704122096457788, 'epsilon': 0.6980556856283499}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,023] Trial 171 finished with value: 1990.52547903287 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999798442249306, 'epsilon': 0.7354124312729747}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,119] Trial 172 finished with value: 1994.0336741864517 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9853803069673777, 'epsilon': 0.7515968765856186}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,215] Trial 173 finished with value: 1990.7478330704614 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9989330951430386, 'epsilon': 0.7344345491643226}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,315] Trial 174 finished with value: 1991.1120655197767 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9970689800623278, 'epsilon': 0.7368842539577081}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,410] Trial 175 finished with value: 1997.1848424051427 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9673540762974908, 'epsilon': 0.7311152124182355}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,506] Trial 176 finished with value: 1990.433168559831 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9989833069436255, 'epsilon': 0.7690201144785604}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,598] Trial 177 finished with value: 2003.1349802850818 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9451550155096373, 'epsilon': 0.838553572178313}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,693] Trial 178 finished with value: 1994.5538812180514 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9755440422889264, 'epsilon': 0.7362676090997768}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,794] Trial 179 finished with value: 1998.6663193404409 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.957035307740572, 'epsilon': 0.7989729714533875}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:26,901] Trial 180 finished with value: 1994.4260571834761 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9807163311242639, 'epsilon': 0.7711504322672965}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,018] Trial 181 finished with value: 1990.2826074730779 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9991079739444022, 'epsilon': 0.7082652873638576}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,146] Trial 182 finished with value: 1990.53558666979 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9981495578157763, 'epsilon': 0.7021434600991551}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,267] Trial 183 finished with value: 1990.9580656654673 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9984751552092321, 'epsilon': 0.752160094025895}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,372] Trial 184 finished with value: 1990.646854697428 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9992652891170017, 'epsilon': 0.7579369212688033}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,474] Trial 185 finished with value: 1994.5342427712856 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.976257281015416, 'epsilon': 0.7638631860412827}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,574] Trial 186 finished with value: 1994.6367601360162 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9823776886442939, 'epsilon': 0.7471346426071871}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,676] Trial 187 finished with value: 1990.515227361672 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999749089772503, 'epsilon': 0.7937140462147175}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,775] Trial 188 finished with value: 1998.7869538172095 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9543774158373391, 'epsilon': 0.8619720449396004}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,877] Trial 189 finished with value: 1993.8513640113715 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9697011227669368, 'epsilon': 0.8145618428413992}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:27,976] Trial 190 finished with value: 1994.0586615264363 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9822094679601414, 'epsilon': 0.7978302853125625}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,078] Trial 191 finished with value: 1990.8832936432043 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9970213168831906, 'epsilon': 0.7154470576535545}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,179] Trial 192 finished with value: 1990.3790816843966 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999645099336733, 'epsilon': 0.7866399320408652}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,277] Trial 193 finished with value: 1993.8276498236455 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9712337898330804, 'epsilon': 0.8810591009057399}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,380] Trial 194 finished with value: 2000.067881583776 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.956879586711052, 'epsilon': 0.7818027228616107}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,494] Trial 195 finished with value: 1990.318352010335 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990933660373471, 'epsilon': 0.7725369994756809}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,614] Trial 196 finished with value: 1994.5023821284021 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9813521634300836, 'epsilon': 0.7676683995295078}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,717] Trial 197 finished with value: 2006.2653109042715 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9354389720723217, 'epsilon': 0.7849074197377592}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,841] Trial 198 finished with value: 16799.73684505072 and parameters: {'kernel': 'rbf', 'C': 0.9825281177379888, 'epsilon': 0.8230280139541288}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:28,953] Trial 199 finished with value: 1996.159031609803 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9661517608836067, 'epsilon': 0.7586837100683212}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,055] Trial 200 finished with value: 1990.6099297370522 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9986685845292346, 'epsilon': 0.7222727949803318}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,156] Trial 201 finished with value: 1990.299289099167 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999734707372849, 'epsilon': 0.7220357777796137}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,257] Trial 202 finished with value: 1990.2975304334661 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999722953467107, 'epsilon': 0.7183967574669265}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,363] Trial 203 finished with value: 1994.3082403672158 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9804780589604781, 'epsilon': 0.7253840743596356}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,470] Trial 204 finished with value: 1990.186195286315 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996924462524912, 'epsilon': 0.7052684930096984}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,567] Trial 205 finished with value: 1998.1320224492356 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.965291815642942, 'epsilon': 0.7359262111508044}. Best is trial 115 with value: 1990.178234293226.\n",
      "[I 2025-08-01 08:10:29,668] Trial 206 finished with value: 1990.1296755184944 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997991869338302, 'epsilon': 0.7067347834255612}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:29,770] Trial 207 finished with value: 1993.8451766568419 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9814904861824773, 'epsilon': 0.7016179689532659}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:29,864] Trial 208 finished with value: 2003.6927686378967 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9482888252529008, 'epsilon': 0.7244963368122518}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:29,963] Trial 209 finished with value: 1995.8439711112107 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9658254113938701, 'epsilon': 0.7720273208108185}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,058] Trial 210 finished with value: 1990.5367988521386 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997197407541364, 'epsilon': 0.7442065975487475}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,153] Trial 211 finished with value: 1994.1107992596387 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.984445493227165, 'epsilon': 0.7428710435249058}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,248] Trial 212 finished with value: 1990.4027594251004 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990245489565901, 'epsilon': 0.7147272521140304}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,346] Trial 213 finished with value: 1994.0959646291603 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9822094653980515, 'epsilon': 0.7136996603986552}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,439] Trial 214 finished with value: 1994.2075067158228 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9797225548337535, 'epsilon': 0.7914603253983645}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,533] Trial 215 finished with value: 1997.9197717365914 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9635673164636664, 'epsilon': 0.7512148954696574}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,624] Trial 216 finished with value: 2112.1241788849793 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6845181055161773, 'epsilon': 0.6989112380361268}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,718] Trial 217 finished with value: 1993.8254970133892 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9851988466741315, 'epsilon': 0.7257952100848203}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:30,812] Trial 218 finished with value: 1990.8313126901514 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9972304165842151, 'epsilon': 0.7698797492496153}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,011] Trial 219 finished with value: 1990.2488048044404 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995892816652833, 'epsilon': 0.7131405447386212}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,115] Trial 220 finished with value: 1990.3790488755085 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999811881449995, 'epsilon': 0.6957756486311332}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,223] Trial 221 finished with value: 1990.3986634223427 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998384562137497, 'epsilon': 0.6936586533681386}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,324] Trial 222 finished with value: 1990.2653201080418 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9993345860982644, 'epsilon': 0.7107169557176977}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,418] Trial 223 finished with value: 1994.5850959459149 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9723908377866592, 'epsilon': 0.7055861605797837}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,515] Trial 224 finished with value: 1994.2062786061783 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9781729117796867, 'epsilon': 0.7171650773669506}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,610] Trial 225 finished with value: 1990.4443376142315 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995307177279792, 'epsilon': 0.6923456387951588}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,703] Trial 226 finished with value: 2000.3295953948586 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9562425362304038, 'epsilon': 0.6912301093917577}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,796] Trial 227 finished with value: 1994.0801484703047 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9796534103543213, 'epsilon': 0.6900350431242015}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,891] Trial 228 finished with value: 1997.5000332035136 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9663837787459143, 'epsilon': 0.7020872035936307}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:31,990] Trial 229 finished with value: 1990.4809968314992 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996825679588038, 'epsilon': 0.7402022613115177}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,091] Trial 230 finished with value: 1990.4836275963899 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997618142109199, 'epsilon': 0.7415108801943567}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,194] Trial 231 finished with value: 1990.4525526343377 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999460285206626, 'epsilon': 0.7422539756216076}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,299] Trial 232 finished with value: 1994.1730644212535 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9814653138771693, 'epsilon': 0.7179689630320438}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,397] Trial 233 finished with value: 1994.5062318065393 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9825348356999847, 'epsilon': 0.7399685962741698}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,511] Trial 234 finished with value: 1990.2483796893848 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9993216854219102, 'epsilon': 0.7093434389066385}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,629] Trial 235 finished with value: 1996.894270071677 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9679132861933921, 'epsilon': 0.727445256480696}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,757] Trial 236 finished with value: 1994.5238235946938 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9828722933004502, 'epsilon': 0.7595400064860015}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,870] Trial 237 finished with value: 1990.3590454380787 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9994383178612017, 'epsilon': 0.7179022710488878}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:32,996] Trial 238 finished with value: 16899.661050671337 and parameters: {'kernel': 'rbf', 'C': 0.9579411811698004, 'epsilon': 0.7105465839095548}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,095] Trial 239 finished with value: 1994.0065205720591 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.980187153305321, 'epsilon': 0.6893802721144967}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,195] Trial 240 finished with value: 2003.3658635066581 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9468242111713447, 'epsilon': 0.8050362380696328}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,290] Trial 241 finished with value: 1990.7645205650176 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9984526122235012, 'epsilon': 0.7398835104755473}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,396] Trial 242 finished with value: 1990.1520725882835 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999923466202408, 'epsilon': 0.7776356441587752}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,517] Trial 243 finished with value: 1994.1725635938224 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9825847893174785, 'epsilon': 0.7859973943340159}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,635] Trial 244 finished with value: 1990.1681131254954 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998492992154004, 'epsilon': 0.7765977248585293}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,731] Trial 245 finished with value: 2354.857918019985 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.2266949460265213, 'epsilon': 0.7718690449057657}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,830] Trial 246 finished with value: 1995.9922998696163 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9695891446432653, 'epsilon': 0.7106215243744852}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:33,936] Trial 247 finished with value: 1994.6829776682537 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9808484488015089, 'epsilon': 0.7497310654971607}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,039] Trial 248 finished with value: 1990.4774286812121 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9993610887273676, 'epsilon': 0.7241796547829794}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,137] Trial 249 finished with value: 1993.7929057906777 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9830534573876998, 'epsilon': 0.6884055475739023}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,240] Trial 250 finished with value: 1996.3730195162914 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9688893055604688, 'epsilon': 0.7177093786251145}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,368] Trial 251 finished with value: 1990.3895072596833 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998011521989867, 'epsilon': 0.6965862551679277}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,473] Trial 252 finished with value: 1993.4771689856993 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9844302871638414, 'epsilon': 0.6990796493670548}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,577] Trial 253 finished with value: 1999.5581460733908 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9605036981219269, 'epsilon': 0.6806717130840833}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,687] Trial 254 finished with value: 1993.5571742868608 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.986040940314479, 'epsilon': 0.7215048959320617}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,800] Trial 255 finished with value: 1990.225315097544 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9993779874744952, 'epsilon': 0.7058891930415555}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:34,901] Trial 256 finished with value: 1997.2015609367065 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.96698640167421, 'epsilon': 0.7018940460356446}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:35,127] Trial 257 finished with value: 6583.265581012791 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.7742129787115644, 'epsilon': 0.6801179674280955}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:35,221] Trial 258 finished with value: 1994.525794684676 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9808452981945006, 'epsilon': 0.7662426125684556}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:36,604] Trial 259 finished with value: 39902.02917382051 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.99969251758118, 'epsilon': 0.7048940723679277}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:36,697] Trial 260 finished with value: 2005.697989502883 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9431199183646887, 'epsilon': 0.6701712587657416}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:36,792] Trial 261 finished with value: 1997.2180145730765 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9664611257783258, 'epsilon': 0.6912825146564315}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:36,910] Trial 262 finished with value: 16734.485122585138 and parameters: {'kernel': 'rbf', 'C': 0.9998414730805028, 'epsilon': 0.8287453642638624}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,008] Trial 263 finished with value: 1994.2389564215916 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9822553008898316, 'epsilon': 0.7207835248685642}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,139] Trial 264 finished with value: 3964.2116366247237 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9510176915115184, 'epsilon': 0.7583543829551389}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,249] Trial 265 finished with value: 1993.9807650110815 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9824145861949569, 'epsilon': 0.7078228698693108}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,347] Trial 266 finished with value: 1995.1294342493452 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9673769240500032, 'epsilon': 0.7772288180654828}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,451] Trial 267 finished with value: 1993.8045176709027 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9827011696301459, 'epsilon': 0.686601395742158}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,553] Trial 268 finished with value: 1994.2207342490326 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9836491636043384, 'epsilon': 0.7277251565100648}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,658] Trial 269 finished with value: 2002.2592593912298 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9535596894669883, 'epsilon': 0.6664739736455209}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,761] Trial 270 finished with value: 1996.1034657825026 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.966840094387991, 'epsilon': 0.7548546047237444}. Best is trial 206 with value: 1990.1296755184944.\n",
      "[I 2025-08-01 08:10:37,865] Trial 271 finished with value: 1990.0964390495324 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999012980803728, 'epsilon': 0.70781984790318}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:37,973] Trial 272 finished with value: 1990.3514738462038 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990008170841871, 'epsilon': 0.711224086312295}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,073] Trial 273 finished with value: 2149.948286573333 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6084263508895396, 'epsilon': 0.7100086095000494}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,181] Trial 274 finished with value: 1990.2449662767997 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998150351143457, 'epsilon': 0.7021785180480105}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,276] Trial 275 finished with value: 2232.5027716423097 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.4812435203703965, 'epsilon': 0.8068465309525636}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,379] Trial 276 finished with value: 1995.6859259389016 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9704042243924221, 'epsilon': 0.7268817735255737}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,481] Trial 277 finished with value: 2007.2956436239615 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9349024694765105, 'epsilon': 0.7082224329164523}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,584] Trial 278 finished with value: 1990.601696972355 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998692822655633, 'epsilon': 0.6787896811723471}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,686] Trial 279 finished with value: 1994.4059705085554 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9812464243630495, 'epsilon': 0.7297005309473525}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,779] Trial 280 finished with value: 2471.832208414031 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.1060626749094773, 'epsilon': 0.6587756186489674}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:38,875] Trial 281 finished with value: 2000.8636933484772 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9554847978215576, 'epsilon': 0.7075576397686669}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:39,008] Trial 282 finished with value: 16797.49441581964 and parameters: {'kernel': 'rbf', 'C': 0.9833019541707783, 'epsilon': 0.7757354938241011}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:39,111] Trial 283 finished with value: 1996.3998300346832 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9690647251709777, 'epsilon': 0.6941658953613207}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:39,226] Trial 284 finished with value: 1994.2173800190596 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9841301483846318, 'epsilon': 0.7448737984266749}. Best is trial 271 with value: 1990.0964390495324.\n",
      "[I 2025-08-01 08:10:39,333] Trial 285 finished with value: 1988.362668176169 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9988224379377415, 'epsilon': 0.9308536349035461}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:39,435] Trial 286 finished with value: 1999.0830643525721 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9547445812336215, 'epsilon': 0.9904350710794882}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:39,550] Trial 287 finished with value: 1992.3862071021642 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9824897180206541, 'epsilon': 0.9534580997611437}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:39,660] Trial 288 finished with value: 1994.6584308622537 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9700059490974885, 'epsilon': 0.9397722030284471}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:39,777] Trial 289 finished with value: 1989.4575943495827 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9993240378357031, 'epsilon': 0.8465737246046234}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:39,880] Trial 290 finished with value: 2004.3922138868654 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9389531760801062, 'epsilon': 0.8855195624033537}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:39,979] Trial 291 finished with value: 1988.812638668288 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995468609867767, 'epsilon': 0.9019576582671038}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,076] Trial 292 finished with value: 1989.3789057796923 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999565018909222, 'epsilon': 0.8694815582546473}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,170] Trial 293 finished with value: 1994.259599106912 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9693265380482174, 'epsilon': 0.9061460322644732}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,264] Trial 294 finished with value: 1992.5419131787917 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9819423945451824, 'epsilon': 0.9152623008607254}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,352] Trial 295 finished with value: 2289.2418109556165 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.3612763486511569, 'epsilon': 0.8913349678187737}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,444] Trial 296 finished with value: 1998.6003087497793 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9549867766976406, 'epsilon': 0.8514253168787663}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,539] Trial 297 finished with value: 1993.3832826388089 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9826709713320859, 'epsilon': 0.8429891390669101}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,634] Trial 298 finished with value: 1993.311503163737 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9829764832588762, 'epsilon': 0.8623576857433196}. Best is trial 285 with value: 1988.362668176169.\n",
      "[I 2025-08-01 08:10:40,734] Trial 299 finished with value: 1989.6030781053148 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990787882576084, 'epsilon': 0.8413174868398008}. Best is trial 285 with value: 1988.362668176169.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "svm_stacking_study = optuna.create_study(direction='minimize')\n",
    "svm_stacking_study.optimize(stacked_objective_svm, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'poly',\n",
       " 'degree': 2,\n",
       " 'C': 0.9988224379377415,\n",
       " 'epsilon': 0.9308536349035461}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/svm_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_stacking_study.best_params, f\"../../split_year_models/ensemble/svm_stacking_best_params.pkl\")\n",
    "joblib.dump(svm_stacking_study, f\"../../split_year_models/ensemble/svm_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/svm_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model = SVR(**svm_stacking_study.best_params)\n",
    "best_svm_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_svm_model, \"../../split_year_models/ensemble/svm_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_mlp(trial):\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 7)\n",
    "\n",
    "    hidden_layer_sizes = []\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        hidden_layer_sizes.append(trial.suggest_int(\"size_hidden_layer_\" + str(i), 5, 150))\n",
    "    \n",
    "    activation = trial.suggest_categorical(\"activation\", [\"logistic\", \"relu\"])\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.001, 0.1)\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"])\n",
    "\n",
    "    mlp = MLPRegressor(random_state=42, hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver='adam', alpha=alpha, learning_rate=learning_rate)\n",
    "    mlp.fit(X_meta_train_scaled, y_meta_train)\n",
    "    mlp_predictions = mlp.predict(X_meta_val_scaled)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, mlp_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 09:38:56,679] A new study created in memory with name: no-name-b2e4c148-dcbb-4f87-8f4a-f3047d8019ef\n",
      "[I 2025-08-01 09:39:00,540] Trial 0 finished with value: 568.519870984605 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 45, 'size_hidden_layer_1': 90, 'size_hidden_layer_2': 147, 'size_hidden_layer_3': 38, 'size_hidden_layer_4': 35, 'size_hidden_layer_5': 45, 'size_hidden_layer_6': 11, 'activation': 'relu', 'alpha': 0.040685611924155825, 'learning_rate': 'adaptive'}. Best is trial 0 with value: 568.519870984605.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:39:04,740] Trial 1 finished with value: 19145.492390541538 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 144, 'size_hidden_layer_1': 23, 'size_hidden_layer_2': 44, 'activation': 'logistic', 'alpha': 0.03396056079192831, 'learning_rate': 'constant'}. Best is trial 0 with value: 568.519870984605.\n",
      "[I 2025-08-01 09:39:07,246] Trial 2 finished with value: 403.5263334120315 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 120, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 89, 'size_hidden_layer_3': 102, 'activation': 'relu', 'alpha': 0.006207894706047092, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:39:12,404] Trial 3 finished with value: 22190.861349054685 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 14, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 66, 'size_hidden_layer_3': 15, 'size_hidden_layer_4': 63, 'size_hidden_layer_5': 62, 'size_hidden_layer_6': 57, 'activation': 'logistic', 'alpha': 0.06081746722899418, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:17,394] Trial 4 finished with value: 484.6116615967733 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 141, 'size_hidden_layer_1': 124, 'size_hidden_layer_2': 81, 'size_hidden_layer_3': 70, 'activation': 'relu', 'alpha': 0.08874115157653999, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:20,052] Trial 5 finished with value: 484.6069289027191 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 21, 'size_hidden_layer_1': 66, 'size_hidden_layer_2': 65, 'size_hidden_layer_3': 100, 'size_hidden_layer_4': 34, 'activation': 'relu', 'alpha': 0.006349989437125152, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:39:21,757] Trial 6 finished with value: 13725.565493613201 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 43, 'size_hidden_layer_1': 23, 'size_hidden_layer_2': 109, 'activation': 'logistic', 'alpha': 0.06508740196924666, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:30,557] Trial 7 finished with value: 22251.857012075045 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 57, 'size_hidden_layer_2': 123, 'size_hidden_layer_3': 84, 'size_hidden_layer_4': 109, 'size_hidden_layer_5': 126, 'size_hidden_layer_6': 139, 'activation': 'logistic', 'alpha': 0.02620164008839562, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:36,281] Trial 8 finished with value: 588.4156082929403 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 31, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 126, 'size_hidden_layer_3': 34, 'size_hidden_layer_4': 121, 'size_hidden_layer_5': 72, 'size_hidden_layer_6': 89, 'activation': 'relu', 'alpha': 0.06477224233051572, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:39:37,898] Trial 9 finished with value: 21963.197085343258 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 117, 'size_hidden_layer_1': 19, 'size_hidden_layer_2': 21, 'activation': 'logistic', 'alpha': 0.06444271373426853, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:40,634] Trial 10 finished with value: 421.7346866860301 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 6, 'size_hidden_layer_3': 141, 'size_hidden_layer_4': 5, 'activation': 'relu', 'alpha': 0.0021261349687112926, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:43,066] Trial 11 finished with value: 595.5286947660577 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 6, 'size_hidden_layer_3': 150, 'size_hidden_layer_4': 5, 'activation': 'relu', 'alpha': 0.0011048474517226412, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:45,978] Trial 12 finished with value: 705.0928447831608 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 90, 'size_hidden_layer_3': 139, 'activation': 'relu', 'alpha': 0.018437951113474828, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:50,125] Trial 13 finished with value: 483.77992599575407 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 65, 'size_hidden_layer_1': 149, 'size_hidden_layer_2': 40, 'size_hidden_layer_3': 117, 'size_hidden_layer_4': 82, 'activation': 'relu', 'alpha': 0.014921075664052697, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:39:56,813] Trial 14 finished with value: 458.70315759295 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 143, 'size_hidden_layer_5': 9, 'activation': 'relu', 'alpha': 0.013710908789266795, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:39:59,715] Trial 15 finished with value: 587.099569814064 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 75, 'size_hidden_layer_1': 132, 'activation': 'relu', 'alpha': 0.044383601786630256, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:02,203] Trial 16 finished with value: 408.5829744114039 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 86, 'size_hidden_layer_1': 77, 'size_hidden_layer_2': 39, 'size_hidden_layer_3': 117, 'size_hidden_layer_4': 14, 'size_hidden_layer_5': 138, 'activation': 'relu', 'alpha': 0.09013954626483646, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:05,481] Trial 17 finished with value: 490.5420354932482 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 71, 'size_hidden_layer_1': 77, 'size_hidden_layer_2': 49, 'size_hidden_layer_3': 73, 'size_hidden_layer_4': 50, 'size_hidden_layer_5': 146, 'activation': 'relu', 'alpha': 0.0991713740703028, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:08,233] Trial 18 finished with value: 618.0258571985062 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 123, 'size_hidden_layer_1': 49, 'size_hidden_layer_2': 28, 'size_hidden_layer_3': 103, 'size_hidden_layer_4': 87, 'size_hidden_layer_5': 110, 'activation': 'relu', 'alpha': 0.08288668393483466, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:11,727] Trial 19 finished with value: 457.6958694455613 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 87, 'size_hidden_layer_2': 60, 'size_hidden_layer_3': 96, 'activation': 'relu', 'alpha': 0.07755131619659937, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:40:12,919] Trial 20 finished with value: 573.961087249097 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 60, 'size_hidden_layer_1': 39, 'activation': 'relu', 'alpha': 0.09570763210264999, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:15,740] Trial 21 finished with value: 566.2004433981597 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 10, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 9, 'activation': 'relu', 'alpha': 0.027727275263136255, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:19,317] Trial 22 finished with value: 540.8620766357255 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 74, 'size_hidden_layer_2': 28, 'size_hidden_layer_3': 115, 'size_hidden_layer_4': 22, 'size_hidden_layer_5': 101, 'activation': 'relu', 'alpha': 0.050750171184406, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:22,293] Trial 23 finished with value: 410.10746527824034 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 132, 'size_hidden_layer_1': 115, 'size_hidden_layer_2': 18, 'size_hidden_layer_3': 138, 'activation': 'relu', 'alpha': 0.007495849178166314, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:25,684] Trial 24 finished with value: 453.8879539066106 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 150, 'size_hidden_layer_1': 91, 'size_hidden_layer_2': 78, 'size_hidden_layer_3': 129, 'activation': 'relu', 'alpha': 0.024037665949754098, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:29,641] Trial 25 finished with value: 483.2874094376393 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 35, 'activation': 'relu', 'alpha': 0.010308823250437055, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:40:34,877] Trial 26 finished with value: 14080.803860441683 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 135, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 19, 'size_hidden_layer_3': 107, 'activation': 'logistic', 'alpha': 0.05362170715987191, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:37,094] Trial 27 finished with value: 473.99018791268963 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 116, 'size_hidden_layer_1': 66, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.07554868152250087, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:40:39,784] Trial 28 finished with value: 433.10333398037704 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 82, 'size_hidden_layer_1': 7, 'size_hidden_layer_2': 51, 'size_hidden_layer_3': 86, 'activation': 'relu', 'alpha': 0.03371199155484592, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:42,144] Trial 29 finished with value: 494.4264938871014 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 52, 'size_hidden_layer_1': 87, 'size_hidden_layer_2': 56, 'size_hidden_layer_3': 60, 'size_hidden_layer_4': 53, 'size_hidden_layer_5': 147, 'activation': 'relu', 'alpha': 0.044538430855397874, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:43,588] Trial 30 finished with value: 487.2984221737777 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 118, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 70, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 96, 'activation': 'relu', 'alpha': 0.01863887648379963, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:47,027] Trial 31 finished with value: 450.90245773508985 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 14, 'size_hidden_layer_3': 150, 'size_hidden_layer_4': 27, 'activation': 'relu', 'alpha': 0.0036371984786519734, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:50,442] Trial 32 finished with value: 1502.7167839315275 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 29, 'size_hidden_layer_3': 138, 'size_hidden_layer_4': 64, 'activation': 'relu', 'alpha': 0.004962781321417803, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:40:53,090] Trial 33 finished with value: 456.0100275732982 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 136, 'size_hidden_layer_2': 18, 'size_hidden_layer_3': 139, 'activation': 'relu', 'alpha': 0.03696335797116239, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:41:01,364] Trial 34 finished with value: 15524.704386702599 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 141, 'size_hidden_layer_1': 125, 'size_hidden_layer_2': 5, 'size_hidden_layer_3': 111, 'size_hidden_layer_4': 16, 'size_hidden_layer_5': 98, 'activation': 'logistic', 'alpha': 0.012751822438733244, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:07,690] Trial 35 finished with value: 511.27042671087133 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 128, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 147, 'size_hidden_layer_3': 123, 'activation': 'relu', 'alpha': 0.008576230984777698, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:10,948] Trial 36 finished with value: 575.8841897094824 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 149, 'size_hidden_layer_2': 39, 'size_hidden_layer_3': 91, 'size_hidden_layer_4': 43, 'activation': 'relu', 'alpha': 0.02239782182304624, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:18,624] Trial 37 finished with value: 22254.43346312404 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 139, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 22, 'size_hidden_layer_3': 140, 'size_hidden_layer_4': 67, 'size_hidden_layer_5': 31, 'size_hidden_layer_6': 149, 'activation': 'logistic', 'alpha': 0.03188899623873162, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:20,822] Trial 38 finished with value: 495.2642214927134 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 148, 'size_hidden_layer_1': 66, 'size_hidden_layer_2': 73, 'activation': 'relu', 'alpha': 0.007780881861984952, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:41:26,816] Trial 39 finished with value: 22577.780260804928 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 7, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 86, 'size_hidden_layer_3': 108, 'size_hidden_layer_4': 22, 'activation': 'logistic', 'alpha': 0.0011919233885222544, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:29,183] Trial 40 finished with value: 591.7044325456068 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 122, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 32, 'size_hidden_layer_3': 131, 'size_hidden_layer_4': 5, 'size_hidden_layer_5': 119, 'activation': 'relu', 'alpha': 0.05617317394133775, 'learning_rate': 'constant'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:30,730] Trial 41 finished with value: 478.4880433545914 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 81, 'size_hidden_layer_1': 5, 'size_hidden_layer_2': 48, 'size_hidden_layer_3': 87, 'activation': 'relu', 'alpha': 0.02978397393617406, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:32,488] Trial 42 finished with value: 607.8266162261032 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 88, 'size_hidden_layer_1': 39, 'size_hidden_layer_2': 51, 'activation': 'relu', 'alpha': 0.03983309950815961, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:34,808] Trial 43 finished with value: 473.1134005531905 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 76, 'size_hidden_layer_1': 16, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 66, 'activation': 'relu', 'alpha': 0.018418793486409537, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:37,733] Trial 44 finished with value: 431.9975833865142 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 48, 'size_hidden_layer_2': 62, 'size_hidden_layer_3': 80, 'activation': 'relu', 'alpha': 0.06916561906841456, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:40,813] Trial 45 finished with value: 526.1957906862575 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 50, 'size_hidden_layer_2': 65, 'size_hidden_layer_3': 52, 'activation': 'relu', 'alpha': 0.07401282603314618, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "[I 2025-08-01 09:41:43,407] Trial 46 finished with value: 517.5546079412818 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 70, 'size_hidden_layer_2': 13, 'size_hidden_layer_3': 96, 'size_hidden_layer_4': 38, 'size_hidden_layer_5': 81, 'size_hidden_layer_6': 8, 'activation': 'relu', 'alpha': 0.0917140030785156, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:41:49,623] Trial 47 finished with value: 14435.685369205888 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 104, 'size_hidden_layer_1': 58, 'size_hidden_layer_2': 44, 'size_hidden_layer_3': 80, 'size_hidden_layer_4': 145, 'activation': 'logistic', 'alpha': 0.08499196194540286, 'learning_rate': 'invscaling'}. Best is trial 2 with value: 403.5263334120315.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:41:53,225] Trial 48 finished with value: 387.50751177995363 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 68, 'size_hidden_layer_1': 37, 'size_hidden_layer_2': 120, 'activation': 'relu', 'alpha': 0.05903839369579609, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:41:54,700] Trial 49 finished with value: 575.8511159887923 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 60, 'size_hidden_layer_1': 33, 'activation': 'relu', 'alpha': 0.01577081569210239, 'learning_rate': 'constant'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:41:57,331] Trial 50 finished with value: 496.0923891071143 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 70, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 122, 'activation': 'relu', 'alpha': 0.06062224395320307, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:42:00,299] Trial 51 finished with value: 582.9774042174852 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 29, 'size_hidden_layer_1': 33, 'size_hidden_layer_2': 150, 'activation': 'relu', 'alpha': 0.0701440024690842, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:04,776] Trial 52 finished with value: 483.35268258376965 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 51, 'size_hidden_layer_2': 114, 'size_hidden_layer_3': 145, 'activation': 'relu', 'alpha': 0.06178045745354903, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:42:07,523] Trial 53 finished with value: 545.0742183055561 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 57, 'activation': 'relu', 'alpha': 0.0702708637742199, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:42:10,950] Trial 54 finished with value: 465.7895434113806 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 69, 'size_hidden_layer_1': 43, 'size_hidden_layer_2': 132, 'activation': 'relu', 'alpha': 0.0854572878737644, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:14,994] Trial 55 finished with value: 574.4667811816454 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 84, 'size_hidden_layer_2': 136, 'size_hidden_layer_3': 17, 'activation': 'relu', 'alpha': 0.08027559684438017, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:18,221] Trial 56 finished with value: 596.3823374279266 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 122, 'size_hidden_layer_1': 27, 'size_hidden_layer_2': 25, 'size_hidden_layer_3': 120, 'size_hidden_layer_4': 17, 'activation': 'relu', 'alpha': 0.04584226039030516, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:20,841] Trial 57 finished with value: 499.2383443426645 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 54, 'size_hidden_layer_1': 60, 'size_hidden_layer_2': 89, 'activation': 'relu', 'alpha': 0.05677543332192806, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:23,833] Trial 58 finished with value: 423.1741003240161 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 84, 'size_hidden_layer_1': 95, 'size_hidden_layer_2': 58, 'size_hidden_layer_3': 134, 'activation': 'relu', 'alpha': 0.08977113681211521, 'learning_rate': 'adaptive'}. Best is trial 48 with value: 387.50751177995363.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:42:32,429] Trial 59 finished with value: 18554.168619718184 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 81, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 9, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 117, 'size_hidden_layer_5': 133, 'activation': 'logistic', 'alpha': 0.0911951805069499, 'learning_rate': 'adaptive'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:34,278] Trial 60 finished with value: 517.9787227361413 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 75, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 38, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 72, 'activation': 'relu', 'alpha': 0.09497156625265549, 'learning_rate': 'adaptive'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:38,895] Trial 61 finished with value: 586.9641013270143 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 84, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 59, 'size_hidden_layer_3': 115, 'activation': 'relu', 'alpha': 0.06769321695068577, 'learning_rate': 'adaptive'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:41,875] Trial 62 finished with value: 595.6766033992185 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 88, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 83, 'size_hidden_layer_3': 144, 'activation': 'relu', 'alpha': 0.09797114924140184, 'learning_rate': 'adaptive'}. Best is trial 48 with value: 387.50751177995363.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:42:45,925] Trial 63 finished with value: 474.2267253241836 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 82, 'size_hidden_layer_2': 69, 'size_hidden_layer_3': 103, 'activation': 'relu', 'alpha': 0.08860770353401314, 'learning_rate': 'adaptive'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:49,837] Trial 64 finished with value: 592.7500111020292 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 66, 'size_hidden_layer_1': 143, 'size_hidden_layer_2': 77, 'size_hidden_layer_3': 145, 'activation': 'relu', 'alpha': 0.04926433988588163, 'learning_rate': 'invscaling'}. Best is trial 48 with value: 387.50751177995363.\n",
      "[I 2025-08-01 09:42:53,032] Trial 65 finished with value: 385.7673674673897 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 35, 'activation': 'relu', 'alpha': 0.010829816889856344, 'learning_rate': 'invscaling'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:42:57,038] Trial 66 finished with value: 540.3269939317132 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 130, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 32, 'activation': 'relu', 'alpha': 0.012917335315320124, 'learning_rate': 'invscaling'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:01,465] Trial 67 finished with value: 404.5005532057312 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 125, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 109, 'size_hidden_layer_3': 122, 'size_hidden_layer_4': 49, 'activation': 'relu', 'alpha': 0.004562834262458389, 'learning_rate': 'adaptive'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:05,246] Trial 68 finished with value: 473.01755294382286 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 112, 'size_hidden_layer_1': 137, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 120, 'size_hidden_layer_4': 49, 'activation': 'relu', 'alpha': 0.0044040600997164725, 'learning_rate': 'invscaling'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:09,552] Trial 69 finished with value: 393.25964111943983 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 127, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 103, 'size_hidden_layer_3': 113, 'size_hidden_layer_4': 16, 'size_hidden_layer_5': 45, 'activation': 'relu', 'alpha': 0.01004698009411583, 'learning_rate': 'constant'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:17,509] Trial 70 finished with value: 454.0423368765433 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 126, 'size_hidden_layer_1': 135, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 109, 'size_hidden_layer_4': 40, 'size_hidden_layer_5': 46, 'activation': 'relu', 'alpha': 0.011280106489670219, 'learning_rate': 'constant'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:24,677] Trial 71 finished with value: 1078.1215212485615 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 135, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 97, 'size_hidden_layer_3': 114, 'size_hidden_layer_4': 14, 'size_hidden_layer_5': 17, 'activation': 'relu', 'alpha': 0.007164049252163469, 'learning_rate': 'constant'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:33,093] Trial 72 finished with value: 469.32306060925634 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 117, 'size_hidden_layer_1': 150, 'size_hidden_layer_2': 117, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 25, 'size_hidden_layer_5': 88, 'activation': 'relu', 'alpha': 0.0011757354251711017, 'learning_rate': 'constant'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:36,931] Trial 73 finished with value: 464.7778679841073 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 137, 'size_hidden_layer_1': 125, 'size_hidden_layer_2': 109, 'size_hidden_layer_3': 101, 'size_hidden_layer_4': 31, 'activation': 'relu', 'alpha': 0.009285423710474406, 'learning_rate': 'constant'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:41,191] Trial 74 finished with value: 582.1246230993218 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 121, 'size_hidden_layer_1': 141, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 13, 'size_hidden_layer_5': 55, 'activation': 'relu', 'alpha': 0.017040909528501586, 'learning_rate': 'constant'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:43:45,912] Trial 75 finished with value: 585.9670228502573 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 144, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 120, 'size_hidden_layer_3': 114, 'size_hidden_layer_4': 57, 'size_hidden_layer_5': 30, 'size_hidden_layer_6': 99, 'activation': 'relu', 'alpha': 0.02151920534585028, 'learning_rate': 'invscaling'}. Best is trial 65 with value: 385.7673674673897.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:43:56,486] Trial 76 finished with value: 23378.17405917852 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 125, 'size_hidden_layer_1': 132, 'size_hidden_layer_2': 127, 'size_hidden_layer_3': 96, 'size_hidden_layer_4': 20, 'activation': 'logistic', 'alpha': 0.005383502599753081, 'learning_rate': 'invscaling'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:44:01,730] Trial 77 finished with value: 538.4648537536777 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 132, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 150, 'size_hidden_layer_4': 32, 'activation': 'relu', 'alpha': 0.003091120386744695, 'learning_rate': 'invscaling'}. Best is trial 65 with value: 385.7673674673897.\n",
      "[I 2025-08-01 09:44:14,067] Trial 78 finished with value: 313.7549089547779 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 114, 'size_hidden_layer_1': 135, 'size_hidden_layer_2': 109, 'size_hidden_layer_3': 118, 'size_hidden_layer_4': 45, 'size_hidden_layer_5': 73, 'size_hidden_layer_6': 49, 'activation': 'relu', 'alpha': 0.010155499726513405, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:44:18,570] Trial 79 finished with value: 349.4275960013745 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 114, 'size_hidden_layer_1': 126, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 105, 'size_hidden_layer_4': 45, 'size_hidden_layer_5': 74, 'size_hidden_layer_6': 47, 'activation': 'relu', 'alpha': 0.010524532343124064, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:44:25,160] Trial 80 finished with value: 697.692313802826 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 107, 'size_hidden_layer_4': 44, 'size_hidden_layer_5': 69, 'size_hidden_layer_6': 46, 'activation': 'relu', 'alpha': 0.020754792271740798, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:44:31,848] Trial 81 finished with value: 687.7365983911816 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 119, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 97, 'size_hidden_layer_3': 116, 'size_hidden_layer_4': 57, 'size_hidden_layer_5': 87, 'size_hidden_layer_6': 47, 'activation': 'relu', 'alpha': 0.025380374264357783, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:44:41,935] Trial 82 finished with value: 624.1278675650913 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 130, 'size_hidden_layer_1': 126, 'size_hidden_layer_2': 110, 'size_hidden_layer_3': 92, 'size_hidden_layer_4': 47, 'size_hidden_layer_5': 52, 'size_hidden_layer_6': 61, 'activation': 'relu', 'alpha': 0.011020965146838453, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:44:49,071] Trial 83 finished with value: 562.6604402154908 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 104, 'size_hidden_layer_3': 105, 'size_hidden_layer_4': 40, 'size_hidden_layer_5': 33, 'size_hidden_layer_6': 27, 'activation': 'relu', 'alpha': 0.015423402412599319, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:44:55,723] Trial 84 finished with value: 542.9556320228315 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 119, 'size_hidden_layer_4': 57, 'size_hidden_layer_5': 66, 'size_hidden_layer_6': 75, 'activation': 'relu', 'alpha': 0.007431725196035977, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:02,950] Trial 85 finished with value: 560.3649529688983 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 128, 'size_hidden_layer_1': 128, 'size_hidden_layer_2': 89, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 29, 'size_hidden_layer_5': 77, 'size_hidden_layer_6': 109, 'activation': 'relu', 'alpha': 0.014069474021721115, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:09,063] Trial 86 finished with value: 403.620471298507 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 144, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 114, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 35, 'size_hidden_layer_5': 97, 'activation': 'relu', 'alpha': 0.010401935617118236, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:12,647] Trial 87 finished with value: 483.46328684532347 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 143, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 114, 'size_hidden_layer_4': 38, 'size_hidden_layer_5': 96, 'activation': 'relu', 'alpha': 0.012095386493370795, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:20,459] Trial 88 finished with value: 487.25840313058757 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 39, 'size_hidden_layer_1': 134, 'size_hidden_layer_2': 118, 'size_hidden_layer_3': 111, 'size_hidden_layer_4': 25, 'size_hidden_layer_5': 58, 'activation': 'relu', 'alpha': 0.005566745134695499, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:31,965] Trial 89 finished with value: 22257.869882195886 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 146, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 126, 'size_hidden_layer_3': 98, 'size_hidden_layer_4': 52, 'size_hidden_layer_5': 116, 'activation': 'logistic', 'alpha': 0.009472047611415685, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:37,201] Trial 90 finished with value: 354.605524951 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 143, 'size_hidden_layer_2': 85, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 34, 'size_hidden_layer_5': 136, 'size_hidden_layer_6': 33, 'activation': 'relu', 'alpha': 0.01911507198170264, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:44,936] Trial 91 finished with value: 690.28925514588 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 35, 'size_hidden_layer_5': 133, 'size_hidden_layer_6': 32, 'activation': 'relu', 'alpha': 0.01970878833239531, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:49,433] Trial 92 finished with value: 447.62502548216696 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 124, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 80, 'size_hidden_layer_3': 131, 'size_hidden_layer_4': 44, 'size_hidden_layer_5': 137, 'size_hidden_layer_6': 28, 'activation': 'relu', 'alpha': 0.017166822952860622, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:52,606] Trial 93 finished with value: 408.90674365678353 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 150, 'size_hidden_layer_1': 136, 'size_hidden_layer_2': 85, 'size_hidden_layer_3': 120, 'size_hidden_layer_4': 34, 'size_hidden_layer_5': 107, 'size_hidden_layer_6': 70, 'activation': 'relu', 'alpha': 0.009439005263831571, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:45:56,841] Trial 94 finished with value: 460.4872430316658 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 111, 'size_hidden_layer_4': 25, 'size_hidden_layer_5': 123, 'size_hidden_layer_6': 42, 'activation': 'relu', 'alpha': 0.014321373055979424, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:04,496] Trial 95 finished with value: 372.2339030532413 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 119, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 92, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 10, 'size_hidden_layer_5': 41, 'activation': 'relu', 'alpha': 0.0036650246416732053, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:10,892] Trial 96 finished with value: 609.5298091660188 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 120, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 18, 'size_hidden_layer_5': 43, 'activation': 'relu', 'alpha': 0.0034981748540537103, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:16,455] Trial 97 finished with value: 469.8526745145611 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 126, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 89, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 9, 'size_hidden_layer_5': 44, 'size_hidden_layer_6': 19, 'activation': 'relu', 'alpha': 0.00664822129671264, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:19,744] Trial 98 finished with value: 410.6049892567105 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 115, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 10, 'size_hidden_layer_5': 73, 'activation': 'relu', 'alpha': 0.002430484708682807, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:23,797] Trial 99 finished with value: 409.9188190465029 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 139, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 103, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 63, 'size_hidden_layer_5': 22, 'activation': 'relu', 'alpha': 0.023390866150115416, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:28,762] Trial 100 finished with value: 340.9489835807172 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 127, 'size_hidden_layer_2': 76, 'size_hidden_layer_3': 104, 'size_hidden_layer_4': 48, 'size_hidden_layer_5': 63, 'size_hidden_layer_6': 58, 'activation': 'relu', 'alpha': 0.011896506384806707, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:33,510] Trial 101 finished with value: 476.0096102730306 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 73, 'size_hidden_layer_3': 104, 'size_hidden_layer_4': 47, 'size_hidden_layer_5': 63, 'size_hidden_layer_6': 60, 'activation': 'relu', 'alpha': 0.012440184490127931, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:42,827] Trial 102 finished with value: 478.924736265564 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 76, 'size_hidden_layer_3': 92, 'size_hidden_layer_4': 52, 'size_hidden_layer_5': 82, 'size_hidden_layer_6': 39, 'activation': 'relu', 'alpha': 0.010327251096535364, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:44,533] Trial 103 finished with value: 896.9745626364727 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 118, 'size_hidden_layer_1': 126, 'size_hidden_layer_2': 86, 'size_hidden_layer_3': 119, 'size_hidden_layer_4': 37, 'size_hidden_layer_5': 51, 'size_hidden_layer_6': 56, 'activation': 'relu', 'alpha': 0.005074446954118765, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:50,150] Trial 104 finished with value: 638.5534844106388 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 143, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 111, 'size_hidden_layer_4': 43, 'size_hidden_layer_5': 39, 'size_hidden_layer_6': 68, 'activation': 'relu', 'alpha': 0.016286343734332794, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:52,958] Trial 105 finished with value: 606.6165361754063 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 123, 'size_hidden_layer_1': 131, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 100, 'size_hidden_layer_4': 28, 'size_hidden_layer_5': 60, 'activation': 'relu', 'alpha': 0.007926795230514908, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:46:58,092] Trial 106 finished with value: 441.4280209889311 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 133, 'size_hidden_layer_1': 137, 'size_hidden_layer_2': 82, 'size_hidden_layer_3': 141, 'size_hidden_layer_4': 70, 'size_hidden_layer_5': 73, 'size_hidden_layer_6': 50, 'activation': 'relu', 'alpha': 0.01348892639881194, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:47:03,021] Trial 107 finished with value: 490.75033068034634 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 128, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 91, 'size_hidden_layer_3': 117, 'size_hidden_layer_4': 60, 'size_hidden_layer_5': 89, 'size_hidden_layer_6': 86, 'activation': 'relu', 'alpha': 0.018922275031809092, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:47:08,592] Trial 108 finished with value: 559.4500077631574 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 142, 'size_hidden_layer_1': 123, 'size_hidden_layer_2': 137, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 21, 'size_hidden_layer_5': 49, 'activation': 'relu', 'alpha': 0.01083519952292317, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:47:33,954] Trial 109 finished with value: 22200.86652839928 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 41, 'activation': 'logistic', 'alpha': 0.006701722662614259, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:47:41,877] Trial 110 finished with value: 491.3381408738605 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 123, 'size_hidden_layer_3': 88, 'size_hidden_layer_4': 75, 'size_hidden_layer_5': 78, 'activation': 'relu', 'alpha': 0.0011915670162918213, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:47:47,077] Trial 111 finished with value: 391.70941958897293 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 70, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 137, 'size_hidden_layer_5': 142, 'activation': 'relu', 'alpha': 0.003873980349999622, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:47:51,025] Trial 112 finished with value: 551.6929919438784 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 127, 'activation': 'relu', 'alpha': 0.003990674743472979, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:47:55,156] Trial 113 finished with value: 556.1535487335907 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 99, 'size_hidden_layer_3': 138, 'size_hidden_layer_4': 46, 'size_hidden_layer_5': 143, 'activation': 'relu', 'alpha': 0.008385704950218134, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:01,412] Trial 114 finished with value: 488.42525833141485 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 120, 'size_hidden_layer_1': 150, 'size_hidden_layer_2': 103, 'size_hidden_layer_3': 131, 'size_hidden_layer_4': 98, 'size_hidden_layer_5': 131, 'activation': 'relu', 'alpha': 0.005291774866760155, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:13,956] Trial 115 finished with value: 384.1276063412998 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 136, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 87, 'activation': 'relu', 'alpha': 0.011964836225941548, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:20,979] Trial 116 finished with value: 458.43952336965106 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 134, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 144, 'size_hidden_layer_4': 137, 'size_hidden_layer_5': 148, 'size_hidden_layer_6': 36, 'activation': 'relu', 'alpha': 0.014865848850733419, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:34,261] Trial 117 finished with value: 638.0813693663614 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 120, 'size_hidden_layer_2': 86, 'size_hidden_layer_3': 136, 'size_hidden_layer_4': 85, 'size_hidden_layer_5': 66, 'activation': 'relu', 'alpha': 0.012592563603419246, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:40,716] Trial 118 finished with value: 541.1476778486416 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 74, 'size_hidden_layer_2': 117, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 126, 'activation': 'relu', 'alpha': 0.009610799180290583, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:45,060] Trial 119 finished with value: 442.5981466141025 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 61, 'size_hidden_layer_1': 10, 'size_hidden_layer_2': 92, 'size_hidden_layer_3': 50, 'size_hidden_layer_4': 98, 'size_hidden_layer_5': 36, 'size_hidden_layer_6': 15, 'activation': 'relu', 'alpha': 0.05654442263392352, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:48,812] Trial 120 finished with value: 519.2444536725317 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 131, 'size_hidden_layer_2': 79, 'activation': 'relu', 'alpha': 0.01760206851961904, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:48:57,717] Trial 121 finished with value: 517.4269098066967 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 117, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 116, 'activation': 'relu', 'alpha': 0.0032693031658295995, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:04,648] Trial 122 finished with value: 696.5568021322931 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 104, 'activation': 'relu', 'alpha': 0.006649196503742445, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:09,693] Trial 123 finished with value: 529.5315578338545 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 78, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 107, 'size_hidden_layer_4': 138, 'activation': 'relu', 'alpha': 0.011343411645775996, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:15,932] Trial 124 finished with value: 511.9320283182389 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 146, 'size_hidden_layer_1': 136, 'size_hidden_layer_2': 121, 'size_hidden_layer_3': 117, 'size_hidden_layer_4': 36, 'activation': 'relu', 'alpha': 0.008413486903978862, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:20,859] Trial 125 finished with value: 430.1874993896324 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 123, 'size_hidden_layer_1': 63, 'size_hidden_layer_2': 115, 'size_hidden_layer_3': 142, 'size_hidden_layer_4': 54, 'activation': 'relu', 'alpha': 0.059098795879794906, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:26,168] Trial 126 finished with value: 481.22780790180616 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 136, 'size_hidden_layer_1': 124, 'size_hidden_layer_2': 104, 'size_hidden_layer_3': 113, 'size_hidden_layer_4': 6, 'size_hidden_layer_5': 92, 'activation': 'relu', 'alpha': 0.015188817288278415, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:31,737] Trial 127 finished with value: 1121.5362805990399 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 128, 'size_hidden_layer_1': 89, 'size_hidden_layer_2': 107, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 50, 'activation': 'relu', 'alpha': 0.049414813258542065, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:49:47,168] Trial 128 finished with value: 22436.9348634523 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 99, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 92, 'size_hidden_layer_5': 23, 'size_hidden_layer_6': 23, 'activation': 'logistic', 'alpha': 0.05265551804956024, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:53,497] Trial 129 finished with value: 500.7589300248999 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 125, 'size_hidden_layer_3': 147, 'size_hidden_layer_4': 79, 'size_hidden_layer_5': 142, 'activation': 'relu', 'alpha': 0.002704185720711705, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:49:57,242] Trial 130 finished with value: 538.6413905792772 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 132, 'size_hidden_layer_2': 129, 'size_hidden_layer_3': 138, 'size_hidden_layer_4': 13, 'size_hidden_layer_5': 105, 'activation': 'relu', 'alpha': 0.006028781162627415, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:00,498] Trial 131 finished with value: 608.3613523088247 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 77, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 117, 'size_hidden_layer_4': 18, 'size_hidden_layer_5': 139, 'activation': 'relu', 'alpha': 0.01033153599867069, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:06,923] Trial 132 finished with value: 394.07734688412756 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 83, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 109, 'size_hidden_layer_4': 31, 'size_hidden_layer_5': 125, 'activation': 'relu', 'alpha': 0.028544293395193248, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:10,483] Trial 133 finished with value: 543.4361703095249 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 55, 'size_hidden_layer_2': 110, 'size_hidden_layer_3': 109, 'size_hidden_layer_4': 32, 'size_hidden_layer_5': 115, 'activation': 'relu', 'alpha': 0.02717326196458488, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:13,672] Trial 134 finished with value: 407.0087198435259 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 19, 'size_hidden_layer_2': 119, 'size_hidden_layer_3': 105, 'size_hidden_layer_4': 41, 'size_hidden_layer_5': 128, 'activation': 'relu', 'alpha': 0.012444653231581646, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:19,395] Trial 135 finished with value: 1181.5187213637137 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 119, 'size_hidden_layer_1': 70, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 102, 'size_hidden_layer_4': 28, 'size_hidden_layer_5': 122, 'size_hidden_layer_6': 80, 'activation': 'relu', 'alpha': 0.037270344586647866, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:23,080] Trial 136 finished with value: 543.9607297433525 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 28, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 97, 'size_hidden_layer_4': 149, 'size_hidden_layer_5': 56, 'activation': 'relu', 'alpha': 0.06476685287249095, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:29,762] Trial 137 finished with value: 450.71127914508895 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 88, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 35, 'size_hidden_layer_5': 136, 'size_hidden_layer_6': 54, 'activation': 'relu', 'alpha': 0.008500590482438576, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:35,030] Trial 138 finished with value: 425.59344632198986 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 121, 'size_hidden_layer_1': 46, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 122, 'size_hidden_layer_4': 47, 'activation': 'relu', 'alpha': 0.00514616787077081, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:41,463] Trial 139 finished with value: 656.857859884683 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 112, 'size_hidden_layer_1': 112, 'size_hidden_layer_2': 83, 'size_hidden_layer_3': 112, 'size_hidden_layer_4': 31, 'size_hidden_layer_5': 82, 'activation': 'relu', 'alpha': 0.028788737011117498, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:46,476] Trial 140 finished with value: 478.6701830004088 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 128, 'size_hidden_layer_2': 117, 'size_hidden_layer_3': 74, 'size_hidden_layer_4': 22, 'size_hidden_layer_5': 70, 'size_hidden_layer_6': 65, 'activation': 'relu', 'alpha': 0.020109036468230073, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:50:51,357] Trial 141 finished with value: 551.1703203947708 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 22, 'size_hidden_layer_2': 120, 'size_hidden_layer_3': 105, 'size_hidden_layer_4': 40, 'size_hidden_layer_5': 125, 'activation': 'relu', 'alpha': 0.013417784117370234, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:02,047] Trial 142 finished with value: 752.1123489405605 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 126, 'size_hidden_layer_1': 135, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 99, 'size_hidden_layer_4': 39, 'size_hidden_layer_5': 129, 'activation': 'relu', 'alpha': 0.016054911862251046, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:10,295] Trial 143 finished with value: 598.2336254548762 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 116, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 74, 'size_hidden_layer_3': 106, 'size_hidden_layer_4': 44, 'size_hidden_layer_5': 150, 'activation': 'relu', 'alpha': 0.011959560455633332, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:18,023] Trial 144 finished with value: 586.5306132760461 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 72, 'size_hidden_layer_1': 141, 'size_hidden_layer_2': 119, 'size_hidden_layer_3': 109, 'size_hidden_layer_4': 26, 'size_hidden_layer_5': 114, 'activation': 'relu', 'alpha': 0.007348868426880628, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:20,534] Trial 145 finished with value: 532.7441564226976 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 34, 'size_hidden_layer_2': 115, 'activation': 'relu', 'alpha': 0.001017719955409089, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:27,490] Trial 146 finished with value: 441.47421971952673 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 9, 'size_hidden_layer_2': 109, 'size_hidden_layer_3': 124, 'size_hidden_layer_4': 54, 'activation': 'relu', 'alpha': 0.010910402088245003, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:51:29,228] Trial 147 finished with value: 572.4235025551466 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 118, 'size_hidden_layer_1': 18, 'activation': 'relu', 'alpha': 0.013588757890369594, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:32,243] Trial 148 finished with value: 455.43290499142444 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 124, 'size_hidden_layer_1': 29, 'size_hidden_layer_2': 69, 'size_hidden_layer_3': 119, 'size_hidden_layer_4': 66, 'size_hidden_layer_5': 144, 'activation': 'relu', 'alpha': 0.031145171170847412, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:38,073] Trial 149 finished with value: 449.41737869334503 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 125, 'size_hidden_layer_2': 123, 'size_hidden_layer_3': 23, 'size_hidden_layer_4': 42, 'size_hidden_layer_5': 129, 'size_hidden_layer_6': 34, 'activation': 'relu', 'alpha': 0.009014529099220538, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:51:49,237] Trial 150 finished with value: 22238.44110123403 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 120, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 49, 'size_hidden_layer_5': 76, 'activation': 'logistic', 'alpha': 0.0038365553144118912, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:52,096] Trial 151 finished with value: 773.006728853684 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 82, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 116, 'size_hidden_layer_4': 9, 'size_hidden_layer_5': 135, 'activation': 'relu', 'alpha': 0.0747934719696406, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:54,497] Trial 152 finished with value: 508.42005716181086 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 107, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 37, 'size_hidden_layer_5': 139, 'activation': 'relu', 'alpha': 0.0065244346441976665, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:55,945] Trial 153 finished with value: 460.60380721254427 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 14, 'size_hidden_layer_2': 54, 'size_hidden_layer_3': 102, 'size_hidden_layer_4': 15, 'size_hidden_layer_5': 63, 'activation': 'relu', 'alpha': 0.08133098877231205, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:51:58,282] Trial 154 finished with value: 403.88805761453307 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 114, 'size_hidden_layer_1': 68, 'size_hidden_layer_2': 45, 'size_hidden_layer_3': 113, 'size_hidden_layer_4': 33, 'size_hidden_layer_5': 121, 'activation': 'relu', 'alpha': 0.024781633139143937, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:06,808] Trial 155 finished with value: 432.69346582099195 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 121, 'size_hidden_layer_1': 64, 'size_hidden_layer_2': 99, 'size_hidden_layer_3': 110, 'size_hidden_layer_4': 33, 'size_hidden_layer_5': 121, 'activation': 'relu', 'alpha': 0.023866767131841698, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:16,071] Trial 156 finished with value: 441.1822779690371 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 114, 'size_hidden_layer_1': 72, 'size_hidden_layer_2': 103, 'size_hidden_layer_3': 94, 'size_hidden_layer_4': 29, 'size_hidden_layer_5': 128, 'size_hidden_layer_6': 6, 'activation': 'relu', 'alpha': 0.02534616144479923, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:20,940] Trial 157 finished with value: 524.9413513888181 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 117, 'size_hidden_layer_1': 134, 'size_hidden_layer_2': 90, 'size_hidden_layer_3': 113, 'size_hidden_layer_4': 46, 'activation': 'relu', 'alpha': 0.022437102854318436, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:24,292] Trial 158 finished with value: 449.2773438208414 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 45, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 60, 'size_hidden_layer_5': 118, 'activation': 'relu', 'alpha': 0.017065618449004515, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:28,766] Trial 159 finished with value: 416.2108253187004 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 66, 'size_hidden_layer_1': 130, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 119, 'size_hidden_layer_4': 38, 'size_hidden_layer_5': 125, 'activation': 'relu', 'alpha': 0.012175503834173429, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:38,168] Trial 160 finished with value: 346.3001649463713 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 141, 'size_hidden_layer_2': 117, 'size_hidden_layer_3': 105, 'size_hidden_layer_4': 24, 'size_hidden_layer_5': 40, 'size_hidden_layer_6': 51, 'activation': 'relu', 'alpha': 0.01908458302008899, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:40,242] Trial 161 finished with value: 478.6819286136508 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 67, 'size_hidden_layer_2': 117, 'size_hidden_layer_3': 106, 'size_hidden_layer_4': 24, 'size_hidden_layer_5': 42, 'size_hidden_layer_6': 51, 'activation': 'relu', 'alpha': 0.020368453477906206, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:45,459] Trial 162 finished with value: 734.7396366707048 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 56, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 114, 'size_hidden_layer_3': 103, 'size_hidden_layer_4': 20, 'size_hidden_layer_5': 31, 'size_hidden_layer_6': 45, 'activation': 'relu', 'alpha': 0.01855075507497745, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:51,702] Trial 163 finished with value: 604.0941458490195 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 118, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 112, 'size_hidden_layer_3': 115, 'size_hidden_layer_4': 34, 'size_hidden_layer_5': 47, 'size_hidden_layer_6': 39, 'activation': 'relu', 'alpha': 0.015243022761862086, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:52:56,499] Trial 164 finished with value: 599.9357999336717 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 137, 'size_hidden_layer_2': 131, 'size_hidden_layer_3': 100, 'size_hidden_layer_4': 30, 'size_hidden_layer_5': 38, 'size_hidden_layer_6': 121, 'activation': 'relu', 'alpha': 0.009932206645598077, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:00,269] Trial 165 finished with value: 483.9720995349765 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 43, 'size_hidden_layer_5': 27, 'size_hidden_layer_6': 61, 'activation': 'relu', 'alpha': 0.034384234227576235, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:04,172] Trial 166 finished with value: 413.67151546129844 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 123, 'size_hidden_layer_3': 109, 'activation': 'relu', 'alpha': 0.00832869350376818, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:11,307] Trial 167 finished with value: 697.239072065753 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 114, 'size_hidden_layer_1': 148, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 113, 'size_hidden_layer_4': 24, 'size_hidden_layer_5': 53, 'activation': 'relu', 'alpha': 0.00532219588122911, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:15,621] Trial 168 finished with value: 535.4167343805262 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 124, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 110, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 36, 'size_hidden_layer_5': 110, 'size_hidden_layer_6': 78, 'activation': 'relu', 'alpha': 0.013893184287456199, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:19,443] Trial 169 finished with value: 372.7816964136911 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 121, 'size_hidden_layer_1': 60, 'size_hidden_layer_2': 118, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 11, 'activation': 'relu', 'alpha': 0.011190645772015246, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:22,411] Trial 170 finished with value: 514.2415505325184 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 120, 'size_hidden_layer_1': 68, 'size_hidden_layer_2': 87, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 12, 'activation': 'relu', 'alpha': 0.06193955513252376, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:27,731] Trial 171 finished with value: 636.7441905669214 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 72, 'size_hidden_layer_2': 118, 'size_hidden_layer_3': 6, 'size_hidden_layer_4': 17, 'activation': 'relu', 'alpha': 0.011660588890222421, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:30,010] Trial 172 finished with value: 479.4768633557391 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 104, 'size_hidden_layer_1': 62, 'size_hidden_layer_2': 115, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 6, 'activation': 'relu', 'alpha': 0.010259786024089486, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:34,715] Trial 173 finished with value: 527.5527532942589 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 127, 'size_hidden_layer_1': 54, 'size_hidden_layer_2': 121, 'size_hidden_layer_3': 118, 'size_hidden_layer_4': 12, 'activation': 'relu', 'alpha': 0.0034319362397757106, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:37,200] Trial 174 finished with value: 485.1913292718823 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 122, 'size_hidden_layer_1': 77, 'size_hidden_layer_2': 126, 'size_hidden_layer_3': 107, 'size_hidden_layer_4': 40, 'activation': 'relu', 'alpha': 0.0073223109235895645, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:53:46,262] Trial 175 finished with value: 872.419106597383 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 116, 'size_hidden_layer_1': 60, 'size_hidden_layer_2': 109, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 130, 'size_hidden_layer_5': 85, 'activation': 'relu', 'alpha': 0.017280738117167925, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:03,594] Trial 176 finished with value: 553.6533391037337 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 147, 'size_hidden_layer_1': 136, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 138, 'size_hidden_layer_4': 27, 'size_hidden_layer_5': 133, 'size_hidden_layer_6': 53, 'activation': 'relu', 'alpha': 0.014818559869269648, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:10,236] Trial 177 finished with value: 469.69077802473583 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 36, 'size_hidden_layer_2': 64, 'size_hidden_layer_3': 124, 'size_hidden_layer_4': 107, 'activation': 'relu', 'alpha': 0.012956711365147294, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:54:22,875] Trial 178 finished with value: 18659.13884937799 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 130, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 91, 'activation': 'logistic', 'alpha': 0.008863309412703817, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:29,059] Trial 179 finished with value: 656.6933820907416 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 119, 'size_hidden_layer_1': 23, 'size_hidden_layer_2': 34, 'size_hidden_layer_3': 104, 'size_hidden_layer_4': 31, 'size_hidden_layer_5': 97, 'activation': 'relu', 'alpha': 0.021579503351528605, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:37,084] Trial 180 finished with value: 429.5432428605959 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 116, 'size_hidden_layer_1': 128, 'size_hidden_layer_2': 84, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 51, 'size_hidden_layer_5': 67, 'size_hidden_layer_6': 27, 'activation': 'relu', 'alpha': 0.005427872121895422, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:45,771] Trial 181 finished with value: 458.8985944754335 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 68, 'size_hidden_layer_2': 116, 'size_hidden_layer_3': 115, 'size_hidden_layer_4': 19, 'size_hidden_layer_5': 140, 'activation': 'relu', 'alpha': 0.010874785146150801, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:53,370] Trial 182 finished with value: 653.3967375710886 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 73, 'size_hidden_layer_2': 41, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 15, 'size_hidden_layer_5': 41, 'activation': 'relu', 'alpha': 0.007255518598393585, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:54:58,812] Trial 183 finished with value: 398.51386567061365 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 85, 'size_hidden_layer_2': 36, 'size_hidden_layer_3': 111, 'size_hidden_layer_4': 9, 'size_hidden_layer_5': 146, 'activation': 'relu', 'alpha': 0.04226869721004641, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:11,930] Trial 184 finished with value: 540.8476517335347 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 91, 'size_hidden_layer_2': 120, 'size_hidden_layer_3': 110, 'size_hidden_layer_4': 8, 'size_hidden_layer_5': 77, 'activation': 'relu', 'alpha': 0.04126898394444804, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:17,943] Trial 185 finished with value: 511.079793025504 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 87, 'size_hidden_layer_2': 37, 'size_hidden_layer_3': 112, 'size_hidden_layer_4': 11, 'size_hidden_layer_5': 145, 'activation': 'relu', 'alpha': 0.04582169341400488, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:23,163] Trial 186 finished with value: 508.55699117627563 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 76, 'size_hidden_layer_2': 29, 'size_hidden_layer_3': 101, 'size_hidden_layer_4': 22, 'size_hidden_layer_5': 47, 'activation': 'relu', 'alpha': 0.04165032232473089, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:31,874] Trial 187 finished with value: 434.361833346642 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 82, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 106, 'size_hidden_layer_4': 34, 'activation': 'relu', 'alpha': 0.05290825838234452, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:40,015] Trial 188 finished with value: 408.6586774133352 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 20, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 131, 'activation': 'relu', 'alpha': 0.025483807254818785, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:50,617] Trial 189 finished with value: 387.29798562320696 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 123, 'size_hidden_layer_1': 132, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 115, 'size_hidden_layer_5': 147, 'activation': 'relu', 'alpha': 0.0029901291473790545, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:54,976] Trial 190 finished with value: 649.0621798239791 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 131, 'size_hidden_layer_2': 25, 'size_hidden_layer_3': 137, 'size_hidden_layer_4': 116, 'size_hidden_layer_5': 147, 'activation': 'relu', 'alpha': 0.0028816778050486853, 'learning_rate': 'adaptive'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:55:59,013] Trial 191 finished with value: 406.8562992066323 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 124, 'size_hidden_layer_1': 135, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 120, 'size_hidden_layer_5': 11, 'activation': 'relu', 'alpha': 0.004918292563722155, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:04,313] Trial 192 finished with value: 485.307532612654 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 125, 'size_hidden_layer_1': 135, 'size_hidden_layer_2': 109, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 125, 'size_hidden_layer_5': 14, 'activation': 'relu', 'alpha': 0.004316225235137198, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:07,145] Trial 193 finished with value: 456.45332613318436 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 123, 'size_hidden_layer_1': 131, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 141, 'size_hidden_layer_4': 112, 'size_hidden_layer_5': 149, 'activation': 'relu', 'alpha': 0.00643868896044998, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:11,383] Trial 194 finished with value: 512.6724478082921 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 128, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 132, 'size_hidden_layer_5': 5, 'activation': 'relu', 'alpha': 0.00117064078247571, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:19,068] Trial 195 finished with value: 609.3377048765642 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 121, 'size_hidden_layer_1': 125, 'size_hidden_layer_2': 107, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 144, 'size_hidden_layer_5': 35, 'size_hidden_layer_6': 47, 'activation': 'relu', 'alpha': 0.03362307628326247, 'learning_rate': 'invscaling'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:24,745] Trial 196 finished with value: 374.8127609844928 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 120, 'size_hidden_layer_1': 143, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 94, 'size_hidden_layer_5': 102, 'activation': 'relu', 'alpha': 0.004321649379716313, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:33,362] Trial 197 finished with value: 487.9036459616638 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 119, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 136, 'size_hidden_layer_4': 89, 'size_hidden_layer_5': 143, 'activation': 'relu', 'alpha': 0.00260175677272418, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:36,559] Trial 198 finished with value: 814.6064814936848 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 117, 'size_hidden_layer_1': 86, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 82, 'size_hidden_layer_5': 93, 'size_hidden_layer_6': 92, 'activation': 'relu', 'alpha': 0.02808102650307587, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:40,858] Trial 199 finished with value: 352.0769835196404 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 141, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 91, 'size_hidden_layer_5': 103, 'activation': 'relu', 'alpha': 0.009092985270080524, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:46,216] Trial 200 finished with value: 410.5457336662499 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 142, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 140, 'size_hidden_layer_4': 91, 'size_hidden_layer_5': 99, 'activation': 'relu', 'alpha': 0.009371254384850711, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:48,779] Trial 201 finished with value: 519.4114576467764 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 150, 'size_hidden_layer_1': 148, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 100, 'size_hidden_layer_5': 101, 'activation': 'relu', 'alpha': 0.008011889094093776, 'learning_rate': 'constant'}. Best is trial 78 with value: 313.7549089547779.\n",
      "[I 2025-08-01 09:56:57,485] Trial 202 finished with value: 300.90824113533495 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 94, 'size_hidden_layer_5': 72, 'activation': 'relu', 'alpha': 0.0058891008596515335, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:02,796] Trial 203 finished with value: 737.6516219105424 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 139, 'size_hidden_layer_1': 145, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 136, 'size_hidden_layer_4': 95, 'size_hidden_layer_5': 104, 'activation': 'relu', 'alpha': 0.010845314281844631, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:10,418] Trial 204 finished with value: 464.8333457971024 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 145, 'size_hidden_layer_1': 143, 'size_hidden_layer_2': 99, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 83, 'size_hidden_layer_5': 71, 'activation': 'relu', 'alpha': 0.005937225991798704, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:18,719] Trial 205 finished with value: 551.3567022583464 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 137, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 94, 'size_hidden_layer_5': 74, 'activation': 'relu', 'alpha': 0.007862912248691081, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:27,201] Trial 206 finished with value: 459.97732756231215 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 137, 'size_hidden_layer_2': 89, 'size_hidden_layer_3': 139, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 111, 'activation': 'relu', 'alpha': 0.00991620433100882, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:32,080] Trial 207 finished with value: 418.50692254514746 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 144, 'size_hidden_layer_1': 149, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 89, 'size_hidden_layer_5': 85, 'activation': 'relu', 'alpha': 0.004148747641824449, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:38,236] Trial 208 finished with value: 489.0531058368279 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 136, 'size_hidden_layer_1': 150, 'size_hidden_layer_2': 103, 'size_hidden_layer_3': 144, 'size_hidden_layer_4': 101, 'size_hidden_layer_5': 146, 'activation': 'relu', 'alpha': 0.013569713004707296, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:40,601] Trial 209 finished with value: 620.0684936005074 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 133, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 136, 'size_hidden_layer_4': 9, 'size_hidden_layer_5': 68, 'activation': 'relu', 'alpha': 0.008639524857203066, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:46,334] Trial 210 finished with value: 22250.21714202828 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 131, 'size_hidden_layer_4': 5, 'size_hidden_layer_5': 141, 'activation': 'logistic', 'alpha': 0.006828345193610162, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:48,625] Trial 211 finished with value: 472.43214640290125 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 142, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 122, 'size_hidden_layer_4': 76, 'activation': 'relu', 'alpha': 0.0027381888765554393, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:55,749] Trial 212 finished with value: 503.4558858174632 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 104, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 91, 'size_hidden_layer_3': 117, 'size_hidden_layer_4': 79, 'size_hidden_layer_5': 79, 'size_hidden_layer_6': 13, 'activation': 'relu', 'alpha': 0.004828842334648281, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:57:59,584] Trial 213 finished with value: 485.0382094990198 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 104, 'size_hidden_layer_3': 109, 'size_hidden_layer_4': 97, 'size_hidden_layer_5': 61, 'activation': 'relu', 'alpha': 0.06752685015421891, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:04,483] Trial 214 finished with value: 713.9232424895642 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 121, 'size_hidden_layer_1': 141, 'size_hidden_layer_2': 81, 'size_hidden_layer_3': 113, 'size_hidden_layer_4': 93, 'size_hidden_layer_5': 136, 'activation': 'relu', 'alpha': 0.0014286008465617954, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:08,923] Trial 215 finished with value: 643.9558881995774 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 112, 'size_hidden_layer_1': 128, 'size_hidden_layer_2': 87, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 71, 'activation': 'relu', 'alpha': 0.01174015527005987, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:12,121] Trial 216 finished with value: 371.1440195584083 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 130, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 17, 'size_hidden_layer_5': 92, 'activation': 'relu', 'alpha': 0.006463446948778455, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:17,673] Trial 217 finished with value: 578.0270676578917 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 127, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 17, 'size_hidden_layer_5': 93, 'activation': 'relu', 'alpha': 0.010095514037962786, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:21,638] Trial 218 finished with value: 490.1737521233372 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 132, 'size_hidden_layer_1': 146, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 14, 'size_hidden_layer_5': 102, 'activation': 'relu', 'alpha': 0.006621948112815143, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:30,004] Trial 219 finished with value: 507.45471932329207 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 137, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 139, 'size_hidden_layer_4': 90, 'size_hidden_layer_5': 107, 'activation': 'relu', 'alpha': 0.01236164730943615, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:34,759] Trial 220 finished with value: 464.40124368409784 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 42, 'size_hidden_layer_3': 82, 'size_hidden_layer_4': 23, 'size_hidden_layer_5': 91, 'activation': 'relu', 'alpha': 0.03061703238219191, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:40,917] Trial 221 finished with value: 483.37261580252084 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 125, 'size_hidden_layer_1': 142, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 130, 'activation': 'relu', 'alpha': 0.004278692247118777, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:45,200] Trial 222 finished with value: 895.1229209534386 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 118, 'size_hidden_layer_1': 136, 'size_hidden_layer_2': 110, 'size_hidden_layer_3': 118, 'size_hidden_layer_4': 104, 'size_hidden_layer_5': 82, 'size_hidden_layer_6': 32, 'activation': 'relu', 'alpha': 0.00795900832267032, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:48,732] Trial 223 finished with value: 597.1637620648577 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 122, 'size_hidden_layer_1': 107, 'size_hidden_layer_2': 116, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 27, 'size_hidden_layer_5': 96, 'activation': 'relu', 'alpha': 0.005839131320934303, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:55,415] Trial 224 finished with value: 546.3110951822598 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 112, 'activation': 'relu', 'alpha': 0.05856536118461349, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:58:59,456] Trial 225 finished with value: 400.6962249995243 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 47, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 48, 'activation': 'relu', 'alpha': 0.01591970759850906, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:02,962] Trial 226 finished with value: 502.5716128466908 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 133, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 54, 'size_hidden_layer_3': 115, 'size_hidden_layer_4': 140, 'size_hidden_layer_5': 44, 'activation': 'relu', 'alpha': 0.01818093527545743, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:07,513] Trial 227 finished with value: 683.9056142018156 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 63, 'size_hidden_layer_1': 132, 'size_hidden_layer_2': 48, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 11, 'size_hidden_layer_5': 74, 'activation': 'relu', 'alpha': 0.01571066633890588, 'learning_rate': 'invscaling'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:14,072] Trial 228 finished with value: 343.0814158213363 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 141, 'size_hidden_layer_1': 138, 'size_hidden_layer_2': 46, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 150, 'size_hidden_layer_5': 132, 'size_hidden_layer_6': 72, 'activation': 'relu', 'alpha': 0.019946681884649237, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:18,000] Trial 229 finished with value: 408.27086925767924 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 137, 'size_hidden_layer_2': 51, 'size_hidden_layer_3': 121, 'size_hidden_layer_4': 141, 'size_hidden_layer_5': 133, 'size_hidden_layer_6': 71, 'activation': 'relu', 'alpha': 0.019372333422790676, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:23,244] Trial 230 finished with value: 683.0015330187806 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 142, 'size_hidden_layer_1': 134, 'size_hidden_layer_2': 91, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 149, 'size_hidden_layer_5': 139, 'size_hidden_layer_6': 61, 'activation': 'relu', 'alpha': 0.014843684638380634, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:26,247] Trial 231 finished with value: 456.0316857933533 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 135, 'size_hidden_layer_1': 143, 'size_hidden_layer_2': 103, 'size_hidden_layer_3': 111, 'size_hidden_layer_4': 15, 'size_hidden_layer_5': 64, 'size_hidden_layer_6': 41, 'activation': 'relu', 'alpha': 0.017935909835275578, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:30,760] Trial 232 finished with value: 720.3932719743068 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 137, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 43, 'size_hidden_layer_3': 63, 'size_hidden_layer_4': 147, 'size_hidden_layer_5': 38, 'size_hidden_layer_6': 65, 'activation': 'relu', 'alpha': 0.021626005271818766, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:34,849] Trial 233 finished with value: 603.2949224829752 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 146, 'size_hidden_layer_1': 45, 'size_hidden_layer_2': 50, 'size_hidden_layer_3': 119, 'size_hidden_layer_4': 136, 'size_hidden_layer_5': 57, 'size_hidden_layer_6': 74, 'activation': 'relu', 'alpha': 0.016184751138989602, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:38,289] Trial 234 finished with value: 591.9767370302332 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 46, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 32, 'activation': 'relu', 'alpha': 0.022506818314272398, 'learning_rate': 'invscaling'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:42,563] Trial 235 finished with value: 485.7436056808066 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 134, 'size_hidden_layer_2': 40, 'size_hidden_layer_3': 108, 'size_hidden_layer_4': 46, 'size_hidden_layer_5': 125, 'activation': 'relu', 'alpha': 0.019925785230714855, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:46,975] Trial 236 finished with value: 547.8043837336019 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 64, 'size_hidden_layer_2': 34, 'size_hidden_layer_3': 124, 'size_hidden_layer_4': 36, 'size_hidden_layer_5': 80, 'size_hidden_layer_6': 58, 'activation': 'relu', 'alpha': 0.011218536419354556, 'learning_rate': 'constant'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:50,322] Trial 237 finished with value: 722.6695263988573 and parameters: {'n_layers': 6, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 53, 'size_hidden_layer_2': 57, 'size_hidden_layer_3': 103, 'size_hidden_layer_4': 20, 'size_hidden_layer_5': 131, 'activation': 'relu', 'alpha': 0.009496586214078964, 'learning_rate': 'invscaling'}. Best is trial 202 with value: 300.90824113533495.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 09:59:52,536] Trial 238 finished with value: 508.4120611554466 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 143, 'size_hidden_layer_1': 59, 'activation': 'relu', 'alpha': 0.012591785809668396, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 09:59:56,322] Trial 239 finished with value: 360.34172911855626 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 94, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 87, 'size_hidden_layer_6': 48, 'activation': 'relu', 'alpha': 0.014044286184670586, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:02,507] Trial 240 finished with value: 511.03013994244435 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 127, 'size_hidden_layer_1': 85, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 136, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 88, 'size_hidden_layer_6': 45, 'activation': 'relu', 'alpha': 0.013961166629017014, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:07,117] Trial 241 finished with value: 380.5663077611356 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 130, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 46, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 88, 'size_hidden_layer_5': 97, 'size_hidden_layer_6': 50, 'activation': 'relu', 'alpha': 0.01662576002587751, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:12,044] Trial 242 finished with value: 380.2431791419573 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 97, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 88, 'size_hidden_layer_5': 91, 'size_hidden_layer_6': 47, 'activation': 'relu', 'alpha': 0.01583539613653462, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:19,494] Trial 243 finished with value: 327.92135419872426 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 130, 'size_hidden_layer_1': 115, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 84, 'size_hidden_layer_5': 90, 'size_hidden_layer_6': 50, 'activation': 'relu', 'alpha': 0.017056230237092868, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:26,122] Trial 244 finished with value: 533.7142265884252 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 132, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 97, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 84, 'size_hidden_layer_5': 95, 'size_hidden_layer_6': 51, 'activation': 'relu', 'alpha': 0.016372023047488755, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:29,897] Trial 245 finished with value: 688.8711008047053 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 131, 'size_hidden_layer_1': 141, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 88, 'size_hidden_layer_5': 85, 'size_hidden_layer_6': 44, 'activation': 'relu', 'alpha': 0.018718232640109803, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:38,568] Trial 246 finished with value: 465.38072733396143 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 138, 'size_hidden_layer_4': 82, 'size_hidden_layer_5': 99, 'size_hidden_layer_6': 55, 'activation': 'relu', 'alpha': 0.016253708119993632, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:46,192] Trial 247 finished with value: 400.25619647573035 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 135, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 142, 'size_hidden_layer_4': 92, 'size_hidden_layer_5': 92, 'size_hidden_layer_6': 38, 'activation': 'relu', 'alpha': 0.014231734701118446, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:48,588] Trial 248 finished with value: 461.610778877905 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 115, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 88, 'size_hidden_layer_5': 90, 'size_hidden_layer_6': 37, 'activation': 'relu', 'alpha': 0.014085161041405406, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:00:53,570] Trial 249 finished with value: 492.411083631287 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 141, 'size_hidden_layer_4': 93, 'size_hidden_layer_5': 93, 'size_hidden_layer_6': 49, 'activation': 'relu', 'alpha': 0.017826071850173746, 'learning_rate': 'adaptive'}. Best is trial 202 with value: 300.90824113533495.\n",
      "[I 2025-08-01 10:01:02,662] Trial 250 finished with value: 285.38361824864904 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 112, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 148, 'size_hidden_layer_4': 80, 'size_hidden_layer_5': 88, 'size_hidden_layer_6': 42, 'activation': 'relu', 'alpha': 0.013573335229886437, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 10:01:17,401] Trial 251 finished with value: 22162.07416573553 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 104, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 79, 'size_hidden_layer_5': 87, 'size_hidden_layer_6': 42, 'activation': 'logistic', 'alpha': 0.01323154304256816, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:21,189] Trial 252 finished with value: 728.4300742877064 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 85, 'size_hidden_layer_5': 90, 'size_hidden_layer_6': 56, 'activation': 'relu', 'alpha': 0.02032181251202522, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:25,512] Trial 253 finished with value: 766.3896728066952 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 126, 'size_hidden_layer_1': 89, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 149, 'size_hidden_layer_4': 82, 'size_hidden_layer_5': 84, 'size_hidden_layer_6': 48, 'activation': 'relu', 'alpha': 0.047401005032920086, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:30,701] Trial 254 finished with value: 329.17749545913216 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 48, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 92, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 95, 'size_hidden_layer_6': 31, 'activation': 'relu', 'alpha': 0.011405926029895442, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:37,855] Trial 255 finished with value: 842.2086498952943 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 46, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 92, 'size_hidden_layer_3': 147, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 96, 'size_hidden_layer_6': 27, 'activation': 'relu', 'alpha': 0.01253233229192462, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:42,241] Trial 256 finished with value: 477.7206876334812 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 35, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 90, 'size_hidden_layer_5': 100, 'size_hidden_layer_6': 34, 'activation': 'relu', 'alpha': 0.01124295407142961, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:49,294] Trial 257 finished with value: 405.1513256056548 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 135, 'size_hidden_layer_1': 124, 'size_hidden_layer_2': 89, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 81, 'size_hidden_layer_5': 103, 'size_hidden_layer_6': 43, 'activation': 'relu', 'alpha': 0.014983780351871938, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:01:58,616] Trial 258 finished with value: 364.3710714750767 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 49, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 104, 'size_hidden_layer_3': 137, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 87, 'size_hidden_layer_6': 51, 'activation': 'relu', 'alpha': 0.009471076582606042, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:03,471] Trial 259 finished with value: 398.74894627868747 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 51, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 138, 'size_hidden_layer_4': 75, 'size_hidden_layer_5': 87, 'size_hidden_layer_6': 52, 'activation': 'relu', 'alpha': 0.009834733911943911, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:12,360] Trial 260 finished with value: 539.8447840371692 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 46, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 131, 'size_hidden_layer_4': 88, 'size_hidden_layer_5': 76, 'size_hidden_layer_6': 47, 'activation': 'relu', 'alpha': 0.008848935352627367, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:19,304] Trial 261 finished with value: 824.6312442634343 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 126, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 85, 'size_hidden_layer_5': 95, 'size_hidden_layer_6': 59, 'activation': 'relu', 'alpha': 0.011346420022810852, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:26,871] Trial 262 finished with value: 496.797598976548 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 139, 'size_hidden_layer_1': 79, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 144, 'size_hidden_layer_4': 80, 'size_hidden_layer_5': 83, 'size_hidden_layer_6': 66, 'activation': 'relu', 'alpha': 0.007378086432741046, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:33,680] Trial 263 finished with value: 392.55110086762926 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 48, 'size_hidden_layer_1': 130, 'size_hidden_layer_2': 99, 'size_hidden_layer_3': 137, 'size_hidden_layer_4': 95, 'size_hidden_layer_5': 71, 'size_hidden_layer_6': 30, 'activation': 'relu', 'alpha': 0.013180572743117893, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:39,855] Trial 264 finished with value: 573.1038602592392 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 46, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 141, 'size_hidden_layer_4': 93, 'size_hidden_layer_5': 72, 'size_hidden_layer_6': 30, 'activation': 'relu', 'alpha': 0.013324850346459425, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:50,122] Trial 265 finished with value: 560.802297516638 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 50, 'size_hidden_layer_1': 126, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 137, 'size_hidden_layer_4': 88, 'size_hidden_layer_5': 80, 'size_hidden_layer_6': 19, 'activation': 'relu', 'alpha': 0.01729340597008604, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:52,282] Trial 266 finished with value: 377.98688409740896 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 58, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 91, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 91, 'size_hidden_layer_5': 69, 'size_hidden_layer_6': 40, 'activation': 'relu', 'alpha': 0.014599557340273059, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:02:58,077] Trial 267 finished with value: 413.39027008684803 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 55, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 90, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 91, 'size_hidden_layer_5': 69, 'size_hidden_layer_6': 40, 'activation': 'relu', 'alpha': 0.016246066586428725, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:03,237] Trial 268 finished with value: 858.0602996074069 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 57, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 87, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 84, 'size_hidden_layer_5': 88, 'size_hidden_layer_6': 50, 'activation': 'relu', 'alpha': 0.01149955118241151, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:09,714] Trial 269 finished with value: 450.8300285458204 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 67, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 84, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 78, 'size_hidden_layer_5': 66, 'size_hidden_layer_6': 55, 'activation': 'relu', 'alpha': 0.014941324260390645, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 10:03:21,052] Trial 270 finished with value: 22144.79912752901 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 93, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 97, 'size_hidden_layer_5': 75, 'size_hidden_layer_6': 45, 'activation': 'logistic', 'alpha': 0.008244709030994748, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:25,259] Trial 271 finished with value: 410.62367652498835 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 60, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 91, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 86, 'size_hidden_layer_5': 90, 'size_hidden_layer_6': 35, 'activation': 'relu', 'alpha': 0.0031130268441778076, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:30,464] Trial 272 finished with value: 523.9335922908325 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 42, 'size_hidden_layer_1': 127, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 89, 'size_hidden_layer_5': 93, 'size_hidden_layer_6': 48, 'activation': 'relu', 'alpha': 0.00578823092135553, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:36,351] Trial 273 finished with value: 356.317930750689 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 73, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 91, 'size_hidden_layer_5': 98, 'size_hidden_layer_6': 41, 'activation': 'relu', 'alpha': 0.009328422009636465, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:42,888] Trial 274 finished with value: 481.51597722361214 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 72, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 106, 'size_hidden_layer_3': 140, 'size_hidden_layer_4': 92, 'size_hidden_layer_5': 97, 'size_hidden_layer_6': 42, 'activation': 'relu', 'alpha': 0.009961448786106837, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:50,192] Trial 275 finished with value: 675.3160353868009 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 73, 'size_hidden_layer_1': 112, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 135, 'size_hidden_layer_4': 100, 'size_hidden_layer_5': 106, 'size_hidden_layer_6': 53, 'activation': 'relu', 'alpha': 0.011818890084341649, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:54,566] Trial 276 finished with value: 501.16868364985413 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 52, 'size_hidden_layer_1': 118, 'size_hidden_layer_2': 88, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 74, 'size_hidden_layer_5': 101, 'size_hidden_layer_6': 38, 'activation': 'relu', 'alpha': 0.014669188257575873, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:03:58,682] Trial 277 finished with value: 726.8790827002149 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 75, 'size_hidden_layer_1': 121, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 95, 'size_hidden_layer_5': 94, 'size_hidden_layer_6': 24, 'activation': 'relu', 'alpha': 0.019094045121720252, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:04,183] Trial 278 finished with value: 838.6006804364602 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 67, 'size_hidden_layer_1': 125, 'size_hidden_layer_2': 96, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 87, 'size_hidden_layer_5': 98, 'size_hidden_layer_6': 62, 'activation': 'relu', 'alpha': 0.0092342110522043, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:15,592] Trial 279 finished with value: 547.5993743959708 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 39, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 137, 'size_hidden_layer_4': 82, 'size_hidden_layer_5': 90, 'size_hidden_layer_6': 83, 'activation': 'relu', 'alpha': 0.01754990795947032, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:21,667] Trial 280 finished with value: 781.1703172742323 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 76, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 90, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 91, 'size_hidden_layer_5': 77, 'size_hidden_layer_6': 45, 'activation': 'relu', 'alpha': 0.012428168734058562, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:29,874] Trial 281 finished with value: 437.9920483901272 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 69, 'size_hidden_layer_1': 135, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 134, 'size_hidden_layer_4': 83, 'size_hidden_layer_5': 84, 'size_hidden_layer_6': 41, 'activation': 'relu', 'alpha': 0.007768695778349067, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:34,708] Trial 282 finished with value: 519.1224041545339 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 81, 'size_hidden_layer_1': 137, 'size_hidden_layer_2': 123, 'size_hidden_layer_3': 139, 'size_hidden_layer_4': 112, 'size_hidden_layer_5': 110, 'size_hidden_layer_6': 51, 'activation': 'relu', 'alpha': 0.010197932987844792, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:40,064] Trial 283 finished with value: 413.24582027721783 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 57, 'size_hidden_layer_1': 132, 'size_hidden_layer_2': 77, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 90, 'size_hidden_layer_5': 87, 'size_hidden_layer_6': 58, 'activation': 'relu', 'alpha': 0.014026718030945734, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:47,577] Trial 284 finished with value: 504.0904338458366 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 49, 'size_hidden_layer_1': 120, 'size_hidden_layer_2': 107, 'size_hidden_layer_3': 143, 'size_hidden_layer_4': 85, 'size_hidden_layer_5': 80, 'size_hidden_layer_6': 34, 'activation': 'relu', 'alpha': 0.01657034752887932, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:53,444] Trial 285 finished with value: 441.2201328001167 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 141, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 95, 'size_hidden_layer_5': 69, 'size_hidden_layer_6': 49, 'activation': 'relu', 'alpha': 0.05484374585180858, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:04:58,741] Trial 286 finished with value: 433.34502079392695 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 53, 'size_hidden_layer_1': 124, 'size_hidden_layer_2': 85, 'size_hidden_layer_3': 89, 'size_hidden_layer_4': 87, 'size_hidden_layer_5': 98, 'size_hidden_layer_6': 46, 'activation': 'relu', 'alpha': 0.011346881328313348, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:07,321] Trial 287 finished with value: 331.0782319195565 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 139, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 119, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 68, 'size_hidden_layer_5': 103, 'size_hidden_layer_6': 53, 'activation': 'relu', 'alpha': 0.006611635774156546, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:13,123] Trial 288 finished with value: 433.9002857866193 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 133, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 125, 'size_hidden_layer_4': 67, 'size_hidden_layer_5': 103, 'size_hidden_layer_6': 54, 'activation': 'relu', 'alpha': 0.006447761194939677, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:20,421] Trial 289 finished with value: 363.16764342768647 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 131, 'size_hidden_layer_2': 118, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 78, 'size_hidden_layer_5': 106, 'size_hidden_layer_6': 37, 'activation': 'relu', 'alpha': 0.008593009500217356, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:26,883] Trial 290 finished with value: 341.4753934479046 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 127, 'size_hidden_layer_2': 122, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 77, 'size_hidden_layer_5': 104, 'size_hidden_layer_6': 39, 'activation': 'relu', 'alpha': 0.009305654325328724, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:34,369] Trial 291 finished with value: 1139.3594795977538 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 138, 'size_hidden_layer_1': 126, 'size_hidden_layer_2': 122, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 73, 'size_hidden_layer_5': 112, 'size_hidden_layer_6': 37, 'activation': 'relu', 'alpha': 0.008794532244655217, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 10:05:49,537] Trial 292 finished with value: 22165.64317083922 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 137, 'size_hidden_layer_1': 128, 'size_hidden_layer_2': 118, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 76, 'size_hidden_layer_5': 106, 'size_hidden_layer_6': 43, 'activation': 'logistic', 'alpha': 0.0069667280638739185, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:55,984] Trial 293 finished with value: 523.1768031358886 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 136, 'size_hidden_layer_1': 121, 'size_hidden_layer_2': 125, 'size_hidden_layer_3': 124, 'size_hidden_layer_4': 80, 'size_hidden_layer_5': 101, 'size_hidden_layer_6': 41, 'activation': 'relu', 'alpha': 0.00962836202184254, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:05:58,556] Trial 294 finished with value: 400.4119155946454 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 121, 'size_hidden_layer_3': 130, 'size_hidden_layer_4': 58, 'size_hidden_layer_5': 103, 'size_hidden_layer_6': 31, 'activation': 'relu', 'alpha': 0.013023948769057214, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:06:02,580] Trial 295 finished with value: 498.97570560756094 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 144, 'size_hidden_layer_1': 123, 'size_hidden_layer_2': 118, 'size_hidden_layer_3': 132, 'size_hidden_layer_4': 78, 'size_hidden_layer_5': 106, 'size_hidden_layer_6': 47, 'activation': 'relu', 'alpha': 0.008000247477009191, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:06:08,501] Trial 296 finished with value: 361.9426742398441 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 142, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 15, 'size_hidden_layer_3': 128, 'size_hidden_layer_4': 63, 'size_hidden_layer_5': 101, 'size_hidden_layer_6': 52, 'activation': 'relu', 'alpha': 0.020753671587197126, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:06:13,406] Trial 297 finished with value: 689.5741184689913 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 142, 'size_hidden_layer_1': 144, 'size_hidden_layer_2': 10, 'size_hidden_layer_3': 127, 'size_hidden_layer_4': 66, 'size_hidden_layer_5': 98, 'size_hidden_layer_6': 52, 'activation': 'relu', 'alpha': 0.018571874330607516, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:06:17,159] Trial 298 finished with value: 459.58049561009807 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 141, 'size_hidden_layer_1': 140, 'size_hidden_layer_2': 127, 'size_hidden_layer_3': 123, 'size_hidden_layer_4': 54, 'size_hidden_layer_5': 107, 'size_hidden_layer_6': 56, 'activation': 'relu', 'alpha': 0.01966851859680441, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n",
      "[I 2025-08-01 10:06:21,607] Trial 299 finished with value: 606.3716002170586 and parameters: {'n_layers': 7, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 30, 'size_hidden_layer_3': 129, 'size_hidden_layer_4': 59, 'size_hidden_layer_5': 100, 'size_hidden_layer_6': 49, 'activation': 'relu', 'alpha': 0.023176127213859844, 'learning_rate': 'adaptive'}. Best is trial 250 with value: 285.38361824864904.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "mlp_stacking_study = optuna.create_study(direction='minimize')\n",
    "mlp_stacking_study.optimize(stacked_objective_mlp, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 7,\n",
       " 'size_hidden_layer_0': 134,\n",
       " 'size_hidden_layer_1': 112,\n",
       " 'size_hidden_layer_2': 102,\n",
       " 'size_hidden_layer_3': 148,\n",
       " 'size_hidden_layer_4': 80,\n",
       " 'size_hidden_layer_5': 88,\n",
       " 'size_hidden_layer_6': 42,\n",
       " 'activation': 'relu',\n",
       " 'alpha': 0.013573335229886437,\n",
       " 'learning_rate': 'adaptive'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.013573335229886437,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': [134, 112, 102, 148, 80, 88, 42]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bp = mlp_stacking_study.best_params\n",
    "mlp_bp_subset = mlp_bp.copy()\n",
    "del mlp_bp_subset['n_layers']\n",
    "mlp_bp_subset['hidden_layer_sizes'] = [mlp_bp_subset.pop(f'size_hidden_layer_{i}') for i in range(mlp_bp['n_layers'])]\n",
    "mlp_bp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 7,\n",
       " 'size_hidden_layer_0': 134,\n",
       " 'size_hidden_layer_1': 112,\n",
       " 'size_hidden_layer_2': 102,\n",
       " 'size_hidden_layer_3': 148,\n",
       " 'size_hidden_layer_4': 80,\n",
       " 'size_hidden_layer_5': 88,\n",
       " 'size_hidden_layer_6': 42,\n",
       " 'activation': 'relu',\n",
       " 'alpha': 0.013573335229886437,\n",
       " 'learning_rate': 'adaptive'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/mlp_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlp_stacking_study.best_params, f\"../../split_year_models/ensemble/mlp_stacking_best_params.pkl\")\n",
    "joblib.dump(mlp_stacking_study, f\"../../split_year_models/ensemble/mlp_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/mlp_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp_model = MLPRegressor(**mlp_bp_subset)\n",
    "best_mlp_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_mlp_model, \"../../split_year_models/ensemble/mlp_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values on Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Estimators' Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = pd.read_csv(filepath + '/test/X_test.csv')\n",
    "test_data_x = test_data_x.drop(columns=['Unnamed: 0'], axis=1)\n",
    "test_data_x['setting'] = test_data_x['setting'].astype(\"category\")\n",
    "test_data_y = pd.read_csv(filepath + '/test/y_test.csv')\n",
    "test_data_y = test_data_y.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for idx, model in enumerate(base_estimators):\n",
    "        if idx < 10:\n",
    "            test_subset = test_data_x.copy()\n",
    "            test_subset.columns = test_subset.columns.str.replace(r'[\\\"\\[\\]\\{\\}\\\\:,]', '', regex=True)\n",
    "            test_subset = test_subset[lgbm_col_needed[idx]]\n",
    "            \n",
    "        else:\n",
    "            test_relevant = test_data_x[rf_col_needed[idx - 10]]\n",
    "            test_subset = test_relevant.copy()\n",
    "            test_subset['setting'] = test_subset['setting'].map(countries_dict)\n",
    "\n",
    "        test_predictions.append(model.predict(test_subset))\n",
    "\n",
    "stacked_test_predictions = np.column_stack(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles' Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Relative Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MSE  MAE   R2 RMSE Relative Error\n",
       "Voting             NaN  NaN  NaN  NaN            NaN\n",
       "Linear Regression  NaN  NaN  NaN  NaN            NaN\n",
       "Random Forest      NaN  NaN  NaN  NaN            NaN\n",
       "SVM                NaN  NaN  NaN  NaN            NaN\n",
       "MLP                NaN  NaN  NaN  NaN            NaN"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the dataframe to hold test results\n",
    "index_rows = ['Voting', 'Linear Regression', 'Random Forest', 'SVM', 'MLP']\n",
    "\n",
    "index_cols = ['MSE', 'MAE', 'R2', 'RMSE', 'Relative Error']\n",
    "\n",
    "test_stats = pd.DataFrame(index=index_rows, columns=index_cols)\n",
    "\n",
    "test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the models' predictions\n",
    "\n",
    "linreg_pred = best_linreg_model.predict(stacked_test_predictions)\n",
    "rf_pred = best_rf_model.predict(stacked_test_predictions)\n",
    "svm_pred = best_svm_model.predict(stacked_test_predictions)\n",
    "mlp_pred = best_mlp_model.predict(stacked_test_predictions)\n",
    "voting_pred = np.dot(stacked_test_predictions, np.array(list(normalised_bp.values())))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n"
     ]
    }
   ],
   "source": [
    "#to evaluate the models' test_predictions\n",
    "for model in ['Voting', 'Linear Regression', 'Random Forest', 'SVM', 'MLP']:\n",
    "    if model == 'Voting':\n",
    "        test_prediction = voting_pred\n",
    "    elif model == 'Linear Regression':\n",
    "        test_prediction = linreg_pred\n",
    "    elif model == 'Random Forest':\n",
    "        test_prediction = rf_pred\n",
    "    elif model == 'SVM':\n",
    "        test_prediction = svm_pred\n",
    "    elif model == 'MLP':\n",
    "        test_prediction = mlp_pred\n",
    "\n",
    "    mse = mean_squared_error(test_data_y, test_prediction)\n",
    "    mae = mean_absolute_error(test_data_y, test_prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(test_data_y, test_prediction)\n",
    "\n",
    "    #to calculate mape\n",
    "    num_test_predictions = len(test_prediction)\n",
    "    mape = 0\n",
    "    for p in range(0, num_test_predictions):\n",
    "        mape += np.abs(test_prediction[p] - test_data_y.iloc[p]) / np.maximum(np.abs(test_prediction[p]), np.abs(test_data_y.iloc[p]))\n",
    "    mape = mape/num_test_predictions\n",
    "\n",
    "    test_stats.loc[model, 'MSE'] = mse\n",
    "    test_stats.loc[model, 'MAE'] = mae\n",
    "    test_stats.loc[model, 'RMSE'] = rmse\n",
    "    test_stats.loc[model, 'R2'] = r2\n",
    "    test_stats.loc[model, 'Relative Error'] = mape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_year_models/ensemble/models_test_values.pkl']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(test_stats, f\"../../split_year_models/ensemble/models_test_values.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Relative Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>5444.169454</td>\n",
       "      <td>25.857684</td>\n",
       "      <td>0.827764</td>\n",
       "      <td>73.784615</td>\n",
       "      <td>0.369144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>5502.843021</td>\n",
       "      <td>27.294151</td>\n",
       "      <td>0.825907</td>\n",
       "      <td>74.18115</td>\n",
       "      <td>0.401715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>5596.340936</td>\n",
       "      <td>26.027285</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>74.808696</td>\n",
       "      <td>0.358431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>7608.360591</td>\n",
       "      <td>35.485181</td>\n",
       "      <td>0.759295</td>\n",
       "      <td>87.225917</td>\n",
       "      <td>0.548144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>5612.478051</td>\n",
       "      <td>25.789477</td>\n",
       "      <td>0.822439</td>\n",
       "      <td>74.916474</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE        MAE        R2       RMSE Relative Error\n",
       "Voting             5444.169454  25.857684  0.827764  73.784615       0.369144\n",
       "Linear Regression  5502.843021  27.294151  0.825907   74.18115       0.401715\n",
       "Random Forest      5596.340936  26.027285  0.822949  74.808696       0.358431\n",
       "SVM                7608.360591  35.485181  0.759295  87.225917       0.548144\n",
       "MLP                5612.478051  25.789477  0.822439  74.916474          0.385"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_validation_values = {'voting' : voting_study.best_value, \n",
    "               'linreg_stacking' : linreg_stacking_study.best_value,\n",
    "               'rf_stacking' : rf_stacking_study.best_value,\n",
    "               'svm_stacking' : svm_stacking_study.best_value,\n",
    "               'mlp_stacking' : mlp_stacking_study.best_value}\n",
    "\n",
    "with open(f\"../../split_year_models/ensemble/models_best_values.json\", 'w') as f:\n",
    "    json.dump(best_validation_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voting': 1742.8116808767434,\n",
       " 'linreg_stacking': 465.84448449172174,\n",
       " 'rf_stacking': 500.1398151756764,\n",
       " 'svm_stacking': 1988.362668176169,\n",
       " 'mlp_stacking': 285.38361824864904}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/205230015.py:3: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  without_xgb = mean_concat.drop(columns=['XGBoost'], axis=1)\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2437/205230015.py:4: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  without_xgb_std = std_concat.drop(columns=['XGBoost'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "mean_concat = joblib.load('../../split_year_models/base_mean_metrics.pkl')\n",
    "std_concat = joblib.load('../../split_year_models/base_std_metrics.pkl')\n",
    "without_xgb = mean_concat.drop(columns=['XGBoost'], axis=1)\n",
    "without_xgb_std = std_concat.drop(columns=['XGBoost'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = ['Relative Error', 'MAE', \"MSE\", 'RMSE', \"R2\"]\n",
    "bar_index = ['Voting', 'Linear Regression', 'Random Forest', 'SVM', 'MLP']\n",
    "\n",
    "for metric in metrics:\n",
    "    data_metric = test_stats[metric]\n",
    "    ax = data_metric.plot.bar(rot=0, figsize=(12, 6))     \n",
    "    plt.title(\"Test \" + metric + \" For Data Split by Year with Mean Base Estimator Metrics\")\n",
    "    plt.xlabel(\"Missing Data Threshold\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
