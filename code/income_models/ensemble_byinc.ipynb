{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import optuna.visualization as vis\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import sys\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../split_income_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = pd.read_csv(filepath + '/test/X_test.csv')\n",
    "test_data_x = test_data_x.drop(columns=['Unnamed: 0'], axis=1)\n",
    "test_data_y = pd.read_csv(filepath + '/test/y_test.csv')\n",
    "test_data_y = test_data_y.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "for fold in range(0, 5):\n",
    "    tdata_x85 = pd.read_csv(filepath + '/train/X_train_' + str(fold) + '_85.csv')\n",
    "    tdata_x85 = tdata_x85.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    tdata_y85 = pd.read_csv(filepath + '/train/y_train_' + str(fold) + '_85.csv')\n",
    "    tdata_y85 = tdata_y85.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "    tdata_x95 = pd.read_csv(filepath + '/train/X_train_' + str(fold) + '_95.csv')\n",
    "    tdata_x95 = tdata_x95.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    tdata_y95 = pd.read_csv(filepath + '/train/y_train_' + str(fold) + '_95.csv')\n",
    "    tdata_y95 = tdata_y95.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "    tdata_x1 = pd.read_csv(filepath + '/train/X_train_' + str(fold) + '_1.csv')\n",
    "    tdata_x1 = tdata_x1.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    tdata_y1 = pd.read_csv(filepath + '/train/y_train_' + str(fold) + '_1.csv')\n",
    "    tdata_y1 = tdata_y1.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "    train[fold] = [tdata_x85, tdata_y85, tdata_x95, tdata_y95, tdata_x1, tdata_y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {}\n",
    "for fold in range(0, 5):\n",
    "    vdata_x = pd.read_csv(filepath + '/val/X_val_' + str(fold) + '.csv')\n",
    "    vdata_x = vdata_x.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    vdata_y = pd.read_csv(filepath + '/val/y_val_' + str(fold) + '.csv')\n",
    "    vdata_y = vdata_y.drop(columns=['Unnamed: 0'], axis=1)\n",
    "    validation[fold] = [vdata_x, vdata_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../split_income_models/countries_dict.pkl', 'rb') as f:\n",
    "    countries_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.read_csv('../../split_income_data/train_val.csv')\n",
    "train_val = train_val.drop(columns=['Unnamed: 0'], axis=1)\n",
    "train_val_input = train_val.drop(columns=['Maternal mortality ratio (national estimate, per 100,000 live births)'], axis=1)\n",
    "train_val_label = train_val['Maternal mortality ratio (national estimate, per 100,000 live births)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using the Random Forest and LightGBM models trained on the full dataset and dataset with a missing data threshold of 95% because XGBoost models and all models trained on dataset with 85% threshold had lower performance across all metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_models = []\n",
    "rf_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_col_needed = []\n",
    "rf_col_needed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../split_income_models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training the models on their best hyperparameters and storing them in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, fold_num in enumerate(['1', '2', '3', '4', '5']):\n",
    "    for thresh, thresh_name in enumerate(['Threshold 85%', 'Threshold 95%', 'None']):\n",
    "        if thresh == 1:\n",
    "            continue\n",
    "\n",
    "        if thresh == 0:\n",
    "            name = '85'\n",
    "        elif thresh == 1:\n",
    "            name = '95'\n",
    "        else: name = '1'\n",
    "\n",
    "        best_params = joblib.load(f\"{output_dir}/lightgbm/best_params_{fold}_{name}.pkl\")\n",
    "\n",
    "        train_input_data = train[fold][thresh * 2].copy()\n",
    "        train_input_data['setting'] = train_input_data['setting'].astype(\"category\")\n",
    "        train_input_data.columns = train_input_data.columns.str.replace(r'[\\\"\\[\\]\\{\\}\\\\:,]', '', regex=True)\n",
    "        lgbm_col_needed.append(train_input_data.columns.tolist())\n",
    "\n",
    "        train_label = train[fold][thresh * 2 + 1].copy()\n",
    "        train_label.column = 'Maternal mortality ratio (national estimate per 100000 live births)'\n",
    "\n",
    "        loaded_model = lgb.LGBMRegressor(**best_params, verbosity = -1)\n",
    "        train_load = loaded_model.fit(train_input_data, train_label)\n",
    "        lgbm_models.append(train_load)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for fold, fold_num in enumerate(['1', '2', '3', '4', '5']):\n",
    "    for thresh, thresh_name in enumerate(['Threshold 85%', 'Threshold 95%', 'None']):\n",
    "\n",
    "        if thresh == 1:\n",
    "            continue\n",
    "        \n",
    "        if thresh == 0:\n",
    "            name = '85'\n",
    "        elif thresh == 1:\n",
    "            name = '95'\n",
    "        else: name = '1'\n",
    "\n",
    "        best_params = joblib.load(f\"{output_dir}/random_forest/best_params_{fold}_{name}.pkl\")\n",
    "        train_input_data = train[fold][thresh * 2].copy()\n",
    "        train_input_data['setting'] = train_input_data['setting'].map(countries_dict)\n",
    "        train_label = train[fold][thresh * 2 + 1].copy()\n",
    "        rf_col_needed.append(train_input_data.columns.tolist())\n",
    "\n",
    "        loaded_model = RandomForestRegressor(**best_params)\n",
    "        train_load = loaded_model.fit(train_input_data, train_label)\n",
    "        rf_models.append(train_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_models), len(lgbm_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LGBMRegressor(bagging_fraction=0.23713628005065854, bagging_freq=3,\n",
       "               boosting_type='dart', l1_norm=0.00046063655997193227,\n",
       "               l2_norm=0.0008894472608021271, learning_rate=0.14770429886804406,\n",
       "               max_tree_depth=4, number_trees=119, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.21628981398600422, bagging_freq=7,\n",
       "               boosting_type='dart', l1_norm=0.0005671785295950157,\n",
       "               l2_norm=8.229054773999363e-05, learning_rate=0.15253369069176093,\n",
       "               max_tree_depth=6, number_trees=120, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.7195200059814708, bagging_freq=8,\n",
       "               boosting_type='dart', l1_norm=0.0005818463195088689,\n",
       "               l2_norm=0.0005887572889401316, learning_rate=0.10420824296752015,\n",
       "               max_tree_depth=17, number_trees=35, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.5426253970612477, bagging_freq=7,\n",
       "               boosting_type='dart', l1_norm=0.0001343448530759062,\n",
       "               l2_norm=2.8304439557087193e-05, learning_rate=0.1647195626617939,\n",
       "               max_tree_depth=18, number_trees=72, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.8931789600641888, bagging_freq=4,\n",
       "               boosting_type='dart', l1_norm=0.0007773926432582108,\n",
       "               l2_norm=0.0007749495029028036, learning_rate=0.6969313273120923,\n",
       "               max_tree_depth=9, number_trees=124, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.8046389275367603, bagging_freq=5,\n",
       "               boosting_type='dart', l1_norm=0.00021093376524500854,\n",
       "               l2_norm=9.069706009853371e-05, learning_rate=0.48067368937343363,\n",
       "               max_tree_depth=4, number_trees=191, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.8616001437971017, bagging_freq=0,\n",
       "               boosting_type='dart', l1_norm=0.0005698236458557804,\n",
       "               l2_norm=4.985427266118507e-05, learning_rate=0.8164951226615668,\n",
       "               max_tree_depth=3, number_trees=63, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.17319518767903705, bagging_freq=8,\n",
       "               boosting_type='dart', l1_norm=0.0009764008072976946,\n",
       "               l2_norm=0.00039173408898225757, learning_rate=0.20771378835712018,\n",
       "               max_tree_depth=7, number_trees=153, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.4107948360666925, bagging_freq=10,\n",
       "               boosting_type='dart', l1_norm=0.0007611947250175949,\n",
       "               l2_norm=5.652846578079629e-05, learning_rate=0.3715333936138515,\n",
       "               max_tree_depth=5, number_trees=62, verbosity=-1),\n",
       " LGBMRegressor(bagging_fraction=0.48873611205657685, bagging_freq=5,\n",
       "               boosting_type='dart', l1_norm=0.0009229656559849679,\n",
       "               l2_norm=0.0002749427662654995, learning_rate=0.334877196863098,\n",
       "               max_tree_depth=19, number_trees=160, verbosity=-1),\n",
       " RandomForestRegressor(max_depth=3, max_samples=0.07863594414139055,\n",
       "                       min_samples_split=10, n_estimators=85),\n",
       " RandomForestRegressor(max_depth=8, max_samples=0.06499816627215384,\n",
       "                       min_samples_split=5, n_estimators=34),\n",
       " RandomForestRegressor(bootstrap=False, max_depth=4, min_samples_split=10,\n",
       "                       n_estimators=172),\n",
       " RandomForestRegressor(max_depth=24, max_samples=0.15026705506099675,\n",
       "                       min_samples_split=10, n_estimators=57),\n",
       " RandomForestRegressor(max_depth=16, max_samples=0.622263479026569,\n",
       "                       min_samples_split=6, n_estimators=265),\n",
       " RandomForestRegressor(max_depth=15, max_samples=0.8380978763793554,\n",
       "                       min_samples_split=7, n_estimators=275),\n",
       " RandomForestRegressor(max_depth=14, max_samples=0.528319273952443,\n",
       "                       min_samples_split=6, n_estimators=282),\n",
       " RandomForestRegressor(max_depth=16, max_samples=0.6440797776426599,\n",
       "                       min_samples_split=7, n_estimators=165),\n",
       " RandomForestRegressor(max_depth=17, max_samples=0.1021571466209434,\n",
       "                       min_samples_split=7, n_estimators=262),\n",
       " RandomForestRegressor(max_depth=21, max_samples=0.06213621471652053,\n",
       "                       min_samples_split=3, n_estimators=220)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine models into a single list of base estimators\n",
    "base_estimators = lgbm_models + rf_models\n",
    "(base_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_input['setting'] = train_val_input['setting'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for idx, model in enumerate(base_estimators):\n",
    "        if idx < 10:\n",
    "            train_val_input_subset = train_val_input.copy()\n",
    "            train_val_input_subset.columns = train_val_input_subset.columns.str.replace(r'[\\\"\\[\\]\\{\\}\\\\:,]', '', regex=True)\n",
    "            train_val_input_subset = train_val_input_subset[lgbm_col_needed[idx]]\n",
    "            \n",
    "        else:\n",
    "            train_val_input_relevant = train_val_input[rf_col_needed[idx - 10]]\n",
    "            train_val_input_subset = train_val_input_relevant.copy()\n",
    "            train_val_input_subset['setting'] = train_val_input_subset['setting'].map(countries_dict)\n",
    "\n",
    "        predictions.append(model.predict(train_val_input_subset))\n",
    "\n",
    "stacked_predictions = np.column_stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
    "    stacked_predictions, train_val_label, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_meta_train_scaled = scaler.fit_transform(X_meta_train)\n",
    "X_meta_val_scaled = scaler.transform(X_meta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_scaler = StandardScaler()\n",
    "y_meta_train_scaled = target_scaler.fit_transform(np.array(y_meta_train).reshape(-1, 1)).ravel()\n",
    "y_meta_val_scaled = target_scaler.transform(np.array(y_meta_val).reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to finetune the weights given to each of the base models in the voting ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_objective(trial):\n",
    "\n",
    "    weights = []\n",
    "    for i in range(20):\n",
    "        weights.append(trial.suggest_float(\"weights_\" + str(i), 0.0, 1.0))\n",
    "\n",
    "    w_sum = sum(weights)\n",
    "    w_normalised = [w / w_sum for w in weights]\n",
    "\n",
    "    weighted_predictions = np.dot(stacked_predictions, w_normalised)\n",
    "\n",
    "    return mean_squared_error(train_val_label, weighted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:05:18,280] A new study created in memory with name: no-name-1d578b58-9f8a-477b-8301-a8d74d14b563\n",
      "[I 2025-08-01 08:05:18,297] Trial 0 finished with value: 3700.2507170100125 and parameters: {'weights_0': 0.19006373348254024, 'weights_1': 0.7313299791613928, 'weights_2': 0.933407126048258, 'weights_3': 0.2182648119201004, 'weights_4': 0.5810476297326944, 'weights_5': 0.5324895544738754, 'weights_6': 0.9656557750064307, 'weights_7': 0.12617946803397206, 'weights_8': 0.785499068708574, 'weights_9': 0.2804408216027864, 'weights_10': 0.3540509122333527, 'weights_11': 0.9624689351313315, 'weights_12': 0.693891952429661, 'weights_13': 0.4776363847115829, 'weights_14': 0.6065874473014051, 'weights_15': 0.4007861436161302, 'weights_16': 0.8968780465966903, 'weights_17': 0.9059430109741012, 'weights_18': 0.9299326331053241, 'weights_19': 0.23649751428586074}. Best is trial 0 with value: 3700.2507170100125.\n",
      "[I 2025-08-01 08:05:18,314] Trial 1 finished with value: 3893.1026654371503 and parameters: {'weights_0': 0.6122761473069774, 'weights_1': 0.47129485929166615, 'weights_2': 0.8011134634350475, 'weights_3': 0.9251142607842491, 'weights_4': 0.33130637598648827, 'weights_5': 0.08180705806303701, 'weights_6': 0.008793851783373885, 'weights_7': 0.7011437620537053, 'weights_8': 0.2921810905969088, 'weights_9': 0.9113638939722513, 'weights_10': 0.5660276030054894, 'weights_11': 0.6992927392058281, 'weights_12': 0.723684098412183, 'weights_13': 0.6722437640186556, 'weights_14': 0.6026071148796787, 'weights_15': 0.14714754005053943, 'weights_16': 0.18436527248108892, 'weights_17': 0.297987353346183, 'weights_18': 0.945830301944805, 'weights_19': 0.03482717833088367}. Best is trial 0 with value: 3700.2507170100125.\n",
      "[I 2025-08-01 08:05:18,326] Trial 2 finished with value: 3511.820317959117 and parameters: {'weights_0': 0.6146979019173047, 'weights_1': 0.8323995178671271, 'weights_2': 0.36477169484692107, 'weights_3': 0.11956085431800545, 'weights_4': 0.9011261903354784, 'weights_5': 0.9905979807186104, 'weights_6': 0.8133231306210701, 'weights_7': 0.24674633118451905, 'weights_8': 0.4262768938134144, 'weights_9': 0.5110847910440105, 'weights_10': 0.4913693997604933, 'weights_11': 0.5924641106914458, 'weights_12': 0.8080491379161873, 'weights_13': 0.5247168968008975, 'weights_14': 0.7007448973369127, 'weights_15': 0.6510675165396221, 'weights_16': 0.969285609968407, 'weights_17': 0.5366078265070406, 'weights_18': 0.745991933562897, 'weights_19': 0.33563378691777157}. Best is trial 2 with value: 3511.820317959117.\n",
      "[I 2025-08-01 08:05:18,354] Trial 3 finished with value: 3542.842819024857 and parameters: {'weights_0': 0.2753874610307546, 'weights_1': 0.5699893775437761, 'weights_2': 0.3369171388017238, 'weights_3': 0.3453977912156383, 'weights_4': 0.04750296850703095, 'weights_5': 0.8088444839176948, 'weights_6': 0.22985314818163816, 'weights_7': 0.514146921281999, 'weights_8': 0.44926360073048965, 'weights_9': 0.9358781441431104, 'weights_10': 0.8826525033929042, 'weights_11': 0.17860985200599722, 'weights_12': 0.23411786910419075, 'weights_13': 0.8142462488495799, 'weights_14': 0.1076612053460192, 'weights_15': 0.14553320205279685, 'weights_16': 0.31916634869559657, 'weights_17': 0.7979947759126238, 'weights_18': 0.5015934209178446, 'weights_19': 0.3296545694921579}. Best is trial 2 with value: 3511.820317959117.\n",
      "[I 2025-08-01 08:05:18,363] Trial 4 finished with value: 3492.1194040132496 and parameters: {'weights_0': 0.3531008463333639, 'weights_1': 0.7967232883532964, 'weights_2': 0.22635831170428544, 'weights_3': 0.4506053296144723, 'weights_4': 0.3314427265448586, 'weights_5': 0.32790709048088307, 'weights_6': 0.8655753654107121, 'weights_7': 0.17872217792837763, 'weights_8': 0.21239906212292747, 'weights_9': 0.11748011400447389, 'weights_10': 0.8579224054788406, 'weights_11': 0.8261911531016213, 'weights_12': 0.5993269097657482, 'weights_13': 0.14849953032237317, 'weights_14': 0.3768862535616979, 'weights_15': 0.8346771488645182, 'weights_16': 0.05403373235699571, 'weights_17': 0.6398727516403312, 'weights_18': 0.19822852504423982, 'weights_19': 0.3586759026020371}. Best is trial 4 with value: 3492.1194040132496.\n",
      "[I 2025-08-01 08:05:18,368] Trial 5 finished with value: 3816.5355700031846 and parameters: {'weights_0': 0.40698192618235285, 'weights_1': 0.03999255264567614, 'weights_2': 0.9561176649783468, 'weights_3': 0.23799162392281625, 'weights_4': 0.44436141257245176, 'weights_5': 0.2074114991207866, 'weights_6': 0.5350926898961808, 'weights_7': 0.1455305027816992, 'weights_8': 0.45310067863180803, 'weights_9': 0.627166449985835, 'weights_10': 0.15279410352806344, 'weights_11': 0.9507436481832346, 'weights_12': 0.5297909587992555, 'weights_13': 0.15494531079445517, 'weights_14': 0.9456953053176828, 'weights_15': 0.15274637048006035, 'weights_16': 0.5133209067671486, 'weights_17': 0.6525333474694107, 'weights_18': 0.813559152051384, 'weights_19': 0.39153024542096027}. Best is trial 4 with value: 3492.1194040132496.\n",
      "[I 2025-08-01 08:05:18,373] Trial 6 finished with value: 3517.0223279085026 and parameters: {'weights_0': 0.24065483923584985, 'weights_1': 0.5781410913348437, 'weights_2': 0.06440051335964803, 'weights_3': 0.6800445356881444, 'weights_4': 0.9436047093038751, 'weights_5': 0.3511917348302471, 'weights_6': 0.6751777611891209, 'weights_7': 0.2796380737477443, 'weights_8': 0.779391506773973, 'weights_9': 0.15649432570306732, 'weights_10': 0.06809578111287795, 'weights_11': 0.557969309814455, 'weights_12': 0.32657666166573696, 'weights_13': 0.4014448720611937, 'weights_14': 0.5500017503331742, 'weights_15': 0.6693479889450752, 'weights_16': 0.7519988749509746, 'weights_17': 0.8674367592134722, 'weights_18': 0.8340914276648533, 'weights_19': 0.9758440633307088}. Best is trial 4 with value: 3492.1194040132496.\n",
      "[I 2025-08-01 08:05:18,375] Trial 7 finished with value: 3520.407051238903 and parameters: {'weights_0': 0.6328300362088797, 'weights_1': 0.9177422593398293, 'weights_2': 0.9349071212139357, 'weights_3': 0.49572287448876207, 'weights_4': 0.2590791227937572, 'weights_5': 0.4865922457717353, 'weights_6': 0.4748774108188639, 'weights_7': 0.9943911209769126, 'weights_8': 0.46730754303280286, 'weights_9': 0.6737171167988194, 'weights_10': 0.32793417344205833, 'weights_11': 0.10159930742504253, 'weights_12': 0.6752695855417972, 'weights_13': 0.396163244793415, 'weights_14': 0.4523616525118501, 'weights_15': 0.8583181861220339, 'weights_16': 0.008088630971626709, 'weights_17': 0.38530187173837716, 'weights_18': 0.8230461189873632, 'weights_19': 0.10040764080487519}. Best is trial 4 with value: 3492.1194040132496.\n",
      "[I 2025-08-01 08:05:18,378] Trial 8 finished with value: 3440.874510473562 and parameters: {'weights_0': 0.8550025455662941, 'weights_1': 0.6899507045393525, 'weights_2': 0.06571411378152758, 'weights_3': 0.6621508859441102, 'weights_4': 0.5208735732568193, 'weights_5': 0.6322025834898868, 'weights_6': 0.27813657239626466, 'weights_7': 0.8774955137700703, 'weights_8': 0.4170555548281867, 'weights_9': 0.8546671232326182, 'weights_10': 0.5582164535300321, 'weights_11': 0.13482792147668332, 'weights_12': 0.31328501676990705, 'weights_13': 0.9903133510190245, 'weights_14': 0.6103129868749781, 'weights_15': 0.33395556762547907, 'weights_16': 0.9009125735915131, 'weights_17': 0.7750119406344378, 'weights_18': 0.09200015128134975, 'weights_19': 0.009190370974229034}. Best is trial 8 with value: 3440.874510473562.\n",
      "[I 2025-08-01 08:05:18,381] Trial 9 finished with value: 3427.161648170962 and parameters: {'weights_0': 0.3955820627917318, 'weights_1': 0.23492436377876158, 'weights_2': 0.4638357525814224, 'weights_3': 0.8280211855767999, 'weights_4': 0.46095820241148955, 'weights_5': 0.8174723159978221, 'weights_6': 0.2800687524072688, 'weights_7': 0.4059707396237492, 'weights_8': 0.06913103103924378, 'weights_9': 0.5556238149512512, 'weights_10': 0.30601594157859924, 'weights_11': 0.6672431158423301, 'weights_12': 0.8994180711817945, 'weights_13': 0.7890596874949432, 'weights_14': 0.9937130855502062, 'weights_15': 0.3524947873275702, 'weights_16': 0.3025193474464254, 'weights_17': 0.7369643100565683, 'weights_18': 0.1561820688361918, 'weights_19': 0.5344982980588526}. Best is trial 9 with value: 3427.161648170962.\n",
      "[I 2025-08-01 08:05:18,415] Trial 10 finished with value: 3587.3584535323266 and parameters: {'weights_0': 0.06386262775061802, 'weights_1': 0.2089950394085267, 'weights_2': 0.6290105419263708, 'weights_3': 0.9565157222554237, 'weights_4': 0.7333003388713699, 'weights_5': 0.9999101152564495, 'weights_6': 0.06625990150925631, 'weights_7': 0.4925452835260725, 'weights_8': 0.041778019198317695, 'weights_9': 0.3522344714973768, 'weights_10': 0.7061783086923574, 'weights_11': 0.3694464306772483, 'weights_12': 0.9956490699751236, 'weights_13': 0.9691613723921606, 'weights_14': 0.9731192184481083, 'weights_15': 0.5436623048078331, 'weights_16': 0.49966253745126477, 'weights_17': 0.009719405371999112, 'weights_18': 0.33316289653578424, 'weights_19': 0.6687479770817419}. Best is trial 9 with value: 3427.161648170962.\n",
      "[I 2025-08-01 08:05:18,451] Trial 11 finished with value: 3380.397034789132 and parameters: {'weights_0': 0.8662962540689382, 'weights_1': 0.32250404934704197, 'weights_2': 0.04211696972268042, 'weights_3': 0.7191931067197777, 'weights_4': 0.6209470723101737, 'weights_5': 0.7053273725917133, 'weights_6': 0.2983426091342653, 'weights_7': 0.9247399842081043, 'weights_8': 0.06098890729582843, 'weights_9': 0.7466373841274971, 'weights_10': 0.29217927365020047, 'weights_11': 0.3290846665516895, 'weights_12': 0.050850474215818786, 'weights_13': 0.9997894481861447, 'weights_14': 0.8334443122340179, 'weights_15': 0.34153253528789107, 'weights_16': 0.5959543068097539, 'weights_17': 0.7609755147392439, 'weights_18': 0.0185211352254111, 'weights_19': 0.6717791472377284}. Best is trial 11 with value: 3380.397034789132.\n",
      "[I 2025-08-01 08:05:18,506] Trial 12 finished with value: 3349.3216985005643 and parameters: {'weights_0': 0.9878721530501564, 'weights_1': 0.30722646803644366, 'weights_2': 0.5787980270080446, 'weights_3': 0.7525485398140437, 'weights_4': 0.7050484111409684, 'weights_5': 0.7591014431477203, 'weights_6': 0.34946878132875303, 'weights_7': 0.455907727600085, 'weights_8': 0.013672913002728625, 'weights_9': 0.7174196183711627, 'weights_10': 0.25847404854916856, 'weights_11': 0.35878795509705075, 'weights_12': 0.005229239830721655, 'weights_13': 0.7975976106287451, 'weights_14': 0.8327965122714451, 'weights_15': 0.3306747099600043, 'weights_16': 0.539576574656961, 'weights_17': 0.6629311216880575, 'weights_18': 0.017508921891284168, 'weights_19': 0.6437811288204129}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,552] Trial 13 finished with value: 3425.9833796395224 and parameters: {'weights_0': 0.9406609358933004, 'weights_1': 0.35987995836526526, 'weights_2': 0.6159915966806199, 'weights_3': 0.6975944086804594, 'weights_4': 0.715964098258209, 'weights_5': 0.7310418658434321, 'weights_6': 0.4294503601406553, 'weights_7': 0.6741209811655711, 'weights_8': 0.18859063017496822, 'weights_9': 0.768656944876251, 'weights_10': 0.16688306557930443, 'weights_11': 0.35713416033529605, 'weights_12': 0.08021886516838261, 'weights_13': 0.781407457109256, 'weights_14': 0.8002876704645838, 'weights_15': 0.006661640083105547, 'weights_16': 0.6238150050626406, 'weights_17': 0.4890104404175595, 'weights_18': 0.0001856894838639933, 'weights_19': 0.7346461697092118}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,599] Trial 14 finished with value: 3519.314528682922 and parameters: {'weights_0': 0.8083657079671999, 'weights_1': 0.33396033696258476, 'weights_2': 0.6664005958075425, 'weights_3': 0.7497830068338287, 'weights_4': 0.712801467122273, 'weights_5': 0.6612884871143123, 'weights_6': 0.1989105958219321, 'weights_7': 0.70142384616265, 'weights_8': 0.6446531949558973, 'weights_9': 0.7359258378897225, 'weights_10': 0.0029464099538258903, 'weights_11': 0.3925459435233908, 'weights_12': 0.0005201916602914792, 'weights_13': 0.8860590834934284, 'weights_14': 0.8146476186172436, 'weights_15': 0.489482451937763, 'weights_16': 0.6730167925643991, 'weights_17': 0.1770364940204101, 'weights_18': 0.3515314866320999, 'weights_19': 0.7535547111052703}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,654] Trial 15 finished with value: 3373.8862567507813 and parameters: {'weights_0': 0.9798535555387043, 'weights_1': 0.053838320113548666, 'weights_2': 0.20524044979303446, 'weights_3': 0.5708158075260303, 'weights_4': 0.8198672326390952, 'weights_5': 0.8341165884730115, 'weights_6': 0.373472252196587, 'weights_7': 0.8212819773882982, 'weights_8': 0.12885154909487445, 'weights_9': 0.3490426196273092, 'weights_10': 0.23034574051642953, 'weights_11': 0.2490871566784387, 'weights_12': 0.19319816291177333, 'weights_13': 0.6532007906614875, 'weights_14': 0.2319962780717385, 'weights_15': 0.27440746202225275, 'weights_16': 0.47998540974174364, 'weights_17': 0.9468130021378438, 'weights_18': 0.5724236687156812, 'weights_19': 0.5665400145560198}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,707] Trial 16 finished with value: 3394.211262784371 and parameters: {'weights_0': 0.9791306320606301, 'weights_1': 0.007288623680529488, 'weights_2': 0.22266494074007837, 'weights_3': 0.557961093581373, 'weights_4': 0.8498399068684936, 'weights_5': 0.87157565003311, 'weights_6': 0.6222066111945945, 'weights_7': 0.8037704598236322, 'weights_8': 0.9473160405855123, 'weights_9': 0.38045278416993733, 'weights_10': 0.1948850046162035, 'weights_11': 0.239792603807916, 'weights_12': 0.19740276138229934, 'weights_13': 0.6200517987838311, 'weights_14': 0.24389693812931967, 'weights_15': 0.2070128565230387, 'weights_16': 0.40002485687508227, 'weights_17': 0.9853634205242944, 'weights_18': 0.6125549344743872, 'weights_19': 0.5187681835981713}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,763] Trial 17 finished with value: 3353.675396138389 and parameters: {'weights_0': 0.7350127912668079, 'weights_1': 0.14164703742478682, 'weights_2': 0.4983401167666548, 'weights_3': 0.5700694974413466, 'weights_4': 0.8192028624969765, 'weights_5': 0.8972432254241329, 'weights_6': 0.3970600517961107, 'weights_7': 0.5609614775233329, 'weights_8': 0.26432885197220485, 'weights_9': 0.4329491496994089, 'weights_10': 0.44502136524049246, 'weights_11': 0.008511795320477383, 'weights_12': 0.4136531712639231, 'weights_13': 0.6556878092427857, 'weights_14': 0.09339744310713316, 'weights_15': 0.9780711698716852, 'weights_16': 0.7691871138236864, 'weights_17': 0.9751715466156639, 'weights_18': 0.5949682762468026, 'weights_19': 0.9770782616287237}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,824] Trial 18 finished with value: 3493.9895344345846 and parameters: {'weights_0': 0.7244242129842535, 'weights_1': 0.1656382544719363, 'weights_2': 0.4989759592411691, 'weights_3': 0.38490789649211116, 'weights_4': 0.9732954208350931, 'weights_5': 0.6021685180375469, 'weights_6': 0.13605610667990764, 'weights_7': 0.02145725651845709, 'weights_8': 0.3063779052557291, 'weights_9': 0.002511517419373388, 'weights_10': 0.4550331108770614, 'weights_11': 0.0346015671904355, 'weights_12': 0.3824735463596127, 'weights_13': 0.008059289204646158, 'weights_14': 0.10558698973536174, 'weights_15': 0.9282454194571967, 'weights_16': 0.7599953298453705, 'weights_17': 0.6008217816100546, 'weights_18': 0.37586345374087937, 'weights_19': 0.9982624730834083}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,872] Trial 19 finished with value: 3497.663738928873 and parameters: {'weights_0': 0.7295176849859561, 'weights_1': 0.4401751189937866, 'weights_2': 0.7616075927923486, 'weights_3': 0.8429128425958315, 'weights_4': 0.7740991243450918, 'weights_5': 0.9139872844423125, 'weights_6': 0.60099372103026, 'weights_7': 0.5675823767380056, 'weights_8': 0.008256799820189457, 'weights_9': 0.46862508322752316, 'weights_10': 0.6663126354640838, 'weights_11': 0.4881379519371176, 'weights_12': 0.4829921197006182, 'weights_13': 0.7094561659194651, 'weights_14': 0.3317295150866287, 'weights_15': 0.7068047374930948, 'weights_16': 0.7848608794401362, 'weights_17': 0.4298442543560776, 'weights_18': 0.6386263499882318, 'weights_19': 0.8767950424025269}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,921] Trial 20 finished with value: 3367.415064957169 and parameters: {'weights_0': 0.5071416914022606, 'weights_1': 0.1510507420463027, 'weights_2': 0.4000225345004458, 'weights_3': 0.6111110568911253, 'weights_4': 0.6338896573826542, 'weights_5': 0.46784590320191105, 'weights_6': 0.38171927798401756, 'weights_7': 0.38568121694126156, 'weights_8': 0.3230233883701594, 'weights_9': 0.603616803245393, 'weights_10': 0.42852716502758514, 'weights_11': 0.05304089815717048, 'weights_12': 0.4186725856105227, 'weights_13': 0.529520524182501, 'weights_14': 0.00841750144262779, 'weights_15': 0.9879831114772887, 'weights_16': 0.8409078163436221, 'weights_17': 0.9976244655841543, 'weights_18': 0.45471310176589325, 'weights_19': 0.8481076766101491}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,958] Trial 21 finished with value: 3396.8698206637578 and parameters: {'weights_0': 0.5254812431027134, 'weights_1': 0.11033607879601526, 'weights_2': 0.41458338559904784, 'weights_3': 0.5939296404037147, 'weights_4': 0.6299406915941225, 'weights_5': 0.41919784788787284, 'weights_6': 0.3992814073195544, 'weights_7': 0.3854906443511777, 'weights_8': 0.33735453107401564, 'weights_9': 0.6101874592522676, 'weights_10': 0.4148812107640682, 'weights_11': 0.04417686798605642, 'weights_12': 0.446077531674723, 'weights_13': 0.5481288505323404, 'weights_14': 0.05609282842600349, 'weights_15': 0.9643916769956137, 'weights_16': 0.8467893550360711, 'weights_17': 0.9875144987479351, 'weights_18': 0.4722700531335471, 'weights_19': 0.8719180715593446}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:18,990] Trial 22 finished with value: 3388.423148845387 and parameters: {'weights_0': 0.533197412218226, 'weights_1': 0.2628075942510737, 'weights_2': 0.5788015037208436, 'weights_3': 0.7951467257524386, 'weights_4': 0.6819295438113617, 'weights_5': 0.5415221898301502, 'weights_6': 0.3564907854002894, 'weights_7': 0.386237067772176, 'weights_8': 0.2290311470594804, 'weights_9': 0.4395032603241542, 'weights_10': 0.62772590368704, 'weights_11': 0.013229253435139685, 'weights_12': 0.564036324368214, 'weights_13': 0.32139076625339014, 'weights_14': 0.029494730871649527, 'weights_15': 0.8223029556356274, 'weights_16': 0.7046011267852428, 'weights_17': 0.8624345902378323, 'weights_18': 0.2666901104265328, 'weights_19': 0.8549318942893605}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,029] Trial 23 finished with value: 3437.9899755969404 and parameters: {'weights_0': 0.7231901710140332, 'weights_1': 0.14620559693487772, 'weights_2': 0.5390546437913879, 'weights_3': 0.001620369472336014, 'weights_4': 0.8456596966764647, 'weights_5': 0.7243684433143056, 'weights_6': 0.5572059297987053, 'weights_7': 0.5372288302890634, 'weights_8': 0.5396334511935933, 'weights_9': 0.8205739242931294, 'weights_10': 0.39886454603020016, 'weights_11': 0.25047504752306005, 'weights_12': 0.40882188117460805, 'weights_13': 0.579157922405256, 'weights_14': 0.2108007904970223, 'weights_15': 0.9741286575154672, 'weights_16': 0.9912672303488346, 'weights_17': 0.8878449128091978, 'weights_18': 0.6924466380682575, 'weights_19': 0.7858735766809362}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,060] Trial 24 finished with value: 3443.279046907236 and parameters: {'weights_0': 0.7977780102662044, 'weights_1': 0.398063177909222, 'weights_2': 0.7134407405352088, 'weights_3': 0.608596492591108, 'weights_4': 0.5321817357486629, 'weights_5': 0.9254767276087579, 'weights_6': 0.47223224389298174, 'weights_7': 0.6128400598705741, 'weights_8': 0.579205745627765, 'weights_9': 0.5764124648906584, 'weights_10': 0.7493340066963283, 'weights_11': 0.16726098532434888, 'weights_12': 0.1172445352106875, 'weights_13': 0.7136370114289169, 'weights_14': 0.11667074225709237, 'weights_15': 0.7565353040725025, 'weights_16': 0.6103530293671541, 'weights_17': 0.6989351719288281, 'weights_18': 0.4550168218400678, 'weights_19': 0.6236595593101084}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,099] Trial 25 finished with value: 3551.7924550186617 and parameters: {'weights_0': 0.49115111746244794, 'weights_1': 0.2641160416915501, 'weights_2': 0.3086972403594975, 'weights_3': 0.4396231067282068, 'weights_4': 0.642172451627649, 'weights_5': 0.26061561565428387, 'weights_6': 0.6890714551742179, 'weights_7': 0.44443599414741075, 'weights_8': 0.15068599077971082, 'weights_9': 0.6768367268870936, 'weights_10': 0.5490732925155135, 'weights_11': 0.4572972553821877, 'weights_12': 0.26705727256592093, 'weights_13': 0.8637817894929428, 'weights_14': 0.003391020229022823, 'weights_15': 0.5642605795540262, 'weights_16': 0.8347114789718325, 'weights_17': 0.8245287184920229, 'weights_18': 0.5572912575144205, 'weights_19': 0.9252445320337381}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,154] Trial 26 finished with value: 3394.7474545464447 and parameters: {'weights_0': 0.9003837478025988, 'weights_1': 0.14358248195237824, 'weights_2': 0.4596623520679143, 'weights_3': 0.8828948868809225, 'weights_4': 0.7819825929370995, 'weights_5': 0.4144134840490895, 'weights_6': 0.335619655730339, 'weights_7': 0.31266837224787725, 'weights_8': 0.296404110955467, 'weights_9': 0.9954552924081028, 'weights_10': 0.9856303799356368, 'weights_11': 0.08293240196874538, 'weights_12': 0.13968124550851674, 'weights_13': 0.46589889285291586, 'weights_14': 0.1654699849094551, 'weights_15': 0.8936027791790256, 'weights_16': 0.6892353955403375, 'weights_17': 0.9986879594811859, 'weights_18': 0.24681455942499952, 'weights_19': 0.8285088773672141}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,196] Trial 27 finished with value: 3495.6942336929565 and parameters: {'weights_0': 0.660035023526489, 'weights_1': 0.10074113399138492, 'weights_2': 0.5399684056551813, 'weights_3': 0.6303113530124751, 'weights_4': 0.921623951875554, 'weights_5': 0.7710448476745575, 'weights_6': 0.1266161414717892, 'weights_7': 0.3267453630640299, 'weights_8': 0.37378218514369443, 'weights_9': 0.2708787693657247, 'weights_10': 0.247811051118353, 'weights_11': 0.0005061065668645615, 'weights_12': 0.31577321239065737, 'weights_13': 0.29890800158382835, 'weights_14': 0.4472856363518646, 'weights_15': 0.4771061854640869, 'weights_16': 0.5566432242763022, 'weights_17': 0.564285597637162, 'weights_18': 0.721651034231362, 'weights_19': 0.9394005967616074}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,246] Trial 28 finished with value: 3559.528472724667 and parameters: {'weights_0': 0.4751380632462011, 'weights_1': 0.5447170836611734, 'weights_2': 0.3980404334060859, 'weights_3': 0.5152715362730202, 'weights_4': 0.38748777089531994, 'weights_5': 0.008245298815446778, 'weights_6': 0.20438462437503763, 'weights_7': 0.6092428737925503, 'weights_8': 0.12124152795926588, 'weights_9': 0.5082199653510051, 'weights_10': 0.4014537972379546, 'weights_11': 0.20042592852776364, 'weights_12': 0.4014171304265929, 'weights_13': 0.6081720953016301, 'weights_14': 0.312734216409534, 'weights_15': 0.7660055099562461, 'weights_16': 0.4154891802319317, 'weights_17': 0.7041671604938504, 'weights_18': 0.08547895904220876, 'weights_19': 0.7154024835148729}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,280] Trial 29 finished with value: 3574.0908582540715 and parameters: {'weights_0': 0.10969196820268423, 'weights_1': 0.20400195614478656, 'weights_2': 0.8500661080438652, 'weights_3': 0.3155544067807617, 'weights_4': 0.5816143854660185, 'weights_5': 0.5389824482638474, 'weights_6': 0.41559607811745225, 'weights_7': 0.46610690307931263, 'weights_8': 0.6649186839713659, 'weights_9': 0.243316869748903, 'weights_10': 0.3752018410953475, 'weights_11': 0.31211859532436764, 'weights_12': 0.6290555807866955, 'weights_13': 0.46434561436720867, 'weights_14': 0.8864060369237928, 'weights_15': 0.9943362230563567, 'weights_16': 0.9087821256389551, 'weights_17': 0.8777332347791678, 'weights_18': 0.4155228124384408, 'weights_19': 0.43612379910460997}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,333] Trial 30 finished with value: 3641.57872847218 and parameters: {'weights_0': 0.7846329777619547, 'weights_1': 0.3046979417340032, 'weights_2': 0.2952727960052193, 'weights_3': 0.753824697386213, 'weights_4': 0.1949379195309522, 'weights_5': 0.5904189125447016, 'weights_6': 0.4877043892560803, 'weights_7': 0.06374886117429157, 'weights_8': 0.2094377015362341, 'weights_9': 0.6682584739061643, 'weights_10': 0.4656025849499421, 'weights_11': 0.09275757133027457, 'weights_12': 0.4945455121969137, 'weights_13': 0.8993824675553143, 'weights_14': 0.7000192450594038, 'weights_15': 0.42514547918408374, 'weights_16': 0.8298994220980188, 'weights_17': 0.3016540035936635, 'weights_18': 0.5293052794744632, 'weights_19': 0.8025501186939762}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,382] Trial 31 finished with value: 3363.9193393878986 and parameters: {'weights_0': 0.9900279190092627, 'weights_1': 0.07386498871054845, 'weights_2': 0.1564437251892812, 'weights_3': 0.532997155807403, 'weights_4': 0.8219873516298506, 'weights_5': 0.8856770712524775, 'weights_6': 0.37198588549043976, 'weights_7': 0.7655014629578352, 'weights_8': 0.11855306339151936, 'weights_9': 0.37527960104181896, 'weights_10': 0.23297651873987488, 'weights_11': 0.27034203246656524, 'weights_12': 0.1860804070790345, 'weights_13': 0.6638000071450157, 'weights_14': 0.218048491803061, 'weights_15': 0.26079375292075524, 'weights_16': 0.4434654879583341, 'weights_17': 0.9396711058465143, 'weights_18': 0.5947758554579354, 'weights_19': 0.5918409746307332}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,412] Trial 32 finished with value: 3431.3886444950017 and parameters: {'weights_0': 0.9155649583621283, 'weights_1': 0.06535194551654822, 'weights_2': 0.1722581654589983, 'weights_3': 0.5303844216646626, 'weights_4': 0.8583845373650778, 'weights_5': 0.9175892626071973, 'weights_6': 0.3241102234533285, 'weights_7': 0.7477325910726775, 'weights_8': 0.2695385123501954, 'weights_9': 0.4249707623011379, 'weights_10': 0.08596535081087103, 'weights_11': 0.4239975619099904, 'weights_12': 0.005184609115575549, 'weights_13': 0.7239428399484499, 'weights_14': 0.14597573726467872, 'weights_15': 0.026574557055989656, 'weights_16': 0.2515696836263998, 'weights_17': 0.9379502893267697, 'weights_18': 0.9964972573804183, 'weights_19': 0.5982425451575389}. Best is trial 12 with value: 3349.3216985005643.\n",
      "[I 2025-08-01 08:05:19,459] Trial 33 finished with value: 3288.9128617118467 and parameters: {'weights_0': 0.5766419615842129, 'weights_1': 0.1848742157823745, 'weights_2': 0.14873624055012408, 'weights_3': 0.40867442944135, 'weights_4': 0.7597934805096624, 'weights_5': 0.8676472828731487, 'weights_6': 0.4348099174241957, 'weights_7': 0.6179380116347586, 'weights_8': 0.13003327151597135, 'weights_9': 0.5514861778285396, 'weights_10': 0.2615134904355585, 'weights_11': 0.2861978615249716, 'weights_12': 0.1498664426325143, 'weights_13': 0.6848293251430256, 'weights_14': 0.06086252719679643, 'weights_15': 0.2232592211663451, 'weights_16': 0.41045292866230576, 'weights_17': 0.9133784339038656, 'weights_18': 0.6757786715397555, 'weights_19': 0.4587576225054406}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,507] Trial 34 finished with value: 3351.214518628377 and parameters: {'weights_0': 0.9946041065718588, 'weights_1': 0.0010957975968708955, 'weights_2': 0.1287781267337706, 'weights_3': 0.2986027119504872, 'weights_4': 0.9976140879706121, 'weights_5': 0.873420290444394, 'weights_6': 0.2491804824657936, 'weights_7': 0.6486091284562727, 'weights_8': 0.10904168937595281, 'weights_9': 0.5447621387347087, 'weights_10': 0.25931198680835515, 'weights_11': 0.5509976437884403, 'weights_12': 0.1258928231106188, 'weights_13': 0.6719346827130306, 'weights_14': 0.29862939920071385, 'weights_15': 0.26256991056342194, 'weights_16': 0.40475488054408093, 'weights_17': 0.8302911829796006, 'weights_18': 0.6611355574932323, 'weights_19': 0.20688443539257623}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,549] Trial 35 finished with value: 3319.44151444804 and parameters: {'weights_0': 0.5696174754169517, 'weights_1': 0.023250031619043633, 'weights_2': 0.8478834039691149, 'weights_3': 0.20160074626828595, 'weights_4': 0.9983364356679293, 'weights_5': 0.9714612912300771, 'weights_6': 0.226252700757422, 'weights_7': 0.6409277306112532, 'weights_8': 0.010755685728123054, 'weights_9': 0.5319078002588837, 'weights_10': 0.12682548649892444, 'weights_11': 0.5600227972033219, 'weights_12': 0.13188133004506575, 'weights_13': 0.7799019891048922, 'weights_14': 0.3653198388321456, 'weights_15': 0.08503452838409609, 'weights_16': 0.15244057854623783, 'weights_17': 0.8099000006411322, 'weights_18': 0.6465152386723714, 'weights_19': 0.24611799376640386}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,599] Trial 36 finished with value: 3347.567193148295 and parameters: {'weights_0': 0.5846819705434722, 'weights_1': 0.0012030493891031224, 'weights_2': 0.8798632125936465, 'weights_3': 0.18232610786794967, 'weights_4': 0.9787513710505402, 'weights_5': 0.9646175745416445, 'weights_6': 0.1413251369488063, 'weights_7': 0.6417638109652727, 'weights_8': 0.0032381761782299895, 'weights_9': 0.5328452319770787, 'weights_10': 0.1284239095777378, 'weights_11': 0.5443762646201528, 'weights_12': 0.09971249596683943, 'weights_13': 0.751623786770709, 'weights_14': 0.39911527904423805, 'weights_15': 0.0833302882985378, 'weights_16': 0.20835315712109068, 'weights_17': 0.8160033214867708, 'weights_18': 0.6591831824693912, 'weights_19': 0.2416444881595663}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,643] Trial 37 finished with value: 3449.863941470415 and parameters: {'weights_0': 0.5578021816347221, 'weights_1': 0.199391758811709, 'weights_2': 0.8898408341704971, 'weights_3': 0.1435563852196788, 'weights_4': 0.9114042800908422, 'weights_5': 0.9949476265556269, 'weights_6': 0.004260810468686871, 'weights_7': 0.7154260663540033, 'weights_8': 0.043621268500765635, 'weights_9': 0.4941735726807589, 'weights_10': 0.10549459128149427, 'weights_11': 0.6624622399857878, 'weights_12': 0.0922571839670834, 'weights_13': 0.8341452183668208, 'weights_14': 0.4031494096967132, 'weights_15': 0.06724914700865552, 'weights_16': 0.14329444927859403, 'weights_17': 0.6368022530167063, 'weights_18': 0.7684502938334413, 'weights_19': 0.2299633548427884}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,699] Trial 38 finished with value: 3420.855957644545 and parameters: {'weights_0': 0.5852195320976377, 'weights_1': 0.015324593757218955, 'weights_2': 0.9942209177534328, 'weights_3': 0.15827865131173463, 'weights_4': 0.9968171529149794, 'weights_5': 0.9560986817308996, 'weights_6': 0.14370173132972527, 'weights_7': 0.6058263998116733, 'weights_8': 0.003495130297477532, 'weights_9': 0.7065654922841208, 'weights_10': 0.03870761869052558, 'weights_11': 0.7810481910548925, 'weights_12': 0.04395088018893382, 'weights_13': 0.9326849528033495, 'weights_14': 0.5648661204143528, 'weights_15': 0.10447473344197465, 'weights_16': 0.1335208914275776, 'weights_17': 0.7076382277286416, 'weights_18': 0.8966742342328213, 'weights_19': 0.29351068795809304}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,749] Trial 39 finished with value: 3307.7325516175015 and parameters: {'weights_0': 0.32501213305106613, 'weights_1': 0.49496406173100715, 'weights_2': 0.8082541263027968, 'weights_3': 0.22070476293012045, 'weights_4': 0.9034035650109308, 'weights_5': 0.7711325012337095, 'weights_6': 0.948286512183605, 'weights_7': 0.20861388730164765, 'weights_8': 0.17120808955959146, 'weights_9': 0.81727865934911, 'weights_10': 0.1278360949614173, 'weights_11': 0.5354200791566139, 'weights_12': 0.2481470003518758, 'weights_13': 0.7556984966468082, 'weights_14': 0.6721906228450403, 'weights_15': 0.1885334753030763, 'weights_16': 0.23353717564498067, 'weights_17': 0.7884096252056864, 'weights_18': 0.7693909518433626, 'weights_19': 0.4462582901468192}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,797] Trial 40 finished with value: 3299.0556163396923 and parameters: {'weights_0': 0.30718153363539, 'weights_1': 0.6953415110692834, 'weights_2': 0.8145505602117895, 'weights_3': 0.22741364356565927, 'weights_4': 0.8871206438722632, 'weights_5': 0.8167305818123458, 'weights_6': 0.9574326356076891, 'weights_7': 0.6419438990141293, 'weights_8': 0.08008250758542718, 'weights_9': 0.8759606506592131, 'weights_10': 0.12445583979391628, 'weights_11': 0.6179703028683728, 'weights_12': 0.26601230542937176, 'weights_13': 0.7450415662907653, 'weights_14': 0.6585672419310836, 'weights_15': 0.18952475114463835, 'weights_16': 0.2296749170233666, 'weights_17': 0.7971033926292482, 'weights_18': 0.8842024385965018, 'weights_19': 0.15795793671778016}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,841] Trial 41 finished with value: 3292.4032099210795 and parameters: {'weights_0': 0.3176368007316861, 'weights_1': 0.6373577044157692, 'weights_2': 0.813319010551223, 'weights_3': 0.2309344560233507, 'weights_4': 0.8989203832906388, 'weights_5': 0.8191752738975887, 'weights_6': 0.8548115521637931, 'weights_7': 0.17765660204991413, 'weights_8': 0.18407641810910358, 'weights_9': 0.88836143082547, 'weights_10': 0.11849608671285043, 'weights_11': 0.6219044860290639, 'weights_12': 0.24681009428692707, 'weights_13': 0.7460066762917295, 'weights_14': 0.6837240239610844, 'weights_15': 0.18622124942429474, 'weights_16': 0.21981021436408565, 'weights_17': 0.795119752873462, 'weights_18': 0.8710908714597508, 'weights_19': 0.13585942148961322}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,894] Trial 42 finished with value: 3319.6924260288333 and parameters: {'weights_0': 0.2977604446850577, 'weights_1': 0.6754606306389312, 'weights_2': 0.7938898369442974, 'weights_3': 0.05652958355012011, 'weights_4': 0.8847820418461616, 'weights_5': 0.8082103440164641, 'weights_6': 0.9831339600993731, 'weights_7': 0.19131805477426012, 'weights_8': 0.1834175242328596, 'weights_9': 0.8975444987066838, 'weights_10': 0.18170340725921855, 'weights_11': 0.6190197577457447, 'weights_12': 0.2279822435055531, 'weights_13': 0.8390668604045098, 'weights_14': 0.6900923196725194, 'weights_15': 0.17148250200987736, 'weights_16': 0.33754211521998473, 'weights_17': 0.7973363477533867, 'weights_18': 0.8702132822249866, 'weights_19': 0.07085213159856037}. Best is trial 33 with value: 3288.9128617118467.\n",
      "[I 2025-08-01 08:05:19,941] Trial 43 finished with value: 3251.678616378243 and parameters: {'weights_0': 0.17801569605220757, 'weights_1': 0.7567863045671068, 'weights_2': 0.8266116907007172, 'weights_3': 0.24445986942667663, 'weights_4': 0.9397190049139273, 'weights_5': 0.8347983692761589, 'weights_6': 0.9038427849658087, 'weights_7': 0.2258007636589201, 'weights_8': 0.09357481182300387, 'weights_9': 0.9734357746813458, 'weights_10': 0.03976038311691166, 'weights_11': 0.7494750922515415, 'weights_12': 0.2770286624972516, 'weights_13': 0.7443871793006475, 'weights_14': 0.64309115183356, 'weights_15': 0.1831567186215934, 'weights_16': 0.07729197214192762, 'weights_17': 0.7375521058064911, 'weights_18': 0.9527285242733345, 'weights_19': 0.14444087654274188}. Best is trial 43 with value: 3251.678616378243.\n",
      "[I 2025-08-01 08:05:19,991] Trial 44 finished with value: 3273.235090985467 and parameters: {'weights_0': 0.19402915738984308, 'weights_1': 0.7802786933689388, 'weights_2': 0.7299254953355842, 'weights_3': 0.2334884509440691, 'weights_4': 0.9425941323772077, 'weights_5': 0.6787598144305576, 'weights_6': 0.9215340633459798, 'weights_7': 0.2211673845882285, 'weights_8': 0.09580020370819443, 'weights_9': 0.9917806280336993, 'weights_10': 0.00724354966730327, 'weights_11': 0.7665745361145206, 'weights_12': 0.35223548110884334, 'weights_13': 0.7393215536697025, 'weights_14': 0.6460100109563244, 'weights_15': 0.20501881699459232, 'weights_16': 0.07372821931187001, 'weights_17': 0.7486745926326718, 'weights_18': 0.9407390179479034, 'weights_19': 0.14673140369920035}. Best is trial 43 with value: 3251.678616378243.\n",
      "[I 2025-08-01 08:05:20,045] Trial 45 finished with value: 3293.1418390196395 and parameters: {'weights_0': 0.19564161913519923, 'weights_1': 0.8116731810032832, 'weights_2': 0.7197541460687731, 'weights_3': 0.25016589278044776, 'weights_4': 0.77092036494196, 'weights_5': 0.6715683894415585, 'weights_6': 0.8112209069142269, 'weights_7': 0.10916795531399202, 'weights_8': 0.07513489179056208, 'weights_9': 0.9918705849049742, 'weights_10': 0.0044030189677364134, 'weights_11': 0.76535814033989, 'weights_12': 0.3453143093171509, 'weights_13': 0.7145105792285047, 'weights_14': 0.6294837787080987, 'weights_15': 0.22975386374182252, 'weights_16': 0.07372377511100532, 'weights_17': 0.7405973411587894, 'weights_18': 0.9572306622054375, 'weights_19': 0.14142553510721115}. Best is trial 43 with value: 3251.678616378243.\n",
      "[I 2025-08-01 08:05:20,083] Trial 46 finished with value: 3338.345220714543 and parameters: {'weights_0': 0.17848999116780334, 'weights_1': 0.8066477070815339, 'weights_2': 0.7109228437415624, 'weights_3': 0.27918738898336515, 'weights_4': 0.7754958611251419, 'weights_5': 0.6561261189075733, 'weights_6': 0.8121506673562818, 'weights_7': 0.10825071859548495, 'weights_8': 0.07773495645059214, 'weights_9': 0.9799372367432613, 'weights_10': 0.0017621491154423824, 'weights_11': 0.8261129288284232, 'weights_12': 0.30396814039388953, 'weights_13': 0.5957420757358993, 'weights_14': 0.7614844418882265, 'weights_15': 0.1288702851063472, 'weights_16': 0.07030303059084284, 'weights_17': 0.49822093859659483, 'weights_18': 0.9644743956454568, 'weights_19': 0.1592998211490177}. Best is trial 43 with value: 3251.678616378243.\n",
      "[I 2025-08-01 08:05:20,139] Trial 47 finished with value: 3290.2131574010596 and parameters: {'weights_0': 0.19960805494104034, 'weights_1': 0.885004008911941, 'weights_2': 0.7514032263415231, 'weights_3': 0.37135123612720433, 'weights_4': 0.9455519173602276, 'weights_5': 0.6869024123868528, 'weights_6': 0.8638046085260259, 'weights_7': 0.13207759807938274, 'weights_8': 0.23996575130824666, 'weights_9': 0.9520718596221871, 'weights_10': 0.05466845327399515, 'weights_11': 0.9532137996257323, 'weights_12': 0.3480476657237869, 'weights_13': 0.7039002471915501, 'weights_14': 0.5075102162081865, 'weights_15': 0.23126030897514666, 'weights_16': 0.013182009349478885, 'weights_17': 0.7383919976048791, 'weights_18': 0.934506183853412, 'weights_19': 0.11187893171731306}. Best is trial 43 with value: 3251.678616378243.\n",
      "[I 2025-08-01 08:05:20,176] Trial 48 finished with value: 3251.2961228959116 and parameters: {'weights_0': 0.0036845949933795308, 'weights_1': 0.9808377430320516, 'weights_2': 0.7548762083281392, 'weights_3': 0.39018745410019706, 'weights_4': 0.9380805571656458, 'weights_5': 0.7103747886470353, 'weights_6': 0.8816490138834612, 'weights_7': 0.25406190691114505, 'weights_8': 0.2267018255784493, 'weights_9': 0.919428986350657, 'weights_10': 0.045945699020085704, 'weights_11': 0.9950153763058835, 'weights_12': 0.3576329615134741, 'weights_13': 0.922118810076112, 'weights_14': 0.5304107134984151, 'weights_15': 0.3811433665329148, 'weights_16': 0.001604506797134619, 'weights_17': 0.6612125012932326, 'weights_18': 0.8253957460186035, 'weights_19': 0.0003385996974338279}. Best is trial 48 with value: 3251.2961228959116.\n",
      "[I 2025-08-01 08:05:20,229] Trial 49 finished with value: 3395.921967824474 and parameters: {'weights_0': 0.046955761882187835, 'weights_1': 0.973105652582336, 'weights_2': 0.6768301965187078, 'weights_3': 0.37047439843127156, 'weights_4': 0.07672737099526139, 'weights_5': 0.7007390024854777, 'weights_6': 0.747652829520416, 'weights_7': 0.24120715072490423, 'weights_8': 0.2263434742431816, 'weights_9': 0.9375048960679077, 'weights_10': 0.05429463629339635, 'weights_11': 0.9896819381915213, 'weights_12': 0.3647078484248604, 'weights_13': 0.9353197768878148, 'weights_14': 0.5191634313509503, 'weights_15': 0.3790454245053402, 'weights_16': 0.016182196451350477, 'weights_17': 0.5669817385113205, 'weights_18': 0.8248617906266275, 'weights_19': 0.04347441431893209}. Best is trial 48 with value: 3251.2961228959116.\n",
      "[I 2025-08-01 08:05:20,276] Trial 50 finished with value: 3330.73963274937 and parameters: {'weights_0': 0.11481522245906264, 'weights_1': 0.754952935739621, 'weights_2': 0.7537450821179714, 'weights_3': 0.43893172022039895, 'weights_4': 0.9380874840240666, 'weights_5': 0.5763161669796638, 'weights_6': 0.9378690035123032, 'weights_7': 0.25407281199814963, 'weights_8': 0.3837252511497692, 'weights_9': 0.9492535669057214, 'weights_10': 0.03355095905223329, 'weights_11': 0.9196812011073782, 'weights_12': 0.4526896332505333, 'weights_13': 0.9234374015259437, 'weights_14': 0.5666797787813145, 'weights_15': 0.29355207183711185, 'weights_16': 0.10381853596009619, 'weights_17': 0.65434037393042, 'weights_18': 0.9226231280456354, 'weights_19': 0.013589990010096547}. Best is trial 48 with value: 3251.2961228959116.\n",
      "[I 2025-08-01 08:05:20,329] Trial 51 finished with value: 3263.350876861229 and parameters: {'weights_0': 0.25029776550694727, 'weights_1': 0.8638414015924268, 'weights_2': 0.7612494834804577, 'weights_3': 0.39477675856374594, 'weights_4': 0.9419417241250001, 'weights_5': 0.8437179023384653, 'weights_6': 0.86008158532152, 'weights_7': 0.06500097182157752, 'weights_8': 0.15591751865012862, 'weights_9': 0.8291144812630286, 'weights_10': 0.07538739409239265, 'weights_11': 0.9286480993756965, 'weights_12': 0.29613182618053824, 'weights_13': 0.8149203796594437, 'weights_14': 0.7639316815082507, 'weights_15': 0.31460098025115746, 'weights_16': 0.01642455785591259, 'weights_17': 0.7421195814413556, 'weights_18': 0.8458208508276708, 'weights_19': 0.10226514673496065}. Best is trial 48 with value: 3251.2961228959116.\n",
      "[I 2025-08-01 08:05:20,382] Trial 52 finished with value: 3263.8090380096387 and parameters: {'weights_0': 0.232086211501826, 'weights_1': 0.8920324803887663, 'weights_2': 0.6502578844997252, 'weights_3': 0.4044951065498322, 'weights_4': 0.9416142617360218, 'weights_5': 0.7473135263712644, 'weights_6': 0.893475187417369, 'weights_7': 0.013511649289866118, 'weights_8': 0.1507647943561884, 'weights_9': 0.827011330468203, 'weights_10': 0.06128303657730419, 'weights_11': 0.9110399717613304, 'weights_12': 0.30873461704880845, 'weights_13': 0.814811902491186, 'weights_14': 0.7470081567213925, 'weights_15': 0.3098767428112061, 'weights_16': 0.01622831516823554, 'weights_17': 0.6049232959810898, 'weights_18': 0.796368928203872, 'weights_19': 0.08424639937639697}. Best is trial 48 with value: 3251.2961228959116.\n",
      "[I 2025-08-01 08:05:20,418] Trial 53 finished with value: 3224.9362061950283 and parameters: {'weights_0': 0.0038529908173651206, 'weights_1': 0.870151553982954, 'weights_2': 0.6394678143852417, 'weights_3': 0.42566172006580544, 'weights_4': 0.9585702290857843, 'weights_5': 0.7519125715561873, 'weights_6': 0.9091175671817712, 'weights_7': 0.008904934588378599, 'weights_8': 0.1367160130373878, 'weights_9': 0.8012318328256354, 'weights_10': 0.08125337031534295, 'weights_11': 0.9014885364634408, 'weights_12': 0.29767062354476814, 'weights_13': 0.8626454241395817, 'weights_14': 0.7568126707961582, 'weights_15': 0.4097696502224085, 'weights_16': 0.02903037656465931, 'weights_17': 0.6156195464348261, 'weights_18': 0.7864815198104049, 'weights_19': 0.0747015987516034}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,461] Trial 54 finished with value: 3233.523561181298 and parameters: {'weights_0': 0.00894791396512773, 'weights_1': 0.8670480063683196, 'weights_2': 0.6344026783191893, 'weights_3': 0.33228482045698315, 'weights_4': 0.9543462991009398, 'weights_5': 0.7447721845053678, 'weights_6': 0.9180446135747077, 'weights_7': 0.004987289767713718, 'weights_8': 0.15741724630227324, 'weights_9': 0.8284157654013499, 'weights_10': 0.07942023223486176, 'weights_11': 0.8978510261569802, 'weights_12': 0.2957314667313337, 'weights_13': 0.8669554678238035, 'weights_14': 0.7476691707328944, 'weights_15': 0.4201953997298097, 'weights_16': 0.05577926080192973, 'weights_17': 0.6050097630183664, 'weights_18': 0.7954195648706538, 'weights_19': 0.06852063840848893}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,511] Trial 55 finished with value: 3240.488867179907 and parameters: {'weights_0': 0.004633271939519444, 'weights_1': 0.8667493492762065, 'weights_2': 0.6262519565977918, 'weights_3': 0.32868491192590943, 'weights_4': 0.9502323931879306, 'weights_5': 0.7717910661499219, 'weights_6': 0.898839169475794, 'weights_7': 0.014144387519838661, 'weights_8': 0.15638600793004026, 'weights_9': 0.7905207671034743, 'weights_10': 0.08295930714064023, 'weights_11': 0.8946405593521523, 'weights_12': 0.29146326403532274, 'weights_13': 0.9666928757720947, 'weights_14': 0.7729920049981617, 'weights_15': 0.427049864431004, 'weights_16': 0.041798188220404174, 'weights_17': 0.5909143256344703, 'weights_18': 0.786854910014284, 'weights_19': 0.06619956033031178}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,557] Trial 56 finished with value: 3286.138192339079 and parameters: {'weights_0': 0.01186585624518604, 'weights_1': 0.9988726617339275, 'weights_2': 0.6032693078924936, 'weights_3': 0.4811143788151362, 'weights_4': 0.8645754819748164, 'weights_5': 0.785169615046426, 'weights_6': 0.7766270422191928, 'weights_7': 0.04921959905954972, 'weights_8': 0.2685527127313413, 'weights_9': 0.7896377558763656, 'weights_10': 0.18448321966150505, 'weights_11': 0.87019197589573, 'weights_12': 0.1930586343694406, 'weights_13': 0.9731856650626968, 'weights_14': 0.8983987880638615, 'weights_15': 0.4318146477049268, 'weights_16': 0.04538219175550624, 'weights_17': 0.46746423086013555, 'weights_18': 0.7314574675096781, 'weights_19': 0.05111631773890285}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,602] Trial 57 finished with value: 3309.5362742162492 and parameters: {'weights_0': 0.11029812722881804, 'weights_1': 0.9404118005603074, 'weights_2': 0.6234130776537691, 'weights_3': 0.31845268007434036, 'weights_4': 0.818990244631591, 'weights_5': 0.6305362397523855, 'weights_6': 0.8953416105407859, 'weights_7': 0.07187698516433705, 'weights_8': 0.206135405663101, 'weights_9': 0.7711516021738055, 'weights_10': 0.08921469342387173, 'weights_11': 0.9998512640017377, 'weights_12': 0.28920011015031855, 'weights_13': 0.874247668875097, 'weights_14': 0.7419554443838119, 'weights_15': 0.5441575072041531, 'weights_16': 0.10588992377339593, 'weights_17': 0.5710928290809775, 'weights_18': 0.8268603546856546, 'weights_19': 0.015516933263970203}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,667] Trial 58 finished with value: 3293.3035008870434 and parameters: {'weights_0': 0.015035046542685782, 'weights_1': 0.8399898944439579, 'weights_2': 0.676711052417029, 'weights_3': 0.4703412757148285, 'weights_4': 0.9558754250310968, 'weights_5': 0.8370149157486602, 'weights_6': 0.713197348861452, 'weights_7': 0.0029163921805337115, 'weights_8': 0.14856609613218064, 'weights_9': 0.8538970901901163, 'weights_10': 0.160832643152574, 'weights_11': 0.8771380498407059, 'weights_12': 0.2304819674028099, 'weights_13': 0.9511597120363352, 'weights_14': 0.868332132174386, 'weights_15': 0.39264443495115076, 'weights_16': 0.1835345216030819, 'weights_17': 0.6072285948938398, 'weights_18': 0.8510490659557988, 'weights_19': 0.1950082734195075}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,720] Trial 59 finished with value: 3359.213764057132 and parameters: {'weights_0': 0.06080758989107768, 'weights_1': 0.8451613207577908, 'weights_2': 0.5522598280205204, 'weights_3': 0.3526328846156467, 'weights_4': 0.8692214566472106, 'weights_5': 0.7202880899528268, 'weights_6': 0.9939323572456223, 'weights_7': 0.15347145326072015, 'weights_8': 0.9195067668661558, 'weights_9': 0.9127577312795838, 'weights_10': 0.21093125136454577, 'weights_11': 0.8333429608879532, 'weights_12': 0.5378276861446457, 'weights_13': 0.994071861312035, 'weights_14': 0.7849206579333565, 'weights_15': 0.610227955790283, 'weights_16': 0.05125994528977835, 'weights_17': 0.5404173904666897, 'weights_18': 0.7890281605708408, 'weights_19': 0.0972499280086569}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,761] Trial 60 finished with value: 3233.278135143852 and parameters: {'weights_0': 0.15660522905531776, 'weights_1': 0.941697288404147, 'weights_2': 0.917940949432303, 'weights_3': 0.2755736090552372, 'weights_4': 0.9603067571965163, 'weights_5': 0.8416851236861868, 'weights_6': 0.8310363782124892, 'weights_7': 0.0725562771046005, 'weights_8': 0.037970615443582434, 'weights_9': 0.8485723636709659, 'weights_10': 0.1551583306939503, 'weights_11': 0.9064873229009973, 'weights_12': 0.2789443886019, 'weights_13': 0.8984249126364328, 'weights_14': 0.6079129976279937, 'weights_15': 0.46007209574280644, 'weights_16': 0.10940728748100298, 'weights_17': 0.686731861608194, 'weights_18': 0.7082644423296975, 'weights_19': 0.000884823913507124}. Best is trial 53 with value: 3224.9362061950283.\n",
      "[I 2025-08-01 08:05:20,817] Trial 61 finished with value: 3207.5057727832705 and parameters: {'weights_0': 0.15349955645148183, 'weights_1': 0.932291800758333, 'weights_2': 0.9288916994418004, 'weights_3': 0.2834744713550645, 'weights_4': 0.9737464141589534, 'weights_5': 0.8514043382759051, 'weights_6': 0.8300077598082941, 'weights_7': 0.08738347633711316, 'weights_8': 0.04370112717744534, 'weights_9': 0.8456299388882854, 'weights_10': 0.07890067156526662, 'weights_11': 0.9129809367344696, 'weights_12': 0.2959282964535881, 'weights_13': 0.900267946585885, 'weights_14': 0.5991978395273398, 'weights_15': 0.45150313869849024, 'weights_16': 0.004752364861136818, 'weights_17': 0.6783381607843972, 'weights_18': 0.7035918316182134, 'weights_19': 0.008772549046450959}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:20,859] Trial 62 finished with value: 3276.118814920076 and parameters: {'weights_0': 0.14541339140866685, 'weights_1': 0.9462615110814006, 'weights_2': 0.9293349222640369, 'weights_3': 0.2712977286469378, 'weights_4': 0.9790264038940444, 'weights_5': 0.7905063381357219, 'weights_6': 0.9070800899822863, 'weights_7': 0.09413381158952264, 'weights_8': 0.044722297972905396, 'weights_9': 0.8540038923155399, 'weights_10': 0.03483420742757859, 'weights_11': 0.8690253513379322, 'weights_12': 0.8172668602605647, 'weights_13': 0.9077952647763875, 'weights_14': 0.6210283491301776, 'weights_15': 0.4477489037562013, 'weights_16': 0.113228557918254, 'weights_17': 0.6532010476769876, 'weights_18': 0.7035228735493837, 'weights_19': 0.002106746865058989}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:20,905] Trial 63 finished with value: 3251.890707238051 and parameters: {'weights_0': 0.03571163315896986, 'weights_1': 0.9155799078622491, 'weights_2': 0.9626631672898469, 'weights_3': 0.33302534408997714, 'weights_4': 0.9144062004436566, 'weights_5': 0.7466949393004725, 'weights_6': 0.7787621543849492, 'weights_7': 0.13959364172237437, 'weights_8': 0.042747480523277176, 'weights_9': 0.7839584157888395, 'weights_10': 0.14413258105786442, 'weights_11': 0.7339176975519979, 'weights_12': 0.2752359846222908, 'weights_13': 0.8587619210609342, 'weights_14': 0.5815763202903658, 'weights_15': 0.5143616913877109, 'weights_16': 0.18193067813924096, 'weights_17': 0.6779644913040624, 'weights_18': 0.7541369847222571, 'weights_19': 0.05464216215444667}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:20,953] Trial 64 finished with value: 3260.7270290887545 and parameters: {'weights_0': 0.07070650097392253, 'weights_1': 0.9605065426457581, 'weights_2': 0.9181166794265759, 'weights_3': 0.10146369060655569, 'weights_4': 0.8328330226099352, 'weights_5': 0.8534997022387015, 'weights_6': 0.8500350366218727, 'weights_7': 0.030708160396497895, 'weights_8': 0.1108618394250027, 'weights_9': 0.7371840268533856, 'weights_10': 0.09564990557155341, 'weights_11': 0.8199352955319144, 'weights_12': 0.1685786363001862, 'weights_13': 0.9675109686211039, 'weights_14': 0.4810427186430316, 'weights_15': 0.35870986500660984, 'weights_16': 0.08824913981798953, 'weights_17': 0.6251688697443009, 'weights_18': 0.7947161687463767, 'weights_19': 0.037747425606506395}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:20,993] Trial 65 finished with value: 3295.5937438938104 and parameters: {'weights_0': 0.08336184383205929, 'weights_1': 0.9079496469544369, 'weights_2': 0.9999703555524272, 'weights_3': 0.3017739325714532, 'weights_4': 0.962058227284625, 'weights_5': 0.7889050995939642, 'weights_6': 0.8175658150168369, 'weights_7': 0.08771307056322591, 'weights_8': 0.08657210421924035, 'weights_9': 0.9173585953912817, 'weights_10': 0.29268113324309963, 'weights_11': 0.972631906488047, 'weights_12': 0.21988845155284176, 'weights_13': 0.8845052561532031, 'weights_14': 0.7312981281658508, 'weights_15': 0.4705792887298862, 'weights_16': 0.045627340516083664, 'weights_17': 0.5291742485230795, 'weights_18': 0.7443308616975696, 'weights_19': 0.0717358478659173}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,050] Trial 66 finished with value: 3433.661019517994 and parameters: {'weights_0': 0.15034751667089072, 'weights_1': 0.8730730784100932, 'weights_2': 0.8528409789479278, 'weights_3': 0.2720334976372101, 'weights_4': 0.8077342287796756, 'weights_5': 0.6266627187997896, 'weights_6': 0.6442663220527923, 'weights_7': 0.0031068736836388135, 'weights_8': 0.047989906737301635, 'weights_9': 0.871254473499076, 'weights_10': 0.33447077263555225, 'weights_11': 0.8977401531796009, 'weights_12': 0.3863102507394647, 'weights_13': 0.9115558487459203, 'weights_14': 0.5971585114994231, 'weights_15': 0.4098068137657094, 'weights_16': 0.28385248880950115, 'weights_17': 0.6851012694256204, 'weights_18': 0.9060262193228139, 'weights_19': 0.19111266186636927}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,101] Trial 67 finished with value: 3278.1464012070883 and parameters: {'weights_0': 0.004826954772875954, 'weights_1': 0.9939440724311008, 'weights_2': 0.8815208998449388, 'weights_3': 0.34488812202293573, 'weights_4': 0.88231035542396, 'weights_5': 0.9333530736504451, 'weights_6': 0.7459535941400001, 'weights_7': 0.28507634824040856, 'weights_8': 0.24666801587540838, 'weights_9': 0.6861184712504901, 'weights_10': 0.16080099961904815, 'weights_11': 0.9572003924020329, 'weights_12': 0.45425291615416585, 'weights_13': 0.8524515201135429, 'weights_14': 0.5380257886019681, 'weights_15': 0.593645575552771, 'weights_16': 0.003607595740215061, 'weights_17': 0.44655146507948673, 'weights_18': 0.7220711007521039, 'weights_19': 0.11501272381673612}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,147] Trial 68 finished with value: 3325.6262640791824 and parameters: {'weights_0': 0.39884899957794523, 'weights_1': 0.7597441173057269, 'weights_2': 0.9583166033460507, 'weights_3': 0.4235175881735034, 'weights_4': 0.9647420299442172, 'weights_5': 0.7293522931721845, 'weights_6': 0.8895553102884391, 'weights_7': 0.04195216385972317, 'weights_8': 0.3360827868448042, 'weights_9': 0.636671880609658, 'weights_10': 0.07703222520119886, 'weights_11': 0.8492017745225036, 'weights_12': 0.3733802588978252, 'weights_13': 0.9526516528308393, 'weights_14': 0.8429812618002309, 'weights_15': 0.5233407636873136, 'weights_16': 0.15334620689058795, 'weights_17': 0.5865744877896559, 'weights_18': 0.6141796718642484, 'weights_19': 0.029743789987668946}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,190] Trial 69 finished with value: 3308.2135684565583 and parameters: {'weights_0': 0.13636164571689777, 'weights_1': 0.8362830980571249, 'weights_2': 0.6930646758116333, 'weights_3': 0.17843610741367655, 'weights_4': 0.9213384196130814, 'weights_5': 0.9028279026819644, 'weights_6': 0.82519378056125, 'weights_7': 0.1836812329518606, 'weights_8': 0.4713170344604874, 'weights_9': 0.8004377766344414, 'weights_10': 0.20896766275662798, 'weights_11': 0.8048330195564718, 'weights_12': 0.3226416202183949, 'weights_13': 0.7882148087247252, 'weights_14': 0.7165362641512742, 'weights_15': 0.45686428567681464, 'weights_16': 0.051666298275858974, 'weights_17': 0.7120617491379817, 'weights_18': 0.9816194958441359, 'weights_19': 0.0014731578319843452}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,240] Trial 70 finished with value: 3317.4650749676202 and parameters: {'weights_0': 0.03737589883136784, 'weights_1': 0.9267314476869478, 'weights_2': 0.586575159987818, 'weights_3': 0.46326771959360896, 'weights_4': 0.8627366157308751, 'weights_5': 0.764540662721734, 'weights_6': 0.9718433390451814, 'weights_7': 0.14917916061041353, 'weights_8': 0.20433336967818216, 'weights_9': 0.760020524040735, 'weights_10': 0.02501165570652497, 'weights_11': 0.9362810572397154, 'weights_12': 0.42927285863244813, 'weights_13': 0.9972126546851089, 'weights_14': 0.9456773436439823, 'weights_15': 0.3628590402392568, 'weights_16': 0.11646633144417776, 'weights_17': 0.39039966231130335, 'weights_18': 0.69694175130924, 'weights_19': 0.29022456524223783}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,575] Trial 71 finished with value: 3264.2492735187725 and parameters: {'weights_0': 0.038090986024672494, 'weights_1': 0.919354653483361, 'weights_2': 0.9607245153982037, 'weights_3': 0.32900935052769886, 'weights_4': 0.9151583343175331, 'weights_5': 0.7547022289338007, 'weights_6': 0.7764077226151134, 'weights_7': 0.12943276211688298, 'weights_8': 0.03387278164309249, 'weights_9': 0.789823570274692, 'weights_10': 0.1508454848867642, 'weights_11': 0.7195344894246083, 'weights_12': 0.27702236761062293, 'weights_13': 0.8417404139460662, 'weights_14': 0.5905992167174268, 'weights_15': 0.5171146763394244, 'weights_16': 0.17200494100539965, 'weights_17': 0.5206930743205118, 'weights_18': 0.7735885193394294, 'weights_19': 0.05785417529076168}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,707] Trial 72 finished with value: 3221.8048142844136 and parameters: {'weights_0': 0.09318963708503332, 'weights_1': 0.9739525277145578, 'weights_2': 0.9120735771619323, 'weights_3': 0.3486521968223453, 'weights_4': 0.9716758310409918, 'weights_5': 0.7091082925780788, 'weights_6': 0.9251614919780795, 'weights_7': 0.04767818931124961, 'weights_8': 0.05652346762001001, 'weights_9': 0.8468904622028627, 'weights_10': 0.10254166381322478, 'weights_11': 0.8796579137072509, 'weights_12': 0.2661828911039085, 'weights_13': 0.8663449439417565, 'weights_14': 0.47334064880503735, 'weights_15': 0.4974205736819194, 'weights_16': 0.03402518964037349, 'weights_17': 0.6264983592359364, 'weights_18': 0.7539260963930802, 'weights_19': 0.07819589722338535}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,776] Trial 73 finished with value: 3239.9711528761327 and parameters: {'weights_0': 0.08636697261322854, 'weights_1': 0.9720367662797491, 'weights_2': 0.9032501801363442, 'weights_3': 0.36018887399696864, 'weights_4': 0.9910000378017795, 'weights_5': 0.7031425674987598, 'weights_6': 0.910916519580512, 'weights_7': 0.0411703358724758, 'weights_8': 0.1372089743829258, 'weights_9': 0.9644765597651799, 'weights_10': 0.10103700352344103, 'weights_11': 0.8923826701267298, 'weights_12': 0.33115410547285296, 'weights_13': 0.8954862699135436, 'weights_14': 0.4715755003084111, 'weights_15': 0.5003865620667387, 'weights_16': 0.03936169737020457, 'weights_17': 0.6208940325668448, 'weights_18': 0.8283981958718695, 'weights_19': 0.09022704415697119}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,863] Trial 74 finished with value: 3245.316259122187 and parameters: {'weights_0': 0.08880173071489178, 'weights_1': 0.9781133527202277, 'weights_2': 0.9212563710643076, 'weights_3': 0.3672312029501688, 'weights_4': 0.9892846986182421, 'weights_5': 0.6920305383147306, 'weights_6': 0.9329923228389535, 'weights_7': 0.03560372855012215, 'weights_8': 0.13394448066790676, 'weights_9': 0.8438059773161516, 'weights_10': 0.1015713203169161, 'weights_11': 0.8891452259728296, 'weights_12': 0.3337556692279008, 'weights_13': 0.8861761742708127, 'weights_14': 0.4333228663548183, 'weights_15': 0.4923469934872526, 'weights_16': 0.04397453056837559, 'weights_17': 0.6191347961272592, 'weights_18': 0.8233554355184642, 'weights_19': 0.03422920447456168}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:21,990] Trial 75 finished with value: 3255.9563812104257 and parameters: {'weights_0': 0.08625674407310317, 'weights_1': 0.9491733743440096, 'weights_2': 0.9174591659716764, 'weights_3': 0.3655042490912325, 'weights_4': 0.9799005423165806, 'weights_5': 0.5624777507773059, 'weights_6': 0.9259287166381799, 'weights_7': 0.033351695299368024, 'weights_8': 0.12488571161026221, 'weights_9': 0.8426202241811941, 'weights_10': 0.1034067925272524, 'weights_11': 0.898632783185499, 'weights_12': 0.2080213017251794, 'weights_13': 0.8878270531186401, 'weights_14': 0.4751594329776268, 'weights_15': 0.5686062598183945, 'weights_16': 0.03486279345197161, 'weights_17': 0.6235279386566022, 'weights_18': 0.7938633341928923, 'weights_19': 0.08547665176175522}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:22,057] Trial 76 finished with value: 3405.477253040723 and parameters: {'weights_0': 0.09184907233290734, 'weights_1': 0.8925207383243677, 'weights_2': 0.900278304361151, 'weights_3': 0.30631832543999044, 'weights_4': 0.997080226286666, 'weights_5': 0.6255861651014508, 'weights_6': 0.9965769851339198, 'weights_7': 0.07263070308217029, 'weights_8': 0.06331621467763779, 'weights_9': 0.714277332892056, 'weights_10': 0.7737762085322673, 'weights_11': 0.8579761834766586, 'weights_12': 0.33155721600633203, 'weights_13': 0.8126029994388058, 'weights_14': 0.4532677578737233, 'weights_15': 0.4834335645911015, 'weights_16': 0.12732844781335162, 'weights_17': 0.5581700193363158, 'weights_18': 0.8575419308676712, 'weights_19': 0.03221317478628033}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:22,136] Trial 77 finished with value: 3359.243438406177 and parameters: {'weights_0': 0.13892411895554507, 'weights_1': 0.9682421385032224, 'weights_2': 0.976546243533166, 'weights_3': 0.2778980897098517, 'weights_4': 0.24233401778666963, 'weights_5': 0.48707779831698156, 'weights_6': 0.9550339111859321, 'weights_7': 0.043299907597191115, 'weights_8': 0.13582776611719202, 'weights_9': 0.8800280516604054, 'weights_10': 0.1836275551694955, 'weights_11': 0.7955789852227863, 'weights_12': 0.16548260929786918, 'weights_13': 0.882059094460986, 'weights_14': 0.3865124176432668, 'weights_15': 0.6269569165962778, 'weights_16': 0.09235274764031322, 'weights_17': 0.6023726738908581, 'weights_18': 0.6840973312797606, 'weights_19': 0.1185283391849119}. Best is trial 61 with value: 3207.5057727832705.\n",
      "[I 2025-08-01 08:05:22,201] Trial 78 finished with value: 3186.0809029868856 and parameters: {'weights_0': 0.11443322721494956, 'weights_1': 0.9320885880166205, 'weights_2': 0.4727386795314077, 'weights_3': 0.430168320175647, 'weights_4': 0.9710757780370776, 'weights_5': 0.7949520729311091, 'weights_6': 0.8379855774548823, 'weights_7': 0.09552145621819583, 'weights_8': 0.022186216526012385, 'weights_9': 0.7501065421276321, 'weights_10': 0.22068448697047527, 'weights_11': 0.8820388273995234, 'weights_12': 0.25043323968513104, 'weights_13': 0.063618520908304, 'weights_14': 0.4498833037644961, 'weights_15': 0.4267095126698469, 'weights_16': 0.03783592162431239, 'weights_17': 0.12158587456001557, 'weights_18': 0.7462159138987502, 'weights_19': 0.17180089887051583}. Best is trial 78 with value: 3186.0809029868856.\n",
      "[I 2025-08-01 08:05:22,258] Trial 79 finished with value: 3219.204804990452 and parameters: {'weights_0': 0.23326786211804187, 'weights_1': 0.8572305944599193, 'weights_2': 0.35147018823614945, 'weights_3': 0.4954451523229433, 'weights_4': 0.8925870948632584, 'weights_5': 0.799153797095239, 'weights_6': 0.8328349324859078, 'weights_7': 0.10848632692686813, 'weights_8': 0.024253901718588648, 'weights_9': 0.7534436398913186, 'weights_10': 0.2306795816918972, 'weights_11': 0.847094668450422, 'weights_12': 0.2423806190993976, 'weights_13': 0.016939274014609068, 'weights_14': 0.8099534779516916, 'weights_15': 0.4154586734278543, 'weights_16': 0.031152760080822288, 'weights_17': 0.03147220924917382, 'weights_18': 0.750004659291629, 'weights_19': 0.07349086910726282}. Best is trial 78 with value: 3186.0809029868856.\n",
      "[I 2025-08-01 08:05:22,319] Trial 80 finished with value: 3121.1492260929567 and parameters: {'weights_0': 0.22408588301799487, 'weights_1': 0.7951380046587728, 'weights_2': 0.3437998703113748, 'weights_3': 0.5013917037060782, 'weights_4': 0.8844962863744361, 'weights_5': 0.8743659582928233, 'weights_6': 0.838382181652078, 'weights_7': 0.09045923638551631, 'weights_8': 0.03193859873580292, 'weights_9': 0.7304351230690904, 'weights_10': 0.2251678774164325, 'weights_11': 0.8471111721320399, 'weights_12': 0.24466905353795326, 'weights_13': 0.013706785372419015, 'weights_14': 0.3621312904273251, 'weights_15': 0.45287658367242956, 'weights_16': 0.07296309263104582, 'weights_17': 0.14015218748656727, 'weights_18': 0.6382621299719263, 'weights_19': 0.1636847044098394}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,376] Trial 81 finished with value: 3153.0434589612764 and parameters: {'weights_0': 0.2242201881814118, 'weights_1': 0.7926699020801674, 'weights_2': 0.3455716968506446, 'weights_3': 0.49086697604984364, 'weights_4': 0.8881230107736878, 'weights_5': 0.87120565648601, 'weights_6': 0.718835512513485, 'weights_7': 0.09296755587237433, 'weights_8': 0.015275536063193328, 'weights_9': 0.7448834149908747, 'weights_10': 0.2298299580800053, 'weights_11': 0.8487362993248287, 'weights_12': 0.25199457300016426, 'weights_13': 0.007382643236205528, 'weights_14': 0.4207830972108826, 'weights_15': 0.4068078568236182, 'weights_16': 0.07028946763484689, 'weights_17': 0.05341635954759694, 'weights_18': 0.6227324917540004, 'weights_19': 0.18117455337863914}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,435] Trial 82 finished with value: 3158.21234436403 and parameters: {'weights_0': 0.35531033780434473, 'weights_1': 0.7863719485700799, 'weights_2': 0.26896392791401064, 'weights_3': 0.5027879512023236, 'weights_4': 0.8979182754391862, 'weights_5': 0.8961809314758518, 'weights_6': 0.8303620510521038, 'weights_7': 0.10503669493713752, 'weights_8': 0.029115441584530357, 'weights_9': 0.7446612684825669, 'weights_10': 0.31432303509349446, 'weights_11': 0.843758034252675, 'weights_12': 0.2543375160998219, 'weights_13': 0.00591721458359621, 'weights_14': 0.3552148930490542, 'weights_15': 0.4081104901886573, 'weights_16': 0.07362047175150953, 'weights_17': 0.049876366289344776, 'weights_18': 0.6247544087740133, 'weights_19': 0.17571297721602536}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,499] Trial 83 finished with value: 3141.081921639785 and parameters: {'weights_0': 0.26544266570376335, 'weights_1': 0.7313491330556662, 'weights_2': 0.26619635316005363, 'weights_3': 0.5078424541232555, 'weights_4': 0.8408398640712722, 'weights_5': 0.8805118354594268, 'weights_6': 0.8357782144900856, 'weights_7': 0.11647140282038049, 'weights_8': 0.021406156839383964, 'weights_9': 0.7487594718343749, 'weights_10': 0.27302020457533455, 'weights_11': 0.6845913020694327, 'weights_12': 0.2555531897428153, 'weights_13': 0.008243033154621295, 'weights_14': 0.3606708168106902, 'weights_15': 0.446675171358531, 'weights_16': 0.15276060707945502, 'weights_17': 0.04634562835962637, 'weights_18': 0.6274918089702948, 'weights_19': 0.28104721411456535}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,574] Trial 84 finished with value: 3187.3096485372357 and parameters: {'weights_0': 0.2651016090488692, 'weights_1': 0.7136275807797882, 'weights_2': 0.25581369281436994, 'weights_3': 0.5088085103853249, 'weights_4': 0.842222337102331, 'weights_5': 0.9425903307807018, 'weights_6': 0.7938717075931886, 'weights_7': 0.1642410226760691, 'weights_8': 0.022875125127463383, 'weights_9': 0.7428177321977043, 'weights_10': 0.36950744908919453, 'weights_11': 0.8416696694860704, 'weights_12': 0.25498309676054587, 'weights_13': 0.0014184618838551663, 'weights_14': 0.350826259818035, 'weights_15': 0.33605563411099226, 'weights_16': 0.14946239795178284, 'weights_17': 0.04151832745895216, 'weights_18': 0.550538218484254, 'weights_19': 0.37245851994042045}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,627] Trial 85 finished with value: 3208.2676445904267 and parameters: {'weights_0': 0.43971330272589654, 'weights_1': 0.6372518713741647, 'weights_2': 0.2677104650882325, 'weights_3': 0.5025309171687723, 'weights_4': 0.7929386825195093, 'weights_5': 0.9398416674679341, 'weights_6': 0.7283296320137862, 'weights_7': 0.16918543116743273, 'weights_8': 0.020410288665095845, 'weights_9': 0.6579721354460517, 'weights_10': 0.3672693026792921, 'weights_11': 0.6902725228285219, 'weights_12': 0.25340618794498715, 'weights_13': 0.00977865714868668, 'weights_14': 0.26790942650503113, 'weights_15': 0.33436844956353867, 'weights_16': 0.16295821243387423, 'weights_17': 0.04411489069834351, 'weights_18': 0.5341430313337068, 'weights_19': 0.4017240190187117}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,716] Trial 86 finished with value: 3194.9185918361136 and parameters: {'weights_0': 0.36078262091497787, 'weights_1': 0.7058585277696396, 'weights_2': 0.2615561373164824, 'weights_3': 0.5048429315057127, 'weights_4': 0.8014451421219163, 'weights_5': 0.9440493970772699, 'weights_6': 0.712544183869168, 'weights_7': 0.16946468140025145, 'weights_8': 0.02332674544152869, 'weights_9': 0.6373285954907474, 'weights_10': 0.36957387856429436, 'weights_11': 0.6924782289584233, 'weights_12': 0.2375964544842923, 'weights_13': 0.0010395341219339646, 'weights_14': 0.2786935742580169, 'weights_15': 0.3466217881084194, 'weights_16': 0.16119957337106583, 'weights_17': 0.054545899598710854, 'weights_18': 0.5290416874346253, 'weights_19': 0.3816222521595601}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:22,996] Trial 87 finished with value: 3193.55862696899 and parameters: {'weights_0': 0.4315739729126451, 'weights_1': 0.5812933617077264, 'weights_2': 0.2513981016480705, 'weights_3': 0.5672280715944845, 'weights_4': 0.7288813617993066, 'weights_5': 0.9330659908516883, 'weights_6': 0.7016261098426916, 'weights_7': 0.16227616329573608, 'weights_8': 0.005365595164641704, 'weights_9': 0.6851583046009113, 'weights_10': 0.3610166982128708, 'weights_11': 0.664558509427072, 'weights_12': 0.18431906017511007, 'weights_13': 0.06738672955470765, 'weights_14': 0.2645076210997289, 'weights_15': 0.3239029534031297, 'weights_16': 0.20691812423444392, 'weights_17': 0.07067046739862695, 'weights_18': 0.5222970561285366, 'weights_19': 0.3631312377757986}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,129] Trial 88 finished with value: 3188.6714674136365 and parameters: {'weights_0': 0.3630102833552002, 'weights_1': 0.692961621156367, 'weights_2': 0.2618641621303991, 'weights_3': 0.5501952198456271, 'weights_4': 0.7406538791594673, 'weights_5': 0.8924557871059454, 'weights_6': 0.6813981303155708, 'weights_7': 0.20819270431550313, 'weights_8': 0.007080894897549532, 'weights_9': 0.6950004159620051, 'weights_10': 0.3287849058998703, 'weights_11': 0.6594838103759273, 'weights_12': 0.16088374524250926, 'weights_13': 0.05424284117848932, 'weights_14': 0.3512037650328097, 'weights_15': 0.284049997448765, 'weights_16': 0.1914117441488464, 'weights_17': 0.11089523657185985, 'weights_18': 0.49167967428518056, 'weights_19': 0.32626463952251444}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,217] Trial 89 finished with value: 3273.3173769849795 and parameters: {'weights_0': 0.36677310240436267, 'weights_1': 0.7126323121228418, 'weights_2': 0.2506215058363437, 'weights_3': 0.5482207397528921, 'weights_4': 0.6760917509256794, 'weights_5': 0.8938683303704048, 'weights_6': 0.6722398374374198, 'weights_7': 0.20778932937907194, 'weights_8': 0.0004764236154092272, 'weights_9': 0.5782801587514275, 'weights_10': 0.5149465482204425, 'weights_11': 0.6484644934239889, 'weights_12': 0.16891110539291443, 'weights_13': 0.05415218977913201, 'weights_14': 0.3427319730398511, 'weights_15': 0.3015930809334191, 'weights_16': 0.2788266570522488, 'weights_17': 0.09792560004301415, 'weights_18': 0.4940691562042553, 'weights_19': 0.31762578711907885}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,335] Trial 90 finished with value: 3210.7119156251483 and parameters: {'weights_0': 0.35493614971862103, 'weights_1': 0.6529546986308188, 'weights_2': 0.3185778818726404, 'weights_3': 0.6490263278272905, 'weights_4': 0.7350507955919356, 'weights_5': 0.9789922021276486, 'weights_6': 0.6996406669848256, 'weights_7': 0.3316249043567036, 'weights_8': 0.06809127496347511, 'weights_9': 0.6941024446752273, 'weights_10': 0.3193103898389017, 'weights_11': 0.7317185008621582, 'weights_12': 0.20802847580639583, 'weights_13': 0.09831104851563428, 'weights_14': 0.26932354021785965, 'weights_15': 0.27785829877920604, 'weights_16': 0.2002491820670378, 'weights_17': 0.13195516475993893, 'weights_18': 0.5697913600153429, 'weights_19': 0.36798168389491553}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,459] Trial 91 finished with value: 3185.4158811387824 and parameters: {'weights_0': 0.2679647507074272, 'weights_1': 0.7201046987889562, 'weights_2': 0.19803563156282744, 'weights_3': 0.5798714612599583, 'weights_4': 0.7445737088884755, 'weights_5': 0.9480494330414876, 'weights_6': 0.6074819357212619, 'weights_7': 0.1465931772706629, 'weights_8': 0.0005434749463531022, 'weights_9': 0.6445135815618634, 'weights_10': 0.2876807846760915, 'weights_11': 0.6990075726824887, 'weights_12': 0.05031765391736409, 'weights_13': 0.14851827388716302, 'weights_14': 0.3606338531161387, 'weights_15': 0.35058638397792496, 'weights_16': 0.3391524713874533, 'weights_17': 0.1906908779245459, 'weights_18': 0.6156093554660786, 'weights_19': 0.2698729615574895}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,602] Trial 92 finished with value: 3203.669721015503 and parameters: {'weights_0': 0.37707910101133557, 'weights_1': 0.5543541127354721, 'weights_2': 0.21497797136182686, 'weights_3': 0.5559976151179225, 'weights_4': 0.751317112125855, 'weights_5': 0.9453780128105236, 'weights_6': 0.5789437132148924, 'weights_7': 0.15521950791776576, 'weights_8': 0.020383412153523944, 'weights_9': 0.6420678298049514, 'weights_10': 0.2714974125940084, 'weights_11': 0.6912328668477107, 'weights_12': 0.10998170082949008, 'weights_13': 0.15833556897661263, 'weights_14': 0.34930178556439256, 'weights_15': 0.34150150704578425, 'weights_16': 0.346043409340625, 'weights_17': 0.21358851510325275, 'weights_18': 0.6225682498428114, 'weights_19': 0.2698315092536273}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,706] Trial 93 finished with value: 3175.3308581751344 and parameters: {'weights_0': 0.4347556729660451, 'weights_1': 0.6116775939368964, 'weights_2': 0.18805874658808353, 'weights_3': 0.5234936236562945, 'weights_4': 0.6806711075399019, 'weights_5': 0.920182479034027, 'weights_6': 0.6592104714967815, 'weights_7': 0.11163176841350647, 'weights_8': 0.0016911968129320102, 'weights_9': 0.7252374629395364, 'weights_10': 0.3384977722237643, 'weights_11': 0.5992157527504537, 'weights_12': 0.04845392887424947, 'weights_13': 0.09846555445082905, 'weights_14': 0.29869698117643173, 'weights_15': 0.3577787611293059, 'weights_16': 0.2599823868954808, 'weights_17': 0.08724306018572252, 'weights_18': 0.5300910049287063, 'weights_19': 0.3375497548954201}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,820] Trial 94 finished with value: 3207.499463995878 and parameters: {'weights_0': 0.4359575066770728, 'weights_1': 0.725418476115089, 'weights_2': 0.09874953511060718, 'weights_3': 0.5806575829737679, 'weights_4': 0.6881611326568602, 'weights_5': 0.9151840030905288, 'weights_6': 0.6361970970947013, 'weights_7': 0.11665366966567281, 'weights_8': 0.0031151245826485964, 'weights_9': 0.7266763061228549, 'weights_10': 0.3405747292543496, 'weights_11': 0.5846017802051284, 'weights_12': 0.0569008558419362, 'weights_13': 0.12484613800784539, 'weights_14': 0.31597460609376365, 'weights_15': 0.37366712799199786, 'weights_16': 0.37752035248375704, 'weights_17': 0.09165649465185824, 'weights_18': 0.59312970362068, 'weights_19': 0.32861660945915694}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:23,941] Trial 95 finished with value: 3178.9699910847044 and parameters: {'weights_0': 0.26372786139081655, 'weights_1': 0.6182778917923915, 'weights_2': 0.19041610753020988, 'weights_3': 0.6037409606631886, 'weights_4': 0.5956618183489031, 'weights_5': 0.8774828124662081, 'weights_6': 0.5211552974194267, 'weights_7': 0.1966751397061564, 'weights_8': 0.08758329154421106, 'weights_9': 0.7112401449195508, 'weights_10': 0.2993114975624779, 'weights_11': 0.654587984359923, 'weights_12': 0.06620928094229662, 'weights_13': 0.05915052553055501, 'weights_14': 0.39787276286109713, 'weights_15': 0.32117014037026537, 'weights_16': 0.2517867449837047, 'weights_17': 0.17220430651207846, 'weights_18': 0.42133223329499336, 'weights_19': 0.3472652762217059}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,045] Trial 96 finished with value: 3140.386406901907 and parameters: {'weights_0': 0.2685469107989377, 'weights_1': 0.6008475719273273, 'weights_2': 0.18717597348419387, 'weights_3': 0.6130271859623883, 'weights_4': 0.6697077952221201, 'weights_5': 0.8882569779879919, 'weights_6': 0.5076440506008207, 'weights_7': 0.20712364286115093, 'weights_8': 0.10122176896092601, 'weights_9': 0.7093918513611266, 'weights_10': 0.2903281782197792, 'weights_11': 0.5886475507883078, 'weights_12': 0.07277199281394595, 'weights_13': 0.18806964704888768, 'weights_14': 0.41766086198713526, 'weights_15': 0.39493660421319376, 'weights_16': 0.2446141909971391, 'weights_17': 0.17186670401683496, 'weights_18': 0.41536483181012857, 'weights_19': 0.22378016051732624}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,171] Trial 97 finished with value: 3157.9166795109945 and parameters: {'weights_0': 0.26118652253589103, 'weights_1': 0.611735059956377, 'weights_2': 0.19581416046440062, 'weights_3': 0.6148617829344677, 'weights_4': 0.5682573034405936, 'weights_5': 0.8680045271454081, 'weights_6': 0.5412828227708517, 'weights_7': 0.27539132019868373, 'weights_8': 0.09826836063511327, 'weights_9': 0.6127692274841929, 'weights_10': 0.2881404078502903, 'weights_11': 0.4714107597760213, 'weights_12': 0.027893918483301996, 'weights_13': 0.17790997834489097, 'weights_14': 0.4202798387061671, 'weights_15': 0.3896780489651664, 'weights_16': 0.25754417701590143, 'weights_17': 0.18261283892063263, 'weights_18': 0.44591594976961185, 'weights_19': 0.2253837915970425}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,262] Trial 98 finished with value: 3157.7376077215786 and parameters: {'weights_0': 0.2816249524436038, 'weights_1': 0.5858359424529659, 'weights_2': 0.18821732775277117, 'weights_3': 0.616203365998051, 'weights_4': 0.5715447290689297, 'weights_5': 0.8756578025980587, 'weights_6': 0.5175485171164244, 'weights_7': 0.28215893645381923, 'weights_8': 0.09496128753348837, 'weights_9': 0.6083764771809164, 'weights_10': 0.28154769114720124, 'weights_11': 0.5095004030556395, 'weights_12': 0.02362816816422575, 'weights_13': 0.1890070311247799, 'weights_14': 0.41732957589326436, 'weights_15': 0.39407463734721737, 'weights_16': 0.2650591685815165, 'weights_17': 0.18887893130754851, 'weights_18': 0.4215110634781381, 'weights_19': 0.22041616996305446}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,435] Trial 99 finished with value: 3153.2420206750853 and parameters: {'weights_0': 0.2836451947945169, 'weights_1': 0.6012573103694923, 'weights_2': 0.18399925320908805, 'weights_3': 0.703736913114126, 'weights_4': 0.5912209300059754, 'weights_5': 0.864054744445894, 'weights_6': 0.503637091522019, 'weights_7': 0.29840141616187693, 'weights_8': 0.09688833225356894, 'weights_9': 0.5989359586445936, 'weights_10': 0.2902351474217158, 'weights_11': 0.5065222168219587, 'weights_12': 0.03423828731839792, 'weights_13': 0.18018270970056363, 'weights_14': 0.4103943217184442, 'weights_15': 0.3950980415158822, 'weights_16': 0.24939088495907796, 'weights_17': 0.20467501595571846, 'weights_18': 0.4081151382811083, 'weights_19': 0.22680289902112186}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,541] Trial 100 finished with value: 3141.199835048034 and parameters: {'weights_0': 0.3300074198833406, 'weights_1': 0.6070984912693093, 'weights_2': 0.11581579573904903, 'weights_3': 0.7040660227413801, 'weights_4': 0.5760729560739963, 'weights_5': 0.868846516311542, 'weights_6': 0.5105745226220308, 'weights_7': 0.27570961657663473, 'weights_8': 0.10067845860155349, 'weights_9': 0.5950808805943048, 'weights_10': 0.25161733154850996, 'weights_11': 0.5016627312221686, 'weights_12': 0.023820989985111566, 'weights_13': 0.21836334105138677, 'weights_14': 0.4031528800366429, 'weights_15': 0.39421771907902575, 'weights_16': 0.2543185307942969, 'weights_17': 0.27323665272147607, 'weights_18': 0.4099484592390403, 'weights_19': 0.2335164908772069}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,677] Trial 101 finished with value: 3135.1554717595627 and parameters: {'weights_0': 0.29243324386153335, 'weights_1': 0.5967615657292674, 'weights_2': 0.11463874995060319, 'weights_3': 0.622028246690503, 'weights_4': 0.5735593464429947, 'weights_5': 0.8693508719031234, 'weights_6': 0.5363595514250844, 'weights_7': 0.29641638848821117, 'weights_8': 0.09792037473711526, 'weights_9': 0.6001544002670078, 'weights_10': 0.24855245670178758, 'weights_11': 0.4966190019213086, 'weights_12': 0.06339008162692161, 'weights_13': 0.1865548754521298, 'weights_14': 0.412450462838949, 'weights_15': 0.39354935094455895, 'weights_16': 0.2570681030278518, 'weights_17': 0.24603702011630707, 'weights_18': 0.40900434418195325, 'weights_19': 0.22051124388086055}. Best is trial 80 with value: 3121.1492260929567.\n",
      "[I 2025-08-01 08:05:24,775] Trial 102 finished with value: 3109.9298775236566 and parameters: {'weights_0': 0.2878364821936763, 'weights_1': 0.592949868301583, 'weights_2': 0.03276796322073185, 'weights_3': 0.669940211129622, 'weights_4': 0.5439957423604002, 'weights_5': 0.8651209522377061, 'weights_6': 0.5085153462020282, 'weights_7': 0.35080535154925563, 'weights_8': 0.10316721825741182, 'weights_9': 0.610823563375601, 'weights_10': 0.24456142342173845, 'weights_11': 0.46766279056335713, 'weights_12': 0.028551002603086784, 'weights_13': 0.18583407648787562, 'weights_14': 0.4194205348632359, 'weights_15': 0.3941050660954603, 'weights_16': 0.31331085098835576, 'weights_17': 0.28026290421683336, 'weights_18': 0.32130291142775425, 'weights_19': 0.22439071259141258}. Best is trial 102 with value: 3109.9298775236566.\n",
      "[I 2025-08-01 08:05:24,892] Trial 103 finished with value: 3109.128217144603 and parameters: {'weights_0': 0.2940039996961811, 'weights_1': 0.5236777702270544, 'weights_2': 0.006137029051097188, 'weights_3': 0.7016327219898955, 'weights_4': 0.5273563435574409, 'weights_5': 0.8680909617813912, 'weights_6': 0.4523319228250197, 'weights_7': 0.28815216497182394, 'weights_8': 0.10277542922452984, 'weights_9': 0.5929077826195482, 'weights_10': 0.24365983407198727, 'weights_11': 0.490135984252694, 'weights_12': 0.025012271769550367, 'weights_13': 0.20146630674905738, 'weights_14': 0.42960879665056295, 'weights_15': 0.3951515909633541, 'weights_16': 0.3025187568457114, 'weights_17': 0.268246753503285, 'weights_18': 0.30865847057682094, 'weights_19': 0.23077962222746579}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,013] Trial 104 finished with value: 3118.732423444302 and parameters: {'weights_0': 0.33114454751091876, 'weights_1': 0.51170997489554, 'weights_2': 0.013549999733932266, 'weights_3': 0.7000200041442924, 'weights_4': 0.5366746832590591, 'weights_5': 0.8657433189095668, 'weights_6': 0.4600848862057724, 'weights_7': 0.3414247143765525, 'weights_8': 0.10780349702524986, 'weights_9': 0.6036244834048552, 'weights_10': 0.2408373997187038, 'weights_11': 0.5036410918123878, 'weights_12': 0.01736345589543411, 'weights_13': 0.20833334382089916, 'weights_14': 0.41693769685013715, 'weights_15': 0.39355297465363803, 'weights_16': 0.28449573077717516, 'weights_17': 0.27992459763653615, 'weights_18': 0.33059988741272966, 'weights_19': 0.21806557062579557}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,099] Trial 105 finished with value: 3124.5953875038986 and parameters: {'weights_0': 0.2940053743831616, 'weights_1': 0.5174357131591715, 'weights_2': 0.007827290125187467, 'weights_3': 0.6800162931380456, 'weights_4': 0.48729149257863774, 'weights_5': 0.8194113413038849, 'weights_6': 0.45770814658249087, 'weights_7': 0.34683839514845005, 'weights_8': 0.0679545105271187, 'weights_9': 0.5813989494000836, 'weights_10': 0.24385888866816824, 'weights_11': 0.5098438444595529, 'weights_12': 0.026264694973841332, 'weights_13': 0.22604985800629193, 'weights_14': 0.3869937748986934, 'weights_15': 0.43822087257231584, 'weights_16': 0.31163036161593693, 'weights_17': 0.27475429441474564, 'weights_18': 0.3071101040319845, 'weights_19': 0.2123124095801094}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,200] Trial 106 finished with value: 3133.994687966237 and parameters: {'weights_0': 0.2158898419702642, 'weights_1': 0.4540910735708162, 'weights_2': 0.01373495991348575, 'weights_3': 0.7080720985334034, 'weights_4': 0.48578284173672354, 'weights_5': 0.8186321972410766, 'weights_6': 0.44527516063560224, 'weights_7': 0.4188364842917157, 'weights_8': 0.17340938331077727, 'weights_9': 0.47515033391436834, 'weights_10': 0.25497701442490694, 'weights_11': 0.42678410754064344, 'weights_12': 0.08187928316344706, 'weights_13': 0.21481435748538136, 'weights_14': 0.3792928601677362, 'weights_15': 0.4429204287201218, 'weights_16': 0.29192249758766414, 'weights_17': 0.26886075691019945, 'weights_18': 0.29060532046351156, 'weights_19': 0.25562978172155554}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,357] Trial 107 finished with value: 3132.524333014113 and parameters: {'weights_0': 0.2114116877192469, 'weights_1': 0.4239732193507631, 'weights_2': 0.004941051879391069, 'weights_3': 0.6783659110673068, 'weights_4': 0.4761097054258766, 'weights_5': 0.8168338243984097, 'weights_6': 0.4578728601803122, 'weights_7': 0.35623767658705563, 'weights_8': 0.18461836220700728, 'weights_9': 0.4920773151314713, 'weights_10': 0.2488314373071953, 'weights_11': 0.4184864617404646, 'weights_12': 0.07587589338450192, 'weights_13': 0.2380569913929161, 'weights_14': 0.38464790401137045, 'weights_15': 0.46880768810819706, 'weights_16': 0.31401660988439095, 'weights_17': 0.2755517131421124, 'weights_18': 0.31552977580477254, 'weights_19': 0.26333208193218127}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,477] Trial 108 finished with value: 3140.211332521571 and parameters: {'weights_0': 0.32319115924332287, 'weights_1': 0.4568812111402096, 'weights_2': 0.017256543939024767, 'weights_3': 0.7304817816416338, 'weights_4': 0.4438215832025726, 'weights_5': 0.8202774067446444, 'weights_6': 0.44343874227772906, 'weights_7': 0.34535281654729044, 'weights_8': 0.18340072715324612, 'weights_9': 0.5756008836092326, 'weights_10': 0.24553834797269636, 'weights_11': 0.4078926489823762, 'weights_12': 0.07777346069628067, 'weights_13': 0.2336478812337463, 'weights_14': 0.32958739887475874, 'weights_15': 0.4428313000642636, 'weights_16': 0.3118458418551079, 'weights_17': 0.29049954705385966, 'weights_18': 0.32461680384517494, 'weights_19': 0.25627676021736767}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,576] Trial 109 finished with value: 3143.691509153311 and parameters: {'weights_0': 0.33029955248639625, 'weights_1': 0.43128049085748765, 'weights_2': 0.0029208662580126436, 'weights_3': 0.7399347027944327, 'weights_4': 0.4802400965089229, 'weights_5': 0.8213508009358857, 'weights_6': 0.47012549835356227, 'weights_7': 0.35352246313999997, 'weights_8': 0.1867129201722923, 'weights_9': 0.4853447705532485, 'weights_10': 0.20452469561975323, 'weights_11': 0.4289991258586073, 'weights_12': 0.08491660521273257, 'weights_13': 0.27660938212742775, 'weights_14': 0.38564772049825097, 'weights_15': 0.4445045740104281, 'weights_16': 0.3124933039160192, 'weights_17': 0.2956060666066067, 'weights_18': 0.3101716436528421, 'weights_19': 0.264831921488745}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,687] Trial 110 finished with value: 3136.1545654777906 and parameters: {'weights_0': 0.20683781332050222, 'weights_1': 0.5160616344575035, 'weights_2': 0.04416571675815621, 'weights_3': 0.6713276254175818, 'weights_4': 0.41274940586146247, 'weights_5': 0.8206104586576972, 'weights_6': 0.44039928196241124, 'weights_7': 0.41056143215826046, 'weights_8': 0.17496121580033486, 'weights_9': 0.46058252248030895, 'weights_10': 0.2513515689215091, 'weights_11': 0.39419480797158735, 'weights_12': 0.07682035577677923, 'weights_13': 0.25172630937004814, 'weights_14': 0.31533424498492024, 'weights_15': 0.5414380689093593, 'weights_16': 0.3740054339753316, 'weights_17': 0.2530426938328285, 'weights_18': 0.2836066034753215, 'weights_19': 0.20688680926634404}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,786] Trial 111 finished with value: 3165.7237250558683 and parameters: {'weights_0': 0.29623652998193084, 'weights_1': 0.5216510831046995, 'weights_2': 0.04075094960896197, 'weights_3': 0.7911349712302129, 'weights_4': 0.42893856321561624, 'weights_5': 0.8186733188017713, 'weights_6': 0.43907631454003637, 'weights_7': 0.423890205725132, 'weights_8': 0.17064553208787683, 'weights_9': 0.45047988398821026, 'weights_10': 0.2460317602150417, 'weights_11': 0.3892148615993939, 'weights_12': 0.07437617167074001, 'weights_13': 0.2499773888926515, 'weights_14': 0.3269337289433841, 'weights_15': 0.5490109891853497, 'weights_16': 0.3802323669544726, 'weights_17': 0.24378559269592234, 'weights_18': 0.2900752412107339, 'weights_19': 0.3037660545132449}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:25,932] Trial 112 finished with value: 3129.414004513389 and parameters: {'weights_0': 0.21923609937355165, 'weights_1': 0.4665127967582449, 'weights_2': 0.006257291872132086, 'weights_3': 0.6738741214104585, 'weights_4': 0.5203323554110886, 'weights_5': 0.8321872012337084, 'weights_6': 0.45741170363140093, 'weights_7': 0.37573080242783014, 'weights_8': 0.07374052651226878, 'weights_9': 0.41105517392160706, 'weights_10': 0.2662264223666225, 'weights_11': 0.4296001115206197, 'weights_12': 0.005699062320821194, 'weights_13': 0.3444248353550991, 'weights_14': 0.37970827415590697, 'weights_15': 0.4705907458872948, 'weights_16': 0.4407283610576248, 'weights_17': 0.33246578228917895, 'weights_18': 0.2246768752530729, 'weights_19': 0.2544133812820556}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,086] Trial 113 finished with value: 3131.348014449004 and parameters: {'weights_0': 0.20313097657375284, 'weights_1': 0.4642096600157505, 'weights_2': 0.0008350921966370495, 'weights_3': 0.6790336170431917, 'weights_4': 0.5233837054251738, 'weights_5': 0.8337346508331631, 'weights_6': 0.4538864815587627, 'weights_7': 0.368193709675396, 'weights_8': 0.17408838328067147, 'weights_9': 0.4054184162771546, 'weights_10': 0.24440994428889407, 'weights_11': 0.45672483879381304, 'weights_12': 0.0007273992332226045, 'weights_13': 0.3424576084418871, 'weights_14': 0.3762843122777799, 'weights_15': 0.46453494809260987, 'weights_16': 0.4430368074222031, 'weights_17': 0.3555421338057711, 'weights_18': 0.2119754681703495, 'weights_19': 0.25359635848767714}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,194] Trial 114 finished with value: 3133.496671282723 and parameters: {'weights_0': 0.21063825081413606, 'weights_1': 0.4734617048851161, 'weights_2': 0.002570910265183744, 'weights_3': 0.6742644818640386, 'weights_4': 0.5234378476941416, 'weights_5': 0.836262533184323, 'weights_6': 0.4497052942761834, 'weights_7': 0.3717425533232425, 'weights_8': 0.17042768703726913, 'weights_9': 0.41862030633739594, 'weights_10': 0.24484785972255976, 'weights_11': 0.4340105292335113, 'weights_12': 0.005408160974914412, 'weights_13': 0.36079082512078375, 'weights_14': 0.3714279424877298, 'weights_15': 0.47091923410854675, 'weights_16': 0.4574274804844964, 'weights_17': 0.3516965110315013, 'weights_18': 0.21629170705990614, 'weights_19': 0.2541256131864427}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,302] Trial 115 finished with value: 3122.796742659054 and parameters: {'weights_0': 0.20405596751985122, 'weights_1': 0.48918228760727206, 'weights_2': 0.07225869619907924, 'weights_3': 0.6680026289908313, 'weights_4': 0.5192662307576595, 'weights_5': 0.8508400380179121, 'weights_6': 0.4056019998582804, 'weights_7': 0.3735461168917403, 'weights_8': 0.21672466953907538, 'weights_9': 0.4045523826908565, 'weights_10': 0.18153557685909172, 'weights_11': 0.4415020586951677, 'weights_12': 0.0062617284767886305, 'weights_13': 0.35479153793763774, 'weights_14': 0.37626195294757225, 'weights_15': 0.4738960662828163, 'weights_16': 0.4536090875128683, 'weights_17': 0.3388068341209036, 'weights_18': 0.19638280467726107, 'weights_19': 0.21062674853006758}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,446] Trial 116 finished with value: 3135.127374122871 and parameters: {'weights_0': 0.21248719093318572, 'weights_1': 0.38357921114136, 'weights_2': 0.07834685930799251, 'weights_3': 0.642338293336177, 'weights_4': 0.5202678197395122, 'weights_5': 0.8422643478003491, 'weights_6': 0.39866893223429467, 'weights_7': 0.3806432527658694, 'weights_8': 0.2060724761810183, 'weights_9': 0.40422972680008595, 'weights_10': 0.18972267386252195, 'weights_11': 0.44896750475540625, 'weights_12': 0.0007399543735684948, 'weights_13': 0.3325876830016903, 'weights_14': 0.37669780682276294, 'weights_15': 0.4710357728518113, 'weights_16': 0.46941375956720144, 'weights_17': 0.3349996302647033, 'weights_18': 0.21083103292323205, 'weights_19': 0.24868646169333913}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,557] Trial 117 finished with value: 3111.3664408285536 and parameters: {'weights_0': 0.1818155928149171, 'weights_1': 0.4135197085612967, 'weights_2': 0.08535413935286044, 'weights_3': 0.6598305977411891, 'weights_4': 0.5228539940998568, 'weights_5': 0.8452408733641441, 'weights_6': 0.4053718621239926, 'weights_7': 0.37400402420022105, 'weights_8': 0.20099451409046595, 'weights_9': 0.3992145597151905, 'weights_10': 0.19892584672149613, 'weights_11': 0.344214593051102, 'weights_12': 0.004078039524189905, 'weights_13': 0.33886837301716216, 'weights_14': 0.38029776349183053, 'weights_15': 0.47903448891231926, 'weights_16': 0.4688800645733032, 'weights_17': 0.346005553055461, 'weights_18': 0.203341713173805, 'weights_19': 0.25195368025995496}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,691] Trial 118 finished with value: 3144.1339795810904 and parameters: {'weights_0': 0.17811642316703402, 'weights_1': 0.4720576888812328, 'weights_2': 0.030431438869656283, 'weights_3': 0.6879641365501333, 'weights_4': 0.544341959809416, 'weights_5': 0.776616661238902, 'weights_6': 0.45967983884652336, 'weights_7': 0.49123086284890305, 'weights_8': 0.25287776130776835, 'weights_9': 0.31986115347313904, 'weights_10': 0.2040657153669163, 'weights_11': 0.358695507430629, 'weights_12': 0.01618067692731081, 'weights_13': 0.37858806420302066, 'weights_14': 0.3767286951297856, 'weights_15': 0.48029873363459363, 'weights_16': 0.5385552185989781, 'weights_17': 0.3343626864502154, 'weights_18': 0.142002436694189, 'weights_19': 0.20324117360624572}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:26,862] Trial 119 finished with value: 3134.459085488822 and parameters: {'weights_0': 0.2417954147484412, 'weights_1': 0.42440857450401964, 'weights_2': 0.06602786771954308, 'weights_3': 0.6727752197217481, 'weights_4': 0.4849741259875452, 'weights_5': 0.8482505762400697, 'weights_6': 0.370804957039267, 'weights_7': 0.36955781206919924, 'weights_8': 0.2266636800838373, 'weights_9': 0.414269718165742, 'weights_10': 0.17780279809624008, 'weights_11': 0.44572596109738777, 'weights_12': 0.0004938571932135358, 'weights_13': 0.42212194278422244, 'weights_14': 0.4340174742696548, 'weights_15': 0.5274636105114443, 'weights_16': 0.4371230727934145, 'weights_17': 0.35661599648353626, 'weights_18': 0.22092075526144453, 'weights_19': 0.16301379665573057}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,014] Trial 120 finished with value: 3274.5917079401447 and parameters: {'weights_0': 0.16878572147568804, 'weights_1': 0.4872521005915286, 'weights_2': 0.002810513923637962, 'weights_3': 0.7583044344026902, 'weights_4': 0.5060808432859563, 'weights_5': 0.32962643786589707, 'weights_6': 0.4841966758989501, 'weights_7': 0.44129847940214256, 'weights_8': 0.2723884080269714, 'weights_9': 0.3819748831629363, 'weights_10': 0.21400480563292323, 'weights_11': 0.3301471236507051, 'weights_12': 0.10345918812314145, 'weights_13': 0.35553052938214474, 'weights_14': 0.494328824297864, 'weights_15': 0.5791904532211003, 'weights_16': 0.5075133778948162, 'weights_17': 0.39374034783669165, 'weights_18': 0.17283643593354336, 'weights_19': 0.28513875536718775}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,146] Trial 121 finished with value: 3390.6025769987036 and parameters: {'weights_0': 0.24076565908300968, 'weights_1': 0.41160578473238624, 'weights_2': 0.06092886032001059, 'weights_3': 0.6576753472629181, 'weights_4': 0.47173307455444247, 'weights_5': 0.1566884165184067, 'weights_6': 0.41252793484308664, 'weights_7': 0.36640890089597417, 'weights_8': 0.30358700648369297, 'weights_9': 0.4046782937985877, 'weights_10': 0.18891098711305737, 'weights_11': 0.44350302185438795, 'weights_12': 0.0014136234281802327, 'weights_13': 0.41451077409063064, 'weights_14': 0.4492051382061008, 'weights_15': 0.525870396575278, 'weights_16': 0.4408109689304112, 'weights_17': 0.3351710139345997, 'weights_18': 0.23463674170037468, 'weights_19': 0.24776463474133864}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,301] Trial 122 finished with value: 3255.8715974219394 and parameters: {'weights_0': 0.22026839784972702, 'weights_1': 0.35422191947217246, 'weights_2': 0.08136059886663932, 'weights_3': 0.7677714923747403, 'weights_4': 0.3580066055511885, 'weights_5': 0.839247265586591, 'weights_6': 0.32382537040880277, 'weights_7': 0.40207476395649994, 'weights_8': 0.22213625648967958, 'weights_9': 0.3518733050474225, 'weights_10': 0.22937755460863454, 'weights_11': 0.4673461447303672, 'weights_12': 0.03871064810520193, 'weights_13': 0.4323490991025128, 'weights_14': 0.3808976923311456, 'weights_15': 0.5071401445924979, 'weights_16': 0.4741845988939715, 'weights_17': 0.31573020517984546, 'weights_18': 0.35252835084296635, 'weights_19': 0.3057491469823763}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,537] Trial 123 finished with value: 3169.0334476322296 and parameters: {'weights_0': 0.24167028981885702, 'weights_1': 0.43861607786083573, 'weights_2': 0.06331042360402143, 'weights_3': 0.7191790101440091, 'weights_4': 0.4929950712827945, 'weights_5': 0.7985696700443986, 'weights_6': 0.368197896666461, 'weights_7': 0.3294337363819395, 'weights_8': 0.16264082704728994, 'weights_9': 0.514384216277771, 'weights_10': 0.26971044428352553, 'weights_11': 0.4254546798483072, 'weights_12': 0.1304816299907511, 'weights_13': 0.2986028334139116, 'weights_14': 0.43114848815424867, 'weights_15': 0.46043129428451546, 'weights_16': 0.5273382762588883, 'weights_17': 0.380137824942334, 'weights_18': 0.2476000483656507, 'weights_19': 0.16632484918280582}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,644] Trial 124 finished with value: 3128.370531963595 and parameters: {'weights_0': 0.19316026180194415, 'weights_1': 0.5286151322045123, 'weights_2': 0.0258789258394206, 'weights_3': 0.6816117880165256, 'weights_4': 0.4536049701723058, 'weights_5': 0.9127488661934736, 'weights_6': 0.41908811364024884, 'weights_7': 0.47691085307648995, 'weights_8': 0.1940836138493533, 'weights_9': 0.42020294810092634, 'weights_10': 0.17079764866718286, 'weights_11': 0.5297515163094165, 'weights_12': 0.017991364100949057, 'weights_13': 0.3658415336361125, 'weights_14': 0.44313838809257533, 'weights_15': 0.4797871816100811, 'weights_16': 0.44715738702145474, 'weights_17': 0.3719919143698973, 'weights_18': 0.19644223729510896, 'weights_19': 0.19339061355753184}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,773] Trial 125 finished with value: 3132.1664704164623 and parameters: {'weights_0': 0.19307351042229448, 'weights_1': 0.5314919173220647, 'weights_2': 0.02195126449117627, 'weights_3': 0.71618127265352, 'weights_4': 0.5445817256367439, 'weights_5': 0.9101740425045503, 'weights_6': 0.4160899777746089, 'weights_7': 0.4823308493696561, 'weights_8': 0.1971191038709031, 'weights_9': 0.3257223464268166, 'weights_10': 0.1683863298691992, 'weights_11': 0.5270199574280677, 'weights_12': 0.020259064486712147, 'weights_13': 0.3259361254350395, 'weights_14': 0.464468739560404, 'weights_15': 0.4743921125694158, 'weights_16': 0.4547824046439116, 'weights_17': 0.26613222292052496, 'weights_18': 0.18216326787578763, 'weights_19': 0.1900784572728253}. Best is trial 103 with value: 3109.128217144603.\n",
      "[I 2025-08-01 08:05:27,876] Trial 126 finished with value: 3108.8409502513878 and parameters: {'weights_0': 0.18433178523891874, 'weights_1': 0.5268332976442236, 'weights_2': 0.03195971065869024, 'weights_3': 0.8398562248180177, 'weights_4': 0.5505389236266317, 'weights_5': 0.9073500871731897, 'weights_6': 0.4157323766998847, 'weights_7': 0.4807258677843229, 'weights_8': 0.1985899702638874, 'weights_9': 0.28312170438330053, 'weights_10': 0.14945701342419807, 'weights_11': 0.4837799168996839, 'weights_12': 0.032532248972663685, 'weights_13': 0.37627360159132095, 'weights_14': 0.4653308827741072, 'weights_15': 0.4820269899609184, 'weights_16': 0.5883750893981285, 'weights_17': 0.40939368368079687, 'weights_18': 0.12125944400729972, 'weights_19': 0.13396493763068423}. Best is trial 126 with value: 3108.8409502513878.\n",
      "[I 2025-08-01 08:05:27,996] Trial 127 finished with value: 3126.539752127047 and parameters: {'weights_0': 0.18083243356350373, 'weights_1': 0.5291704203034818, 'weights_2': 0.03779880230731992, 'weights_3': 0.9292092128943339, 'weights_4': 0.5380701187818434, 'weights_5': 0.9088255247881946, 'weights_6': 0.38654879233561434, 'weights_7': 0.47819970533971434, 'weights_8': 0.1994191452324293, 'weights_9': 0.32210254480122, 'weights_10': 0.16860611620128993, 'weights_11': 0.53256384838775, 'weights_12': 0.04142616583507427, 'weights_13': 0.29558377707518235, 'weights_14': 0.5066224759445861, 'weights_15': 0.48965608220277085, 'weights_16': 0.586603604295913, 'weights_17': 0.4062832997046862, 'weights_18': 0.1430209181337956, 'weights_19': 0.1884546733851022}. Best is trial 126 with value: 3108.8409502513878.\n",
      "[I 2025-08-01 08:05:28,106] Trial 128 finished with value: 3106.423383740086 and parameters: {'weights_0': 0.1914164830934053, 'weights_1': 0.5387315953901048, 'weights_2': 0.03079389680659967, 'weights_3': 0.9633661134095735, 'weights_4': 0.45601263236202855, 'weights_5': 0.9845096323170959, 'weights_6': 0.41033521778659976, 'weights_7': 0.5198556232938737, 'weights_8': 0.28232752104625314, 'weights_9': 0.22122656254882317, 'weights_10': 0.13667228003954418, 'weights_11': 0.5319396837374356, 'weights_12': 0.03664526535567526, 'weights_13': 0.3175952429899818, 'weights_14': 0.5012218085204436, 'weights_15': 0.5036995965938165, 'weights_16': 0.5734763105558489, 'weights_17': 0.42905296456191744, 'weights_18': 0.08850734129741492, 'weights_19': 0.12496872061994382}. Best is trial 128 with value: 3106.423383740086.\n",
      "[I 2025-08-01 08:05:28,209] Trial 129 finished with value: 3185.6785289864297 and parameters: {'weights_0': 0.16693482796919829, 'weights_1': 0.5484209455405089, 'weights_2': 0.04713270124611396, 'weights_3': 0.9779575271375955, 'weights_4': 0.457138188075492, 'weights_5': 0.9982176654147015, 'weights_6': 0.287401522240721, 'weights_7': 0.5120052744724783, 'weights_8': 0.6793380932984677, 'weights_9': 0.2355546149633569, 'weights_10': 0.13848980675541786, 'weights_11': 0.5596903571119857, 'weights_12': 0.04374537890623595, 'weights_13': 0.2952557029136554, 'weights_14': 0.5015548885875117, 'weights_15': 0.4979589319838199, 'weights_16': 0.572891922474126, 'weights_17': 0.42878010053141963, 'weights_18': 0.11230330242134653, 'weights_19': 0.13060576042983205}. Best is trial 128 with value: 3106.423383740086.\n",
      "[I 2025-08-01 08:05:28,308] Trial 130 finished with value: 3086.453670329305 and parameters: {'weights_0': 0.12463427999476505, 'weights_1': 0.49998302396718264, 'weights_2': 0.14905422845905492, 'weights_3': 0.935553588142254, 'weights_4': 0.6081968405344104, 'weights_5': 0.9774601349670854, 'weights_6': 0.3428493156348761, 'weights_7': 0.5505707052191766, 'weights_8': 0.12079693837651151, 'weights_9': 0.25110281059290485, 'weights_10': 0.16154164037348845, 'weights_11': 0.47452964445109524, 'weights_12': 0.10202067426544305, 'weights_13': 0.27356404517860833, 'weights_14': 0.523214815381923, 'weights_15': 0.5355417886027596, 'weights_16': 0.62722022811295, 'weights_17': 0.4114009800200278, 'weights_18': 0.07695463570984132, 'weights_19': 0.14633997818640154}. Best is trial 130 with value: 3086.453670329305.\n",
      "[I 2025-08-01 08:05:28,429] Trial 131 finished with value: 3106.246758315535 and parameters: {'weights_0': 0.1822760359798251, 'weights_1': 0.5037085777406952, 'weights_2': 0.14760680873822712, 'weights_3': 0.888127226620576, 'weights_4': 0.5484669495988088, 'weights_5': 0.9691622168582558, 'weights_6': 0.3441953760697524, 'weights_7': 0.5785650175923303, 'weights_8': 0.12885331598878985, 'weights_9': 0.16859554513423525, 'weights_10': 0.14124120885324332, 'weights_11': 0.4795900814556062, 'weights_12': 0.042728388648827414, 'weights_13': 0.27284335529984544, 'weights_14': 0.5099744247940918, 'weights_15': 0.5486697758015978, 'weights_16': 0.6405305720933465, 'weights_17': 0.40524806565074606, 'weights_18': 0.06327904599956198, 'weights_19': 0.1462253562918331}. Best is trial 130 with value: 3086.453670329305.\n",
      "[I 2025-08-01 08:05:28,540] Trial 132 finished with value: 3095.020153083794 and parameters: {'weights_0': 0.13379817315889408, 'weights_1': 0.4920947292017118, 'weights_2': 0.1499528615566247, 'weights_3': 0.9123714605785032, 'weights_4': 0.6132615954712515, 'weights_5': 0.9722979616956757, 'weights_6': 0.3495379367547144, 'weights_7': 0.543315431822722, 'weights_8': 0.11426290940863837, 'weights_9': 0.17751248904431294, 'weights_10': 0.12516559686427406, 'weights_11': 0.5244541883994036, 'weights_12': 0.10694908769516909, 'weights_13': 0.2813344241434806, 'weights_14': 0.5489756697901146, 'weights_15': 0.5571284057883787, 'weights_16': 0.6437324095446265, 'weights_17': 0.4061467690543594, 'weights_18': 0.06359550647576603, 'weights_19': 0.1312099891047509}. Best is trial 130 with value: 3086.453670329305.\n",
      "[I 2025-08-01 08:05:28,666] Trial 133 finished with value: 3085.2570839966597 and parameters: {'weights_0': 0.13103092658021792, 'weights_1': 0.5011612263982292, 'weights_2': 0.14316814600949707, 'weights_3': 0.9207879611361061, 'weights_4': 0.60837363995986, 'weights_5': 0.9705944968037683, 'weights_6': 0.3388488939080106, 'weights_7': 0.5462623908186075, 'weights_8': 0.11683914656586518, 'weights_9': 0.1637853028176924, 'weights_10': 0.13364112083250812, 'weights_11': 0.4825019204646201, 'weights_12': 0.11174924344145785, 'weights_13': 0.2723982248080293, 'weights_14': 0.5336209871753503, 'weights_15': 0.6036220741891637, 'weights_16': 0.6415197266758363, 'weights_17': 0.4099648926158522, 'weights_18': 0.056247392211530425, 'weights_19': 0.14031670611509117}. Best is trial 133 with value: 3085.2570839966597.\n",
      "[I 2025-08-01 08:05:28,812] Trial 134 finished with value: 3088.674185272089 and parameters: {'weights_0': 0.13159510298991522, 'weights_1': 0.507481152069654, 'weights_2': 0.15010173995611198, 'weights_3': 0.9185519869570931, 'weights_4': 0.6197891642042653, 'weights_5': 0.9660495548574235, 'weights_6': 0.34466846983684235, 'weights_7': 0.5598296208814405, 'weights_8': 0.11915296431391306, 'weights_9': 0.18034228814061742, 'weights_10': 0.1268209372565848, 'weights_11': 0.47744101116096943, 'weights_12': 0.10879059541630952, 'weights_13': 0.28677504502284507, 'weights_14': 0.5555023824352822, 'weights_15': 0.6374863498308347, 'weights_16': 0.673803191426429, 'weights_17': 0.4158419178855971, 'weights_18': 0.061634338427168645, 'weights_19': 0.13766906621821584}. Best is trial 133 with value: 3085.2570839966597.\n",
      "[I 2025-08-01 08:05:28,916] Trial 135 finished with value: 3090.8152997417337 and parameters: {'weights_0': 0.15700366937051832, 'weights_1': 0.5023568126244924, 'weights_2': 0.15507107022648967, 'weights_3': 0.8754058191419216, 'weights_4': 0.6184519283359488, 'weights_5': 0.9742160968351828, 'weights_6': 0.31653546377454467, 'weights_7': 0.5642484754767446, 'weights_8': 0.12210253136522248, 'weights_9': 0.1523171287320397, 'weights_10': 0.1297048747528803, 'weights_11': 0.4841711128117579, 'weights_12': 0.12060040401613356, 'weights_13': 0.26074302765680435, 'weights_14': 0.5544046273161606, 'weights_15': 0.6385718591832842, 'weights_16': 0.6427226418727396, 'weights_17': 0.4279681586776562, 'weights_18': 0.04605905662219512, 'weights_19': 0.13496237666125363}. Best is trial 133 with value: 3085.2570839966597.\n",
      "[I 2025-08-01 08:05:29,030] Trial 136 finished with value: 3079.649989930066 and parameters: {'weights_0': 0.128570474692836, 'weights_1': 0.5001795121440339, 'weights_2': 0.14208671714738852, 'weights_3': 0.8635269909845479, 'weights_4': 0.616049833192983, 'weights_5': 0.9704702962217695, 'weights_6': 0.3409628518797536, 'weights_7': 0.5551482813478426, 'weights_8': 0.13237262198894087, 'weights_9': 0.12544014896242212, 'weights_10': 0.12219948142554077, 'weights_11': 0.473501010462753, 'weights_12': 0.11032583503021602, 'weights_13': 0.2756589666651456, 'weights_14': 0.5544237306219627, 'weights_15': 0.6459077697192623, 'weights_16': 0.6432919787609757, 'weights_17': 0.47320273957110826, 'weights_18': 0.04781690606494157, 'weights_19': 0.13068409003811768}. Best is trial 136 with value: 3079.649989930066.\n",
      "[I 2025-08-01 08:05:29,141] Trial 137 finished with value: 3074.1972226519824 and parameters: {'weights_0': 0.13441046007093385, 'weights_1': 0.5004049832428095, 'weights_2': 0.14754223557167412, 'weights_3': 0.8624285820967954, 'weights_4': 0.6198079292293128, 'weights_5': 0.9686636896141033, 'weights_6': 0.34190556184670634, 'weights_7': 0.5597182043230992, 'weights_8': 0.12298212562980115, 'weights_9': 0.13472987214934526, 'weights_10': 0.12272845657294265, 'weights_11': 0.4679174101025969, 'weights_12': 0.12016000652691973, 'weights_13': 0.2704910001565248, 'weights_14': 0.543867123470773, 'weights_15': 0.6842850643974844, 'weights_16': 0.653581190801497, 'weights_17': 0.4681256035604444, 'weights_18': 0.04134424260281159, 'weights_19': 0.1343443662043775}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,254] Trial 138 finished with value: 3078.8454870533983 and parameters: {'weights_0': 0.12398259733582473, 'weights_1': 0.563263111488161, 'weights_2': 0.1456957249286848, 'weights_3': 0.8830201002836139, 'weights_4': 0.6161528035752707, 'weights_5': 0.9743048042436734, 'weights_6': 0.3363415426269806, 'weights_7': 0.5556881730568699, 'weights_8': 0.11880081341888465, 'weights_9': 0.12690089145818217, 'weights_10': 0.12195210577144061, 'weights_11': 0.48020406161909235, 'weights_12': 0.11857235444941903, 'weights_13': 0.26886256663365676, 'weights_14': 0.5571052345818528, 'weights_15': 0.6717037027021868, 'weights_16': 0.6465729545193297, 'weights_17': 0.46027471903650446, 'weights_18': 0.04299749809198093, 'weights_19': 0.12641325376911133}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,343] Trial 139 finished with value: 3087.444540403788 and parameters: {'weights_0': 0.1286366720328891, 'weights_1': 0.5586918992805304, 'weights_2': 0.16193198992888944, 'weights_3': 0.8711262142856318, 'weights_4': 0.6125453401144041, 'weights_5': 0.9685639792529985, 'weights_6': 0.3422220057916977, 'weights_7': 0.5539104079253517, 'weights_8': 0.12529324632863392, 'weights_9': 0.13864688876776743, 'weights_10': 0.12192996046276253, 'weights_11': 0.47836293757357373, 'weights_12': 0.1448232526000491, 'weights_13': 0.27168563152045716, 'weights_14': 0.5625776534039085, 'weights_15': 0.6724115637704301, 'weights_16': 0.6452341153885555, 'weights_17': 0.4426148811801052, 'weights_18': 0.0413824879362797, 'weights_19': 0.12895875184623787}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,449] Trial 140 finished with value: 3093.9851541901853 and parameters: {'weights_0': 0.12489650081035991, 'weights_1': 0.5645189301497192, 'weights_2': 0.1517151400284719, 'weights_3': 0.8660256605841048, 'weights_4': 0.6131810549502988, 'weights_5': 0.9672491176807811, 'weights_6': 0.2635311709401258, 'weights_7': 0.548042108049458, 'weights_8': 0.12613595022717233, 'weights_9': 0.12371783382260347, 'weights_10': 0.12166983180810939, 'weights_11': 0.47132852373623474, 'weights_12': 0.14540695393790515, 'weights_13': 0.270201929515351, 'weights_14': 0.5664226921830551, 'weights_15': 0.7061467349339517, 'weights_16': 0.6450353150979432, 'weights_17': 0.46533253458100265, 'weights_18': 0.053544084264439046, 'weights_19': 0.12689370165600486}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,573] Trial 141 finished with value: 3085.3525154334425 and parameters: {'weights_0': 0.12141490467433946, 'weights_1': 0.554350976824749, 'weights_2': 0.14442329130333667, 'weights_3': 0.8672511944572263, 'weights_4': 0.6216364135134038, 'weights_5': 0.9748927167936537, 'weights_6': 0.31154179418309336, 'weights_7': 0.5505839509362246, 'weights_8': 0.1198141888731365, 'weights_9': 0.11947618549993007, 'weights_10': 0.1375799157236306, 'weights_11': 0.47976317508986205, 'weights_12': 0.14239993140882698, 'weights_13': 0.2661679337284793, 'weights_14': 0.5646251152887005, 'weights_15': 0.6949093644675376, 'weights_16': 0.6358357445686369, 'weights_17': 0.47718087063296294, 'weights_18': 0.052058652500157156, 'weights_19': 0.1254069094148844}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,682] Trial 142 finished with value: 3094.8494210796 and parameters: {'weights_0': 0.1245844637093829, 'weights_1': 0.5650074268166544, 'weights_2': 0.1506536215366966, 'weights_3': 0.8598183231968286, 'weights_4': 0.6133498051670033, 'weights_5': 0.9759067289360146, 'weights_6': 0.25402439077608424, 'weights_7': 0.5471037669997262, 'weights_8': 0.12425352295266268, 'weights_9': 0.12081479444341606, 'weights_10': 0.12326519313055796, 'weights_11': 0.48312901147172255, 'weights_12': 0.13947917757065645, 'weights_13': 0.27091475965818085, 'weights_14': 0.5564266574293397, 'weights_15': 0.6799554911772129, 'weights_16': 0.6450309402980348, 'weights_17': 0.47253259765980077, 'weights_18': 0.04755064827336014, 'weights_19': 0.12802718388925557}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,768] Trial 143 finished with value: 3095.1894443806773 and parameters: {'weights_0': 0.12695112895346072, 'weights_1': 0.5650028093231114, 'weights_2': 0.15711515660166972, 'weights_3': 0.8698758891036825, 'weights_4': 0.614467448853407, 'weights_5': 0.9717198610194522, 'weights_6': 0.2618685356861839, 'weights_7': 0.5487849617374644, 'weights_8': 0.13161995561633652, 'weights_9': 0.11840853152461361, 'weights_10': 0.13379073218369847, 'weights_11': 0.4700656323006528, 'weights_12': 0.14369596091107892, 'weights_13': 0.2682421757472173, 'weights_14': 0.5556083444908301, 'weights_15': 0.6840044912206458, 'weights_16': 0.6445982694897696, 'weights_17': 0.48206181970052514, 'weights_18': 0.04568991274061904, 'weights_19': 0.12349970254683103}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,880] Trial 144 finished with value: 3092.1510902733903 and parameters: {'weights_0': 0.12823951140999074, 'weights_1': 0.563958296075633, 'weights_2': 0.15153133725687137, 'weights_3': 0.8779461178890484, 'weights_4': 0.6437758607699142, 'weights_5': 0.9708303731126594, 'weights_6': 0.2520338324583194, 'weights_7': 0.5625207040148406, 'weights_8': 0.12878557911808172, 'weights_9': 0.11523654692379573, 'weights_10': 0.1199137457208985, 'weights_11': 0.47618174516594436, 'weights_12': 0.14847754206559324, 'weights_13': 0.2723570489820562, 'weights_14': 0.557013466065929, 'weights_15': 0.6810849354456384, 'weights_16': 0.647686377753905, 'weights_17': 0.4754286825551557, 'weights_18': 0.04691633640244892, 'weights_19': 0.11077384225394812}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:29,998] Trial 145 finished with value: 3096.7724171098444 and parameters: {'weights_0': 0.11754594032384225, 'weights_1': 0.5672865538796594, 'weights_2': 0.14884320563235728, 'weights_3': 0.8676125457969933, 'weights_4': 0.6229040720825129, 'weights_5': 0.9665531001267804, 'weights_6': 0.24990290260516743, 'weights_7': 0.5710219982159613, 'weights_8': 0.12274431763659868, 'weights_9': 0.10222562057218437, 'weights_10': 0.11997657752612324, 'weights_11': 0.4760050568872864, 'weights_12': 0.1493664342777621, 'weights_13': 0.2710280391948106, 'weights_14': 0.5578179783137335, 'weights_15': 0.6919540159777451, 'weights_16': 0.6536118580947893, 'weights_17': 0.47594806479552976, 'weights_18': 0.05370516142665978, 'weights_19': 0.10644979263253317}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:30,115] Trial 146 finished with value: 3115.9856473991827 and parameters: {'weights_0': 0.1327540591132609, 'weights_1': 0.5657399342271133, 'weights_2': 0.16021805991310345, 'weights_3': 0.88629160119867, 'weights_4': 0.6166702952332564, 'weights_5': 0.9646898252838787, 'weights_6': 0.2573888379837737, 'weights_7': 0.5455110965170057, 'weights_8': 0.14409971020515222, 'weights_9': 0.07409273710785819, 'weights_10': 0.11868352218798861, 'weights_11': 0.471544435931448, 'weights_12': 0.14389094274653066, 'weights_13': 0.26895523967451856, 'weights_14': 0.5587552171087089, 'weights_15': 0.6869677018311282, 'weights_16': 0.7224000496943479, 'weights_17': 0.47793778816865035, 'weights_18': 0.05317422876237496, 'weights_19': 0.11274274011417584}. Best is trial 137 with value: 3074.1972226519824.\n",
      "[I 2025-08-01 08:05:30,212] Trial 147 finished with value: 3073.7589336901196 and parameters: {'weights_0': 0.12241874682511211, 'weights_1': 0.5720917059842039, 'weights_2': 0.13817282054423072, 'weights_3': 0.8659471516698146, 'weights_4': 0.6494932647861101, 'weights_5': 0.9952227315310237, 'weights_6': 0.30785765427137224, 'weights_7': 0.5917286127415712, 'weights_8': 0.12705479781228118, 'weights_9': 0.1185565609412432, 'weights_10': 0.11335985198194999, 'weights_11': 0.5705630513997405, 'weights_12': 0.12251581991026557, 'weights_13': 0.2584113189473253, 'weights_14': 0.5401393211948553, 'weights_15': 0.7276470526474592, 'weights_16': 0.6577165098451463, 'weights_17': 0.45105664744886964, 'weights_18': 0.015124360629517025, 'weights_19': 0.10257973129477387}. Best is trial 147 with value: 3073.7589336901196.\n",
      "[I 2025-08-01 08:05:30,330] Trial 148 finished with value: 3045.8133337507797 and parameters: {'weights_0': 0.0634201879890034, 'weights_1': 0.5546064838878166, 'weights_2': 0.12552923813521652, 'weights_3': 0.9183672610511625, 'weights_4': 0.6480377674028004, 'weights_5': 0.9961514553425606, 'weights_6': 0.3053372322473525, 'weights_7': 0.5839862148391298, 'weights_8': 0.1463060144977199, 'weights_9': 0.15267877347243666, 'weights_10': 0.06334491813757617, 'weights_11': 0.570345561539166, 'weights_12': 0.12205460750402826, 'weights_13': 0.26059558460002086, 'weights_14': 0.5407640924863425, 'weights_15': 0.7394118246880428, 'weights_16': 0.6745374177195468, 'weights_17': 0.4539602700705947, 'weights_18': 0.017462683562719784, 'weights_19': 0.10062081543682747}. Best is trial 148 with value: 3045.8133337507797.\n",
      "[I 2025-08-01 08:05:30,444] Trial 149 finished with value: 3041.493479385695 and parameters: {'weights_0': 0.061759869849340746, 'weights_1': 0.4940877738949673, 'weights_2': 0.12539798696188303, 'weights_3': 0.9189083767160735, 'weights_4': 0.6516919049651881, 'weights_5': 0.9974292184587901, 'weights_6': 0.3187592564079012, 'weights_7': 0.5882520285558284, 'weights_8': 0.14695741077087315, 'weights_9': 0.15692580404616335, 'weights_10': 0.06517540782544998, 'weights_11': 0.571628764668142, 'weights_12': 0.11934950212840069, 'weights_13': 0.3114324487184733, 'weights_14': 0.5324955822328874, 'weights_15': 0.7362453392859993, 'weights_16': 0.6781336740080359, 'weights_17': 0.4537154690949927, 'weights_18': 0.004224914200768551, 'weights_19': 0.09837727937135823}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:30,559] Trial 150 finished with value: 3051.798659285485 and parameters: {'weights_0': 0.06212218362966035, 'weights_1': 0.5572467052417583, 'weights_2': 0.12886965119447122, 'weights_3': 0.9317504587365383, 'weights_4': 0.6546231042355677, 'weights_5': 0.996883016115627, 'weights_6': 0.30799426547074404, 'weights_7': 0.5963756581412056, 'weights_8': 0.1493592826272181, 'weights_9': 0.141003939268368, 'weights_10': 0.06705149136276065, 'weights_11': 0.5741116387954905, 'weights_12': 0.12413845698604274, 'weights_13': 0.25539453033949855, 'weights_14': 0.5785029898611912, 'weights_15': 0.7345684130759161, 'weights_16': 0.6803092963303382, 'weights_17': 0.45056026678555317, 'weights_18': 0.004558334454403019, 'weights_19': 0.09618836841963846}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:30,659] Trial 151 finished with value: 3051.4970689280854 and parameters: {'weights_0': 0.06122028923140313, 'weights_1': 0.5549808593991192, 'weights_2': 0.1234100091097061, 'weights_3': 0.9331030348873767, 'weights_4': 0.6612650835852691, 'weights_5': 0.9997863154074063, 'weights_6': 0.3052619939095476, 'weights_7': 0.5909518862137966, 'weights_8': 0.14350817739242955, 'weights_9': 0.12608142100563632, 'weights_10': 0.06552682709409935, 'weights_11': 0.5729641134474028, 'weights_12': 0.12154058014887421, 'weights_13': 0.25041837933235234, 'weights_14': 0.5803958589996244, 'weights_15': 0.7364216696595179, 'weights_16': 0.6826297337090295, 'weights_17': 0.4505231183263597, 'weights_18': 0.013806878645331144, 'weights_19': 0.09540164379662786}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:30,779] Trial 152 finished with value: 3053.1090613996594 and parameters: {'weights_0': 0.06094321048930369, 'weights_1': 0.5424436851180263, 'weights_2': 0.12743818968884404, 'weights_3': 0.9342717240211236, 'weights_4': 0.659757189768891, 'weights_5': 0.998344830231479, 'weights_6': 0.3137913819002988, 'weights_7': 0.597444133977853, 'weights_8': 0.1500427650706475, 'weights_9': 0.0521040232035348, 'weights_10': 0.04974486085161199, 'weights_11': 0.5715086679746177, 'weights_12': 0.11902624682301138, 'weights_13': 0.3129745355512591, 'weights_14': 0.5273588056109543, 'weights_15': 0.7527184588231906, 'weights_16': 0.6856894040090297, 'weights_17': 0.4520323922091289, 'weights_18': 0.0007801356867809389, 'weights_19': 0.09535139927468246}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:30,924] Trial 153 finished with value: 3056.5792671048594 and parameters: {'weights_0': 0.0605817602321953, 'weights_1': 0.5534608380596393, 'weights_2': 0.11046002834641404, 'weights_3': 0.9328206197411408, 'weights_4': 0.6532759937467958, 'weights_5': 0.9852545077606527, 'weights_6': 0.312553369865363, 'weights_7': 0.5950290883287287, 'weights_8': 0.15305647040716988, 'weights_9': 0.04756385482034266, 'weights_10': 0.06069735312605978, 'weights_11': 0.5657649759601737, 'weights_12': 0.11520277012022302, 'weights_13': 0.31475737213997873, 'weights_14': 0.5304247823745533, 'weights_15': 0.7426708789208566, 'weights_16': 0.6830601982391682, 'weights_17': 0.5062936998169176, 'weights_18': 0.006181564682835573, 'weights_19': 0.09698997470099428}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,032] Trial 154 finished with value: 3060.429525459524 and parameters: {'weights_0': 0.0578159961214014, 'weights_1': 0.4995933631861512, 'weights_2': 0.11940747778974345, 'weights_3': 0.9305987701936597, 'weights_4': 0.6546190213671917, 'weights_5': 0.9966953903979101, 'weights_6': 0.3096959296118773, 'weights_7': 0.5875072509919751, 'weights_8': 0.15356177433671409, 'weights_9': 0.03599807023984901, 'weights_10': 0.06060720318893424, 'weights_11': 0.5761438210031065, 'weights_12': 0.11340365588706253, 'weights_13': 0.3138250890791042, 'weights_14': 0.5829643596474805, 'weights_15': 0.764485724323772, 'weights_16': 0.6832200671375429, 'weights_17': 0.45161237443498337, 'weights_18': 0.002123859214654967, 'weights_19': 0.09351625763904176}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,160] Trial 155 finished with value: 3064.2238672361023 and parameters: {'weights_0': 0.06166965566323846, 'weights_1': 0.634192521183517, 'weights_2': 0.123448082727761, 'weights_3': 0.930256120904475, 'weights_4': 0.6481418936666395, 'weights_5': 0.9903130338154915, 'weights_6': 0.30466167521063686, 'weights_7': 0.5936777116569569, 'weights_8': 0.14987165856608534, 'weights_9': 0.04674423099816215, 'weights_10': 0.0577118598430145, 'weights_11': 0.5735298688899997, 'weights_12': 0.11823383240502491, 'weights_13': 0.30687123804707234, 'weights_14': 0.5357885772011235, 'weights_15': 0.7499847353199206, 'weights_16': 0.6862261577836027, 'weights_17': 0.5100135892675466, 'weights_18': 0.007938419031097314, 'weights_19': 0.0936570709060516}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,284] Trial 156 finished with value: 3079.662743646109 and parameters: {'weights_0': 0.06009938582214938, 'weights_1': 0.6361924431092855, 'weights_2': 0.11297251802897533, 'weights_3': 0.9989773785783467, 'weights_4': 0.6477318495818704, 'weights_5': 0.9939923251137762, 'weights_6': 0.3027647623935864, 'weights_7': 0.591690469788279, 'weights_8': 0.1514964899022208, 'weights_9': 0.030457458829902445, 'weights_10': 0.060246022903460435, 'weights_11': 0.572861230030172, 'weights_12': 0.17995333493163213, 'weights_13': 0.31411202584121395, 'weights_14': 0.5902878872490389, 'weights_15': 0.75641229401102, 'weights_16': 0.7132064722920868, 'weights_17': 0.5102656727740966, 'weights_18': 0.0035817989075035534, 'weights_19': 0.08941436086943953}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,420] Trial 157 finished with value: 3080.1045434554726 and parameters: {'weights_0': 0.057047193847286216, 'weights_1': 0.6545111827160073, 'weights_2': 0.12425998316422923, 'weights_3': 0.9380370051102862, 'weights_4': 0.6450721292272135, 'weights_5': 0.9975157113771392, 'weights_6': 0.3026700634594677, 'weights_7': 0.59116575095645, 'weights_8': 0.1509838321486746, 'weights_9': 0.035080830990679684, 'weights_10': 0.05859434885956053, 'weights_11': 0.5844634590437654, 'weights_12': 0.1813213808370394, 'weights_13': 0.31478554898461336, 'weights_14': 0.5290618740571311, 'weights_15': 0.7530189945347832, 'weights_16': 0.7259713813710704, 'weights_17': 0.5051473197673393, 'weights_18': 0.004669704282193156, 'weights_19': 0.08793982494798741}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,546] Trial 158 finished with value: 3089.4462686091824 and parameters: {'weights_0': 0.06114090100593259, 'weights_1': 0.6645017254937301, 'weights_2': 0.12157985379302905, 'weights_3': 0.9447829419312208, 'weights_4': 0.661520303671439, 'weights_5': 0.9946880588478598, 'weights_6': 0.3029480805148017, 'weights_7': 0.5937404049343455, 'weights_8': 0.15269928170562008, 'weights_9': 0.01642383636564719, 'weights_10': 0.059196975606641986, 'weights_11': 0.5794108124828243, 'weights_12': 0.18682285242189298, 'weights_13': 0.3100736149922232, 'weights_14': 0.5837508261043063, 'weights_15': 0.7538367097016029, 'weights_16': 0.7253287983981199, 'weights_17': 0.5094678449381613, 'weights_18': 0.008911795500376324, 'weights_19': 0.08495282534063153}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,664] Trial 159 finished with value: 3089.901758326088 and parameters: {'weights_0': 0.0491827089093747, 'weights_1': 0.6276840058860209, 'weights_2': 0.10150776817948971, 'weights_3': 0.9044524818828944, 'weights_4': 0.7011516911748054, 'weights_5': 0.9973307949356761, 'weights_6': 0.2060120976148146, 'weights_7': 0.6742891735858101, 'weights_8': 0.1499303546523485, 'weights_9': 0.04233609226298285, 'weights_10': 0.01894636947812034, 'weights_11': 0.6180203722462259, 'weights_12': 0.17899097412087092, 'weights_13': 0.30923042336748474, 'weights_14': 0.6202317763662057, 'weights_15': 0.7352219885546297, 'weights_16': 0.6996935967562766, 'weights_17': 0.5007095978508762, 'weights_18': 0.022421626903498738, 'weights_19': 0.04627389057292372}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,789] Trial 160 finished with value: 3056.3611270903284 and parameters: {'weights_0': 0.027106178033268882, 'weights_1': 0.6479921617093689, 'weights_2': 0.12673151543922365, 'weights_3': 0.9935020688836878, 'weights_4': 0.6476221027581064, 'weights_5': 0.99947725876645, 'weights_6': 0.2996770349432107, 'weights_7': 0.6262308490178446, 'weights_8': 0.15591609223847344, 'weights_9': 0.058376512366806396, 'weights_10': 0.062052381682807266, 'weights_11': 0.5676486910537316, 'weights_12': 0.1245562245111789, 'weights_13': 0.24302047145559402, 'weights_14': 0.6446569399772455, 'weights_15': 0.7840455840666979, 'weights_16': 0.6748939646790242, 'weights_17': 0.5417364537410727, 'weights_18': 0.0047133859647827325, 'weights_19': 0.08986030132432209}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:31,887] Trial 161 finished with value: 3048.303639708207 and parameters: {'weights_0': 0.07031467483576091, 'weights_1': 0.6733398983376013, 'weights_2': 0.12532223355114097, 'weights_3': 0.9969650215117211, 'weights_4': 0.6500324956254193, 'weights_5': 0.9979732725934413, 'weights_6': 0.29928584849702716, 'weights_7': 0.6329018924363596, 'weights_8': 0.16548178716683593, 'weights_9': 0.07080558601150314, 'weights_10': 0.05987600541922609, 'weights_11': 0.5675636210994776, 'weights_12': 0.12464660386252754, 'weights_13': 0.24823813541792555, 'weights_14': 0.5342572812635958, 'weights_15': 0.8090948525397448, 'weights_16': 0.6776270023906276, 'weights_17': 0.5410486963966079, 'weights_18': 0.0047456878373182115, 'weights_19': 0.0880180033380496}. Best is trial 149 with value: 3041.493479385695.\n",
      "[I 2025-08-01 08:05:32,007] Trial 162 finished with value: 3040.0460959240827 and parameters: {'weights_0': 0.0339869190434097, 'weights_1': 0.6304022684891988, 'weights_2': 0.12775816572179557, 'weights_3': 0.9793295245635412, 'weights_4': 0.6486006442473181, 'weights_5': 0.9973213913322938, 'weights_6': 0.2817605174303072, 'weights_7': 0.6258889265085016, 'weights_8': 0.16215349317870878, 'weights_9': 0.07405665954945867, 'weights_10': 0.05121040347612985, 'weights_11': 0.5707132615393452, 'weights_12': 0.12457354153488993, 'weights_13': 0.24076491498004182, 'weights_14': 0.5351380177353952, 'weights_15': 0.8100494210903587, 'weights_16': 0.6825064788810364, 'weights_17': 0.5426336618917966, 'weights_18': 0.0007524967861306849, 'weights_19': 0.09762362756410012}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,107] Trial 163 finished with value: 3047.06393098514 and parameters: {'weights_0': 0.03215039576870064, 'weights_1': 0.6437454652741954, 'weights_2': 0.10952122568386514, 'weights_3': 0.9999145748986205, 'weights_4': 0.6503587261230289, 'weights_5': 0.9992056564050554, 'weights_6': 0.2863459263618411, 'weights_7': 0.6248510382338791, 'weights_8': 0.16023262650550263, 'weights_9': 0.07332407960212231, 'weights_10': 0.04893142568586435, 'weights_11': 0.5696532032233879, 'weights_12': 0.12242213958096404, 'weights_13': 0.2279357237663545, 'weights_14': 0.6359993158283164, 'weights_15': 0.7958628104654616, 'weights_16': 0.6773514712171013, 'weights_17': 0.5329187604342325, 'weights_18': 1.8195225954554042e-05, 'weights_19': 0.0910309663887214}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,207] Trial 164 finished with value: 3052.1784607439367 and parameters: {'weights_0': 0.03278629204128068, 'weights_1': 0.6792963332036377, 'weights_2': 0.10563811947184923, 'weights_3': 0.9906243173489606, 'weights_4': 0.6558187686662623, 'weights_5': 0.9467250682423036, 'weights_6': 0.28372734171629166, 'weights_7': 0.6223491897753628, 'weights_8': 0.15654463698424695, 'weights_9': 0.07756518943010557, 'weights_10': 0.04033357808704329, 'weights_11': 0.5610662047250139, 'weights_12': 0.12156466923994641, 'weights_13': 0.23790726853998367, 'weights_14': 0.6015538776738312, 'weights_15': 0.8025628847492087, 'weights_16': 0.6763742030094717, 'weights_17': 0.5489689600802778, 'weights_18': 0.0261177923841545, 'weights_19': 0.060292318831772954}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,306] Trial 165 finished with value: 3075.3407679294064 and parameters: {'weights_0': 0.0272340839028919, 'weights_1': 0.6856453004532596, 'weights_2': 0.10030971779666127, 'weights_3': 0.9990062608401024, 'weights_4': 0.7023453619899898, 'weights_5': 0.9366276439057636, 'weights_6': 0.21975508191340629, 'weights_7': 0.6284076798736108, 'weights_8': 0.16200376294447918, 'weights_9': 0.0717436618359844, 'weights_10': 0.03371012861465281, 'weights_11': 0.6343407925598267, 'weights_12': 0.12502755484840447, 'weights_13': 0.24136593150005556, 'weights_14': 0.6462554354684708, 'weights_15': 0.8037018424316261, 'weights_16': 0.6764652877592212, 'weights_17': 0.5366259038040213, 'weights_18': 0.029842541490533964, 'weights_19': 0.057058333610760244}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,395] Trial 166 finished with value: 3067.0902563674877 and parameters: {'weights_0': 0.032551769539205334, 'weights_1': 0.6773515589811169, 'weights_2': 0.10081520822422366, 'weights_3': 0.9952879629036501, 'weights_4': 0.7017920466707479, 'weights_5': 0.9466035122783167, 'weights_6': 0.22300717752857466, 'weights_7': 0.6333477692428452, 'weights_8': 0.1648880010309908, 'weights_9': 0.07327115950725492, 'weights_10': 0.02312907633118988, 'weights_11': 0.6103382769231959, 'weights_12': 0.12052854778824046, 'weights_13': 0.23869855014018698, 'weights_14': 0.6566325669875981, 'weights_15': 0.8055956193575695, 'weights_16': 0.678622514073635, 'weights_17': 0.5467641684191435, 'weights_18': 0.02573065192457158, 'weights_19': 0.06071632511677601}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,511] Trial 167 finished with value: 3069.864938659557 and parameters: {'weights_0': 0.025904292686084122, 'weights_1': 0.6830405012191312, 'weights_2': 0.09495692342436628, 'weights_3': 0.9936356973086266, 'weights_4': 0.7123191291592501, 'weights_5': 0.9471406978898651, 'weights_6': 0.28121762318762594, 'weights_7': 0.6244203742727746, 'weights_8': 0.16840342726143576, 'weights_9': 0.07136991758066727, 'weights_10': 0.02754468384599534, 'weights_11': 0.6314656794487967, 'weights_12': 0.08959427535367967, 'weights_13': 0.2432275747819549, 'weights_14': 0.664291940498121, 'weights_15': 0.8085886586701435, 'weights_16': 0.7501704165021522, 'weights_17': 0.551514266350046, 'weights_18': 0.02633713076105268, 'weights_19': 0.053820653779126204}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,667] Trial 168 finished with value: 3083.254530956178 and parameters: {'weights_0': 0.024761216279893146, 'weights_1': 0.658909091033702, 'weights_2': 0.10171381786636878, 'weights_3': 0.9738819424136302, 'weights_4': 0.6634242263224475, 'weights_5': 0.9469821125938185, 'weights_6': 0.2862668705500006, 'weights_7': 0.6623087032210143, 'weights_8': 0.24187810445433855, 'weights_9': 0.07882140874378514, 'weights_10': 0.017704141441759663, 'weights_11': 0.6072654215120546, 'weights_12': 0.08940435071960798, 'weights_13': 0.23806498763324058, 'weights_14': 0.6617978435923143, 'weights_15': 0.7968892785394234, 'weights_16': 0.7887260263663081, 'weights_17': 0.5559297736636457, 'weights_18': 0.022940878738272934, 'weights_19': 0.03779750744590685}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,783] Trial 169 finished with value: 3066.344286130766 and parameters: {'weights_0': 0.0763285866174866, 'weights_1': 0.6789330836261924, 'weights_2': 0.12622361938936397, 'weights_3': 0.9552850582481696, 'weights_4': 0.7121420527867796, 'weights_5': 0.9482406821605387, 'weights_6': 0.2729630894108331, 'weights_7': 0.6221638980933148, 'weights_8': 0.16631255747656923, 'weights_9': 0.054181595752249484, 'weights_10': 0.04238417579231144, 'weights_11': 0.5562146623479706, 'weights_12': 0.09255114809390615, 'weights_13': 0.2164547920358468, 'weights_14': 0.6336127159378798, 'weights_15': 0.8611481558543247, 'weights_16': 0.753727396503948, 'weights_17': 0.5496480466902168, 'weights_18': 0.021203083904861933, 'weights_19': 0.06322804048075255}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:32,889] Trial 170 finished with value: 3066.0609176442604 and parameters: {'weights_0': 0.07411449910201505, 'weights_1': 0.6906471170366354, 'weights_2': 0.09387677060159244, 'weights_3': 0.9535181793574179, 'weights_4': 0.7223664123493413, 'weights_5': 0.9988213546088703, 'weights_6': 0.1685121931112239, 'weights_7': 0.6240261893840384, 'weights_8': 0.16865335917918362, 'weights_9': 0.05960631084248175, 'weights_10': 0.0016164968326358511, 'weights_11': 0.5586460055051992, 'weights_12': 0.16318141898646976, 'weights_13': 0.21423766348968837, 'weights_14': 0.681974875148605, 'weights_15': 0.8585829946608831, 'weights_16': 0.7575584448492527, 'weights_17': 0.5376196971382339, 'weights_18': 8.415991418270208e-05, 'weights_19': 0.0628870622058115}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:33,024] Trial 171 finished with value: 3067.7806210947797 and parameters: {'weights_0': 0.07952476365811155, 'weights_1': 0.6759874578899039, 'weights_2': 0.12617558168374465, 'weights_3': 0.9572999651676469, 'weights_4': 0.6953530846710675, 'weights_5': 0.9973018154989841, 'weights_6': 0.17667857401874132, 'weights_7': 0.6220409478612863, 'weights_8': 0.1659362209575912, 'weights_9': 0.05585929373347166, 'weights_10': 0.045422282631405686, 'weights_11': 0.5581427920397214, 'weights_12': 0.09269119806400739, 'weights_13': 0.21824088477771136, 'weights_14': 0.6782949604808325, 'weights_15': 0.8564508412179719, 'weights_16': 0.7481032804019653, 'weights_17': 0.5803570616474222, 'weights_18': 0.0011720992242496239, 'weights_19': 0.061741484150574906}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:33,136] Trial 172 finished with value: 3071.5096011569913 and parameters: {'weights_0': 0.08249163297752915, 'weights_1': 0.6692024501919894, 'weights_2': 0.12195302757150508, 'weights_3': 0.9567315713917683, 'weights_4': 0.7163773216948938, 'weights_5': 0.9293737303966592, 'weights_6': 0.18595740463413787, 'weights_7': 0.6207739265089631, 'weights_8': 0.17419005329954734, 'weights_9': 0.05509559684230138, 'weights_10': 0.0006331571275308701, 'weights_11': 0.5498598142533131, 'weights_12': 0.0931910871765146, 'weights_13': 0.2202744450382974, 'weights_14': 0.7013343599586888, 'weights_15': 0.8673774439640357, 'weights_16': 0.7492931600084798, 'weights_17': 0.5765850901474955, 'weights_18': 0.001999859861489218, 'weights_19': 0.06351990910487695}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:33,253] Trial 173 finished with value: 3110.8360942365675 and parameters: {'weights_0': 0.040302998279808204, 'weights_1': 0.6907512865116805, 'weights_2': 0.08677010493225731, 'weights_3': 0.9858047107091357, 'weights_4': 0.6830883503458819, 'weights_5': 0.9470264850399276, 'weights_6': 0.1801651635297693, 'weights_7': 0.6902986216954106, 'weights_8': 0.16217007212060697, 'weights_9': 0.00287721677948001, 'weights_10': 0.042448055507400786, 'weights_11': 0.600919984272141, 'weights_12': 0.16321555003206206, 'weights_13': 0.2058078663229273, 'weights_14': 0.6715252648383149, 'weights_15': 0.835177306381635, 'weights_16': 0.7880124144525913, 'weights_17': 0.5481521671857035, 'weights_18': 0.023260465233331102, 'weights_19': 0.06611156122287529}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:33,402] Trial 174 finished with value: 3097.814862466544 and parameters: {'weights_0': 0.07788868242918914, 'weights_1': 0.7464767240789904, 'weights_2': 0.09556475105440847, 'weights_3': 0.9574207735421048, 'weights_4': 0.6995942736496583, 'weights_5': 0.999107135410209, 'weights_6': 0.10062642683954197, 'weights_7': 0.638776212409741, 'weights_8': 0.18717206140014, 'weights_9': 0.08885082979368505, 'weights_10': 0.07237140435738393, 'weights_11': 0.6372589803514876, 'weights_12': 0.09502875989152769, 'weights_13': 0.22585494675923698, 'weights_14': 0.6316913403570732, 'weights_15': 0.7891944364986367, 'weights_16': 0.7518083356100872, 'weights_17': 0.5221183663519884, 'weights_18': 0.002227814644855327, 'weights_19': 0.02220926368850408}. Best is trial 162 with value: 3040.0460959240827.\n",
      "[I 2025-08-01 08:05:33,516] Trial 175 finished with value: 3036.2908912780385 and parameters: {'weights_0': 0.022334894669535893, 'weights_1': 0.6822565010212698, 'weights_2': 0.12104435193784199, 'weights_3': 0.9830413681035493, 'weights_4': 0.724015976209565, 'weights_5': 0.9528056099677131, 'weights_6': 0.2782495072300732, 'weights_7': 0.6592600708694512, 'weights_8': 0.2204317597933996, 'weights_9': 0.05675017147649222, 'weights_10': 0.02370113070622865, 'weights_11': 0.5552496708301079, 'weights_12': 0.06530252170618077, 'weights_13': 0.16898632995011162, 'weights_14': 0.6099419206981741, 'weights_15': 0.9217365976794407, 'weights_16': 0.6904162500059942, 'weights_17': 0.5448779379144965, 'weights_18': 0.02252954578283572, 'weights_19': 0.09452264250884461}. Best is trial 175 with value: 3036.2908912780385.\n",
      "[I 2025-08-01 08:05:33,621] Trial 176 finished with value: 3147.25667181157 and parameters: {'weights_0': 0.07012949917830309, 'weights_1': 0.6436362104258474, 'weights_2': 0.11948455422343676, 'weights_3': 0.9711585456498784, 'weights_4': 0.6760540832614369, 'weights_5': 0.9509044205770181, 'weights_6': 0.22998212546213295, 'weights_7': 0.7172293722747186, 'weights_8': 0.21854717792959305, 'weights_9': 0.05125147282257178, 'weights_10': 0.04478475466500681, 'weights_11': 0.5560652925363407, 'weights_12': 0.6698194179270713, 'weights_13': 0.17105187647623782, 'weights_14': 0.6131843434724378, 'weights_15': 0.9124951992873445, 'weights_16': 0.689437043782223, 'weights_17': 0.5354936962805176, 'weights_18': 5.6767140635637786e-05, 'weights_19': 0.09509697466421932}. Best is trial 175 with value: 3036.2908912780385.\n",
      "[I 2025-08-01 08:05:33,761] Trial 177 finished with value: 3037.9548203384716 and parameters: {'weights_0': 0.04835402218359275, 'weights_1': 0.7024786819067517, 'weights_2': 0.12623088205792043, 'weights_3': 0.9555637052133463, 'weights_4': 0.7263473985641611, 'weights_5': 0.9975217113388319, 'weights_6': 0.1690628265689914, 'weights_7': 0.6584287489353874, 'weights_8': 0.1534671573444638, 'weights_9': 0.09490447935829212, 'weights_10': 0.08291375915466749, 'weights_11': 0.5519099681271337, 'weights_12': 0.061475200621122744, 'weights_13': 0.13070306431204604, 'weights_14': 0.6086895818793862, 'weights_15': 0.8471266177567228, 'weights_16': 0.6133866787976445, 'weights_17': 0.5801107014692111, 'weights_18': 0.08526767144500419, 'weights_19': 0.029474985158049964}. Best is trial 175 with value: 3036.2908912780385.\n",
      "[I 2025-08-01 08:05:33,920] Trial 178 finished with value: 3144.087754083228 and parameters: {'weights_0': 0.04450571516639112, 'weights_1': 0.7043684570556548, 'weights_2': 0.17618786323311167, 'weights_3': 0.942556468464814, 'weights_4': 0.7647435910580548, 'weights_5': 0.933366986121939, 'weights_6': 0.22990160255987346, 'weights_7': 0.6547900157987635, 'weights_8': 0.41970243303146987, 'weights_9': 0.020195387227739406, 'weights_10': 0.07984611066662811, 'weights_11': 0.6045114576307467, 'weights_12': 0.1596605328106192, 'weights_13': 0.13074701594852267, 'weights_14': 0.6038814773434303, 'weights_15': 0.7800249444790375, 'weights_16': 0.6934946650927146, 'weights_17': 0.5270236225194587, 'weights_18': 0.09564880007442259, 'weights_19': 0.03333637615183055}. Best is trial 175 with value: 3036.2908912780385.\n",
      "[I 2025-08-01 08:05:34,037] Trial 179 finished with value: 3048.029468210436 and parameters: {'weights_0': 0.09565262032857763, 'weights_1': 0.7403069221771647, 'weights_2': 0.22262299947497688, 'weights_3': 0.9035326182598394, 'weights_4': 0.7241097798138901, 'weights_5': 0.9987806079308136, 'weights_6': 0.273020703381308, 'weights_7': 0.6752666680432104, 'weights_8': 0.14589872557311803, 'weights_9': 0.08497822825902368, 'weights_10': 0.02025903862446754, 'weights_11': 0.57123468177711, 'weights_12': 0.06962319729970873, 'weights_13': 0.16567190120817332, 'weights_14': 0.634063302460497, 'weights_15': 0.9500315796197745, 'weights_16': 0.6754984324097921, 'weights_17': 0.4971923327161296, 'weights_18': 0.029901558856989092, 'weights_19': 0.08337592790139649}. Best is trial 175 with value: 3036.2908912780385.\n",
      "[I 2025-08-01 08:05:34,152] Trial 180 finished with value: 3030.157318916391 and parameters: {'weights_0': 0.0976871299188933, 'weights_1': 0.7488336923184599, 'weights_2': 0.22242514354029347, 'weights_3': 0.9030553384971928, 'weights_4': 0.7241756702711787, 'weights_5': 0.9966512723464305, 'weights_6': 0.28142091851750595, 'weights_7': 0.6738708062451386, 'weights_8': 0.1465937143550927, 'weights_9': 0.09644259389196233, 'weights_10': 0.000547658742706508, 'weights_11': 0.5444405140053803, 'weights_12': 0.07017549995351455, 'weights_13': 0.15545094015465197, 'weights_14': 0.5896105472177945, 'weights_15': 0.9394919879093734, 'weights_16': 0.6166038493002924, 'weights_17': 0.5667011537907148, 'weights_18': 0.08273933146558522, 'weights_19': 0.08097753234017088}. Best is trial 180 with value: 3030.157318916391.\n",
      "[I 2025-08-01 08:05:34,291] Trial 181 finished with value: 3039.6413342821065 and parameters: {'weights_0': 0.09631463323473932, 'weights_1': 0.7398276685419902, 'weights_2': 0.21601492767326783, 'weights_3': 0.9055371110770183, 'weights_4': 0.7244759615192301, 'weights_5': 0.9883513886309013, 'weights_6': 0.275982515488026, 'weights_7': 0.676939036901331, 'weights_8': 0.14617982136339516, 'weights_9': 0.09952843668584278, 'weights_10': 0.0016812252167592867, 'weights_11': 0.5453679206165944, 'weights_12': 0.06229309181823538, 'weights_13': 0.12347341927682717, 'weights_14': 0.58082078151343, 'weights_15': 0.9560360294609902, 'weights_16': 0.6946292243705169, 'weights_17': 0.4976785107424166, 'weights_18': 0.07879918207491848, 'weights_19': 0.0794553549698171}. Best is trial 180 with value: 3030.157318916391.\n",
      "[I 2025-08-01 08:05:34,409] Trial 182 finished with value: 3017.1442830564865 and parameters: {'weights_0': 0.001749249432262425, 'weights_1': 0.7648518219356146, 'weights_2': 0.22745166243577453, 'weights_3': 0.9056005694917081, 'weights_4': 0.7315929212853177, 'weights_5': 0.999270877289029, 'weights_6': 0.288957832761446, 'weights_7': 0.6823172640682048, 'weights_8': 0.14395663024009653, 'weights_9': 0.07827789277799221, 'weights_10': 0.0009368716671176201, 'weights_11': 0.5784233583585238, 'weights_12': 0.05323356001836482, 'weights_13': 0.10880115376202629, 'weights_14': 0.5837744391049604, 'weights_15': 0.9609264232531822, 'weights_16': 0.6013777415398394, 'weights_17': 0.49655035976406237, 'weights_18': 0.08407880135406161, 'weights_19': 0.09146146563050075}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:34,561] Trial 183 finished with value: 3042.352418693157 and parameters: {'weights_0': 0.005748934632926354, 'weights_1': 0.7354086265754693, 'weights_2': 0.22834092847289444, 'weights_3': 0.9047775299821496, 'weights_4': 0.6584594819042442, 'weights_5': 0.9907665474262416, 'weights_6': 0.2859509681017868, 'weights_7': 0.6831567736869416, 'weights_8': 0.14344684382245293, 'weights_9': 0.08523836678382792, 'weights_10': 0.0660350099824456, 'weights_11': 0.584306006705678, 'weights_12': 0.05434670813061872, 'weights_13': 0.1238428873795726, 'weights_14': 0.5837070413440147, 'weights_15': 0.9482150017386759, 'weights_16': 0.6070573325082654, 'weights_17': 0.5039646404935555, 'weights_18': 0.07595909334234632, 'weights_19': 0.09348327192855196}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:34,661] Trial 184 finished with value: 3108.0969912080345 and parameters: {'weights_0': 0.002355667770808728, 'weights_1': 0.7772831271167147, 'weights_2': 0.21622324004337926, 'weights_3': 0.9055887052714741, 'weights_4': 0.7520374834178161, 'weights_5': 0.9881420658472081, 'weights_6': 0.2809937171666059, 'weights_7': 0.7344364799541964, 'weights_8': 0.5591434468300218, 'weights_9': 0.09616761349444672, 'weights_10': 0.08855269919671262, 'weights_11': 0.590826741432585, 'weights_12': 0.06354614237878617, 'weights_13': 0.1105117577756045, 'weights_14': 0.584205154315085, 'weights_15': 0.9562933240879512, 'weights_16': 0.6126676189462738, 'weights_17': 0.44954760227217266, 'weights_18': 0.0820237213961197, 'weights_19': 0.08237896988705079}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:34,767] Trial 185 finished with value: 3048.4666592139174 and parameters: {'weights_0': 0.09726158196317686, 'weights_1': 0.7396593572643975, 'weights_2': 0.2300805370291557, 'weights_3': 0.9073388905151704, 'weights_4': 0.6686760184362754, 'weights_5': 0.9994437233684604, 'weights_6': 0.2812714917575833, 'weights_7': 0.6809283056952654, 'weights_8': 0.14607604960142578, 'weights_9': 0.09941594050774916, 'weights_10': 0.016573486934987666, 'weights_11': 0.5380716537172342, 'weights_12': 0.07742822892693554, 'weights_13': 0.13955563615712496, 'weights_14': 0.6081807176551558, 'weights_15': 0.9557897971337895, 'weights_16': 0.6079594922799297, 'weights_17': 0.4957620538247108, 'weights_18': 0.10018031393673342, 'weights_19': 0.10426914290871102}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:34,912] Trial 186 finished with value: 3161.187969889196 and parameters: {'weights_0': 0.02024368723759009, 'weights_1': 0.7505572580015779, 'weights_2': 0.23122553508008206, 'weights_3': 0.9075461688752142, 'weights_4': 0.6725849863069231, 'weights_5': 0.9996121629791974, 'weights_6': 0.28279150439644957, 'weights_7': 0.6826904804073632, 'weights_8': 0.9860581615716109, 'weights_9': 0.09190440242978096, 'weights_10': 0.018159803499340356, 'weights_11': 0.5367759107154414, 'weights_12': 0.06257912661682966, 'weights_13': 0.14735390171175164, 'weights_14': 0.6152601053526192, 'weights_15': 0.9490667947960902, 'weights_16': 0.6041645674742329, 'weights_17': 0.48888448495239045, 'weights_18': 0.10815583978951689, 'weights_19': 0.021911884182955706}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,022] Trial 187 finished with value: 3087.7517141913977 and parameters: {'weights_0': 0.09972726023304629, 'weights_1': 0.738984473916616, 'weights_2': 0.22262846259858124, 'weights_3': 0.8176390890171712, 'weights_4': 0.7300402926305569, 'weights_5': 0.9584251010817216, 'weights_6': 0.2719455146905837, 'weights_7': 0.7116109384870936, 'weights_8': 0.1865962769478626, 'weights_9': 0.19582355230656123, 'weights_10': 0.027225171865950176, 'weights_11': 0.5188032480856406, 'weights_12': 0.05098838878497142, 'weights_13': 0.09077519304648189, 'weights_14': 0.5993697867030084, 'weights_15': 0.9884792019842558, 'weights_16': 0.6078015011937303, 'weights_17': 0.5665805097130162, 'weights_18': 0.07461720343678349, 'weights_19': 0.4844894873536267}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,164] Trial 188 finished with value: 3084.209621875126 and parameters: {'weights_0': 0.0007350395717288793, 'weights_1': 0.817788836080109, 'weights_2': 0.2931541083354955, 'weights_3': 0.9781124066988293, 'weights_4': 0.7758370247324539, 'weights_5': 0.9271088555687215, 'weights_6': 0.23711711739855823, 'weights_7': 0.6548149744223959, 'weights_8': 0.1473659645060349, 'weights_9': 0.09982644011239361, 'weights_10': 0.07160414270814801, 'weights_11': 0.5396778619389171, 'weights_12': 0.06548113585677963, 'weights_13': 0.1252716195748953, 'weights_14': 0.6285764419191041, 'weights_15': 0.9202092181856746, 'weights_16': 0.7009201846084581, 'weights_17': 0.495249566110415, 'weights_18': 0.09791592978981048, 'weights_19': 0.10298264963120284}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,271] Trial 189 finished with value: 3183.1941136679056 and parameters: {'weights_0': 0.10027490517316007, 'weights_1': 0.7266145735123214, 'weights_2': 0.20457448813303014, 'weights_3': 0.8969421142374454, 'weights_4': 0.6834876611995481, 'weights_5': 0.955685850193709, 'weights_6': 0.2876423101215323, 'weights_7': 0.6703631318336116, 'weights_8': 0.08036546409139764, 'weights_9': 0.09431012344025097, 'weights_10': 0.00950869240335405, 'weights_11': 0.5880026941605743, 'weights_12': 0.8927586371239487, 'weights_13': 0.15958444747656103, 'weights_14': 0.6063266492068526, 'weights_15': 0.9356246118244604, 'weights_16': 0.6674887813935323, 'weights_17': 0.5240556042088322, 'weights_18': 0.12258609835319406, 'weights_19': 0.07938401324507126}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,388] Trial 190 finished with value: 3073.1510868214496 and parameters: {'weights_0': 0.04264930184831672, 'weights_1': 0.7815095887642383, 'weights_2': 0.23861944707286342, 'weights_3': 0.9717675051423367, 'weights_4': 0.6675111855709229, 'weights_5': 0.9805618256969392, 'weights_6': 0.3209973616324967, 'weights_7': 0.7771598900605701, 'weights_8': 0.37007677130192856, 'weights_9': 0.15124775765058654, 'weights_10': 0.09418510634399054, 'weights_11': 0.5492453734521083, 'weights_12': 0.0791837756039491, 'weights_13': 0.12854337436744717, 'weights_14': 0.5833734885547965, 'weights_15': 0.8970131972789852, 'weights_16': 0.6137136418282734, 'weights_17': 0.5961787877805762, 'weights_18': 0.06987417068781586, 'weights_19': 0.045282305273853275}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,517] Trial 191 finished with value: 3178.301631329785 and parameters: {'weights_0': 0.04077998944741467, 'weights_1': 0.7650343726284617, 'weights_2': 0.17739004510288528, 'weights_3': 0.930410443646142, 'weights_4': 0.6555290240690456, 'weights_5': 0.4388148152073237, 'weights_6': 0.3230713318836547, 'weights_7': 0.6847744214726089, 'weights_8': 0.14641325133085364, 'weights_9': 0.02480659947282992, 'weights_10': 0.05932420149356171, 'weights_11': 0.5704724597186039, 'weights_12': 0.05658319967491372, 'weights_13': 0.1457195519717259, 'weights_14': 0.580338325442113, 'weights_15': 0.9643543769595699, 'weights_16': 0.6706607386303718, 'weights_17': 0.4954209237435278, 'weights_18': 0.025477365170234346, 'weights_19': 0.09980514107882804}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,670] Trial 192 finished with value: 3095.2271211355123 and parameters: {'weights_0': 0.019388625372458928, 'weights_1': 0.7603348718762605, 'weights_2': 0.17516525181533704, 'weights_3': 0.9206691128563232, 'weights_4': 0.6368735560515091, 'weights_5': 0.9998311286651447, 'weights_6': 0.04239691943787549, 'weights_7': 0.6502990680773969, 'weights_8': 0.14552271059432345, 'weights_9': 0.08444095078831142, 'weights_10': 0.03761851835040621, 'weights_11': 0.5922307004673372, 'weights_12': 0.09953157391997543, 'weights_13': 0.10862564619832843, 'weights_14': 0.6401428150464252, 'weights_15': 0.8336990789389499, 'weights_16': 0.7109398950890219, 'weights_17': 0.4434048301093658, 'weights_18': 0.03135225876124319, 'weights_19': 0.08173157454954623}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,803] Trial 193 finished with value: 3090.729883819936 and parameters: {'weights_0': 0.055239828516543084, 'weights_1': 0.738882920963837, 'weights_2': 0.23982595175559643, 'weights_3': 0.9390337913869573, 'weights_4': 0.6611424191459212, 'weights_5': 0.9824205635274066, 'weights_6': 0.29094290458338823, 'weights_7': 0.6052484753726335, 'weights_8': 0.20360863669719337, 'weights_9': 0.10126679587394452, 'weights_10': 0.07106264351267509, 'weights_11': 0.5705439242814108, 'weights_12': 0.07418704499980869, 'weights_13': 0.164283111513016, 'weights_14': 0.5789765457299292, 'weights_15': 0.776114612805548, 'weights_16': 0.6899474943657256, 'weights_17': 0.5165491162701467, 'weights_18': 0.08475401652137868, 'weights_19': 0.10420743654665218}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:35,910] Trial 194 finished with value: 3083.665906553926 and parameters: {'weights_0': 0.09707315261477234, 'weights_1': 0.7123794744049181, 'weights_2': 0.28882533510770475, 'weights_3': 0.9033063110267632, 'weights_4': 0.7412383465780569, 'weights_5': 0.982423782423395, 'weights_6': 0.27229163951316576, 'weights_7': 0.7000395923388009, 'weights_8': 0.18365541123401635, 'weights_9': 0.06467466181727219, 'weights_10': 0.0007158964616456598, 'weights_11': 0.5525231328173084, 'weights_12': 0.13253175783128052, 'weights_13': 0.08607086524148602, 'weights_14': 0.6064293080760625, 'weights_15': 0.7308602762701385, 'weights_16': 0.7104729737352493, 'weights_17': 0.49911790163610614, 'weights_18': 0.025477496293337433, 'weights_19': 0.08245837346627427}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,032] Trial 195 finished with value: 3039.5333689525505 and parameters: {'weights_0': 0.018136322862580885, 'weights_1': 0.7221732732958761, 'weights_2': 0.20703747311008072, 'weights_3': 0.9767724239276403, 'weights_4': 0.6947006146022943, 'weights_5': 0.9585560715113297, 'weights_6': 0.3206733484705867, 'weights_7': 0.6654974202368348, 'weights_8': 0.14423719797208087, 'weights_9': 0.0036189492626967495, 'weights_10': 0.02978038291754207, 'weights_11': 0.6174166745372477, 'weights_12': 0.10257011005815989, 'weights_13': 0.13668804858164652, 'weights_14': 0.5794490301896434, 'weights_15': 0.9304632992357114, 'weights_16': 0.5560908817253252, 'weights_17': 0.572848207716319, 'weights_18': 0.0729136715017965, 'weights_19': 0.10756765514146888}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,152] Trial 196 finished with value: 3037.913221493009 and parameters: {'weights_0': 0.023616151280345797, 'weights_1': 0.7092019754501518, 'weights_2': 0.2095714540515773, 'weights_3': 0.9764766971300174, 'weights_4': 0.7269022018184133, 'weights_5': 0.957857427717893, 'weights_6': 0.2411376899970975, 'weights_7': 0.6689345371643275, 'weights_8': 0.0911551766662819, 'weights_9': 0.001957967162986851, 'weights_10': 0.03465665966402634, 'weights_11': 0.61835000732318, 'weights_12': 0.06241932779686991, 'weights_13': 0.1951408489479653, 'weights_14': 0.6228845148923671, 'weights_15': 0.9414386995622092, 'weights_16': 0.5551525949699723, 'weights_17': 0.571242851885478, 'weights_18': 0.0742214708302856, 'weights_19': 0.04642347910377455}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,264] Trial 197 finished with value: 3039.5970967992016 and parameters: {'weights_0': 0.015589956094521181, 'weights_1': 0.723309859625068, 'weights_2': 0.21246913970271258, 'weights_3': 0.9773290211584622, 'weights_4': 0.7255979217650635, 'weights_5': 0.9563714517721541, 'weights_6': 0.2480716326101, 'weights_7': 0.7340060195016843, 'weights_8': 0.08415584823233245, 'weights_9': 0.018551186929673044, 'weights_10': 0.025308424528692225, 'weights_11': 0.6140878145970918, 'weights_12': 0.06280899532354989, 'weights_13': 0.13872616218225747, 'weights_14': 0.6239309627984699, 'weights_15': 0.9993952475499486, 'weights_16': 0.5671637487922535, 'weights_17': 0.5780822911697239, 'weights_18': 0.13218793856098826, 'weights_19': 0.044437773982399245}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,378] Trial 198 finished with value: 3049.06285926428 and parameters: {'weights_0': 0.0008701959784689836, 'weights_1': 0.7294035880131243, 'weights_2': 0.21540430135964508, 'weights_3': 0.9703684683426896, 'weights_4': 0.728868583112237, 'weights_5': 0.9550844455696601, 'weights_6': 0.24059385375007727, 'weights_7': 0.7300605541263456, 'weights_8': 0.09757458268872404, 'weights_9': 0.01161211985324048, 'weights_10': 0.02076171211459198, 'weights_11': 0.6148714343388356, 'weights_12': 0.05922736920807572, 'weights_13': 0.1402525261639285, 'weights_14': 0.6144696345035601, 'weights_15': 0.9825816088937466, 'weights_16': 0.6229526487217365, 'weights_17': 0.5872565226419448, 'weights_18': 0.13675306203823656, 'weights_19': 0.03930455828220428}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,495] Trial 199 finished with value: 3040.496499871089 and parameters: {'weights_0': 0.012767040816142185, 'weights_1': 0.7142342588880359, 'weights_2': 0.1941282835263116, 'weights_3': 0.9787030008955983, 'weights_4': 0.7255725805293946, 'weights_5': 0.9248297199915647, 'weights_6': 0.24694073087107593, 'weights_7': 0.7377148678580596, 'weights_8': 0.08258917271949988, 'weights_9': 0.003554350224323837, 'weights_10': 0.02146364325380462, 'weights_11': 0.6249205820150111, 'weights_12': 0.05852808517055601, 'weights_13': 0.13960632260222527, 'weights_14': 0.6166328816504263, 'weights_15': 0.9860438521880662, 'weights_16': 0.5542945065713347, 'weights_17': 0.5848020308216311, 'weights_18': 0.13439062708293492, 'weights_19': 0.02217374805897409}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,587] Trial 200 finished with value: 3045.446378074452 and parameters: {'weights_0': 0.0020492404756165816, 'weights_1': 0.7166961578474774, 'weights_2': 0.20678936842938656, 'weights_3': 0.9692920871258139, 'weights_4': 0.7322992566797375, 'weights_5': 0.9232167471572411, 'weights_6': 0.20764919454495379, 'weights_7': 0.7296221879294995, 'weights_8': 0.0820844489046361, 'weights_9': 0.0010494165657198573, 'weights_10': 0.02257269736922569, 'weights_11': 0.6218439019691329, 'weights_12': 0.054989990728009294, 'weights_13': 0.1363876573993018, 'weights_14': 0.6324553067721204, 'weights_15': 0.9776754431507956, 'weights_16': 0.549881248080718, 'weights_17': 0.586369278224145, 'weights_18': 0.13189477942396843, 'weights_19': 0.02367907443873938}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,718] Trial 201 finished with value: 3046.434951778813 and parameters: {'weights_0': 0.006464963678776976, 'weights_1': 0.7164821712467757, 'weights_2': 0.21174915276216832, 'weights_3': 0.9697748127381554, 'weights_4': 0.7620469999047272, 'weights_5': 0.9209698332264843, 'weights_6': 0.20760379551710517, 'weights_7': 0.7504427379348353, 'weights_8': 0.0689866616824063, 'weights_9': 0.0030589887103219388, 'weights_10': 0.02115818290926111, 'weights_11': 0.6198821445953421, 'weights_12': 0.06319743689173789, 'weights_13': 0.1323458562843445, 'weights_14': 0.6267648616606425, 'weights_15': 0.9987054897758761, 'weights_16': 0.5596671457362377, 'weights_17': 0.5825485960163047, 'weights_18': 0.15074879657301532, 'weights_19': 0.01746276261095847}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:36,826] Trial 202 finished with value: 3044.6356858142117 and parameters: {'weights_0': 0.00453643111914936, 'weights_1': 0.7287669873816486, 'weights_2': 0.20697272754410018, 'weights_3': 0.9685024812755946, 'weights_4': 0.7595407471057382, 'weights_5': 0.9558764812493573, 'weights_6': 0.1524547213121127, 'weights_7': 0.76595520049695, 'weights_8': 0.07227710439417528, 'weights_9': 0.00720751548164789, 'weights_10': 0.020494142210656607, 'weights_11': 0.6449077500545182, 'weights_12': 0.05507394951014393, 'weights_13': 0.14051031703335387, 'weights_14': 0.6167005846506315, 'weights_15': 0.9950317530437209, 'weights_16': 0.5574931307033018, 'weights_17': 0.5885924927841513, 'weights_18': 0.1309518958525794, 'weights_19': 0.01653710384583409}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,003] Trial 203 finished with value: 3050.047969283966 and parameters: {'weights_0': 0.008223673272626934, 'weights_1': 0.7276682349451833, 'weights_2': 0.21607995679373318, 'weights_3': 0.9727915084395766, 'weights_4': 0.7951254024419762, 'weights_5': 0.9272630431674351, 'weights_6': 0.1489949196700211, 'weights_7': 0.7686090015564708, 'weights_8': 0.06043452503302423, 'weights_9': 0.0012414614428851649, 'weights_10': 0.01439569447161973, 'weights_11': 0.6486402739063862, 'weights_12': 0.053638884220875545, 'weights_13': 0.14314295894111673, 'weights_14': 0.6358356811638086, 'weights_15': 0.9927476627412235, 'weights_16': 0.5528388746732182, 'weights_17': 0.583540550006815, 'weights_18': 0.13474114638482623, 'weights_19': 0.009687175320026987}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,126] Trial 204 finished with value: 3048.7971578995403 and parameters: {'weights_0': 0.0026710895882145515, 'weights_1': 0.712875320198323, 'weights_2': 0.20138705418987224, 'weights_3': 0.971226476292066, 'weights_4': 0.7545844489818311, 'weights_5': 0.9224677697024513, 'weights_6': 0.20504914734538643, 'weights_7': 0.7309013655961745, 'weights_8': 0.07867674440177341, 'weights_9': 0.0027243438169942367, 'weights_10': 0.02332262065489616, 'weights_11': 0.6239406945993398, 'weights_12': 0.05730480744596119, 'weights_13': 0.12895143435416725, 'weights_14': 0.6166046187932633, 'weights_15': 0.9757680285360436, 'weights_16': 0.5666609845397361, 'weights_17': 0.6010775445980292, 'weights_18': 0.15278081574460195, 'weights_19': 0.03526145451732906}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,254] Trial 205 finished with value: 3051.5890088242363 and parameters: {'weights_0': 0.01987888116933144, 'weights_1': 0.706472072670707, 'weights_2': 0.20120566349177305, 'weights_3': 0.9580731565312436, 'weights_4': 0.7639327039619291, 'weights_5': 0.9284026717831456, 'weights_6': 0.2079642201940769, 'weights_7': 0.8373617038985584, 'weights_8': 0.06922685230993962, 'weights_9': 0.021333766533902048, 'weights_10': 0.0008691410701267884, 'weights_11': 0.6376691456926223, 'weights_12': 0.05162863168054596, 'weights_13': 0.12490980722951935, 'weights_14': 0.6233587472463993, 'weights_15': 0.9411507531760387, 'weights_16': 0.5547456631853231, 'weights_17': 0.6404255755635742, 'weights_18': 0.1646668833203958, 'weights_19': 0.024679101320869555}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,455] Trial 206 finished with value: 3073.5098083483167 and parameters: {'weights_0': 0.01929903019382303, 'weights_1': 0.7668897185557431, 'weights_2': 0.24631592907588973, 'weights_3': 0.9752976647427904, 'weights_4': 0.7542508602774659, 'weights_5': 0.9187888637956837, 'weights_6': 0.19206646935180677, 'weights_7': 0.7489794331382194, 'weights_8': 0.0825067324068486, 'weights_9': 0.003001699845013087, 'weights_10': 0.0289767631976671, 'weights_11': 0.6702432684697521, 'weights_12': 0.07391875094039249, 'weights_13': 0.08050222010845207, 'weights_14': 0.6497195513549296, 'weights_15': 0.9665951110535013, 'weights_16': 0.5775319089623612, 'weights_17': 0.6004106658130591, 'weights_18': 0.1547471736508162, 'weights_19': 0.016999062424015665}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,605] Trial 207 finished with value: 3043.0453851517686 and parameters: {'weights_0': 0.004553314769959085, 'weights_1': 0.7434062821009988, 'weights_2': 0.2268968575673499, 'weights_3': 0.9559715618198121, 'weights_4': 0.7870548483258818, 'weights_5': 0.9047858174845321, 'weights_6': 0.12240311844278921, 'weights_7': 0.7475118978764232, 'weights_8': 0.07693872461415267, 'weights_9': 0.025650679654975174, 'weights_10': 0.027135555112822722, 'weights_11': 0.6229191995916685, 'weights_12': 0.04269573849393579, 'weights_13': 0.1084608974774692, 'weights_14': 0.6275932525165134, 'weights_15': 0.9976111906094038, 'weights_16': 0.5222563238918984, 'weights_17': 0.5790141041988449, 'weights_18': 0.10499934692661136, 'weights_19': 0.0311695132652025}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,742] Trial 208 finished with value: 3058.6585746570804 and parameters: {'weights_0': 0.034366845883211844, 'weights_1': 0.7525046388485781, 'weights_2': 0.21942771908667694, 'weights_3': 0.9524997440718475, 'weights_4': 0.7836248762267882, 'weights_5': 0.9591672952174457, 'weights_6': 0.10443232734823844, 'weights_7': 0.8070082532641891, 'weights_8': 0.06779775199423992, 'weights_9': 0.030892598687899866, 'weights_10': 0.03539484750359749, 'weights_11': 0.6084588877597145, 'weights_12': 0.03938096545789387, 'weights_13': 0.1653018244097521, 'weights_14': 0.6295234531183349, 'weights_15': 0.906681106735711, 'weights_16': 0.540247338612555, 'weights_17': 0.5739651980635676, 'weights_18': 0.11450907768464258, 'weights_19': 0.0016358781597476668}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:37,884] Trial 209 finished with value: 3048.0881616707825 and parameters: {'weights_0': 0.01878949343501341, 'weights_1': 0.7425377971241406, 'weights_2': 0.2761494751134451, 'weights_3': 0.9833991258248969, 'weights_4': 0.7328043893991336, 'weights_5': 0.8968209146933681, 'weights_6': 0.24144097996273778, 'weights_7': 0.786688481770091, 'weights_8': 0.09264445130317195, 'weights_9': 0.034480394037690584, 'weights_10': 0.003283525525117828, 'weights_11': 0.6531034505951927, 'weights_12': 0.08032548227804098, 'weights_13': 0.10691455194825422, 'weights_14': 0.59746309206361, 'weights_15': 0.9970731295503352, 'weights_16': 0.5237053760665074, 'weights_17': 0.5717419343401525, 'weights_18': 0.10366643091765629, 'weights_19': 0.041810366331943606}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,001] Trial 210 finished with value: 3081.6455616543326 and parameters: {'weights_0': 0.018938079264797895, 'weights_1': 0.7107643279670508, 'weights_2': 0.28474194983238993, 'weights_3': 0.9845014576806025, 'weights_4': 0.7264078440568608, 'weights_5': 0.8912110215612844, 'weights_6': 0.13126708822689692, 'weights_7': 0.7894679341519987, 'weights_8': 0.08951929801265812, 'weights_9': 0.030069747138832877, 'weights_10': 0.0011240657324879234, 'weights_11': 0.6538067051318337, 'weights_12': 0.08196496310744204, 'weights_13': 0.1036995148866725, 'weights_14': 0.7027962130138454, 'weights_15': 0.9993537267844809, 'weights_16': 0.5479369155762599, 'weights_17': 0.5650824171609173, 'weights_18': 0.11622309102892908, 'weights_19': 0.04444080207715623}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,124] Trial 211 finished with value: 3025.0655101873363 and parameters: {'weights_0': 0.00020644233239973386, 'weights_1': 0.7379029578631505, 'weights_2': 0.23033461325104057, 'weights_3': 0.9599591964545044, 'weights_4': 0.7436374247401107, 'weights_5': 0.9633368850918169, 'weights_6': 0.15732023361626044, 'weights_7': 0.7455838727965329, 'weights_8': 0.04721479600734954, 'weights_9': 0.021743374289488197, 'weights_10': 0.03113508529881764, 'weights_11': 0.6243913627954029, 'weights_12': 0.06840223504217025, 'weights_13': 0.10868442623117153, 'weights_14': 0.598525783722469, 'weights_15': 0.9379252603664949, 'weights_16': 0.5160162030027666, 'weights_17': 0.6168666968944729, 'weights_18': 0.09560614331826446, 'weights_19': 0.020560174182768676}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,257] Trial 212 finished with value: 3221.1742104204295 and parameters: {'weights_0': 0.038602722884548725, 'weights_1': 0.7982395934958577, 'weights_2': 0.23853070342833685, 'weights_3': 0.9973271388435665, 'weights_4': 0.7418046786455696, 'weights_5': 0.24879952265264016, 'weights_6': 0.1470443592591558, 'weights_7': 0.7468204387019026, 'weights_8': 0.05092682384949939, 'weights_9': 0.021426746170630787, 'weights_10': 0.03743719216322017, 'weights_11': 0.6774070633956085, 'weights_12': 0.042036415224996085, 'weights_13': 0.1178570418772122, 'weights_14': 0.5912346088859423, 'weights_15': 0.9342011541825314, 'weights_16': 0.5165330735718741, 'weights_17': 0.6176235037246294, 'weights_18': 0.08271160292846833, 'weights_19': 0.02158626447957491}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,373] Trial 213 finished with value: 3030.2531909138506 and parameters: {'weights_0': 0.00028407719701009984, 'weights_1': 0.729731340868626, 'weights_2': 0.27306519991731837, 'weights_3': 0.9540529438933081, 'weights_4': 0.8113356288168334, 'weights_5': 0.9082251217296743, 'weights_6': 0.10704587459833381, 'weights_7': 0.7032789307489794, 'weights_8': 0.05051438791787148, 'weights_9': 0.03506724970339164, 'weights_10': 0.027000180562326483, 'weights_11': 0.6299417459600828, 'weights_12': 0.0652321106894191, 'weights_13': 0.07710940837418996, 'weights_14': 0.5969853084990696, 'weights_15': 0.9722766069718877, 'weights_16': 0.5217959255247401, 'weights_17': 0.6423790928023776, 'weights_18': 0.09160389784024855, 'weights_19': 0.043865086998210456}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,507] Trial 214 finished with value: 3186.3015181289015 and parameters: {'weights_0': 0.004529940088671788, 'weights_1': 0.7713333870639534, 'weights_2': 0.27437208353080805, 'weights_3': 0.9554036062945453, 'weights_4': 0.784255274795064, 'weights_5': 0.9003824892437704, 'weights_6': 0.08003907839105284, 'weights_7': 0.7018941849518298, 'weights_8': 0.050797457294606316, 'weights_9': 0.03340793844889141, 'weights_10': 0.6025979759143898, 'weights_11': 0.6258386125338776, 'weights_12': 0.05707748085743972, 'weights_13': 0.08235036343953264, 'weights_14': 0.6533603112809409, 'weights_15': 0.9711963247518215, 'weights_16': 0.4981496140184545, 'weights_17': 0.6351270588807783, 'weights_18': 0.12642710612741853, 'weights_19': 0.004277628191548345}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,675] Trial 215 finished with value: 3029.882555567195 and parameters: {'weights_0': 0.0017846180925721912, 'weights_1': 0.7440311087189178, 'weights_2': 0.2506788356339909, 'weights_3': 0.950694457097298, 'weights_4': 0.8228700389588629, 'weights_5': 0.9036472522121344, 'weights_6': 0.15932839335338642, 'weights_7': 0.7505405952254516, 'weights_8': 0.08643198611658647, 'weights_9': 0.0016709671154010747, 'weights_10': 0.02874310410842218, 'weights_11': 0.6390516277523154, 'weights_12': 0.032406782259524494, 'weights_13': 0.048898099174002826, 'weights_14': 0.5997010466142969, 'weights_15': 0.999814209524927, 'weights_16': 0.49448674484869637, 'weights_17': 0.5684111500339998, 'weights_18': 0.09800660227174056, 'weights_19': 0.041131465465210834}. Best is trial 182 with value: 3017.1442830564865.\n",
      "[I 2025-08-01 08:05:38,777] Trial 216 finished with value: 3009.78031454313 and parameters: {'weights_0': 0.0010633909739175482, 'weights_1': 0.7279549926467512, 'weights_2': 0.25735078782036974, 'weights_3': 0.949728517462487, 'weights_4': 0.8041455391082096, 'weights_5': 0.9557324182768573, 'weights_6': 0.1559344302966877, 'weights_7': 0.713949623835776, 'weights_8': 0.04836773818659324, 'weights_9': 0.004051778420558105, 'weights_10': 0.030515189234202666, 'weights_11': 0.6025620670777622, 'weights_12': 0.034162342061615204, 'weights_13': 0.0662845853228392, 'weights_14': 0.626771199779991, 'weights_15': 0.8850496142200149, 'weights_16': 0.4908567503305679, 'weights_17': 0.6498587833839845, 'weights_18': 0.07417172210778886, 'weights_19': 0.027909870524405096}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:38,961] Trial 217 finished with value: 3039.8510623997095 and parameters: {'weights_0': 0.003997099702518334, 'weights_1': 0.7216300746456792, 'weights_2': 0.3239431323337182, 'weights_3': 0.9539209959229755, 'weights_4': 0.8146411991932085, 'weights_5': 0.9157151647849023, 'weights_6': 0.11481017900513307, 'weights_7': 0.7528231976104258, 'weights_8': 0.04876392767312074, 'weights_9': 0.002205033946567146, 'weights_10': 0.04267867185903579, 'weights_11': 0.6051903139068976, 'weights_12': 0.031538729854471016, 'weights_13': 0.05458834777422278, 'weights_14': 0.6208159390144854, 'weights_15': 0.8784203755928879, 'weights_16': 0.49012463328338945, 'weights_17': 0.6569054285890404, 'weights_18': 0.09358033907086434, 'weights_19': 0.026154369595193433}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:39,121] Trial 218 finished with value: 3028.9304588953564 and parameters: {'weights_0': 0.00027625127556799153, 'weights_1': 0.6977466683474179, 'weights_2': 0.3122937419480683, 'weights_3': 0.9590365330847844, 'weights_4': 0.8264631894937716, 'weights_5': 0.9133242376753328, 'weights_6': 0.16056799355030826, 'weights_7': 0.7543688463387263, 'weights_8': 0.05710398890471796, 'weights_9': 0.0014431218630003677, 'weights_10': 0.035903514542040715, 'weights_11': 0.6279260137682601, 'weights_12': 0.023462432170379507, 'weights_13': 0.05581074637872221, 'weights_14': 0.6006047326220149, 'weights_15': 0.8837911815555453, 'weights_16': 0.4918436467382636, 'weights_17': 0.660060194901956, 'weights_18': 0.09418086240616262, 'weights_19': 0.02585253604366616}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:39,263] Trial 219 finished with value: 3244.6946656590585 and parameters: {'weights_0': 0.00213820638016435, 'weights_1': 0.7003497970139968, 'weights_2': 0.31522459086516025, 'weights_3': 0.9462587199096053, 'weights_4': 0.8006421777533133, 'weights_5': 0.9087765146129395, 'weights_6': 0.11248742761513537, 'weights_7': 0.7226874644444534, 'weights_8': 0.041557873390983685, 'weights_9': 0.016274318782936097, 'weights_10': 0.9277298053543651, 'weights_11': 0.6002609965227439, 'weights_12': 0.025802530000644842, 'weights_13': 0.0565323887741471, 'weights_14': 0.5750758459255687, 'weights_15': 0.8815692591373053, 'weights_16': 0.4925414743862946, 'weights_17': 0.6599838358146572, 'weights_18': 0.08538762537988343, 'weights_19': 0.036242071500608555}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:39,395] Trial 220 finished with value: 3034.132070797241 and parameters: {'weights_0': 0.041383156910586305, 'weights_1': 0.7275721829162581, 'weights_2': 0.26042924984939764, 'weights_3': 0.9518791818450849, 'weights_4': 0.8345893156926136, 'weights_5': 0.9363012563579421, 'weights_6': 0.1547519012734277, 'weights_7': 0.7495818870568042, 'weights_8': 0.05249090497478065, 'weights_9': 0.00461848246123508, 'weights_10': 0.03954659272109038, 'weights_11': 0.6382240200181681, 'weights_12': 0.038199863207029255, 'weights_13': 0.046982655161429014, 'weights_14': 0.6088966825240534, 'weights_15': 0.8870401337014863, 'weights_16': 0.5089357882667931, 'weights_17': 0.6476720126457315, 'weights_18': 0.10110070329366923, 'weights_19': 0.025310903368597697}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:39,528] Trial 221 finished with value: 3011.406078649354 and parameters: {'weights_0': 0.00042748481931471904, 'weights_1': 0.7258111465173056, 'weights_2': 0.25432040301045566, 'weights_3': 0.9512308935793138, 'weights_4': 0.8253417736508694, 'weights_5': 0.9423209441103954, 'weights_6': 0.1462201280391004, 'weights_7': 0.7631223238921911, 'weights_8': 0.04927938658935242, 'weights_9': 0.0010709616223429747, 'weights_10': 0.03924421590738036, 'weights_11': 0.6337868293609119, 'weights_12': 0.03297083482603454, 'weights_13': 0.027676918297581805, 'weights_14': 0.599691491283897, 'weights_15': 0.9243939681111302, 'weights_16': 0.48878603637335005, 'weights_17': 0.6735736960234063, 'weights_18': 0.1023312493195461, 'weights_19': 0.0013701239331286655}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:39,684] Trial 222 finished with value: 3037.419744787044 and parameters: {'weights_0': 0.0003721209064471865, 'weights_1': 0.7248951220964465, 'weights_2': 0.3915691228520046, 'weights_3': 0.9507755395258222, 'weights_4': 0.8240001538339599, 'weights_5': 0.9326483823507227, 'weights_6': 0.15432414114825982, 'weights_7': 0.7636004685464235, 'weights_8': 0.04835924903974368, 'weights_9': 0.0006084758521423899, 'weights_10': 0.03767266128719346, 'weights_11': 0.6398663876762867, 'weights_12': 0.032962532309640746, 'weights_13': 0.03218808337379979, 'weights_14': 0.5983241755078589, 'weights_15': 0.8838192221782976, 'weights_16': 0.5081171962539068, 'weights_17': 0.6727119361151135, 'weights_18': 0.10255187918992463, 'weights_19': 0.000387133340740909}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:39,825] Trial 223 finished with value: 3020.698108578239 and parameters: {'weights_0': 0.02523118525025383, 'weights_1': 0.7562638079135049, 'weights_2': 0.25253281308394104, 'weights_3': 0.9467497203634528, 'weights_4': 0.828846956069669, 'weights_5': 0.9407046614349103, 'weights_6': 0.16034877406745857, 'weights_7': 0.756372281921232, 'weights_8': 0.043468796691644815, 'weights_9': 0.021865110167131288, 'weights_10': 0.040237362347194605, 'weights_11': 0.6476724329883888, 'weights_12': 0.029493486580119195, 'weights_13': 0.03975561291400655, 'weights_14': 0.5971354950551692, 'weights_15': 0.8866398169639778, 'weights_16': 0.4857159200508786, 'weights_17': 0.6602646606742085, 'weights_18': 0.10162285760896494, 'weights_19': 0.0091632691283699}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,041] Trial 224 finished with value: 3047.1517164336615 and parameters: {'weights_0': 0.03693998443726948, 'weights_1': 0.7576651561825787, 'weights_2': 0.3804566227128998, 'weights_3': 0.953232962413889, 'weights_4': 0.8198976027787176, 'weights_5': 0.939851724217385, 'weights_6': 0.11683379158265061, 'weights_7': 0.7544208901136542, 'weights_8': 0.03549306734087662, 'weights_9': 0.038863451959298995, 'weights_10': 0.040548570850477306, 'weights_11': 0.6735083263445975, 'weights_12': 0.034087851902987784, 'weights_13': 0.03742495993889649, 'weights_14': 0.5904727630470524, 'weights_15': 0.8878333558098247, 'weights_16': 0.49470635341689556, 'weights_17': 0.712670855622445, 'weights_18': 0.10087516068973917, 'weights_19': 0.04423104647973295}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,199] Trial 225 finished with value: 3039.751153337448 and parameters: {'weights_0': 0.02454044016248695, 'weights_1': 0.7807433550332097, 'weights_2': 0.32750316848930694, 'weights_3': 0.9431195812060365, 'weights_4': 0.847922609882104, 'weights_5': 0.9064621380225115, 'weights_6': 0.16543114546034554, 'weights_7': 0.7051419032481945, 'weights_8': 0.03597211308385565, 'weights_9': 0.02003522576715047, 'weights_10': 0.09000542762161803, 'weights_11': 0.6422898048331298, 'weights_12': 0.024019973113076964, 'weights_13': 0.06962608452698585, 'weights_14': 0.6057695853340217, 'weights_15': 0.9209119813846525, 'weights_16': 0.5159170021262082, 'weights_17': 0.675773927214088, 'weights_18': 0.07390662238044625, 'weights_19': 0.005716911564088479}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,315] Trial 226 finished with value: 3025.743488122238 and parameters: {'weights_0': 0.025678175822204614, 'weights_1': 0.8147583349793939, 'weights_2': 0.32545006056134707, 'weights_3': 0.9237792996472093, 'weights_4': 0.8447547786534743, 'weights_5': 0.9330032194985354, 'weights_6': 0.15270804926188342, 'weights_7': 0.7053363957193027, 'weights_8': 0.04484969560836209, 'weights_9': 0.02008240586369843, 'weights_10': 0.08020982714234302, 'weights_11': 0.6413373855126143, 'weights_12': 0.022172758071771367, 'weights_13': 0.028231322800882953, 'weights_14': 0.5981232043068803, 'weights_15': 0.9173338551018569, 'weights_16': 0.48121609548981764, 'weights_17': 0.6815941313220727, 'weights_18': 0.07185932419843076, 'weights_19': 0.005546261811364018}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,548] Trial 227 finished with value: 3040.338651937468 and parameters: {'weights_0': 0.04202209994659657, 'weights_1': 0.8082044906055393, 'weights_2': 0.32535251278743355, 'weights_3': 0.9449862868992084, 'weights_4': 0.8549582971089664, 'weights_5': 0.9223374383733434, 'weights_6': 0.1597770293708504, 'weights_7': 0.7037527306112576, 'weights_8': 0.028169678022719122, 'weights_9': 0.0011960859124502923, 'weights_10': 0.09753035219623622, 'weights_11': 0.6620787981179986, 'weights_12': 0.021472081693120558, 'weights_13': 0.03483916087682423, 'weights_14': 0.6012205913696929, 'weights_15': 0.9107595801802437, 'weights_16': 0.4822860754198559, 'weights_17': 0.6824048753151947, 'weights_18': 0.07407036053134013, 'weights_19': 0.02321256946997571}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,658] Trial 228 finished with value: 3038.5122110003654 and parameters: {'weights_0': 0.028394066684361764, 'weights_1': 0.7995450396091812, 'weights_2': 0.32690027479034267, 'weights_3': 0.9421147753768132, 'weights_4': 0.8527583602871714, 'weights_5': 0.9321862979873619, 'weights_6': 0.08428563702689071, 'weights_7': 0.7047311673479879, 'weights_8': 0.04498259563053718, 'weights_9': 0.017795143412196793, 'weights_10': 0.09438178108181616, 'weights_11': 0.6559274120096633, 'weights_12': 0.027069183369165854, 'weights_13': 0.034999933566439656, 'weights_14': 0.6023204984591357, 'weights_15': 0.920812239285432, 'weights_16': 0.4793943294199342, 'weights_17': 0.6746737768376757, 'weights_18': 0.06747097693842115, 'weights_19': 0.0032245379794270737}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,808] Trial 229 finished with value: 3045.5679187478104 and parameters: {'weights_0': 0.038033097161153925, 'weights_1': 0.8207707880686238, 'weights_2': 0.32455137496787734, 'weights_3': 0.9406366115259437, 'weights_4': 0.8538240297170958, 'weights_5': 0.889806207552268, 'weights_6': 0.16041113939406865, 'weights_7': 0.6976747323739263, 'weights_8': 0.045450039456193206, 'weights_9': 0.020715436687264548, 'weights_10': 0.08919706079155827, 'weights_11': 0.7021548508652098, 'weights_12': 0.01946451081396016, 'weights_13': 0.036804674236027346, 'weights_14': 0.5959414317463553, 'weights_15': 0.9199268729185356, 'weights_16': 0.48540844213387513, 'weights_17': 0.6890647425415911, 'weights_18': 0.07190185286761917, 'weights_19': 0.002461029632403071}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:40,966] Trial 230 finished with value: 3038.8008446469544 and parameters: {'weights_0': 0.027843541958778056, 'weights_1': 0.8074529753255884, 'weights_2': 0.3696889246605293, 'weights_3': 0.9424646031567308, 'weights_4': 0.8300915458491157, 'weights_5': 0.9382638480951138, 'weights_6': 0.07907607784319769, 'weights_7': 0.7109476622449867, 'weights_8': 0.027940661774283424, 'weights_9': 0.04390497696897569, 'weights_10': 0.04579231699481588, 'weights_11': 0.6580272083302128, 'weights_12': 0.024206214403139213, 'weights_13': 0.033904959902601575, 'weights_14': 0.6021228028059371, 'weights_15': 0.8856184540720122, 'weights_16': 0.476383228512606, 'weights_17': 0.6673636012194925, 'weights_18': 0.09318438147036548, 'weights_19': 0.006088228394455521}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,071] Trial 231 finished with value: 3051.111379093627 and parameters: {'weights_0': 0.027498559361179085, 'weights_1': 0.8053760425640801, 'weights_2': 0.3804331034835145, 'weights_3': 0.9443282566521346, 'weights_4': 0.8312653975523278, 'weights_5': 0.9375172900487092, 'weights_6': 0.07893062326493758, 'weights_7': 0.70473663469353, 'weights_8': 0.031031978300658777, 'weights_9': 0.04016014480799749, 'weights_10': 0.08911141465396101, 'weights_11': 0.655228272622333, 'weights_12': 0.02172889894877262, 'weights_13': 0.02081448227138863, 'weights_14': 0.6024878968359099, 'weights_15': 0.8916686299933057, 'weights_16': 0.5092439093969827, 'weights_17': 0.6722867510996541, 'weights_18': 0.0906532513583485, 'weights_19': 0.0004334794338815329}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,204] Trial 232 finished with value: 3029.598549997227 and parameters: {'weights_0': 0.04088244756322346, 'weights_1': 0.7918302878096555, 'weights_2': 0.3348199115918225, 'weights_3': 0.9206100023592948, 'weights_4': 0.8464099548119275, 'weights_5': 0.914835828422477, 'weights_6': 0.1350308755460948, 'weights_7': 0.713556901924136, 'weights_8': 0.04701244056126144, 'weights_9': 0.019932911624570553, 'weights_10': 0.04129567590482232, 'weights_11': 0.6626767779187328, 'weights_12': 0.02416000346097115, 'weights_13': 0.04126354007012811, 'weights_14': 0.5733909637746117, 'weights_15': 0.910903046701156, 'weights_16': 0.4718073270123851, 'weights_17': 0.6475399061343031, 'weights_18': 0.0748144636903412, 'weights_19': 0.007965612932950996}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,327] Trial 233 finished with value: 3061.295697830332 and parameters: {'weights_0': 0.02442031245975295, 'weights_1': 0.7898969394747863, 'weights_2': 0.34429851833264663, 'weights_3': 0.9196606492727473, 'weights_4': 0.8239242312961291, 'weights_5': 0.902608886484117, 'weights_6': 0.04923864229916751, 'weights_7': 0.830262759376758, 'weights_8': 0.05248207315615524, 'weights_9': 0.023314752596472157, 'weights_10': 0.04561158784755827, 'weights_11': 0.6694143712386748, 'weights_12': 0.02975481976408881, 'weights_13': 0.05028833327313656, 'weights_14': 0.5775619386655185, 'weights_15': 0.925418822666924, 'weights_16': 0.4723055216324707, 'weights_17': 0.6503327414682174, 'weights_18': 0.09453684809270732, 'weights_19': 0.0018723615826958997}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,620] Trial 234 finished with value: 3044.44647383999 and parameters: {'weights_0': 0.04267306262681257, 'weights_1': 0.8394010938776929, 'weights_2': 0.4225532519247968, 'weights_3': 0.9222200607757878, 'weights_4': 0.8139308852539344, 'weights_5': 0.9515775114327202, 'weights_6': 0.14056180801798923, 'weights_7': 0.7160854371803911, 'weights_8': 0.055756994426808926, 'weights_9': 0.044829945055668306, 'weights_10': 0.04500103516662769, 'weights_11': 0.6378472457896205, 'weights_12': 0.013888040304750613, 'weights_13': 0.03681326830570063, 'weights_14': 0.5721220564863326, 'weights_15': 0.8722082861695637, 'weights_16': 0.5108389185609605, 'weights_17': 0.7009159231597615, 'weights_18': 0.07078563282547534, 'weights_19': 0.051666201804659924}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,733] Trial 235 finished with value: 3055.5440825301134 and parameters: {'weights_0': 0.025383544499699782, 'weights_1': 0.776637122335901, 'weights_2': 0.3077619917837967, 'weights_3': 0.947298457811904, 'weights_4': 0.8423744114825871, 'weights_5': 0.9390068504029523, 'weights_6': 0.13117953696103826, 'weights_7': 0.8044693554328176, 'weights_8': 0.042593840548090296, 'weights_9': 0.028218197027109985, 'weights_10': 0.04376303937356518, 'weights_11': 0.6966185227964874, 'weights_12': 0.03408837935741173, 'weights_13': 0.06949910259050282, 'weights_14': 0.6071981543769446, 'weights_15': 0.8960250471987669, 'weights_16': 0.530555003545206, 'weights_17': 0.6612867893614054, 'weights_18': 0.11185143434041322, 'weights_19': 0.0010369487853397075}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,865] Trial 236 finished with value: 3031.4417056119605 and parameters: {'weights_0': 0.024311831033335708, 'weights_1': 0.7877662971906664, 'weights_2': 0.30245463538007655, 'weights_3': 0.9600341967251051, 'weights_4': 0.8345431401475416, 'weights_5': 0.9130060203742189, 'weights_6': 0.16954981945556827, 'weights_7': 0.7728533708953688, 'weights_8': 0.027581835393022447, 'weights_9': 0.016194496107209515, 'weights_10': 0.07785927473107185, 'weights_11': 0.6411818966300883, 'weights_12': 0.0014588178413057831, 'weights_13': 0.06946492124679274, 'weights_14': 0.5967782256208988, 'weights_15': 0.9309230165510713, 'weights_16': 0.4989202975791606, 'weights_17': 0.7153376742308749, 'weights_18': 0.06705602249301057, 'weights_19': 0.030578362798131857}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:41,997] Trial 237 finished with value: 3054.1557647664968 and parameters: {'weights_0': 0.022623002712784338, 'weights_1': 0.7953691148678939, 'weights_2': 0.3636172710950988, 'weights_3': 0.8915168116619707, 'weights_4': 0.8704865021829818, 'weights_5': 0.9025870095280374, 'weights_6': 0.09038328627605247, 'weights_7': 0.768074238795383, 'weights_8': 0.023446494801012477, 'weights_9': 0.01593982836728017, 'weights_10': 0.08655370227443204, 'weights_11': 0.6393346175755633, 'weights_12': 0.0032803048900532897, 'weights_13': 0.07141447205903259, 'weights_14': 0.5991901938643472, 'weights_15': 0.9073595019852316, 'weights_16': 0.49803620232583207, 'weights_17': 0.71884232803309, 'weights_18': 0.06700043943558055, 'weights_19': 0.03301821662289147}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,145] Trial 238 finished with value: 3028.311538312193 and parameters: {'weights_0': 0.04488378551197572, 'weights_1': 0.8275915766075415, 'weights_2': 0.3055503715595639, 'weights_3': 0.9250127506325254, 'weights_4': 0.8335002648036456, 'weights_5': 0.8850057876142303, 'weights_6': 0.16984173532685376, 'weights_7': 0.720559911733523, 'weights_8': 0.05658858522812488, 'weights_9': 0.0457360456122559, 'weights_10': 0.0026872370152151636, 'weights_11': 0.6808961080215774, 'weights_12': 0.03402662357781546, 'weights_13': 0.029174435380798662, 'weights_14': 0.5753616208754493, 'weights_15': 0.9301362720645057, 'weights_16': 0.47059123110424533, 'weights_17': 0.6465312491274339, 'weights_18': 0.09204157606103122, 'weights_19': 0.018050795128013605}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,258] Trial 239 finished with value: 3015.4474180014904 and parameters: {'weights_0': 0.047018549341957275, 'weights_1': 0.8204504162988919, 'weights_2': 0.2590258111690533, 'weights_3': 0.9240112477020374, 'weights_4': 0.8384638747644061, 'weights_5': 0.8806114358830706, 'weights_6': 0.17558307417387128, 'weights_7': 0.7196525986922213, 'weights_8': 0.016167407870845134, 'weights_9': 0.0511037752545676, 'weights_10': 0.006313151851925717, 'weights_11': 0.6831632993895479, 'weights_12': 0.01695032505359425, 'weights_13': 0.025221928733735938, 'weights_14': 0.5724300591019307, 'weights_15': 0.9266535556973052, 'weights_16': 0.4706225705540134, 'weights_17': 0.6366168601645137, 'weights_18': 0.06475731404486729, 'weights_19': 0.049296582852203605}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,353] Trial 240 finished with value: 3024.171194531595 and parameters: {'weights_0': 0.047576269911385506, 'weights_1': 0.8238005686115377, 'weights_2': 0.29756863436968456, 'weights_3': 0.9199282836106544, 'weights_4': 0.8334413966711335, 'weights_5': 0.9378949504621857, 'weights_6': 0.18440038174953624, 'weights_7': 0.7854168631876757, 'weights_8': 0.017423710471958592, 'weights_9': 0.04682321957748011, 'weights_10': 0.002086740769922493, 'weights_11': 0.7162807890463783, 'weights_12': 0.0012582199238351521, 'weights_13': 0.02751008399951435, 'weights_14': 0.5717638378809382, 'weights_15': 0.9337625564247155, 'weights_16': 0.4685744773023421, 'weights_17': 0.6463882848333324, 'weights_18': 0.10206914831330041, 'weights_19': 0.04766244394586978}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,485] Trial 241 finished with value: 3146.78937737903 and parameters: {'weights_0': 0.6937530928171237, 'weights_1': 0.8126173940917683, 'weights_2': 0.2971593729131645, 'weights_3': 0.9184710704331775, 'weights_4': 0.8349408997009048, 'weights_5': 0.886414711770114, 'weights_6': 0.18081473239333973, 'weights_7': 0.9671172199050886, 'weights_8': 0.013932373625183916, 'weights_9': 0.04384207480586241, 'weights_10': 0.004168535173088156, 'weights_11': 0.6929183962459625, 'weights_12': 0.005405306676857936, 'weights_13': 0.0245345980236333, 'weights_14': 0.5729446867887312, 'weights_15': 0.9317559056931147, 'weights_16': 0.4304663275368214, 'weights_17': 0.6304947133412977, 'weights_18': 0.11046934609235637, 'weights_19': 0.051215802412103856}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,666] Trial 242 finished with value: 3025.0853443784677 and parameters: {'weights_0': 0.04902472145353182, 'weights_1': 0.8484956010367545, 'weights_2': 0.2701182892857834, 'weights_3': 0.919921636787245, 'weights_4': 0.8764794037942427, 'weights_5': 0.9360092742063172, 'weights_6': 0.16771164044363882, 'weights_7': 0.7801118483460374, 'weights_8': 0.05333821869558895, 'weights_9': 0.05292898195980208, 'weights_10': 0.002832405243439782, 'weights_11': 0.7147359513394246, 'weights_12': 0.040011546364775136, 'weights_13': 0.03923550050992146, 'weights_14': 0.5691220474849327, 'weights_15': 0.9372556245582652, 'weights_16': 0.4600965568100005, 'weights_17': 0.6433125357564259, 'weights_18': 0.09022178367072013, 'weights_19': 0.04533526874233258}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,821] Trial 243 finished with value: 3033.7162515514297 and parameters: {'weights_0': 0.045662778364471183, 'weights_1': 0.8458471575917801, 'weights_2': 0.2638056759800195, 'weights_3': 0.9271646824166798, 'weights_4': 0.8720265338295263, 'weights_5': 0.9337412723887759, 'weights_6': 0.1705793260798651, 'weights_7': 0.7871893024549608, 'weights_8': 0.054820223797117415, 'weights_9': 0.05214214606096246, 'weights_10': 0.03153629335113385, 'weights_11': 0.710750717811532, 'weights_12': 0.038317623923323565, 'weights_13': 0.03475936746622889, 'weights_14': 0.567566882002103, 'weights_15': 0.9341631089767276, 'weights_16': 0.4704143742461417, 'weights_17': 0.6227158210291865, 'weights_18': 0.09245985002758647, 'weights_19': 0.044297425771961135}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:42,940] Trial 244 finished with value: 3023.8467596390783 and parameters: {'weights_0': 0.047199066860994135, 'weights_1': 0.847709541504572, 'weights_2': 0.2595715246443018, 'weights_3': 0.9248665968533726, 'weights_4': 0.872968231215133, 'weights_5': 0.9353344360450505, 'weights_6': 0.17448705188821367, 'weights_7': 0.7800720838819035, 'weights_8': 0.05713432980674421, 'weights_9': 0.05700188845295072, 'weights_10': 0.033318776137449636, 'weights_11': 0.7277765536258268, 'weights_12': 0.036445311507418206, 'weights_13': 0.04141100932592759, 'weights_14': 0.5639469451284015, 'weights_15': 0.9344467445332068, 'weights_16': 0.41854393790628136, 'weights_17': 0.6376838588856403, 'weights_18': 0.09619943055856682, 'weights_19': 0.02384089894067597}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:43,268] Trial 245 finished with value: 3025.7141768869915 and parameters: {'weights_0': 0.048412365165701174, 'weights_1': 0.85412122438248, 'weights_2': 0.255654246180857, 'weights_3': 0.9221937364788277, 'weights_4': 0.8837542098591161, 'weights_5': 0.9301044693898711, 'weights_6': 0.17630737935873883, 'weights_7': 0.7908953727426494, 'weights_8': 0.05297172239694789, 'weights_9': 0.049480706141522834, 'weights_10': 0.00038987008970350207, 'weights_11': 0.7222731501600889, 'weights_12': 0.03679374145351723, 'weights_13': 0.030630110384587517, 'weights_14': 0.5680282579994902, 'weights_15': 0.9037035984136146, 'weights_16': 0.4680568180916296, 'weights_17': 0.6430821607633653, 'weights_18': 0.09650609429406572, 'weights_19': 0.02059687235825117}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:43,427] Trial 246 finished with value: 3041.9434318877416 and parameters: {'weights_0': 0.04631831310877615, 'weights_1': 0.8499981418654845, 'weights_2': 0.26229890313694176, 'weights_3': 0.9235365927883774, 'weights_4': 0.868200308981224, 'weights_5': 0.8812413151004523, 'weights_6': 0.17072192229618977, 'weights_7': 0.7887737757433826, 'weights_8': 0.05343566372801208, 'weights_9': 0.056069598289055125, 'weights_10': 0.002502903074051966, 'weights_11': 0.7232970182714442, 'weights_12': 0.03477312749471602, 'weights_13': 0.04525313798032738, 'weights_14': 0.5674918297716606, 'weights_15': 0.9084862157414715, 'weights_16': 0.4578148503305244, 'weights_17': 0.6301865136135976, 'weights_18': 0.10692576532941478, 'weights_19': 0.028274660486757353}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:43,546] Trial 247 finished with value: 3030.5859457110932 and parameters: {'weights_0': 0.05001341959229766, 'weights_1': 0.831393043840731, 'weights_2': 0.29721693499786805, 'weights_3': 0.8926762626562734, 'weights_4': 0.873796414466166, 'weights_5': 0.9227113062516599, 'weights_6': 0.14249275148246887, 'weights_7': 0.8585760424102807, 'weights_8': 0.060507455357615085, 'weights_9': 0.05271755786266473, 'weights_10': 0.013300524250480544, 'weights_11': 0.753211292402632, 'weights_12': 0.004203130845374967, 'weights_13': 0.022099978493250804, 'weights_14': 0.555721438990104, 'weights_15': 0.9386935894712868, 'weights_16': 0.41928877779657825, 'weights_17': 0.643342247758745, 'weights_18': 0.057527649987531036, 'weights_19': 0.04764312054006117}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:43,683] Trial 248 finished with value: 3037.9427598911334 and parameters: {'weights_0': 0.051015330597749445, 'weights_1': 0.8839668118522093, 'weights_2': 0.29838878998537866, 'weights_3': 0.8975322486784156, 'weights_4': 0.8840373506193561, 'weights_5': 0.915375150122954, 'weights_6': 0.14280603858762378, 'weights_7': 0.8478582038979786, 'weights_8': 0.012892949806836959, 'weights_9': 0.045940561835022556, 'weights_10': 0.014406030863528648, 'weights_11': 0.7512910307334416, 'weights_12': 0.015474080648891414, 'weights_13': 4.9230391665638223e-05, 'weights_14': 0.5616375852713331, 'weights_15': 0.9448413657624264, 'weights_16': 0.4250955757272102, 'weights_17': 0.6393230842003575, 'weights_18': 0.09463724826963832, 'weights_19': 0.04707417859049358}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:43,825] Trial 249 finished with value: 3039.5293967574557 and parameters: {'weights_0': 0.04728813279865723, 'weights_1': 0.8374929676452603, 'weights_2': 0.30207797324381447, 'weights_3': 0.8917111411442322, 'weights_4': 0.8775182558136047, 'weights_5': 0.9141880628714172, 'weights_6': 0.14458573355555107, 'weights_7': 0.8732504807617346, 'weights_8': 0.0036491753677538458, 'weights_9': 0.06059671203060319, 'weights_10': 0.01715972891101859, 'weights_11': 0.7535726982839568, 'weights_12': 0.0024605810801994815, 'weights_13': 0.015578523621076638, 'weights_14': 0.5582884295009316, 'weights_15': 0.9406855745746016, 'weights_16': 0.41407823337530053, 'weights_17': 0.6494686817355625, 'weights_18': 0.11198179394876796, 'weights_19': 0.056907825249007025}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:44,048] Trial 250 finished with value: 3027.9535029538783 and parameters: {'weights_0': 0.05503960547043456, 'weights_1': 0.8825771030640029, 'weights_2': 0.2788571730700243, 'weights_3': 0.8944663420570483, 'weights_4': 0.8920242533473149, 'weights_5': 0.9029856721620821, 'weights_6': 0.182699537721376, 'weights_7': 0.8560961965392421, 'weights_8': 0.05644051408837518, 'weights_9': 0.044886043116136067, 'weights_10': 0.0022869612975615072, 'weights_11': 0.7412352779771618, 'weights_12': 0.0026143876284524525, 'weights_13': 0.005927269554757586, 'weights_14': 0.551035677092251, 'weights_15': 0.940349421654145, 'weights_16': 0.4318324102546562, 'weights_17': 0.641790011166249, 'weights_18': 0.06393078085480838, 'weights_19': 0.049959947529314284}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:44,220] Trial 251 finished with value: 3018.725553048365 and parameters: {'weights_0': 0.06928518555244176, 'weights_1': 0.8299798267057885, 'weights_2': 0.2609318883228021, 'weights_3': 0.9219780798661091, 'weights_4': 0.9079436712960406, 'weights_5': 0.88683846781855, 'weights_6': 0.18967040002850866, 'weights_7': 0.8047114668724022, 'weights_8': 0.060400955505183554, 'weights_9': 0.05718095175857916, 'weights_10': 0.0025750178926118306, 'weights_11': 0.7170814415482007, 'weights_12': 0.04126583111348214, 'weights_13': 0.022222578511529756, 'weights_14': 0.5497114429941892, 'weights_15': 0.9084270301075935, 'weights_16': 0.38751061401589043, 'weights_17': 0.6168433388853133, 'weights_18': 0.0580959768885256, 'weights_19': 0.06174195479112733}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:44,481] Trial 252 finished with value: 3028.215124933834 and parameters: {'weights_0': 0.07997507770530674, 'weights_1': 0.8544115932418508, 'weights_2': 0.2732663258287936, 'weights_3': 0.8361778896179096, 'weights_4': 0.9265592835369831, 'weights_5': 0.8942467166273647, 'weights_6': 0.18397396942728084, 'weights_7': 0.817591269576847, 'weights_8': 0.060178065196422374, 'weights_9': 0.048066561306977715, 'weights_10': 0.0022662739372281485, 'weights_11': 0.7154367220365244, 'weights_12': 0.004347577444614219, 'weights_13': 0.05808802444289974, 'weights_14': 0.5484262201169376, 'weights_15': 0.9027597600430294, 'weights_16': 0.40317987778536113, 'weights_17': 0.6167802456919659, 'weights_18': 0.05031545160647097, 'weights_19': 0.06227516535016229}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:44,604] Trial 253 finished with value: 3024.4176668020978 and parameters: {'weights_0': 0.07777037984246644, 'weights_1': 0.8585586859921888, 'weights_2': 0.26033584298619133, 'weights_3': 0.8945956555353913, 'weights_4': 0.9106700095216098, 'weights_5': 0.8830890008404068, 'weights_6': 0.18925881976659187, 'weights_7': 0.8171333630125176, 'weights_8': 0.05485536832404346, 'weights_9': 0.06025281477045444, 'weights_10': 0.001994769883360399, 'weights_11': 0.715499757937019, 'weights_12': 0.007001778471821932, 'weights_13': 0.05608462341905658, 'weights_14': 0.5182618953951745, 'weights_15': 0.9034221256342104, 'weights_16': 0.4029902962459898, 'weights_17': 0.624151159107135, 'weights_18': 0.058462456668585724, 'weights_19': 0.06750491658618696}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:44,812] Trial 254 finished with value: 3029.528178026604 and parameters: {'weights_0': 0.07991456854207843, 'weights_1': 0.8596540518528546, 'weights_2': 0.26392980697510876, 'weights_3': 0.890396332115592, 'weights_4': 0.915889275880333, 'weights_5': 0.8900033039462835, 'weights_6': 0.19012649127985864, 'weights_7': 0.8558843844174796, 'weights_8': 0.05733740827271812, 'weights_9': 0.055745183440570084, 'weights_10': 0.0026509949145239443, 'weights_11': 0.726626667355881, 'weights_12': 0.0006823170506955224, 'weights_13': 0.05136369408528252, 'weights_14': 0.5456572451483416, 'weights_15': 0.9012003097111837, 'weights_16': 0.39045220087168164, 'weights_17': 0.6178990793475428, 'weights_18': 0.054879874210848986, 'weights_19': 0.06560474888930513}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:44,933] Trial 255 finished with value: 3022.84344088972 and parameters: {'weights_0': 0.07982589060821738, 'weights_1': 0.8609264291724994, 'weights_2': 0.2728503754506164, 'weights_3': 0.8493711772527306, 'weights_4': 0.9146502655460385, 'weights_5': 0.8791173410435829, 'weights_6': 0.18628590259714498, 'weights_7': 0.8199277857639864, 'weights_8': 0.06338768653392307, 'weights_9': 0.06286351967885326, 'weights_10': 0.005165043763396727, 'weights_11': 0.7214360849110599, 'weights_12': 0.005953703855509976, 'weights_13': 0.01962861834910914, 'weights_14': 0.501852528530612, 'weights_15': 0.9061326711149937, 'weights_16': 0.39269344779464516, 'weights_17': 0.6138374611963631, 'weights_18': 0.055201690535032835, 'weights_19': 0.06628327025066137}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:45,089] Trial 256 finished with value: 3034.2873987935645 and parameters: {'weights_0': 0.07886492159613713, 'weights_1': 0.8976253017057835, 'weights_2': 0.2867450643998761, 'weights_3': 0.8493514660215665, 'weights_4': 0.8951887331558037, 'weights_5': 0.879405701214632, 'weights_6': 0.18930580571021471, 'weights_7': 0.8613194685596431, 'weights_8': 0.0628997817139072, 'weights_9': 0.06698266329252728, 'weights_10': 0.0060207731188511035, 'weights_11': 0.7338821196686147, 'weights_12': 0.0025780590093902414, 'weights_13': 0.06265677850999077, 'weights_14': 0.5017356736445218, 'weights_15': 0.9045113010273694, 'weights_16': 0.36721314215406714, 'weights_17': 0.6262628384995412, 'weights_18': 0.048940642021919153, 'weights_19': 0.06779008502665416}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:45,224] Trial 257 finished with value: 3026.5823547321725 and parameters: {'weights_0': 0.08246163467223534, 'weights_1': 0.8317248533821163, 'weights_2': 0.27763927903011876, 'weights_3': 0.8813399579770143, 'weights_4': 0.922806891741956, 'weights_5': 0.8589767970853476, 'weights_6': 0.1895616971520777, 'weights_7': 0.8158368275521959, 'weights_8': 0.02516934298658338, 'weights_9': 0.040928600894556716, 'weights_10': 0.0018688048164855824, 'weights_11': 0.7722261970851544, 'weights_12': 0.0015662911927217058, 'weights_13': 0.017958647923622107, 'weights_14': 0.5142624486307024, 'weights_15': 0.96427441807116, 'weights_16': 0.4142875874754063, 'weights_17': 0.6169632774299875, 'weights_18': 0.058610191597342445, 'weights_19': 0.06201815246753282}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:45,418] Trial 258 finished with value: 3039.152421665105 and parameters: {'weights_0': 0.08016698856896344, 'weights_1': 0.8737188239123618, 'weights_2': 0.2759114326456308, 'weights_3': 0.8922200151608058, 'weights_4': 0.9223129659761615, 'weights_5': 0.8601215646111617, 'weights_6': 0.19021626218667792, 'weights_7': 0.9020833803357935, 'weights_8': 0.06381420230885998, 'weights_9': 0.06976789180776671, 'weights_10': 4.312717475295582e-05, 'weights_11': 0.7876932959078273, 'weights_12': 0.015102879903429128, 'weights_13': 0.024626995725066415, 'weights_14': 0.5162928420936568, 'weights_15': 0.9573660424153276, 'weights_16': 0.4061792564569243, 'weights_17': 0.6150138846479097, 'weights_18': 0.052497695874399466, 'weights_19': 0.052713075370891115}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:45,577] Trial 259 finished with value: 3011.610272372238 and parameters: {'weights_0': 0.07169439171314215, 'weights_1': 0.856445073792039, 'weights_2': 0.2502106498302231, 'weights_3': 0.8493624802715789, 'weights_4': 0.9218098236921938, 'weights_5': 0.8824885751092416, 'weights_6': 0.18776141937136262, 'weights_7': 0.8307945217769753, 'weights_8': 0.02346727474746352, 'weights_9': 0.04337269122186244, 'weights_10': 0.0017487955066616781, 'weights_11': 0.7173144341304096, 'weights_12': 0.015109147961894723, 'weights_13': 0.01603274009549939, 'weights_14': 0.4959219573252225, 'weights_15': 0.9100070885125687, 'weights_16': 0.3938656382391707, 'weights_17': 0.6412775369326577, 'weights_18': 0.053690326248737805, 'weights_19': 0.06390486976534451}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:45,729] Trial 260 finished with value: 3020.0514187263675 and parameters: {'weights_0': 0.09241197654532318, 'weights_1': 0.8581654035629622, 'weights_2': 0.2530301690885662, 'weights_3': 0.8311625935952012, 'weights_4': 0.9179916056730291, 'weights_5': 0.8823570303825042, 'weights_6': 0.19198811888451287, 'weights_7': 0.8116486262475308, 'weights_8': 0.022556066227149507, 'weights_9': 0.044178729318975, 'weights_10': 0.00016311592944530384, 'weights_11': 0.7190718720830951, 'weights_12': 0.001228448192341424, 'weights_13': 0.005536244491152975, 'weights_14': 0.4909558744966018, 'weights_15': 0.8999274215583979, 'weights_16': 0.4358239956912189, 'weights_17': 0.6110880106646087, 'weights_18': 0.05567885100214122, 'weights_19': 0.06406052701204873}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:45,933] Trial 261 finished with value: 3020.669159242012 and parameters: {'weights_0': 0.0723701760081503, 'weights_1': 0.8504727862307223, 'weights_2': 0.25504090079350883, 'weights_3': 0.8325917478903818, 'weights_4': 0.9176956366413549, 'weights_5': 0.8768381021541348, 'weights_6': 0.19398791793581333, 'weights_7': 0.8152200310823987, 'weights_8': 0.00032243290315404904, 'weights_9': 0.040695333481567904, 'weights_10': 0.005980066429998549, 'weights_11': 0.7275559373851973, 'weights_12': 0.017958459450320936, 'weights_13': 0.01352592747698886, 'weights_14': 0.5399792390777794, 'weights_15': 0.9008467719506412, 'weights_16': 0.39816209698590893, 'weights_17': 0.6110415501297637, 'weights_18': 0.05231690618067292, 'weights_19': 0.06597663391576959}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,097] Trial 262 finished with value: 3021.9630357964907 and parameters: {'weights_0': 0.07926665906654445, 'weights_1': 0.8647427284621447, 'weights_2': 0.2509848339732472, 'weights_3': 0.8202399287182676, 'weights_4': 0.9187854933560626, 'weights_5': 0.8620597962752381, 'weights_6': 0.19594125295958012, 'weights_7': 0.8202723698569078, 'weights_8': 0.017684364133830018, 'weights_9': 0.04366186382878068, 'weights_10': 0.0007981943599711036, 'weights_11': 0.7723618333058804, 'weights_12': 0.0020687849226594434, 'weights_13': 0.010692133834391777, 'weights_14': 0.4995566698812377, 'weights_15': 0.9076647472578924, 'weights_16': 0.38653035797972707, 'weights_17': 0.6089222482283992, 'weights_18': 0.03842455113724459, 'weights_19': 0.06594753242201644}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,237] Trial 263 finished with value: 3016.8837649804864 and parameters: {'weights_0': 0.07189923176387422, 'weights_1': 0.8626347404309282, 'weights_2': 0.2513416261819384, 'weights_3': 0.8237951450178125, 'weights_4': 0.9323904720317531, 'weights_5': 0.8575455852529246, 'weights_6': 0.19256093796694596, 'weights_7': 0.8230815903180714, 'weights_8': 0.003209156843277553, 'weights_9': 0.06326094842265255, 'weights_10': 0.002334829655066255, 'weights_11': 0.7255707182019774, 'weights_12': 0.0030397522633697593, 'weights_13': 0.002759280630975183, 'weights_14': 0.5146618605549903, 'weights_15': 0.9005063797248639, 'weights_16': 0.39531285380301295, 'weights_17': 0.6064443112815352, 'weights_18': 0.056830550888975366, 'weights_19': 0.06621037959961613}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,346] Trial 264 finished with value: 3125.053882964423 and parameters: {'weights_0': 0.0801502318688593, 'weights_1': 0.8671621241382101, 'weights_2': 0.2593107238088706, 'weights_3': 0.8201454539842892, 'weights_4': 0.9208808514525729, 'weights_5': 0.8659477509697661, 'weights_6': 0.18545559098090458, 'weights_7': 0.8160248569430669, 'weights_8': 0.00047076934917480344, 'weights_9': 0.06711047959370392, 'weights_10': 0.0062766337435037, 'weights_11': 0.772540773533262, 'weights_12': 0.002742298698422696, 'weights_13': 0.00026451271140427723, 'weights_14': 0.4941376412025927, 'weights_15': 0.897734511275648, 'weights_16': 0.4004958249445567, 'weights_17': 0.6049235859354446, 'weights_18': 0.04196111308541801, 'weights_19': 0.6698918145556101}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,466] Trial 265 finished with value: 3106.090800608477 and parameters: {'weights_0': 0.07152467509311307, 'weights_1': 0.858417390941247, 'weights_2': 0.2521165815950811, 'weights_3': 0.7982195784923637, 'weights_4': 0.9063439821338046, 'weights_5': 0.8557063532178129, 'weights_6': 0.19501137693584847, 'weights_7': 0.8263025829155449, 'weights_8': 0.020210770884416945, 'weights_9': 0.04648965415659125, 'weights_10': 0.00044899009014811317, 'weights_11': 0.7220861357459671, 'weights_12': 0.0017061845813505115, 'weights_13': 0.01676759360992942, 'weights_14': 0.48918511088778827, 'weights_15': 0.8671486038413282, 'weights_16': 0.38338371286233386, 'weights_17': 0.6132712333485841, 'weights_18': 0.04887102525335609, 'weights_19': 0.5534340074710605}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,637] Trial 266 finished with value: 3015.51735547454 and parameters: {'weights_0': 0.10352865263852193, 'weights_1': 0.9052408506833403, 'weights_2': 0.24654631416018832, 'weights_3': 0.83521143978967, 'weights_4': 0.9344495749512861, 'weights_5': 0.8835723420090287, 'weights_6': 0.21277135278932668, 'weights_7': 0.8140939879312052, 'weights_8': 0.020191731367381196, 'weights_9': 0.06692195243601137, 'weights_10': 0.0010034070028378007, 'weights_11': 0.7305951122081542, 'weights_12': 0.01769211764699653, 'weights_13': 0.00030719908298701415, 'weights_14': 0.5160149596147631, 'weights_15': 0.9002546376312616, 'weights_16': 0.38427402073282607, 'weights_17': 0.6141657334153569, 'weights_18': 0.0574213599474847, 'weights_19': 0.05825714065866687}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,773] Trial 267 finished with value: 3017.4402871139337 and parameters: {'weights_0': 0.0902941788564609, 'weights_1': 0.9125507019374814, 'weights_2': 0.24229260432068203, 'weights_3': 0.8446717293756878, 'weights_4': 0.9291063305969433, 'weights_5': 0.8787915203778918, 'weights_6': 0.20676988696101378, 'weights_7': 0.8096574976725844, 'weights_8': 0.01808847171612536, 'weights_9': 0.03877294967725002, 'weights_10': 0.0012657883150778704, 'weights_11': 0.7421761352592747, 'weights_12': 0.01979630487908324, 'weights_13': 0.0040980048624847006, 'weights_14': 0.5107988976213222, 'weights_15': 0.8739155421786793, 'weights_16': 0.3618808423019833, 'weights_17': 0.6314584698818707, 'weights_18': 0.04344267117351233, 'weights_19': 0.07054377269812677}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:46,899] Trial 268 finished with value: 3083.072634767209 and parameters: {'weights_0': 0.10391069702469392, 'weights_1': 0.9073969153287568, 'weights_2': 0.2447773888230271, 'weights_3': 0.8427973460881103, 'weights_4': 0.94074134793412, 'weights_5': 0.8805579248872397, 'weights_6': 0.22097880101711637, 'weights_7': 0.8121622833115864, 'weights_8': 0.014492543722517286, 'weights_9': 0.07520490473527688, 'weights_10': 0.002088752291229078, 'weights_11': 0.7410508624709206, 'weights_12': 0.5952929521890291, 'weights_13': 0.004539790137293241, 'weights_14': 0.47980320746804483, 'weights_15': 0.8449052898386116, 'weights_16': 0.35987213156608633, 'weights_17': 0.6112189156585998, 'weights_18': 0.04061032647123966, 'weights_19': 0.07013985621240398}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,021] Trial 269 finished with value: 3131.054354664686 and parameters: {'weights_0': 0.10314153995421833, 'weights_1': 0.8844331274223962, 'weights_2': 0.24288104801503255, 'weights_3': 0.8046297993462219, 'weights_4': 0.9315469056603285, 'weights_5': 0.8484371263045557, 'weights_6': 0.2178793869257301, 'weights_7': 0.8307228800598965, 'weights_8': 0.0025187342621768374, 'weights_9': 0.042451372032713944, 'weights_10': 0.000571201893213683, 'weights_11': 0.7144562646935879, 'weights_12': 0.01933942156214573, 'weights_13': 0.0009301446840650814, 'weights_14': 0.5164944588201742, 'weights_15': 0.9114369918171892, 'weights_16': 0.39730190275438054, 'weights_17': 0.6319037343407878, 'weights_18': 0.06284873642321667, 'weights_19': 0.7025517985738065}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,172] Trial 270 finished with value: 3015.7234613030605 and parameters: {'weights_0': 0.07118770574675203, 'weights_1': 0.8302250270858892, 'weights_2': 0.2810953687984851, 'weights_3': 0.8313202426571497, 'weights_4': 0.9068566255504765, 'weights_5': 0.8683476551350721, 'weights_6': 0.20276525007209245, 'weights_7': 0.8076190294966632, 'weights_8': 0.028348657760296547, 'weights_9': 0.06910503552862812, 'weights_10': 5.35462099137316e-05, 'weights_11': 0.7681147272867518, 'weights_12': 0.00039072028339787526, 'weights_13': 0.01886878000987824, 'weights_14': 0.5136330929293796, 'weights_15': 0.8690268597143224, 'weights_16': 0.36151582105308006, 'weights_17': 0.632587692066873, 'weights_18': 0.038412087807790804, 'weights_19': 0.061325772662973926}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,336] Trial 271 finished with value: 3030.0847989758036 and parameters: {'weights_0': 0.08368904832491525, 'weights_1': 0.8785859920669987, 'weights_2': 0.27359913329845564, 'weights_3': 0.8337332544471246, 'weights_4': 0.9009126155552848, 'weights_5': 0.8576875225611815, 'weights_6': 0.19657485692146962, 'weights_7': 0.806990854691756, 'weights_8': 0.024863338401675615, 'weights_9': 0.07615175600629612, 'weights_10': 0.022100298985280115, 'weights_11': 0.7682778043500929, 'weights_12': 0.016459354178203964, 'weights_13': 0.015688985459340863, 'weights_14': 0.5158385272125651, 'weights_15': 0.8680448126660718, 'weights_16': 0.34440251265645905, 'weights_17': 0.6224104229295883, 'weights_18': 0.03622149456802247, 'weights_19': 0.07346868430313086}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,449] Trial 272 finished with value: 3012.9620181391533 and parameters: {'weights_0': 0.07256295335652825, 'weights_1': 0.8478370792231966, 'weights_2': 0.28390501200854495, 'weights_3': 0.8294758481823069, 'weights_4': 0.9488117774571087, 'weights_5': 0.8718954682338451, 'weights_6': 0.20109320119778631, 'weights_7': 0.7984749163114098, 'weights_8': 0.000964813975180237, 'weights_9': 0.06597058048455073, 'weights_10': 0.01787242766719859, 'weights_11': 0.8109754565751512, 'weights_12': 0.0009868814886682502, 'weights_13': 0.001338941066926688, 'weights_14': 0.47911636277496844, 'weights_15': 0.8977086689905912, 'weights_16': 0.3582427136844179, 'weights_17': 0.6915068932988956, 'weights_18': 0.05622560587532522, 'weights_19': 0.06655565648496277}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,588] Trial 273 finished with value: 3247.2094147698317 and parameters: {'weights_0': 0.1046670930013833, 'weights_1': 0.9167036823546997, 'weights_2': 0.24785184779615252, 'weights_3': 0.77755715555021, 'weights_4': 0.9449940303689441, 'weights_5': 0.004057428101939764, 'weights_6': 0.2059049705599782, 'weights_7': 0.7954843122610702, 'weights_8': 0.0006206232809096088, 'weights_9': 0.07460355309390028, 'weights_10': 0.019605965781161954, 'weights_11': 0.8013262086870405, 'weights_12': 0.0006754257864121475, 'weights_13': 0.016996300346495036, 'weights_14': 0.4764860519665376, 'weights_15': 0.8750168646259557, 'weights_16': 0.35493986119277054, 'weights_17': 0.6953383503697401, 'weights_18': 0.059380554972121774, 'weights_19': 0.06561952729868675}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,694] Trial 274 finished with value: 3030.728511283853 and parameters: {'weights_0': 0.06784213540727964, 'weights_1': 0.8970713556150394, 'weights_2': 0.28565702404347787, 'weights_3': 0.8157691007611706, 'weights_4': 0.9012845120664974, 'weights_5': 0.8694499896446719, 'weights_6': 0.21230618085842776, 'weights_7': 0.887146656195129, 'weights_8': 0.02632694106077695, 'weights_9': 0.06237239624765686, 'weights_10': 0.018123820444719888, 'weights_11': 0.749276953487019, 'weights_12': 0.03575146384648403, 'weights_13': 0.017941202243783084, 'weights_14': 0.49315201447299734, 'weights_15': 0.8955353629643983, 'weights_16': 0.381396176179644, 'weights_17': 0.6843278230947607, 'weights_18': 0.039565287039335, 'weights_19': 0.06857230444188583}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,854] Trial 275 finished with value: 3134.123114216468 and parameters: {'weights_0': 0.06779559581444806, 'weights_1': 0.8446543684704181, 'weights_2': 0.24333898275123794, 'weights_3': 0.8527901038402668, 'weights_4': 0.9628915234032521, 'weights_5': 0.8497828770089343, 'weights_6': 0.19599266417588623, 'weights_7': 0.8308794469340404, 'weights_8': 0.029215859070860016, 'weights_9': 0.03703679487420144, 'weights_10': 0.020460070466899818, 'weights_11': 0.8130293041662969, 'weights_12': 0.7558676675325297, 'weights_13': 0.0036987616931506394, 'weights_14': 0.45996342616948643, 'weights_15': 0.8567061169125721, 'weights_16': 0.42526480984211373, 'weights_17': 0.6610488619376783, 'weights_18': 0.0620123646461587, 'weights_19': 0.06615158850121965}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:47,991] Trial 276 finished with value: 3139.466593925767 and parameters: {'weights_0': 0.09546033862397879, 'weights_1': 0.8678678860564382, 'weights_2': 0.2798635075058877, 'weights_3': 0.8353217873848886, 'weights_4': 0.9025202064948294, 'weights_5': 0.8716091426968543, 'weights_6': 0.18075099653237647, 'weights_7': 0.8442126460380733, 'weights_8': 0.0010142354506788784, 'weights_9': 0.08638079567549434, 'weights_10': 0.4744788830362322, 'weights_11': 0.7806492680565907, 'weights_12': 0.019005185795772053, 'weights_13': 0.0011176334385431426, 'weights_14': 0.5158580400667688, 'weights_15': 0.9163267959395979, 'weights_16': 0.3745588111448224, 'weights_17': 0.6046671507713305, 'weights_18': 0.04782179745200516, 'weights_19': 0.05892896690023201}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:48,133] Trial 277 finished with value: 3267.1300003974443 and parameters: {'weights_0': 0.6162145088816773, 'weights_1': 0.8287353893519618, 'weights_2': 0.2570151066889576, 'weights_3': 0.7876777139487894, 'weights_4': 0.9415323767731342, 'weights_5': 0.840932013609195, 'weights_6': 0.22153093423816358, 'weights_7': 0.7998751518268599, 'weights_8': 0.023274519567866487, 'weights_9': 0.06601359443727013, 'weights_10': 0.7890392961210714, 'weights_11': 0.7394575268660327, 'weights_12': 0.04524844846424842, 'weights_13': 0.022722633116708295, 'weights_14': 0.5017640495643947, 'weights_15': 0.9562633378007014, 'weights_16': 0.3364052590538165, 'weights_17': 0.632803117544312, 'weights_18': 0.03955904272505863, 'weights_19': 0.07280237741393722}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:48,287] Trial 278 finished with value: 3014.8333664885995 and parameters: {'weights_0': 0.064704345146182, 'weights_1': 0.8275463774947748, 'weights_2': 0.24060603024386876, 'weights_3': 0.8497753441552282, 'weights_4': 0.9230035295862363, 'weights_5': 0.8794774174588654, 'weights_6': 0.18025440704952733, 'weights_7': 0.8192826310641084, 'weights_8': 0.026960370669084986, 'weights_9': 0.03675983168068184, 'weights_10': 0.0005986542136064492, 'weights_11': 0.7076378747764923, 'weights_12': 0.019595864836554573, 'weights_13': 0.027012575336164836, 'weights_14': 0.47975654474813767, 'weights_15': 0.8886749633629857, 'weights_16': 0.4416194175517403, 'weights_17': 0.6605194832015632, 'weights_18': 0.0648197552314728, 'weights_19': 0.05178573181881844}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:48,402] Trial 279 finished with value: 3015.6436863190947 and parameters: {'weights_0': 0.06761184038773387, 'weights_1': 0.8444336336543083, 'weights_2': 0.2360597569862766, 'weights_3': 0.8269194105364392, 'weights_4': 0.9228301723206628, 'weights_5': 0.8777145130032871, 'weights_6': 0.20128086385542115, 'weights_7': 0.7873414026989113, 'weights_8': 0.0183610003800058, 'weights_9': 0.03376575468099566, 'weights_10': 0.022958484479741754, 'weights_11': 0.7042527215973096, 'weights_12': 0.039990306006172274, 'weights_13': 0.03384591696453198, 'weights_14': 0.4809719346341855, 'weights_15': 0.8764284027853458, 'weights_16': 0.4491845185296963, 'weights_17': 0.6918177440711248, 'weights_18': 0.0354439920250897, 'weights_19': 0.06875786208934868}. Best is trial 216 with value: 3009.78031454313.\n",
      "[I 2025-08-01 08:05:48,583] Trial 280 finished with value: 3006.477313168933 and parameters: {'weights_0': 0.06507020125688419, 'weights_1': 0.8564953055084626, 'weights_2': 0.23387274761593915, 'weights_3': 0.8078249985057935, 'weights_4': 0.9134012294306836, 'weights_5': 0.8776112040144457, 'weights_6': 0.20769208094565086, 'weights_7': 0.7892383488636175, 'weights_8': 0.000135710000591302, 'weights_9': 0.03487120548060044, 'weights_10': 0.024559869471247837, 'weights_11': 0.7073436405952582, 'weights_12': 0.04378316784470937, 'weights_13': 0.03691300114034939, 'weights_14': 0.4635150082740114, 'weights_15': 0.8424891707468367, 'weights_16': 0.44511291037412065, 'weights_17': 0.769061243847942, 'weights_18': 0.034112830642266695, 'weights_19': 0.036170244356058506}. Best is trial 280 with value: 3006.477313168933.\n",
      "[I 2025-08-01 08:05:48,733] Trial 281 finished with value: 3004.777666966688 and parameters: {'weights_0': 0.06564946103758051, 'weights_1': 0.8541796843980276, 'weights_2': 0.24498717775592588, 'weights_3': 0.805160421038575, 'weights_4': 0.9561578167961695, 'weights_5': 0.8747510322517406, 'weights_6': 0.21057313617594514, 'weights_7': 0.7850080053121797, 'weights_8': 0.0002781565621447976, 'weights_9': 0.06483393963660504, 'weights_10': 0.02401118025626036, 'weights_11': 0.7059916323003171, 'weights_12': 0.043211192735190716, 'weights_13': 0.039228542120130785, 'weights_14': 0.47279077578009754, 'weights_15': 0.8366878514533354, 'weights_16': 0.44867047082759726, 'weights_17': 0.8404277950663437, 'weights_18': 0.03593284936060362, 'weights_19': 0.07462421765009714}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:48,861] Trial 282 finished with value: 3074.067933214019 and parameters: {'weights_0': 0.10918674859230096, 'weights_1': 0.8642089148362049, 'weights_2': 0.23884124294947925, 'weights_3': 0.8138965323025964, 'weights_4': 0.9570417931732816, 'weights_5': 0.867537230789483, 'weights_6': 0.21731485405789064, 'weights_7': 0.7839031382609871, 'weights_8': 0.00039005452604405026, 'weights_9': 0.0831306978420007, 'weights_10': 0.027146185448513164, 'weights_11': 0.706982806939481, 'weights_12': 0.03868503533591278, 'weights_13': 0.5086997831669499, 'weights_14': 0.4689399154165334, 'weights_15': 0.8278801739204694, 'weights_16': 0.440766720312044, 'weights_17': 0.7444986039210949, 'weights_18': 0.03388111272734684, 'weights_19': 0.08029036975266986}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,002] Trial 283 finished with value: 3014.117083582453 and parameters: {'weights_0': 0.07197619110869449, 'weights_1': 0.8427011823354636, 'weights_2': 0.23662440622600878, 'weights_3': 0.8311917424043156, 'weights_4': 0.9300221802410972, 'weights_5': 0.8412729635587739, 'weights_6': 0.21202588075548837, 'weights_7': 0.8072638697953854, 'weights_8': 0.01828304734498164, 'weights_9': 0.10888034541498773, 'weights_10': 0.05033089604937335, 'weights_11': 0.6940647133221985, 'weights_12': 0.04499902881765325, 'weights_13': 0.04489744250345647, 'weights_14': 0.48055702599363653, 'weights_15': 0.8441438056872523, 'weights_16': 0.4480911314517976, 'weights_17': 0.8092053658797, 'weights_18': 0.033279902468056344, 'weights_19': 0.05252399687022617}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,188] Trial 284 finished with value: 3010.5486110520246 and parameters: {'weights_0': 0.07206638895208992, 'weights_1': 0.902098411231425, 'weights_2': 0.23602794061526872, 'weights_3': 0.8282304167240857, 'weights_4': 0.9264452765089465, 'weights_5': 0.8341766424934993, 'weights_6': 0.2067615700881604, 'weights_7': 0.8084871873933136, 'weights_8': 0.019315553854049934, 'weights_9': 0.10448560543500907, 'weights_10': 0.05679870007760224, 'weights_11': 0.697670110192894, 'weights_12': 0.044523104441645756, 'weights_13': 0.04971845819423343, 'weights_14': 0.4524227838624095, 'weights_15': 0.855492972072269, 'weights_16': 0.38885856149225384, 'weights_17': 0.8812833906556987, 'weights_18': 0.03568863184227534, 'weights_19': 0.06397435386936874}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,366] Trial 285 finished with value: 3014.506023945194 and parameters: {'weights_0': 0.09104644015332511, 'weights_1': 0.9013911082397752, 'weights_2': 0.23541886780552373, 'weights_3': 0.8244269810880881, 'weights_4': 0.9325926939082588, 'weights_5': 0.8305722718722325, 'weights_6': 0.2256971456905527, 'weights_7': 0.8199984792325526, 'weights_8': 0.01611933349341907, 'weights_9': 0.09366428639513666, 'weights_10': 0.04313791752187561, 'weights_11': 0.694628090095396, 'weights_12': 0.04378117427025003, 'weights_13': 0.05019342022563622, 'weights_14': 0.4592337024909353, 'weights_15': 0.8501390279096798, 'weights_16': 0.39730183169157046, 'weights_17': 0.8531492021966233, 'weights_18': 0.03142253510757629, 'weights_19': 0.07199488348637047}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,525] Trial 286 finished with value: 3018.7485749307775 and parameters: {'weights_0': 0.1031378473871463, 'weights_1': 0.9276917964490202, 'weights_2': 0.24410928851611313, 'weights_3': 0.8248165630946472, 'weights_4': 0.9360209304832067, 'weights_5': 0.8209567367435152, 'weights_6': 0.2261669543380329, 'weights_7': 0.8349081696597251, 'weights_8': 0.009394535559515256, 'weights_9': 0.10978324239421924, 'weights_10': 0.0551527550283762, 'weights_11': 0.6914897265824432, 'weights_12': 0.04483550686069302, 'weights_13': 0.04621759284546861, 'weights_14': 0.4489372919927456, 'weights_15': 0.8399197532273222, 'weights_16': 0.36118207908548783, 'weights_17': 0.8398320290633607, 'weights_18': 0.031783210878129756, 'weights_19': 0.07694085041069484}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,662] Trial 287 finished with value: 3023.9482753186317 and parameters: {'weights_0': 0.1125524836020245, 'weights_1': 0.9254704389903906, 'weights_2': 0.23553911397942673, 'weights_3': 0.8235185343174132, 'weights_4': 0.9726474110063835, 'weights_5': 0.820273679750509, 'weights_6': 0.22925666626178212, 'weights_7': 0.8258747934580871, 'weights_8': 0.016027384767625826, 'weights_9': 0.10467667946077172, 'weights_10': 0.05859145593064333, 'weights_11': 0.7027615598665558, 'weights_12': 0.04532721134901444, 'weights_13': 0.0856506157701888, 'weights_14': 0.4510374330888902, 'weights_15': 0.8362304652379194, 'weights_16': 0.36102568504948285, 'weights_17': 0.8424793481512174, 'weights_18': 0.03227640065079201, 'weights_19': 0.077383723772772}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,823] Trial 288 finished with value: 3127.0690341531963 and parameters: {'weights_0': 0.8197774829501326, 'weights_1': 0.9043147643393832, 'weights_2': 0.2387333820390175, 'weights_3': 0.7982062756133432, 'weights_4': 0.930431526919563, 'weights_5': 0.800008693511842, 'weights_6': 0.21455183409589482, 'weights_7': 0.8043077765269308, 'weights_8': 0.002786140871805647, 'weights_9': 0.09856010906152039, 'weights_10': 0.05216537126459329, 'weights_11': 0.6903158476258323, 'weights_12': 0.04265869082085155, 'weights_13': 0.04658915055727987, 'weights_14': 0.47508228343455083, 'weights_15': 0.8488564106552983, 'weights_16': 0.33104648166669187, 'weights_17': 0.8885934291184134, 'weights_18': 0.03226941120974846, 'weights_19': 0.07626815719635549}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:49,992] Trial 289 finished with value: 3014.33160513754 and parameters: {'weights_0': 0.09521601678223383, 'weights_1': 0.9404974016229124, 'weights_2': 0.23032483571776527, 'weights_3': 0.8438430325375497, 'weights_4': 0.9540149452598429, 'weights_5': 0.826644309713703, 'weights_6': 0.22861030882178945, 'weights_7': 0.8272014787577219, 'weights_8': 0.019523669893507067, 'weights_9': 0.10570081413915519, 'weights_10': 0.05267562029096844, 'weights_11': 0.6982698621738624, 'weights_12': 0.04420418392000303, 'weights_13': 0.047918088225415253, 'weights_14': 0.4531299827256562, 'weights_15': 0.8594058052740968, 'weights_16': 0.37955999309550625, 'weights_17': 0.8533819614803051, 'weights_18': 0.029414013268975952, 'weights_19': 0.0757956416894183}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:50,187] Trial 290 finished with value: 3015.481534583302 and parameters: {'weights_0': 0.09793372597365355, 'weights_1': 0.9518760132162721, 'weights_2': 0.232850394361512, 'weights_3': 0.8314542109011482, 'weights_4': 0.9575001367047142, 'weights_5': 0.8294222203490573, 'weights_6': 0.23481069686179246, 'weights_7': 0.8439744381929275, 'weights_8': 0.020857556836698266, 'weights_9': 0.11619356717251354, 'weights_10': 0.05880480565468884, 'weights_11': 0.689135857544399, 'weights_12': 0.04743859340794569, 'weights_13': 0.0003796470357049183, 'weights_14': 0.4549067292905602, 'weights_15': 0.8682694801099593, 'weights_16': 0.38052213799277607, 'weights_17': 0.851856130654863, 'weights_18': 0.026206243317894076, 'weights_19': 0.11618880050379884}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:50,324] Trial 291 finished with value: 3129.589867221901 and parameters: {'weights_0': 0.10697805426803977, 'weights_1': 0.9611345759392279, 'weights_2': 0.2507197387293485, 'weights_3': 0.8260536401450904, 'weights_4': 0.9521261297628019, 'weights_5': 0.8363981976448999, 'weights_6': 0.22832639630364973, 'weights_7': 0.8345708590412972, 'weights_8': 0.8513028676180298, 'weights_9': 0.11314152701849156, 'weights_10': 0.052783479336572285, 'weights_11': 0.686904096855304, 'weights_12': 0.05156813945213948, 'weights_13': 0.0007846833034406489, 'weights_14': 0.4534197460934324, 'weights_15': 0.8251071130697393, 'weights_16': 0.36799020140229094, 'weights_17': 0.7705020787586239, 'weights_18': 0.026183795378517005, 'weights_19': 0.07696938114988505}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:50,445] Trial 292 finished with value: 3151.279659421202 and parameters: {'weights_0': 0.14765344058772323, 'weights_1': 0.9206692104931503, 'weights_2': 0.2267712122963358, 'weights_3': 0.7738357302521435, 'weights_4': 0.9721897094721856, 'weights_5': 0.8307948908563442, 'weights_6': 0.234570137723374, 'weights_7': 0.8373015199745306, 'weights_8': 0.0003203316131168766, 'weights_9': 0.13849025010051164, 'weights_10': 0.05540766651436454, 'weights_11': 0.688570201637751, 'weights_12': 0.04777408883917022, 'weights_13': 0.0695863219404785, 'weights_14': 0.4370131562824964, 'weights_15': 0.8565889634850042, 'weights_16': 0.3774125293269192, 'weights_17': 0.8385449047818312, 'weights_18': 0.02513247442590687, 'weights_19': 0.909030900402002}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:50,683] Trial 293 finished with value: 3091.227422513872 and parameters: {'weights_0': 0.09722220696075981, 'weights_1': 0.9449285888296599, 'weights_2': 0.2339351887549862, 'weights_3': 0.8114572908641973, 'weights_4': 0.9457533082559373, 'weights_5': 0.8029182465264826, 'weights_6': 0.2108105060225395, 'weights_7': 0.8846494145165765, 'weights_8': 0.026888683751699977, 'weights_9': 0.12159960770427783, 'weights_10': 0.04803890743963833, 'weights_11': 0.6824992487165424, 'weights_12': 0.0242902514364792, 'weights_13': 0.5544503198028373, 'weights_14': 0.4808519038134785, 'weights_15': 0.8666416662589647, 'weights_16': 0.3539216200002129, 'weights_17': 0.861412391962003, 'weights_18': 0.034898525273461795, 'weights_19': 0.1126540236673862}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:50,811] Trial 294 finished with value: 3077.3815860679256 and parameters: {'weights_0': 0.06798096787674619, 'weights_1': 0.9375934213620443, 'weights_2': 0.23068767105809354, 'weights_3': 0.8371308675044351, 'weights_4': 0.9850303774896585, 'weights_5': 0.8284633523170148, 'weights_6': 0.2143607475746674, 'weights_7': 0.8451880427705281, 'weights_8': 0.018933720162703994, 'weights_9': 0.10912384057040521, 'weights_10': 0.06854197290358559, 'weights_11': 0.759167415673875, 'weights_12': 0.5180571669743609, 'weights_13': 0.04515480838645911, 'weights_14': 0.46219966972088655, 'weights_15': 0.843461148254915, 'weights_16': 0.3880893747921701, 'weights_17': 0.9112720024654362, 'weights_18': 0.03664980608245613, 'weights_19': 0.08173878727329127}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:50,964] Trial 295 finished with value: 3019.9859138378456 and parameters: {'weights_0': 0.0921049773080564, 'weights_1': 0.8975797994345992, 'weights_2': 0.18969829700419155, 'weights_3': 0.8017098318247367, 'weights_4': 0.9335868465590064, 'weights_5': 0.8477604747645683, 'weights_6': 0.22816312389084623, 'weights_7': 0.8677580376541387, 'weights_8': 0.028999494307864495, 'weights_9': 0.08869396592041671, 'weights_10': 0.0311326297095269, 'weights_11': 0.6921315139187938, 'weights_12': 0.04763133536485864, 'weights_13': 0.022856134077399188, 'weights_14': 0.4474122719884544, 'weights_15': 0.8706847829125155, 'weights_16': 0.4411613942434665, 'weights_17': 0.7831189043990185, 'weights_18': 0.02544582923947017, 'weights_19': 0.11588188783139948}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:51,145] Trial 296 finished with value: 3036.679789383508 and parameters: {'weights_0': 0.11258515327837984, 'weights_1': 0.897720043783332, 'weights_2': 0.1978981765022999, 'weights_3': 0.7927642166144735, 'weights_4': 0.9433347336949609, 'weights_5': 0.8095783236228159, 'weights_6': 0.2548674749431198, 'weights_7': 0.8694262329080746, 'weights_8': 0.02822983221089938, 'weights_9': 0.08870822754019189, 'weights_10': 0.04043899940176641, 'weights_11': 0.6985982733586028, 'weights_12': 0.04870966413995743, 'weights_13': 0.06271263477154156, 'weights_14': 0.4417204578410608, 'weights_15': 0.824803424308849, 'weights_16': 0.44385178596612734, 'weights_17': 0.8186011961891047, 'weights_18': 0.020861804774694175, 'weights_19': 0.10787186994329626}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:51,288] Trial 297 finished with value: 3025.963289429292 and parameters: {'weights_0': 0.10014159004196123, 'weights_1': 0.914607724489988, 'weights_2': 0.22865254231709098, 'weights_3': 0.8495808294818014, 'weights_4': 0.9578806497151267, 'weights_5': 0.8408558861210006, 'weights_6': 0.2336334592935655, 'weights_7': 0.9100344226352113, 'weights_8': 0.0005729352703793891, 'weights_9': 0.10957872316540893, 'weights_10': 0.03413688328499166, 'weights_11': 0.697963963356778, 'weights_12': 0.04675914574828812, 'weights_13': 0.034073363653357065, 'weights_14': 0.4673017998365255, 'weights_15': 0.8695771545736363, 'weights_16': 0.43995180114871757, 'weights_17': 0.8011390744732483, 'weights_18': 0.024413480083183156, 'weights_19': 0.11398003736547604}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:51,420] Trial 298 finished with value: 3121.5954690016442 and parameters: {'weights_0': 0.09286654481419875, 'weights_1': 0.8899745034349307, 'weights_2': 0.19406716953626046, 'weights_3': 0.8025126888445382, 'weights_4': 0.9279756778535208, 'weights_5': 0.37221890727010565, 'weights_6': 0.20791608852633275, 'weights_7': 0.8004188119197981, 'weights_8': 0.03138937426757278, 'weights_9': 0.08495003430066383, 'weights_10': 0.060580117586087556, 'weights_11': 0.6780005732436245, 'weights_12': 0.025187756434472953, 'weights_13': 0.0775967115736805, 'weights_14': 0.4379984650086942, 'weights_15': 0.846330108197949, 'weights_16': 0.4135733163575963, 'weights_17': 0.8595945692148306, 'weights_18': 0.039997603478656274, 'weights_19': 0.04932052821831317}. Best is trial 281 with value: 3004.777666966688.\n",
      "[I 2025-08-01 08:05:51,589] Trial 299 finished with value: 3002.1264270475076 and parameters: {'weights_0': 0.06669989268838142, 'weights_1': 0.9536686459146361, 'weights_2': 0.1796602802050831, 'weights_3': 0.7492933131753414, 'weights_4': 0.9918525374510491, 'weights_5': 0.8552849041797908, 'weights_6': 0.23025380128334066, 'weights_7': 0.842029780866265, 'weights_8': 0.03164585934420342, 'weights_9': 0.11304115388901759, 'weights_10': 0.028411473860111343, 'weights_11': 0.7389804247164484, 'weights_12': 0.08358943334202834, 'weights_13': 0.0005920244172715651, 'weights_14': 0.4882370555688748, 'weights_15': 0.877400571183822, 'weights_16': 0.35117766365171366, 'weights_17': 0.893197183763655, 'weights_18': 0.04896598006915863, 'weights_19': 0.08939501138355935}. Best is trial 299 with value: 3002.1264270475076.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "voting_study = optuna.create_study(direction='minimize')\n",
    "voting_study.optimize(voting_objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/voting_optuna_study.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(voting_study.best_params, f\"../../split_income_models/ensemble/voting_best_params.pkl\")\n",
    "joblib.dump(voting_study, f\"../../split_income_models/ensemble/voting_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weights_0': 0.007743756340681867,\n",
       " 'weights_1': 0.11071948283654971,\n",
       " 'weights_2': 0.020858285942177188,\n",
       " 'weights_3': 0.08699181679407403,\n",
       " 'weights_4': 0.11515257470940235,\n",
       " 'weights_5': 0.09929727969390618,\n",
       " 'weights_6': 0.02673211697632253,\n",
       " 'weights_7': 0.09775837998854707,\n",
       " 'weights_8': 0.003674036255169101,\n",
       " 'weights_9': 0.013123906454778388,\n",
       " 'weights_10': 0.0032985290078386973,\n",
       " 'weights_11': 0.08579450609123075,\n",
       " 'weights_12': 0.009704606384907872,\n",
       " 'weights_13': 6.873313659594165e-05,\n",
       " 'weights_14': 0.05668358137367592,\n",
       " 'weights_15': 0.10186487507806949,\n",
       " 'weights_16': 0.04077119392551145,\n",
       " 'weights_17': 0.10369883783117126,\n",
       " 'weights_18': 0.0056848759923762105,\n",
       " 'weights_19': 0.010378625187013987}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = voting_study.best_params\n",
    "normalised_bp = {k: v / sum(bp.values()) for k, v in bp.items()}\n",
    "normalised_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/voting_normalised_best_params.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(normalised_bp, f\"../../split_income_models/ensemble/voting_normalised_best_params.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression -> Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_linreg(trial):\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 1.0)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "    \n",
    "    #to get the predictions of the base models \n",
    "    #fit_intercept=True\n",
    "    elastic_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True, random_state=42)\n",
    "    elastic_model.fit(X_meta_train, y_meta_train)\n",
    "    elastic_predictions = elastic_model.predict(X_meta_val)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, elastic_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:05:51,885] A new study created in memory with name: no-name-1951b1b2-2fb8-46e9-8ebe-d88b7f679b76\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,058] Trial 0 finished with value: 1898.7451405993302 and parameters: {'alpha': 0.16244045561433715, 'l1_ratio': 0.9127415109945574}. Best is trial 0 with value: 1898.7451405993302.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.807e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,177] Trial 1 finished with value: 1898.9806795277404 and parameters: {'alpha': 0.10521319362358335, 'l1_ratio': 0.0516780997888342}. Best is trial 0 with value: 1898.7451405993302.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,349] Trial 2 finished with value: 1897.647577669805 and parameters: {'alpha': 0.9590996423853857, 'l1_ratio': 0.3904505171771997}. Best is trial 2 with value: 1897.647577669805.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,512] Trial 3 finished with value: 1898.7968906910457 and parameters: {'alpha': 0.2809060966102415, 'l1_ratio': 0.004080397196786656}. Best is trial 2 with value: 1897.647577669805.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.795e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,654] Trial 4 finished with value: 1898.2602064690668 and parameters: {'alpha': 0.7509877335046368, 'l1_ratio': 0.048073501253917406}. Best is trial 2 with value: 1897.647577669805.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.791e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,810] Trial 5 finished with value: 1898.021416508691 and parameters: {'alpha': 0.9692938087132816, 'l1_ratio': 0.04978952050437979}. Best is trial 2 with value: 1897.647577669805.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:52,955] Trial 6 finished with value: 1898.4451266761548 and parameters: {'alpha': 0.4031034435322715, 'l1_ratio': 0.4595652332283148}. Best is trial 2 with value: 1897.647577669805.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:53,060] Trial 7 finished with value: 1897.467470702006 and parameters: {'alpha': 0.9064057046649594, 'l1_ratio': 0.6337699076828855}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:53,291] Trial 8 finished with value: 1898.1647618941436 and parameters: {'alpha': 0.5487167974311746, 'l1_ratio': 0.5327348953063504}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:53,492] Trial 9 finished with value: 1898.4806256491877 and parameters: {'alpha': 0.491064629902227, 'l1_ratio': 0.1598920533558963}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.535e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:53,646] Trial 10 finished with value: 1897.487092069444 and parameters: {'alpha': 0.7982292459733631, 'l1_ratio': 0.8165627759844527}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:53,852] Trial 11 finished with value: 1897.587714139753 and parameters: {'alpha': 0.7503969497512127, 'l1_ratio': 0.8080035112822277}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:54,017] Trial 12 finished with value: 1897.6592736858665 and parameters: {'alpha': 0.7630382990195491, 'l1_ratio': 0.6994408554505238}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:54,202] Trial 13 finished with value: 1897.5468164964013 and parameters: {'alpha': 0.8499488253770398, 'l1_ratio': 0.6529300368316694}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:54,338] Trial 14 finished with value: 1897.697059672124 and parameters: {'alpha': 0.6361395047573206, 'l1_ratio': 0.9620644647519243}. Best is trial 7 with value: 1897.467470702006.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:54,507] Trial 15 finished with value: 1897.4033044632151 and parameters: {'alpha': 0.8626910579961007, 'l1_ratio': 0.774550871343769}. Best is trial 15 with value: 1897.4033044632151.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:54,677] Trial 16 finished with value: 1897.495384428263 and parameters: {'alpha': 0.9039285264072094, 'l1_ratio': 0.6112277200783951}. Best is trial 15 with value: 1897.4033044632151.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:54,878] Trial 17 finished with value: 1898.150821055259 and parameters: {'alpha': 0.6694156285426626, 'l1_ratio': 0.2972685790569721}. Best is trial 15 with value: 1897.4033044632151.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:55,038] Trial 18 finished with value: 1897.8227653729023 and parameters: {'alpha': 0.6527444395180947, 'l1_ratio': 0.7510851396815965}. Best is trial 15 with value: 1897.4033044632151.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:55,195] Trial 19 finished with value: 1897.3782087156076 and parameters: {'alpha': 0.9971485150025425, 'l1_ratio': 0.5747028057009115}. Best is trial 19 with value: 1897.3782087156076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.668e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:55,370] Trial 20 finished with value: 1897.6680889279583 and parameters: {'alpha': 0.9931149837337536, 'l1_ratio': 0.33016716499760196}. Best is trial 19 with value: 1897.3782087156076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:55,524] Trial 21 finished with value: 1897.5936835668872 and parameters: {'alpha': 0.8755030562384285, 'l1_ratio': 0.562572457802617}. Best is trial 19 with value: 1897.3782087156076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.626e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:55,688] Trial 22 finished with value: 1897.6461201723355 and parameters: {'alpha': 0.9061437640195126, 'l1_ratio': 0.4648980213543305}. Best is trial 19 with value: 1897.3782087156076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.508e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:55,865] Trial 23 finished with value: 1897.356577372299 and parameters: {'alpha': 0.8419863053798602, 'l1_ratio': 0.8626460658088881}. Best is trial 23 with value: 1897.356577372299.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:56,035] Trial 24 finished with value: 1897.3876843667454 and parameters: {'alpha': 0.8400743690200556, 'l1_ratio': 0.8347564560409207}. Best is trial 23 with value: 1897.356577372299.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.507e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:56,208] Trial 25 finished with value: 1897.3872416146894 and parameters: {'alpha': 0.8098124387063604, 'l1_ratio': 0.8987355530651354}. Best is trial 23 with value: 1897.356577372299.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:56,387] Trial 26 finished with value: 1897.5316513343487 and parameters: {'alpha': 0.7023665655202378, 'l1_ratio': 0.9920238059962286}. Best is trial 23 with value: 1897.356577372299.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:56,520] Trial 27 finished with value: 1897.8906261525062 and parameters: {'alpha': 0.5759892209674613, 'l1_ratio': 0.8670981208503608}. Best is trial 23 with value: 1897.356577372299.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.499e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:56,709] Trial 28 finished with value: 1897.3527403133357 and parameters: {'alpha': 0.8192501298196024, 'l1_ratio': 0.9147441039025304}. Best is trial 28 with value: 1897.3527403133357.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:56,840] Trial 29 finished with value: 1898.590731419921 and parameters: {'alpha': 0.2650169184256186, 'l1_ratio': 0.6998540998537454}. Best is trial 28 with value: 1897.3527403133357.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.468e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:57,008] Trial 30 finished with value: 1897.1463305344157 and parameters: {'alpha': 0.9219290020378796, 'l1_ratio': 0.9091433371835611}. Best is trial 30 with value: 1897.1463305344157.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:57,175] Trial 31 finished with value: 1896.9503165966362 and parameters: {'alpha': 0.9979440810972694, 'l1_ratio': 0.9442746347097122}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:57,366] Trial 32 finished with value: 1897.090663748117 and parameters: {'alpha': 0.9356385378079706, 'l1_ratio': 0.9343116092290542}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:57,523] Trial 33 finished with value: 1897.0917755929627 and parameters: {'alpha': 0.9301281825449577, 'l1_ratio': 0.9438536117089998}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:57,796] Trial 34 finished with value: 1897.0501192254978 and parameters: {'alpha': 0.9418008567593239, 'l1_ratio': 0.9596088607453741}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:57,930] Trial 35 finished with value: 1897.0468555726295 and parameters: {'alpha': 0.9407964036488885, 'l1_ratio': 0.9645331232657742}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:58,130] Trial 36 finished with value: 1897.0064388126236 and parameters: {'alpha': 0.9514745438000072, 'l1_ratio': 0.9809781810030201}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:58,283] Trial 37 finished with value: 1896.9551550356812 and parameters: {'alpha': 0.9705639687610246, 'l1_ratio': 0.9908165544043128}. Best is trial 31 with value: 1896.9503165966362.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:58,435] Trial 38 finished with value: 1896.891026279284 and parameters: {'alpha': 0.9961910682785788, 'l1_ratio': 0.9992189058310572}. Best is trial 38 with value: 1896.891026279284.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:58,610] Trial 39 finished with value: 1898.7948669201955 and parameters: {'alpha': 0.13381036514174433, 'l1_ratio': 0.9914825022757195}. Best is trial 38 with value: 1896.891026279284.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:58,762] Trial 40 finished with value: 1897.0335761755932 and parameters: {'alpha': 0.9986165790428195, 'l1_ratio': 0.8709469509178301}. Best is trial 38 with value: 1896.891026279284.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:58,942] Trial 41 finished with value: 1897.1116624790536 and parameters: {'alpha': 0.9589086808629643, 'l1_ratio': 0.8720327602723064}. Best is trial 38 with value: 1896.891026279284.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:59,098] Trial 42 finished with value: 1896.8908341792076 and parameters: {'alpha': 0.9973537416615238, 'l1_ratio': 0.9972257606174582}. Best is trial 42 with value: 1896.8908341792076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:59,328] Trial 43 finished with value: 1897.13288262073 and parameters: {'alpha': 0.8927158213661784, 'l1_ratio': 0.9795114247537718}. Best is trial 42 with value: 1896.8908341792076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.416e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:59,504] Trial 44 finished with value: 1896.8983244604178 and parameters: {'alpha': 0.9927143141004386, 'l1_ratio': 0.999340768925297}. Best is trial 42 with value: 1896.8908341792076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:59,652] Trial 45 finished with value: 1898.3426835276423 and parameters: {'alpha': 0.3739019563420223, 'l1_ratio': 0.7918749345169864}. Best is trial 42 with value: 1896.8908341792076.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:05:59,849] Trial 46 finished with value: 1896.8862711177196 and parameters: {'alpha': 0.9983098197052184, 'l1_ratio': 0.9995004779897848}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:00,031] Trial 47 finished with value: 1897.4141190800865 and parameters: {'alpha': 0.8784472203132874, 'l1_ratio': 0.7344530768995063}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:00,128] Trial 48 finished with value: 1897.4498042734313 and parameters: {'alpha': 0.7709829045800015, 'l1_ratio': 0.9177353532928031}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:00,419] Trial 49 finished with value: 1897.8682215334009 and parameters: {'alpha': 0.9978616776841059, 'l1_ratio': 0.1539266920920077}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:00,585] Trial 50 finished with value: 1897.1624783598738 and parameters: {'alpha': 0.9622875748122185, 'l1_ratio': 0.8203268961428574}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:00,874] Trial 51 finished with value: 1896.951083899533 and parameters: {'alpha': 0.9721377621320543, 'l1_ratio': 0.9914319107436731}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:01,176] Trial 52 finished with value: 1897.092778424716 and parameters: {'alpha': 0.901832314611481, 'l1_ratio': 0.9992057644907738}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:01,520] Trial 53 finished with value: 1897.0129201584382 and parameters: {'alpha': 0.9739308345610895, 'l1_ratio': 0.9328485301928564}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:01,728] Trial 54 finished with value: 1898.102169702835 and parameters: {'alpha': 0.4669338336012102, 'l1_ratio': 0.891760489378018}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:01,999] Trial 55 finished with value: 1896.9510078549392 and parameters: {'alpha': 0.9968239999802667, 'l1_ratio': 0.9456919624261387}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,220] Trial 56 finished with value: 1897.334005196681 and parameters: {'alpha': 0.8669712720202055, 'l1_ratio': 0.8353912857779298}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,527] Trial 57 finished with value: 1896.943348826144 and parameters: {'alpha': 0.9998960534290764, 'l1_ratio': 0.9468408190603097}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.473e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,687] Trial 58 finished with value: 1897.1610980518246 and parameters: {'alpha': 0.923169776076762, 'l1_ratio': 0.8927416888317647}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.688e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,827] Trial 59 finished with value: 1897.9999716416137 and parameters: {'alpha': 0.7188423486703177, 'l1_ratio': 0.39393364480316617}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.496e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:02,958] Trial 60 finished with value: 1897.272182156012 and parameters: {'alpha': 0.8881962493770389, 'l1_ratio': 0.854820897088109}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,123] Trial 61 finished with value: 1896.949362332582 and parameters: {'alpha': 0.9991580033745263, 'l1_ratio': 0.9429240919772157}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,344] Trial 62 finished with value: 1897.019485872736 and parameters: {'alpha': 0.966712050969959, 'l1_ratio': 0.9403465418249038}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,534] Trial 63 finished with value: 1897.1099410619765 and parameters: {'alpha': 0.9159021509539613, 'l1_ratio': 0.9548155261162206}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.735e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,722] Trial 64 finished with value: 1898.6446119559457 and parameters: {'alpha': 0.2268724371996762, 'l1_ratio': 0.7690355918655957}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:03,863] Trial 65 finished with value: 1897.089293984479 and parameters: {'alpha': 0.9504276225368925, 'l1_ratio': 0.9078074800185186}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,042] Trial 66 finished with value: 1897.2821918840636 and parameters: {'alpha': 0.8327637123992722, 'l1_ratio': 0.9580546981111471}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,215] Trial 67 finished with value: 1897.4817473059186 and parameters: {'alpha': 0.7895923501464823, 'l1_ratio': 0.8407770589725886}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,411] Trial 68 finished with value: 1897.0541238588075 and parameters: {'alpha': 0.9786006866214809, 'l1_ratio': 0.8881741639506915}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,547] Trial 69 finished with value: 1897.793604893722 and parameters: {'alpha': 0.6045263170468758, 'l1_ratio': 0.9213492250762203}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.523e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,723] Trial 70 finished with value: 1897.3880022269707 and parameters: {'alpha': 0.8582353969340487, 'l1_ratio': 0.7983004603946701}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:04,921] Trial 71 finished with value: 1896.9614979281234 and parameters: {'alpha': 0.9959540086988077, 'l1_ratio': 0.9379827366324758}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,090] Trial 72 finished with value: 1897.0584879580304 and parameters: {'alpha': 0.9384698417145029, 'l1_ratio': 0.9584280578923177}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,261] Trial 73 finished with value: 1896.9373606712165 and parameters: {'alpha': 0.9929863471961224, 'l1_ratio': 0.9645824311855433}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,482] Trial 74 finished with value: 1897.093217098052 and parameters: {'alpha': 0.9161647955210289, 'l1_ratio': 0.9698293228817472}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,686] Trial 75 finished with value: 1896.9875023211698 and parameters: {'alpha': 0.9522917969323854, 'l1_ratio': 0.9966783099492755}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:05,889] Trial 76 finished with value: 1897.0713166026185 and parameters: {'alpha': 0.9742956242278111, 'l1_ratio': 0.8805303033885172}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.474e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,076] Trial 77 finished with value: 1897.1955930593167 and parameters: {'alpha': 0.8925340645340941, 'l1_ratio': 0.9196611021340424}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,228] Trial 78 finished with value: 1897.0651683843498 and parameters: {'alpha': 0.9289687964928979, 'l1_ratio': 0.9707790812527856}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.465e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,334] Trial 79 finished with value: 1897.0660846682858 and parameters: {'alpha': 0.9931284516811685, 'l1_ratio': 0.852182868525269}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,517] Trial 80 finished with value: 1897.0843266220622 and parameters: {'alpha': 0.9541814801621107, 'l1_ratio': 0.9053340206540303}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,690] Trial 81 finished with value: 1896.9761842371663 and parameters: {'alpha': 0.9865188399631917, 'l1_ratio': 0.9423144029655957}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,838] Trial 82 finished with value: 1896.9297735467826 and parameters: {'alpha': 0.991231980550481, 'l1_ratio': 0.9744025013688202}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:06,982] Trial 83 finished with value: 1897.0150570843866 and parameters: {'alpha': 0.9393675710033158, 'l1_ratio': 0.9966294132468068}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,252] Trial 84 finished with value: 1896.9756727193742 and parameters: {'alpha': 0.9718034379268461, 'l1_ratio': 0.9700015922074174}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.470e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,427] Trial 85 finished with value: 1897.168015559149 and parameters: {'alpha': 0.9058622317810349, 'l1_ratio': 0.9196597378575115}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,677] Trial 86 finished with value: 1896.9649254776718 and parameters: {'alpha': 0.9614553851247922, 'l1_ratio': 0.9993982058556278}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:07,899] Trial 87 finished with value: 1896.9196400808078 and parameters: {'alpha': 0.9991085108455787, 'l1_ratio': 0.9688267950675381}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,065] Trial 88 finished with value: 1896.9183788221244 and parameters: {'alpha': 0.9998875829045855, 'l1_ratio': 0.9685170337220971}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,229] Trial 89 finished with value: 1898.6343159238027 and parameters: {'alpha': 0.3616364932056426, 'l1_ratio': 0.17810122825725017}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,408] Trial 90 finished with value: 1897.0877695011518 and parameters: {'alpha': 0.9176448070915807, 'l1_ratio': 0.9720321884763534}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,642] Trial 91 finished with value: 1896.9176161369444 and parameters: {'alpha': 0.9991058130263204, 'l1_ratio': 0.9706272791524037}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,775] Trial 92 finished with value: 1896.957485755485 and parameters: {'alpha': 0.9785643867201341, 'l1_ratio': 0.9735992497283161}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:08,928] Trial 93 finished with value: 1897.0905133663364 and parameters: {'alpha': 0.9539476771074226, 'l1_ratio': 0.9002416376208657}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,091] Trial 94 finished with value: 1897.1020685170718 and parameters: {'alpha': 0.9343925766064591, 'l1_ratio': 0.9263000901146627}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,248] Trial 95 finished with value: 1897.0672738370445 and parameters: {'alpha': 0.9802053224774477, 'l1_ratio': 0.8736815578285154}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.458e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,410] Trial 96 finished with value: 1897.1458204423302 and parameters: {'alpha': 0.8875141634682797, 'l1_ratio': 0.977804413534111}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,583] Trial 97 finished with value: 1897.2900237993897 and parameters: {'alpha': 0.9990427288727295, 'l1_ratio': 0.64894210591284}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,716] Trial 98 finished with value: 1897.029809586763 and parameters: {'alpha': 0.9548787149172074, 'l1_ratio': 0.9532837203863535}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:09,870] Trial 99 finished with value: 1897.0193524680722 and parameters: {'alpha': 0.9731137979729039, 'l1_ratio': 0.9287052405964692}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,013] Trial 100 finished with value: 1897.1790795044508 and parameters: {'alpha': 0.868251358717982, 'l1_ratio': 0.9854410469592499}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,199] Trial 101 finished with value: 1896.9412786197454 and parameters: {'alpha': 0.9984511750559445, 'l1_ratio': 0.951236733151153}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,352] Trial 102 finished with value: 1897.0710840717347 and parameters: {'alpha': 0.9349479077894496, 'l1_ratio': 0.953758521783728}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.455e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,519] Trial 103 finished with value: 1897.046140329628 and parameters: {'alpha': 0.9798514735007348, 'l1_ratio': 0.8929044629380178}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,701] Trial 104 finished with value: 1896.9657751301672 and parameters: {'alpha': 0.9611951717382039, 'l1_ratio': 0.9991210385427952}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:10,986] Trial 105 finished with value: 1897.0891320540452 and parameters: {'alpha': 0.9177983016371312, 'l1_ratio': 0.9704252174435625}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,161] Trial 106 finished with value: 1897.959176087792 and parameters: {'alpha': 0.5285499138663776, 'l1_ratio': 0.9142447588829321}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,366] Trial 107 finished with value: 1897.122432427778 and parameters: {'alpha': 0.9828314792619524, 'l1_ratio': 0.8205182779875053}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,539] Trial 108 finished with value: 1897.343471608593 and parameters: {'alpha': 0.9999277417227797, 'l1_ratio': 0.6009813787698259}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,726] Trial 109 finished with value: 1897.06586111789 and parameters: {'alpha': 0.9442999214300143, 'l1_ratio': 0.9406254421600635}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:11,870] Trial 110 finished with value: 1897.6443845887304 and parameters: {'alpha': 0.9080511932321073, 'l1_ratio': 0.46373693052811144}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,015] Trial 111 finished with value: 1896.958731509347 and parameters: {'alpha': 0.9845902548141766, 'l1_ratio': 0.9612293169957291}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,180] Trial 112 finished with value: 1897.4887139707664 and parameters: {'alpha': 0.9632493223862473, 'l1_ratio': 0.5261523756539964}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,352] Trial 113 finished with value: 1896.959771664008 and parameters: {'alpha': 0.9984398066390715, 'l1_ratio': 0.9350070134401832}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,551] Trial 114 finished with value: 1897.0133346825703 and parameters: {'alpha': 0.9471162328583921, 'l1_ratio': 0.9830838867720367}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,729] Trial 115 finished with value: 1896.9862538829764 and parameters: {'alpha': 0.9765810716161282, 'l1_ratio': 0.9517363202973773}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.481e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:12,903] Trial 116 finished with value: 1897.1801829214794 and parameters: {'alpha': 0.9294118169951803, 'l1_ratio': 0.8633594934979105}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.806e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,067] Trial 117 finished with value: 1898.0664876756998 and parameters: {'alpha': 0.9665430561121783, 'l1_ratio': 0.01293748994373356}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,228] Trial 118 finished with value: 1897.0106195310636 and parameters: {'alpha': 0.9854906148963719, 'l1_ratio': 0.9139662474789736}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,423] Trial 119 finished with value: 1897.1085710076777 and parameters: {'alpha': 0.9523250510109604, 'l1_ratio': 0.8869185019777192}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,573] Trial 120 finished with value: 1897.4151186008032 and parameters: {'alpha': 0.8979496718578612, 'l1_ratio': 0.6985847011327357}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,729] Trial 121 finished with value: 1896.950804004619 and parameters: {'alpha': 0.9992577666061416, 'l1_ratio': 0.9414653009529964}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:13,892] Trial 122 finished with value: 1896.9368956345497 and parameters: {'alpha': 0.9831634497614647, 'l1_ratio': 0.9831781072636254}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,032] Trial 123 finished with value: 1896.9575343051276 and parameters: {'alpha': 0.9650750476678442, 'l1_ratio': 0.999163765004306}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,173] Trial 124 finished with value: 1896.9457182938518 and parameters: {'alpha': 0.9823630369229295, 'l1_ratio': 0.9769362080856455}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.444e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,360] Trial 125 finished with value: 1897.050439218252 and parameters: {'alpha': 0.9360448690550766, 'l1_ratio': 0.9704573219818559}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,520] Trial 126 finished with value: 1896.945965489435 and parameters: {'alpha': 0.9805304506318596, 'l1_ratio': 0.9801448492755505}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,677] Trial 127 finished with value: 1897.0246508060102 and parameters: {'alpha': 0.9513191065987746, 'l1_ratio': 0.9647223019930026}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:14,852] Trial 128 finished with value: 1896.9370920404333 and parameters: {'alpha': 0.9837198321185352, 'l1_ratio': 0.9819658394532998}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,006] Trial 129 finished with value: 1897.1109439476395 and parameters: {'alpha': 0.92612889199238, 'l1_ratio': 0.9339798782180072}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.620e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,154] Trial 130 finished with value: 1898.1106911104328 and parameters: {'alpha': 0.4366946514376676, 'l1_ratio': 0.9975440358716611}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,303] Trial 131 finished with value: 1896.9050039211074 and parameters: {'alpha': 0.9996554151328432, 'l1_ratio': 0.9806654290359005}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,445] Trial 132 finished with value: 1897.0052484109435 and parameters: {'alpha': 0.9658137558487674, 'l1_ratio': 0.9546679947209465}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,597] Trial 133 finished with value: 1896.9091366036384 and parameters: {'alpha': 0.9876987253271335, 'l1_ratio': 0.9992718661239993}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,757] Trial 134 finished with value: 1896.9421823978382 and parameters: {'alpha': 0.9816463010841352, 'l1_ratio': 0.9813788707835549}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:15,911] Trial 135 finished with value: 1896.99212594635 and parameters: {'alpha': 0.9489134378178167, 'l1_ratio': 0.9990736785803548}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,057] Trial 136 finished with value: 1897.0403650799426 and parameters: {'alpha': 0.9650451455741947, 'l1_ratio': 0.9246983520330235}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,248] Trial 137 finished with value: 1896.9381606368722 and parameters: {'alpha': 0.9975782901131478, 'l1_ratio': 0.9555122912111199}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,383] Trial 138 finished with value: 1898.6719877790217 and parameters: {'alpha': 0.1892214248577505, 'l1_ratio': 0.977904985355095}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,539] Trial 139 finished with value: 1897.0531393391748 and parameters: {'alpha': 0.9396121785247619, 'l1_ratio': 0.9610807662991583}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,698] Trial 140 finished with value: 1896.9918559953717 and parameters: {'alpha': 0.9999595666031816, 'l1_ratio': 0.9045395345205401}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.643e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:16,849] Trial 141 finished with value: 1897.6125783514265 and parameters: {'alpha': 0.9831785815872053, 'l1_ratio': 0.39030663609968463}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,020] Trial 142 finished with value: 1896.9983511521364 and parameters: {'alpha': 0.968560840940825, 'l1_ratio': 0.9558012390728226}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,181] Trial 143 finished with value: 1896.9011610442064 and parameters: {'alpha': 0.9985951802230063, 'l1_ratio': 0.9859669891767647}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,369] Trial 144 finished with value: 1896.9359153483583 and parameters: {'alpha': 0.9827877145907981, 'l1_ratio': 0.984740780457257}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,519] Trial 145 finished with value: 1896.9681501035932 and parameters: {'alpha': 0.9599172517053974, 'l1_ratio': 0.9994101774201604}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.527e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,686] Trial 146 finished with value: 1897.5763763735126 and parameters: {'alpha': 0.6860228799388417, 'l1_ratio': 0.98033212995025}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:17,855] Trial 147 finished with value: 1897.1367049114085 and parameters: {'alpha': 0.9153752283846588, 'l1_ratio': 0.9306819936089937}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,024] Trial 148 finished with value: 1896.9506114496276 and parameters: {'alpha': 0.9794064740855132, 'l1_ratio': 0.9781642995934869}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,158] Trial 149 finished with value: 1897.0196167657814 and parameters: {'alpha': 0.9436275674654564, 'l1_ratio': 0.9841571458784127}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.667e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,336] Trial 150 finished with value: 1898.3464423779433 and parameters: {'alpha': 0.3307970814889134, 'l1_ratio': 0.9999092287524896}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,482] Trial 151 finished with value: 1896.9311241444475 and parameters: {'alpha': 0.9979688335468868, 'l1_ratio': 0.9608822717095231}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,642] Trial 152 finished with value: 1896.9596072581146 and parameters: {'alpha': 0.982801810572547, 'l1_ratio': 0.9637620128914992}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,831] Trial 153 finished with value: 1896.952003655793 and parameters: {'alpha': 0.9999079400417016, 'l1_ratio': 0.9392283390895887}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:18,944] Trial 154 finished with value: 1897.8347323167072 and parameters: {'alpha': 0.9634266083341567, 'l1_ratio': 0.21981566897953286}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,136] Trial 155 finished with value: 1896.966421037646 and parameters: {'alpha': 0.9771080488769992, 'l1_ratio': 0.9682413758361889}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,269] Trial 156 finished with value: 1897.538759472989 and parameters: {'alpha': 0.7288354210412001, 'l1_ratio': 0.9159795802012598}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,461] Trial 157 finished with value: 1896.9783374614874 and parameters: {'alpha': 0.9550240964709512, 'l1_ratio': 0.999623989798706}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,578] Trial 158 finished with value: 1896.9485938191003 and parameters: {'alpha': 0.9997617278168924, 'l1_ratio': 0.9425141817966117}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,761] Trial 159 finished with value: 1896.9613293298332 and parameters: {'alpha': 0.9735729154516338, 'l1_ratio': 0.9795262045244454}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.469e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:19,923] Trial 160 finished with value: 1897.1467728148468 and parameters: {'alpha': 0.9247813205224718, 'l1_ratio': 0.9032794789665076}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,080] Trial 161 finished with value: 1896.9299066886535 and parameters: {'alpha': 0.9996086520454386, 'l1_ratio': 0.9589526455733721}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,231] Trial 162 finished with value: 1896.9620808960594 and parameters: {'alpha': 0.9830860325067748, 'l1_ratio': 0.9610044373726736}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,375] Trial 163 finished with value: 1897.0407075772923 and parameters: {'alpha': 0.9639439666744088, 'l1_ratio': 0.9264195055201844}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,644] Trial 164 finished with value: 1897.0164204801981 and parameters: {'alpha': 0.9463335662646124, 'l1_ratio': 0.9818010393862292}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,793] Trial 165 finished with value: 1896.9713912457914 and parameters: {'alpha': 0.9852309361314063, 'l1_ratio': 0.9488555385823364}. Best is trial 46 with value: 1896.8862711177196.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:20,936] Trial 166 finished with value: 1896.8860797089305 and parameters: {'alpha': 0.9984419770603075, 'l1_ratio': 0.9994247478831803}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,064] Trial 167 finished with value: 1896.9607020320987 and parameters: {'alpha': 0.9724991942708552, 'l1_ratio': 0.982133776382515}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,236] Trial 168 finished with value: 1896.9111620655567 and parameters: {'alpha': 0.9882722920647204, 'l1_ratio': 0.9964214528869865}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,406] Trial 169 finished with value: 1896.886690875506 and parameters: {'alpha': 0.9995016734946973, 'l1_ratio': 0.9969060947149935}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,577] Trial 170 finished with value: 1896.9757145069823 and parameters: {'alpha': 0.9571260691630328, 'l1_ratio': 0.9979138109863335}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,716] Trial 171 finished with value: 1896.9275940163034 and parameters: {'alpha': 0.9983976344172186, 'l1_ratio': 0.9631506431950625}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:21,873] Trial 172 finished with value: 1896.9356571428054 and parameters: {'alpha': 0.9971742317897665, 'l1_ratio': 0.9584105686558777}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,052] Trial 173 finished with value: 1896.9372045833102 and parameters: {'alpha': 0.9963703106452727, 'l1_ratio': 0.9585353124814209}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,194] Trial 174 finished with value: 1897.02782607662 and parameters: {'alpha': 0.9658380882121342, 'l1_ratio': 0.9346005821669323}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,386] Trial 175 finished with value: 1896.8952929457803 and parameters: {'alpha': 0.9939532718783759, 'l1_ratio': 0.9996724590612466}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,494] Trial 176 finished with value: 1896.8869850502822 and parameters: {'alpha': 0.9992001987900642, 'l1_ratio': 0.9972049088123793}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,652] Trial 177 finished with value: 1897.0003640899636 and parameters: {'alpha': 0.9458999509105911, 'l1_ratio': 0.9974918466607896}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,802] Trial 178 finished with value: 1897.6969795264345 and parameters: {'alpha': 0.6316416009416513, 'l1_ratio': 0.9751711562827555}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:22,915] Trial 179 finished with value: 1896.949485901033 and parameters: {'alpha': 0.9705473513938896, 'l1_ratio': 0.9958597201702104}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,087] Trial 180 finished with value: 1897.0192658211881 and parameters: {'alpha': 0.9643682111052349, 'l1_ratio': 0.9448853770765422}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,283] Trial 181 finished with value: 1896.9228665243443 and parameters: {'alpha': 0.9982947938666833, 'l1_ratio': 0.9674559838991164}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,438] Trial 182 finished with value: 1896.950084271922 and parameters: {'alpha': 0.9853207678517721, 'l1_ratio': 0.9676150883041329}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,597] Trial 183 finished with value: 1896.9108441401572 and parameters: {'alpha': 0.9972729843324858, 'l1_ratio': 0.9799787486206774}. Best is trial 166 with value: 1896.8860797089305.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,785] Trial 184 finished with value: 1896.8845761341383 and parameters: {'alpha': 0.9996900584898871, 'l1_ratio': 0.9984397096684908}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:23,962] Trial 185 finished with value: 1896.9347227112203 and parameters: {'alpha': 0.9755186788142254, 'l1_ratio': 0.9994476530668738}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,105] Trial 186 finished with value: 1896.9868390229344 and parameters: {'alpha': 0.951412081870199, 'l1_ratio': 0.9989825748176898}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,277] Trial 187 finished with value: 1896.9562649804116 and parameters: {'alpha': 0.9772967049169088, 'l1_ratio': 0.9770901889964488}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,443] Trial 188 finished with value: 1897.0491686265002 and parameters: {'alpha': 0.9343737212524564, 'l1_ratio': 0.974926860199779}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,625] Trial 189 finished with value: 1896.9523046512043 and parameters: {'alpha': 0.9984102587574829, 'l1_ratio': 0.9416659968792718}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,755] Trial 190 finished with value: 1897.0345271359345 and parameters: {'alpha': 0.9661113660313557, 'l1_ratio': 0.92802021394006}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:24,909] Trial 191 finished with value: 1896.8857392956636 and parameters: {'alpha': 0.9987096883167106, 'l1_ratio': 0.9992292052605146}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,089] Trial 192 finished with value: 1896.9121448717988 and parameters: {'alpha': 0.9977689110139184, 'l1_ratio': 0.9779418438341634}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,263] Trial 193 finished with value: 1896.9361692919033 and parameters: {'alpha': 0.9835971418826784, 'l1_ratio': 0.983003681694336}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,411] Trial 194 finished with value: 1896.8851523541832 and parameters: {'alpha': 0.9987034751112678, 'l1_ratio': 0.9997642056614312}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,548] Trial 195 finished with value: 1896.9423733622489 and parameters: {'alpha': 0.9722816826714579, 'l1_ratio': 0.998846782499465}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.772e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,740] Trial 196 finished with value: 1897.9858719313117 and parameters: {'alpha': 0.9555769581221639, 'l1_ratio': 0.09439976820255813}. Best is trial 184 with value: 1896.8845761341383.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:25,894] Trial 197 finished with value: 1896.8827532200382 and parameters: {'alpha': 0.9997537272126099, 'l1_ratio': 0.9999451727780118}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,039] Trial 198 finished with value: 1896.945499823393 and parameters: {'alpha': 0.9783230815078676, 'l1_ratio': 0.9846975496720656}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,175] Trial 199 finished with value: 1896.9233293120867 and parameters: {'alpha': 0.981999590480979, 'l1_ratio': 0.9973799292689834}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,318] Trial 200 finished with value: 1896.9049170716205 and parameters: {'alpha': 0.9998379739053636, 'l1_ratio': 0.9804046009784806}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,509] Trial 201 finished with value: 1896.9372488109284 and parameters: {'alpha': 0.9838875146650273, 'l1_ratio': 0.9815152752440928}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,653] Trial 202 finished with value: 1896.8885482058772 and parameters: {'alpha': 0.9989530369726242, 'l1_ratio': 0.9962714687633013}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,829] Trial 203 finished with value: 1896.9570877962667 and parameters: {'alpha': 0.9657411362468193, 'l1_ratio': 0.9982858600489226}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:26,969] Trial 204 finished with value: 1896.8862253829986 and parameters: {'alpha': 0.9985438582281229, 'l1_ratio': 0.9991048462117081}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,110] Trial 205 finished with value: 1896.884374528633 and parameters: {'alpha': 0.9991439377571175, 'l1_ratio': 0.999636586503841}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,244] Trial 206 finished with value: 1896.9747404521872 and parameters: {'alpha': 0.9565372369793712, 'l1_ratio': 0.9999236455969384}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,381] Trial 207 finished with value: 1896.9302716000695 and parameters: {'alpha': 0.9773158405316916, 'l1_ratio': 0.9999956516319697}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,548] Trial 208 finished with value: 1896.9732951649517 and parameters: {'alpha': 0.983543375638589, 'l1_ratio': 0.9502850155405934}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.440e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:27,808] Trial 209 finished with value: 1897.0325687946886 and parameters: {'alpha': 0.940461763381428, 'l1_ratio': 0.9785163612320317}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,025] Trial 210 finished with value: 1896.9760507289325 and parameters: {'alpha': 0.9663015315697341, 'l1_ratio': 0.9800640290929248}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,263] Trial 211 finished with value: 1896.8859023951595 and parameters: {'alpha': 0.9987769574349973, 'l1_ratio': 0.9989583777447824}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,454] Trial 212 finished with value: 1898.8600200509163 and parameters: {'alpha': 0.10485467307467833, 'l1_ratio': 0.9983611361453473}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,569] Trial 213 finished with value: 1896.8837967205652 and parameters: {'alpha': 0.9997458327751503, 'l1_ratio': 0.9990302446724061}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,724] Trial 214 finished with value: 1896.9547438803181 and parameters: {'alpha': 0.984073707847516, 'l1_ratio': 0.9657775721209602}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,869] Trial 215 finished with value: 1896.9082638391408 and parameters: {'alpha': 0.9984351733014448, 'l1_ratio': 0.980077851382242}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:28,969] Trial 216 finished with value: 1896.9481934928917 and parameters: {'alpha': 0.9690541930768551, 'l1_ratio': 0.999845949471168}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,126] Trial 217 finished with value: 1896.9358734594514 and parameters: {'alpha': 0.9974921230759987, 'l1_ratio': 0.9576454993863859}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,309] Trial 218 finished with value: 1896.9377331373087 and parameters: {'alpha': 0.9994857767750501, 'l1_ratio': 0.9524245626056508}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,520] Trial 219 finished with value: 1896.996765329152 and parameters: {'alpha': 0.9567383845117265, 'l1_ratio': 0.979771316137406}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,716] Trial 220 finished with value: 1896.9261142127818 and parameters: {'alpha': 0.9797324066712265, 'l1_ratio': 0.9991609265608352}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:29,879] Trial 221 finished with value: 1896.9138583405124 and parameters: {'alpha': 0.9975610043974179, 'l1_ratio': 0.9768069340774552}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,043] Trial 222 finished with value: 1896.9458666679732 and parameters: {'alpha': 0.9815211042692575, 'l1_ratio': 0.9783782717860117}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,242] Trial 223 finished with value: 1896.924535159153 and parameters: {'alpha': 0.9989258305266495, 'l1_ratio': 0.9648292558817075}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,450] Trial 224 finished with value: 1896.9659874872273 and parameters: {'alpha': 0.9698002198707758, 'l1_ratio': 0.9824460130980791}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,823] Trial 225 finished with value: 1896.9459253406553 and parameters: {'alpha': 0.9985487354443525, 'l1_ratio': 0.9470485580144449}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:30,978] Trial 226 finished with value: 1896.904071952336 and parameters: {'alpha': 0.9995856052102191, 'l1_ratio': 0.9816048231682936}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,156] Trial 227 finished with value: 1896.968368027317 and parameters: {'alpha': 0.9784301323595292, 'l1_ratio': 0.9640623843867347}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,371] Trial 228 finished with value: 1896.9031718619185 and parameters: {'alpha': 0.9996784059331701, 'l1_ratio': 0.9822166668686206}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,547] Trial 229 finished with value: 1896.9762586364723 and parameters: {'alpha': 0.9562948499100478, 'l1_ratio': 0.9990312182471416}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,664] Trial 230 finished with value: 1896.9802536351094 and parameters: {'alpha': 0.979495319183458, 'l1_ratio': 0.9516321932577647}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:31,857] Trial 231 finished with value: 1896.9031554391363 and parameters: {'alpha': 0.9998505317177634, 'l1_ratio': 0.9819135533813839}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,036] Trial 232 finished with value: 1896.906594970541 and parameters: {'alpha': 0.9988473627887016, 'l1_ratio': 0.9807706598040214}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.421e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,213] Trial 233 finished with value: 1896.9087708234558 and parameters: {'alpha': 0.999896552845871, 'l1_ratio': 0.9769512351000893}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,358] Trial 234 finished with value: 1896.9436560977138 and parameters: {'alpha': 0.9714561375931141, 'l1_ratio': 0.999283551050051}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,530] Trial 235 finished with value: 1896.9624023082474 and parameters: {'alpha': 0.9806629794218314, 'l1_ratio': 0.965224426516226}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,737] Trial 236 finished with value: 1896.904560326989 and parameters: {'alpha': 0.9995806963356876, 'l1_ratio': 0.981189025058657}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:32,962] Trial 237 finished with value: 1897.0135580458189 and parameters: {'alpha': 0.9652825702261086, 'l1_ratio': 0.9482573783461137}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,145] Trial 238 finished with value: 1896.922401138859 and parameters: {'alpha': 0.9813816644034695, 'l1_ratio': 0.9993934571970466}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.428e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,301] Trial 239 finished with value: 1896.9486866883844 and parameters: {'alpha': 0.9841290570460831, 'l1_ratio': 0.9710473606724311}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,435] Trial 240 finished with value: 1896.9991651555617 and parameters: {'alpha': 0.953593876336842, 'l1_ratio': 0.9836274346079076}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,639] Trial 241 finished with value: 1896.9020221219323 and parameters: {'alpha': 0.9997708377385002, 'l1_ratio': 0.9830462255170881}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,780] Trial 242 finished with value: 1896.9623430203073 and parameters: {'alpha': 0.9815901745854134, 'l1_ratio': 0.9635496518928456}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:33,950] Trial 243 finished with value: 1896.9095249841823 and parameters: {'alpha': 0.9981276205375618, 'l1_ratio': 0.9795471181668205}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,130] Trial 244 finished with value: 1896.904248465277 and parameters: {'alpha': 0.9996872838713386, 'l1_ratio': 0.9812638224436905}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,263] Trial 245 finished with value: 1896.9009478037028 and parameters: {'alpha': 0.9995520556405045, 'l1_ratio': 0.984384577009413}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,448] Trial 246 finished with value: 1896.9522599359568 and parameters: {'alpha': 0.9672112248322295, 'l1_ratio': 0.9997608851782567}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,577] Trial 247 finished with value: 1896.921613062732 and parameters: {'alpha': 0.9818132336774138, 'l1_ratio': 0.9992892626806863}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,734] Trial 248 finished with value: 1896.9696281326135 and parameters: {'alpha': 0.9814379299897488, 'l1_ratio': 0.957378340104223}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.520e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:34,885] Trial 249 finished with value: 1897.270535222909 and parameters: {'alpha': 0.9647051864630282, 'l1_ratio': 0.7201840145249487}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.583e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,027] Trial 250 finished with value: 1897.8888850619596 and parameters: {'alpha': 0.546213258311588, 'l1_ratio': 0.9641909909669916}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,168] Trial 251 finished with value: 1896.9854809379024 and parameters: {'alpha': 0.9841031413603321, 'l1_ratio': 0.9385926480881913}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,326] Trial 252 finished with value: 1896.8829170512747 and parameters: {'alpha': 0.9999887798906953, 'l1_ratio': 0.9993614807781024}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.604e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,498] Trial 253 finished with value: 1897.5225980240045 and parameters: {'alpha': 0.965825881138519, 'l1_ratio': 0.4923564727190687}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,671] Trial 254 finished with value: 1896.9367245354495 and parameters: {'alpha': 0.9829721996709928, 'l1_ratio': 0.9836859565117854}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:35,819] Trial 255 finished with value: 1896.925712461235 and parameters: {'alpha': 0.9996673582700096, 'l1_ratio': 0.9624636092986086}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.436e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,013] Trial 256 finished with value: 1897.0132484469495 and parameters: {'alpha': 0.9466971685104189, 'l1_ratio': 0.983973988095004}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,144] Trial 257 finished with value: 1896.9486961078942 and parameters: {'alpha': 0.9689060566120357, 'l1_ratio': 0.9996834698317262}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,327] Trial 258 finished with value: 1896.942642417802 and parameters: {'alpha': 0.9999526081701854, 'l1_ratio': 0.9473478967867156}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.601e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,494] Trial 259 finished with value: 1898.0073822498666 and parameters: {'alpha': 0.48708448955038797, 'l1_ratio': 0.9825444267033694}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,639] Trial 260 finished with value: 1896.9183602469434 and parameters: {'alpha': 0.9833857210290643, 'l1_ratio': 0.9992557870802006}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:36,818] Trial 261 finished with value: 1896.9985185195696 and parameters: {'alpha': 0.964845373233868, 'l1_ratio': 0.9626596256762089}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,035] Trial 262 finished with value: 1896.9252080025044 and parameters: {'alpha': 0.9802974451974353, 'l1_ratio': 0.998907108817886}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,157] Trial 263 finished with value: 1896.9177218216644 and parameters: {'alpha': 0.9994509924022984, 'l1_ratio': 0.9699000439476314}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.450e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,322] Trial 264 finished with value: 1897.0612570486346 and parameters: {'alpha': 0.9480524438055534, 'l1_ratio': 0.9376834908312504}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.424e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,452] Trial 265 finished with value: 1896.9377435388167 and parameters: {'alpha': 0.9828636020367716, 'l1_ratio': 0.9829956314019264}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,633] Trial 266 finished with value: 1896.9259221730501 and parameters: {'alpha': 0.9995121338616079, 'l1_ratio': 0.9625650185009509}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,785] Trial 267 finished with value: 1896.9586495075882 and parameters: {'alpha': 0.9649938275629403, 'l1_ratio': 0.9983273503639231}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.427e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:37,993] Trial 268 finished with value: 1896.9491949570404 and parameters: {'alpha': 0.9794676589234426, 'l1_ratio': 0.9792959593376017}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.447e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,144] Trial 269 finished with value: 1897.048529601763 and parameters: {'alpha': 0.9497571213106596, 'l1_ratio': 0.9458956755987162}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,307] Trial 270 finished with value: 1896.9186688648672 and parameters: {'alpha': 0.983148899819604, 'l1_ratio': 0.9994249499458137}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,576] Trial 271 finished with value: 1896.927980894796 and parameters: {'alpha': 0.9988416319458595, 'l1_ratio': 0.9620082944983298}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,757] Trial 272 finished with value: 1897.7020895365206 and parameters: {'alpha': 0.9655070824867751, 'l1_ratio': 0.3341169882028703}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:38,932] Trial 273 finished with value: 1896.9433374473608 and parameters: {'alpha': 0.9821111412687661, 'l1_ratio': 0.9794956039997356}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,068] Trial 274 finished with value: 1896.904475691087 and parameters: {'alpha': 0.9992166181447892, 'l1_ratio': 0.9819340933528694}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,213] Trial 275 finished with value: 1896.9971391457627 and parameters: {'alpha': 0.9677158023123864, 'l1_ratio': 0.958500284297722}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,380] Trial 276 finished with value: 1897.371907982191 and parameters: {'alpha': 0.9367981758248589, 'l1_ratio': 0.6737912698059224}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,569] Trial 277 finished with value: 1896.9447678927095 and parameters: {'alpha': 0.9804543088334301, 'l1_ratio': 0.9813401149884338}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,734] Trial 278 finished with value: 1897.3678571689738 and parameters: {'alpha': 0.9994399755297839, 'l1_ratio': 0.5804458528328004}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:39,873] Trial 279 finished with value: 1897.3854982299376 and parameters: {'alpha': 0.7668037696020213, 'l1_ratio': 0.9993971781802309}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,044] Trial 280 finished with value: 1898.423505899591 and parameters: {'alpha': 0.30877240628657865, 'l1_ratio': 0.9264962174739193}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.438e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,210] Trial 281 finished with value: 1897.007685644879 and parameters: {'alpha': 0.9594654667146257, 'l1_ratio': 0.9644667049395854}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,375] Trial 282 finished with value: 1896.918783373554 and parameters: {'alpha': 0.9833565307657213, 'l1_ratio': 0.9989279876550216}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,539] Trial 283 finished with value: 1896.945784841126 and parameters: {'alpha': 0.9993969719864381, 'l1_ratio': 0.9456396563844124}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,676] Trial 284 finished with value: 1896.9770144650122 and parameters: {'alpha': 0.9704098806556424, 'l1_ratio': 0.9714337562496401}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,827] Trial 285 finished with value: 1897.0113333608829 and parameters: {'alpha': 0.9523742559302103, 'l1_ratio': 0.9747325265733956}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:40,959] Trial 286 finished with value: 1896.9140562018817 and parameters: {'alpha': 0.9852178254765038, 'l1_ratio': 0.999615261390741}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,121] Trial 287 finished with value: 1896.966515852261 and parameters: {'alpha': 0.9708206805995928, 'l1_ratio': 0.9800222650315124}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.435e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,297] Trial 288 finished with value: 1896.958371885905 and parameters: {'alpha': 0.9991682297493478, 'l1_ratio': 0.9349162207729}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.491e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,447] Trial 289 finished with value: 1897.1431162232425 and parameters: {'alpha': 0.9999962338315841, 'l1_ratio': 0.7738253911345875}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,615] Trial 290 finished with value: 1896.924307784211 and parameters: {'alpha': 0.9801757682862784, 'l1_ratio': 0.999953469712987}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,752] Trial 291 finished with value: 1897.0323312480318 and parameters: {'alpha': 0.9526448163742582, 'l1_ratio': 0.9552523846343897}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:41,937] Trial 292 finished with value: 1896.9439164970495 and parameters: {'alpha': 0.9821857739116119, 'l1_ratio': 0.9788480300453327}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,102] Trial 293 finished with value: 1897.3041144405129 and parameters: {'alpha': 0.820355957162333, 'l1_ratio': 0.96270765071364}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,386] Trial 294 finished with value: 1896.972655009036 and parameters: {'alpha': 0.9659410411622537, 'l1_ratio': 0.9837764283251264}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.636e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,584] Trial 295 finished with value: 1897.637982548029 and parameters: {'alpha': 0.9390354860371686, 'l1_ratio': 0.4258449774339442}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,827] Trial 296 finished with value: 1896.942122564478 and parameters: {'alpha': 0.9997936799980764, 'l1_ratio': 0.9480827617102676}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:42,995] Trial 297 finished with value: 1896.9191066719404 and parameters: {'alpha': 0.9826569400274489, 'l1_ratio': 0.9999608218952145}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.636e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,127] Trial 298 finished with value: 1898.176596503037 and parameters: {'alpha': 0.4140812342481517, 'l1_ratio': 0.965931706580895}. Best is trial 197 with value: 1896.8827532200382.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+06, tolerance: 5.518e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-08-01 08:06:43,294] Trial 299 finished with value: 1897.050205691523 and parameters: {'alpha': 0.9624838665926467, 'l1_ratio': 0.9207001736404203}. Best is trial 197 with value: 1896.8827532200382.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "linreg_stacking_study = optuna.create_study(direction='minimize')\n",
    "linreg_stacking_study.optimize(stacked_objective_linreg, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.9997537272126099, 'l1_ratio': 0.9999451727780118}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/linreg_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(linreg_stacking_study.best_params, f\"../../split_income_models/ensemble/linreg_stacking_best_params.pkl\")\n",
    "joblib.dump(linreg_stacking_study, f\"../../split_income_models/ensemble/linreg_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e+06, tolerance: 6.429e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/linreg_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_linreg_model = ElasticNet(**linreg_stacking_study.best_params)\n",
    "best_linreg_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_linreg_model, \"../../split_income_models/ensemble/linreg_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_rf(trial):\n",
    "\n",
    "    n_trees = trial.suggest_int(\"n_estimators\", 10, 300)\n",
    "\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 25)\n",
    "\n",
    "    min_sample_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "\n",
    "    bootstrapping = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    if bootstrapping == False:\n",
    "        max_samples = None\n",
    "    else:\n",
    "        max_samples = trial.suggest_float(\"max_samples\", 0.01, 1.0)\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=42, min_samples_split=min_sample_split, bootstrap=bootstrapping, max_samples=max_samples, n_estimators=n_trees, max_depth=max_depth)\n",
    "    \n",
    "    rf.fit(X_meta_train, y_meta_train)\n",
    "    rf_predictions = rf.predict(X_meta_val)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:06:43,556] A new study created in memory with name: no-name-1aee06a1-70fd-4a70-a5f2-a7c1990c21ee\n",
      "[I 2025-08-01 08:06:45,566] Trial 0 finished with value: 2278.3481622018967 and parameters: {'n_estimators': 219, 'max_depth': 6, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.31161303507067534}. Best is trial 0 with value: 2278.3481622018967.\n",
      "[I 2025-08-01 08:06:53,518] Trial 1 finished with value: 2128.8497574598664 and parameters: {'n_estimators': 221, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': False}. Best is trial 1 with value: 2128.8497574598664.\n",
      "[I 2025-08-01 08:07:01,744] Trial 2 finished with value: 2128.5739101409877 and parameters: {'n_estimators': 222, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 2 with value: 2128.5739101409877.\n",
      "[I 2025-08-01 08:07:08,449] Trial 3 finished with value: 2038.4947388382286 and parameters: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 3 with value: 2038.4947388382286.\n",
      "[I 2025-08-01 08:07:11,448] Trial 4 finished with value: 2034.2927304041414 and parameters: {'n_estimators': 148, 'max_depth': 8, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:12,640] Trial 5 finished with value: 2149.063659031339 and parameters: {'n_estimators': 39, 'max_depth': 25, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:13,042] Trial 6 finished with value: 2295.9362655599684 and parameters: {'n_estimators': 42, 'max_depth': 12, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.5682854651592852}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:19,271] Trial 7 finished with value: 2128.4766186209563 and parameters: {'n_estimators': 236, 'max_depth': 13, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:25,796] Trial 8 finished with value: 2281.406878210926 and parameters: {'n_estimators': 259, 'max_depth': 14, 'min_samples_split': 10, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:29,794] Trial 9 finished with value: 2219.088014532003 and parameters: {'n_estimators': 181, 'max_depth': 10, 'min_samples_split': 7, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:30,347] Trial 10 finished with value: 2345.87950913404 and parameters: {'n_estimators': 114, 'max_depth': 3, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.9191057909365445}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:32,906] Trial 11 finished with value: 2086.0632122027882 and parameters: {'n_estimators': 137, 'max_depth': 7, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:37,878] Trial 12 finished with value: 2092.9431643362277 and parameters: {'n_estimators': 295, 'max_depth': 7, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:40,764] Trial 13 finished with value: 2240.125224379978 and parameters: {'n_estimators': 95, 'max_depth': 17, 'min_samples_split': 7, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:40,847] Trial 14 finished with value: 3606.391868732733 and parameters: {'n_estimators': 155, 'max_depth': 3, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.023183565973947273}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:47,294] Trial 15 finished with value: 2063.4473004448428 and parameters: {'n_estimators': 299, 'max_depth': 9, 'min_samples_split': 2, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:52,503] Trial 16 finished with value: 2110.4593304384107 and parameters: {'n_estimators': 176, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:53,451] Trial 17 finished with value: 2568.4040520793205 and parameters: {'n_estimators': 77, 'max_depth': 5, 'min_samples_split': 6, 'bootstrap': False}. Best is trial 4 with value: 2034.2927304041414.\n",
      "[I 2025-08-01 08:07:55,872] Trial 18 finished with value: 1944.7446375632492 and parameters: {'n_estimators': 175, 'max_depth': 10, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.9478876600935073}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:07:59,075] Trial 19 finished with value: 2041.065689602986 and parameters: {'n_estimators': 189, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9760765380309772}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:00,812] Trial 20 finished with value: 2052.8997815052617 and parameters: {'n_estimators': 137, 'max_depth': 9, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6873477772834885}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:03,996] Trial 21 finished with value: 2042.0445280067918 and parameters: {'n_estimators': 273, 'max_depth': 10, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7340719294942019}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:04,340] Trial 22 finished with value: 2211.647705012946 and parameters: {'n_estimators': 65, 'max_depth': 8, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.3321806819752747}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:05,207] Trial 23 finished with value: 2076.3215200429504 and parameters: {'n_estimators': 119, 'max_depth': 5, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8210369565351867}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:05,499] Trial 24 finished with value: 2127.641419142985 and parameters: {'n_estimators': 12, 'max_depth': 11, 'min_samples_split': 6, 'bootstrap': False}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:11,000] Trial 25 finished with value: 2225.4283275123144 and parameters: {'n_estimators': 202, 'max_depth': 14, 'min_samples_split': 8, 'bootstrap': False}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:12,596] Trial 26 finished with value: 2154.2925511474577 and parameters: {'n_estimators': 256, 'max_depth': 5, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.42770688422166603}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:15,707] Trial 27 finished with value: 2042.3274039001017 and parameters: {'n_estimators': 160, 'max_depth': 8, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:16,317] Trial 28 finished with value: 2185.581570268265 and parameters: {'n_estimators': 157, 'max_depth': 11, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.1997650400982779}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:17,593] Trial 29 finished with value: 2107.472282965986 and parameters: {'n_estimators': 203, 'max_depth': 6, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.5612816660916873}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:24,749] Trial 30 finished with value: 2123.526900154103 and parameters: {'n_estimators': 245, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 18 with value: 1944.7446375632492.\n",
      "[I 2025-08-01 08:08:28,151] Trial 31 finished with value: 1928.9152375121396 and parameters: {'n_estimators': 200, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9969912744693181}. Best is trial 31 with value: 1928.9152375121396.\n",
      "[I 2025-08-01 08:08:30,259] Trial 32 finished with value: 1902.2849065067796 and parameters: {'n_estimators': 134, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.978544903505074}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:32,726] Trial 33 finished with value: 1977.4707290908113 and parameters: {'n_estimators': 134, 'max_depth': 22, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9927763419730259}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:34,721] Trial 34 finished with value: 1981.8040896039224 and parameters: {'n_estimators': 115, 'max_depth': 22, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9950801988684613}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:38,323] Trial 35 finished with value: 2034.934580062804 and parameters: {'n_estimators': 212, 'max_depth': 22, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.8444672022072786}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:41,832] Trial 36 finished with value: 1930.9803060688823 and parameters: {'n_estimators': 172, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8624123245615887}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:44,628] Trial 37 finished with value: 2093.6827796608613 and parameters: {'n_estimators': 170, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8620787948376045}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:47,697] Trial 38 finished with value: 2022.4629694623757 and parameters: {'n_estimators': 195, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7552593752308001}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:51,558] Trial 39 finished with value: 1944.1318830079347 and parameters: {'n_estimators': 228, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.892400055299627}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:55,124] Trial 40 finished with value: 2006.594635008833 and parameters: {'n_estimators': 220, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8484440759191303}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:08:57,958] Trial 41 finished with value: 1960.6427535136827 and parameters: {'n_estimators': 169, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.9305615278767393}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:01,747] Trial 42 finished with value: 2017.256676265857 and parameters: {'n_estimators': 235, 'max_depth': 16, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.898034063043543}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:04,762] Trial 43 finished with value: 2052.9100933627697 and parameters: {'n_estimators': 183, 'max_depth': 24, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7954376753706227}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:07,722] Trial 44 finished with value: 1974.8297218646444 and parameters: {'n_estimators': 229, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6668596257233692}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:11,118] Trial 45 finished with value: 2026.0332702955286 and parameters: {'n_estimators': 211, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.9429931908244802}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:13,280] Trial 46 finished with value: 1947.1855868951134 and parameters: {'n_estimators': 145, 'max_depth': 16, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8954407860955798}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:16,860] Trial 47 finished with value: 1975.429705569311 and parameters: {'n_estimators': 193, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9855543319507115}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:18,898] Trial 48 finished with value: 1991.1441482406901 and parameters: {'n_estimators': 125, 'max_depth': 21, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.8981833120097326}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:22,462] Trial 49 finished with value: 2185.177512458348 and parameters: {'n_estimators': 266, 'max_depth': 16, 'min_samples_split': 10, 'bootstrap': True, 'max_samples': 0.8098997146893572}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:23,921] Trial 50 finished with value: 1918.1748608540902 and parameters: {'n_estimators': 96, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9989883174179123}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:25,277] Trial 51 finished with value: 1940.0226315171967 and parameters: {'n_estimators': 87, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.994081973089305}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:27,122] Trial 52 finished with value: 1929.6604548137475 and parameters: {'n_estimators': 98, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9284771957337148}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:28,786] Trial 53 finished with value: 1999.7013023155387 and parameters: {'n_estimators': 100, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.998509499857827}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:30,125] Trial 54 finished with value: 1924.8609112967067 and parameters: {'n_estimators': 80, 'max_depth': 15, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.937888036476734}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:31,182] Trial 55 finished with value: 1906.4098405577495 and parameters: {'n_estimators': 57, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.93856036905414}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:32,185] Trial 56 finished with value: 1983.5031686442019 and parameters: {'n_estimators': 60, 'max_depth': 15, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9466873649947195}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:32,783] Trial 57 finished with value: 2107.4146836164523 and parameters: {'n_estimators': 39, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9220241771723304}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:34,287] Trial 58 finished with value: 2000.4556691593207 and parameters: {'n_estimators': 106, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7761155826249162}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:35,197] Trial 59 finished with value: 2034.947860447569 and parameters: {'n_estimators': 68, 'max_depth': 15, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.6932701548445792}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:36,552] Trial 60 finished with value: 1984.564579778269 and parameters: {'n_estimators': 81, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9368564795692239}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:37,508] Trial 61 finished with value: 2081.3236376838813 and parameters: {'n_estimators': 51, 'max_depth': 15, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8658475271312664}. Best is trial 32 with value: 1902.2849065067796.\n",
      "[I 2025-08-01 08:09:38,798] Trial 62 finished with value: 1836.2179033091984 and parameters: {'n_estimators': 90, 'max_depth': 11, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9450973202323844}. Best is trial 62 with value: 1836.2179033091984.\n",
      "[I 2025-08-01 08:09:39,158] Trial 63 finished with value: 1801.500447821266 and parameters: {'n_estimators': 24, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9452814214871088}. Best is trial 63 with value: 1801.500447821266.\n",
      "[I 2025-08-01 08:09:39,474] Trial 64 finished with value: 1884.1898064121901 and parameters: {'n_estimators': 21, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9577125317141585}. Best is trial 63 with value: 1801.500447821266.\n",
      "[I 2025-08-01 08:09:39,526] Trial 65 finished with value: 3037.8165207096604 and parameters: {'n_estimators': 25, 'max_depth': 11, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.08114190237004998}. Best is trial 63 with value: 1801.500447821266.\n",
      "[I 2025-08-01 08:09:39,941] Trial 66 finished with value: 1745.0669673439156 and parameters: {'n_estimators': 28, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9486784738618063}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:40,065] Trial 67 finished with value: 2118.3262836362496 and parameters: {'n_estimators': 14, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.4569914977401455}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:40,490] Trial 68 finished with value: 1914.6528502196306 and parameters: {'n_estimators': 28, 'max_depth': 13, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9635600482734368}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:40,854] Trial 69 finished with value: 1866.0605698116563 and parameters: {'n_estimators': 28, 'max_depth': 12, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.8290513904197303}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:41,416] Trial 70 finished with value: 2146.0374037321694 and parameters: {'n_estimators': 50, 'max_depth': 9, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.8193022361846838}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:41,793] Trial 71 finished with value: 1853.9735106062908 and parameters: {'n_estimators': 25, 'max_depth': 11, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.9544014423892184}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:42,237] Trial 72 finished with value: 1974.7798403466631 and parameters: {'n_estimators': 32, 'max_depth': 11, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.8876361587698011}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:42,500] Trial 73 finished with value: 1974.6736266222986 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.9607801146558947}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:43,125] Trial 74 finished with value: 2072.279107517994 and parameters: {'n_estimators': 48, 'max_depth': 12, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.8403899267776257}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:43,799] Trial 75 finished with value: 2030.1710496978162 and parameters: {'n_estimators': 33, 'max_depth': 11, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.8978249384050615}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:43,919] Trial 76 finished with value: 2459.5523883354367 and parameters: {'n_estimators': 19, 'max_depth': 10, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.33160040644798233}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:45,297] Trial 77 finished with value: 2241.391521374546 and parameters: {'n_estimators': 57, 'max_depth': 9, 'min_samples_split': 10, 'bootstrap': False}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:45,921] Trial 78 finished with value: 2012.5776813500934 and parameters: {'n_estimators': 46, 'max_depth': 10, 'min_samples_split': 8, 'bootstrap': True, 'max_samples': 0.9614832004510093}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:46,055] Trial 79 finished with value: 1918.478154046208 and parameters: {'n_estimators': 11, 'max_depth': 12, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.603752305719939}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:47,053] Trial 80 finished with value: 2262.55340894791 and parameters: {'n_estimators': 70, 'max_depth': 13, 'min_samples_split': 10, 'bootstrap': True, 'max_samples': 0.8677954507116847}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:47,519] Trial 81 finished with value: 2023.1004666934484 and parameters: {'n_estimators': 30, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9608729085879608}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:48,175] Trial 82 finished with value: 2013.8723428251128 and parameters: {'n_estimators': 40, 'max_depth': 13, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9656994823314279}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:48,695] Trial 83 finished with value: 1983.9102056911868 and parameters: {'n_estimators': 23, 'max_depth': 11, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.9169332475746099}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:49,236] Trial 84 finished with value: 1789.643939200631 and parameters: {'n_estimators': 29, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9667123051577068}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:49,812] Trial 85 finished with value: 1862.688759568984 and parameters: {'n_estimators': 36, 'max_depth': 14, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9203339451555493}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:50,041] Trial 86 finished with value: 2079.016362220655 and parameters: {'n_estimators': 38, 'max_depth': 14, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.2626749726150184}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:50,437] Trial 87 finished with value: 2189.9971132908454 and parameters: {'n_estimators': 16, 'max_depth': 11, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:50,948] Trial 88 finished with value: 1992.7581318309387 and parameters: {'n_estimators': 34, 'max_depth': 14, 'min_samples_split': 9, 'bootstrap': True, 'max_samples': 0.9046948182399572}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:51,089] Trial 89 finished with value: 2024.7500700632215 and parameters: {'n_estimators': 11, 'max_depth': 10, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.838931860031207}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:51,406] Trial 90 finished with value: 2055.2932547664254 and parameters: {'n_estimators': 23, 'max_depth': 12, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8695681538150689}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:52,194] Trial 91 finished with value: 1915.040680467233 and parameters: {'n_estimators': 57, 'max_depth': 12, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9254832426577935}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:52,896] Trial 92 finished with value: 1900.4501065711077 and parameters: {'n_estimators': 46, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9718045088194719}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:53,537] Trial 93 finished with value: 2009.766691037383 and parameters: {'n_estimators': 42, 'max_depth': 14, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.9684285691201316}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:53,966] Trial 94 finished with value: 1944.3741221373243 and parameters: {'n_estimators': 27, 'max_depth': 16, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.970490608445149}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:54,380] Trial 95 finished with value: 1963.2524384700446 and parameters: {'n_estimators': 37, 'max_depth': 9, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8859803615418304}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:55,059] Trial 96 finished with value: 1841.8507751378036 and parameters: {'n_estimators': 45, 'max_depth': 15, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9207446753385}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:55,733] Trial 97 finished with value: 1802.8199518634037 and parameters: {'n_estimators': 43, 'max_depth': 15, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.9193807572194423}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:56,026] Trial 98 finished with value: 1790.6502943966952 and parameters: {'n_estimators': 18, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7850706381597459}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:56,290] Trial 99 finished with value: 1818.6765490135328 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7413601862710408}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:58,017] Trial 100 finished with value: 2104.288492161751 and parameters: {'n_estimators': 63, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:58,152] Trial 101 finished with value: 2211.8024615866984 and parameters: {'n_estimators': 10, 'max_depth': 15, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7298070396243874}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:58,398] Trial 102 finished with value: 1887.37359729794 and parameters: {'n_estimators': 17, 'max_depth': 17, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.8140962082311255}. Best is trial 66 with value: 1745.0669673439156.\n",
      "[I 2025-08-01 08:09:58,780] Trial 103 finished with value: 1646.6170669987123 and parameters: {'n_estimators': 28, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7671197899596347}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:09:59,513] Trial 104 finished with value: 2058.7520633135678 and parameters: {'n_estimators': 52, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7503510189523569}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:00,046] Trial 105 finished with value: 2077.1479604306505 and parameters: {'n_estimators': 41, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.6437548480941481}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:00,986] Trial 106 finished with value: 2045.7388993032207 and parameters: {'n_estimators': 72, 'max_depth': 16, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7123811131257272}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:01,182] Trial 107 finished with value: 2299.781777526345 and parameters: {'n_estimators': 18, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5436161792191945}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:01,670] Trial 108 finished with value: 1692.2551832682545 and parameters: {'n_estimators': 31, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7821784260462438}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:02,105] Trial 109 finished with value: 1649.80161126506 and parameters: {'n_estimators': 30, 'max_depth': 17, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7820283926132142}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:02,547] Trial 110 finished with value: 1843.267970518994 and parameters: {'n_estimators': 32, 'max_depth': 17, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7774028932685206}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:02,993] Trial 111 finished with value: 1856.697513504419 and parameters: {'n_estimators': 31, 'max_depth': 17, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7936676897371114}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:03,636] Trial 112 finished with value: 1937.5644450509706 and parameters: {'n_estimators': 44, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7790418019110424}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:03,982] Trial 113 finished with value: 1811.537345800415 and parameters: {'n_estimators': 23, 'max_depth': 16, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7558768956073351}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:04,206] Trial 114 finished with value: 1879.176198466607 and parameters: {'n_estimators': 16, 'max_depth': 16, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.660732805700766}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:04,538] Trial 115 finished with value: 1856.3156838803027 and parameters: {'n_estimators': 24, 'max_depth': 15, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7369314743308523}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:05,259] Trial 116 finished with value: 2031.9698836597074 and parameters: {'n_estimators': 54, 'max_depth': 17, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7053452412241822}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:05,404] Trial 117 finished with value: 2027.4508861187126 and parameters: {'n_estimators': 10, 'max_depth': 16, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7641930400017979}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:05,824] Trial 118 finished with value: 1790.5654118526695 and parameters: {'n_estimators': 29, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.6781078074983085}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:06,178] Trial 119 finished with value: 1901.9693116396083 and parameters: {'n_estimators': 21, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7976295393616922}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:06,559] Trial 120 finished with value: 1851.7107115919973 and parameters: {'n_estimators': 27, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7363185455172625}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:07,057] Trial 121 finished with value: 1896.814189971044 and parameters: {'n_estimators': 38, 'max_depth': 16, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.6732411991212607}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:07,664] Trial 122 finished with value: 2111.5154499313517 and parameters: {'n_estimators': 45, 'max_depth': 17, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7130245978286454}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:08,050] Trial 123 finished with value: 2158.3948997941147 and parameters: {'n_estimators': 33, 'max_depth': 15, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6303784309855223}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:08,290] Trial 124 finished with value: 1656.3937053909824 and parameters: {'n_estimators': 16, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7549001523310804}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:08,723] Trial 125 finished with value: 2016.922725214253 and parameters: {'n_estimators': 17, 'max_depth': 20, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.756309734362623}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:09,589] Trial 126 finished with value: 2088.837100424378 and parameters: {'n_estimators': 26, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:09,846] Trial 127 finished with value: 1751.453036927696 and parameters: {'n_estimators': 16, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7947398588035796}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:10,059] Trial 128 finished with value: 1867.140043102433 and parameters: {'n_estimators': 14, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7993856617199525}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:10,358] Trial 129 finished with value: 1778.6730624156642 and parameters: {'n_estimators': 20, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6894153518888941}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:10,706] Trial 130 finished with value: 1866.2026210302965 and parameters: {'n_estimators': 21, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7760095919369835}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:11,134] Trial 131 finished with value: 1749.9245111499572 and parameters: {'n_estimators': 31, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6870525955842571}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:11,531] Trial 132 finished with value: 1877.1438255058995 and parameters: {'n_estimators': 29, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.68912508304462}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:11,954] Trial 133 finished with value: 1985.068911887874 and parameters: {'n_estimators': 35, 'max_depth': 21, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6020444542259067}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:12,253] Trial 134 finished with value: 2100.0487731247545 and parameters: {'n_estimators': 22, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.711293657033277}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:12,697] Trial 135 finished with value: 1800.572177678103 and parameters: {'n_estimators': 30, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8256289199079374}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:13,188] Trial 136 finished with value: 1915.6582832042557 and parameters: {'n_estimators': 32, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8271698243100801}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:13,812] Trial 137 finished with value: 2119.364984663006 and parameters: {'n_estimators': 40, 'max_depth': 20, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8574869484378912}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:14,025] Trial 138 finished with value: 1847.5782307629188 and parameters: {'n_estimators': 16, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6783816338054344}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:14,474] Trial 139 finished with value: 1688.2855795535222 and parameters: {'n_estimators': 29, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8082390638080104}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:14,888] Trial 140 finished with value: 1735.5850393743692 and parameters: {'n_estimators': 28, 'max_depth': 18, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8119566917556427}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:15,304] Trial 141 finished with value: 1871.641779931622 and parameters: {'n_estimators': 29, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.791399826607661}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:15,819] Trial 142 finished with value: 1853.228691247607 and parameters: {'n_estimators': 36, 'max_depth': 18, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8199506755427173}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:16,219] Trial 143 finished with value: 1817.2079209183146 and parameters: {'n_estimators': 28, 'max_depth': 18, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8410951395710078}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:16,458] Trial 144 finished with value: 1997.0653756169663 and parameters: {'n_estimators': 17, 'max_depth': 21, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7626714347444251}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:16,763] Trial 145 finished with value: 2112.8880792990726 and parameters: {'n_estimators': 23, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.724926743583495}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:17,506] Trial 146 finished with value: 1941.4776272233123 and parameters: {'n_estimators': 51, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8102151223294012}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:18,001] Trial 147 finished with value: 1746.5372767471051 and parameters: {'n_estimators': 35, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7778607205397664}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:19,023] Trial 148 finished with value: 2105.7071031676746 and parameters: {'n_estimators': 35, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:19,266] Trial 149 finished with value: 2188.647098055736 and parameters: {'n_estimators': 16, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.39112016000728544}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:19,705] Trial 150 finished with value: 1667.219861729175 and parameters: {'n_estimators': 30, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7776346654516815}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:20,106] Trial 151 finished with value: 1828.8542379091707 and parameters: {'n_estimators': 28, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7744934151455342}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:24,133] Trial 152 finished with value: 1976.993272644721 and parameters: {'n_estimators': 280, 'max_depth': 21, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8013997977357246}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:24,709] Trial 153 finished with value: 1954.1084522527285 and parameters: {'n_estimators': 40, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7905109547794679}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:25,182] Trial 154 finished with value: 1927.6922852476991 and parameters: {'n_estimators': 34, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7490545939198645}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:25,345] Trial 155 finished with value: 1661.9020322218369 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8321818445833198}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:25,518] Trial 156 finished with value: 2219.6288673715617 and parameters: {'n_estimators': 10, 'max_depth': 17, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.8536300829763519}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:25,807] Trial 157 finished with value: 1828.6263624605297 and parameters: {'n_estimators': 20, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6986631830584041}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:26,010] Trial 158 finished with value: 1961.1396811083046 and parameters: {'n_estimators': 15, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6501568099679736}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:26,324] Trial 159 finished with value: 2056.2098724515427 and parameters: {'n_estimators': 23, 'max_depth': 18, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7243089066730529}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:26,597] Trial 160 finished with value: 1794.7691702635136 and parameters: {'n_estimators': 19, 'max_depth': 17, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7675188677147529}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:26,906] Trial 161 finished with value: 1833.771031764391 and parameters: {'n_estimators': 20, 'max_depth': 17, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7729507531481903}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:27,365] Trial 162 finished with value: 2001.413765804867 and parameters: {'n_estimators': 27, 'max_depth': 17, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7525047497417107}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:27,533] Trial 163 finished with value: 2132.955226386252 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8145430573240053}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:28,099] Trial 164 finished with value: 2022.4926278173891 and parameters: {'n_estimators': 38, 'max_depth': 17, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.7829989455640511}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:28,340] Trial 165 finished with value: 1902.2324588784952 and parameters: {'n_estimators': 16, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7319368172340723}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:28,782] Trial 166 finished with value: 1800.6209866142028 and parameters: {'n_estimators': 26, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.798736316739275}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:29,325] Trial 167 finished with value: 2004.104934762504 and parameters: {'n_estimators': 32, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8812357785450391}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:29,929] Trial 168 finished with value: 2084.018450871877 and parameters: {'n_estimators': 48, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.6190516798543434}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:30,222] Trial 169 finished with value: 1932.9695993399662 and parameters: {'n_estimators': 20, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.765896822038012}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:30,941] Trial 170 finished with value: 1968.6069565155738 and parameters: {'n_estimators': 42, 'max_depth': 20, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8416433419443449}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:31,422] Trial 171 finished with value: 1826.2026219740496 and parameters: {'n_estimators': 30, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8304722531075718}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:31,801] Trial 172 finished with value: 1781.0543761742408 and parameters: {'n_estimators': 25, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8103952867693269}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:32,164] Trial 173 finished with value: 1820.6167132069124 and parameters: {'n_estimators': 24, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8114521931573945}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:32,395] Trial 174 finished with value: 2020.7229156268234 and parameters: {'n_estimators': 15, 'max_depth': 20, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7458679423529901}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:32,972] Trial 175 finished with value: 1856.5396658927443 and parameters: {'n_estimators': 35, 'max_depth': 16, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.783903547208332}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:33,274] Trial 176 finished with value: 1891.6715613597225 and parameters: {'n_estimators': 20, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7673538142500497}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:33,624] Trial 177 finished with value: 2125.5773199823807 and parameters: {'n_estimators': 10, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': False}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:34,019] Trial 178 finished with value: 1832.9903003696809 and parameters: {'n_estimators': 25, 'max_depth': 17, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.8034771753806673}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:34,482] Trial 179 finished with value: 1770.7021961791 and parameters: {'n_estimators': 31, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6948295310470419}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:35,014] Trial 180 finished with value: 1822.6223908154955 and parameters: {'n_estimators': 37, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6742123194942297}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:35,433] Trial 181 finished with value: 1999.4662170281895 and parameters: {'n_estimators': 31, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7278800302505987}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:35,741] Trial 182 finished with value: 1887.9224889492384 and parameters: {'n_estimators': 24, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.6941636174878381}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:35,975] Trial 183 finished with value: 1886.3443434318858 and parameters: {'n_estimators': 18, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7065815310224836}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:36,408] Trial 184 finished with value: 1918.8391049100567 and parameters: {'n_estimators': 31, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7480609656848067}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:37,081] Trial 185 finished with value: 2006.191923560328 and parameters: {'n_estimators': 44, 'max_depth': 20, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7876230640400502}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:37,412] Trial 186 finished with value: 2059.2828151311096 and parameters: {'n_estimators': 26, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.5776535109730889}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:37,700] Trial 187 finished with value: 1845.904866266959 and parameters: {'n_estimators': 15, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8319978123018474}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:38,293] Trial 188 finished with value: 2015.2653514530073 and parameters: {'n_estimators': 38, 'max_depth': 18, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.7595025281897979}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:38,777] Trial 189 finished with value: 1983.0370248406957 and parameters: {'n_estimators': 30, 'max_depth': 21, 'min_samples_split': 7, 'bootstrap': True, 'max_samples': 0.8489458013775126}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:39,047] Trial 190 finished with value: 1870.9901996540973 and parameters: {'n_estimators': 21, 'max_depth': 19, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.659054216320659}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:39,598] Trial 191 finished with value: 1826.2608027020838 and parameters: {'n_estimators': 32, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8142106157691558}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:40,044] Trial 192 finished with value: 1787.4455577809051 and parameters: {'n_estimators': 27, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8235080071536544}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:40,257] Trial 193 finished with value: 2459.001293873259 and parameters: {'n_estimators': 21, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.4920267999194201}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:40,482] Trial 194 finished with value: 2092.71419574904 and parameters: {'n_estimators': 14, 'max_depth': 16, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8683088479812645}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:40,998] Trial 195 finished with value: 1816.2715909705996 and parameters: {'n_estimators': 26, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7818643906781007}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:41,551] Trial 196 finished with value: 1915.279148652882 and parameters: {'n_estimators': 36, 'max_depth': 16, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7986163402614919}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:41,804] Trial 197 finished with value: 1803.4073972948477 and parameters: {'n_estimators': 19, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8214492251561841}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:42,250] Trial 198 finished with value: 1931.4494144055686 and parameters: {'n_estimators': 40, 'max_depth': 18, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.7259871397746865}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:42,569] Trial 199 finished with value: 1836.655576716334 and parameters: {'n_estimators': 26, 'max_depth': 17, 'min_samples_split': 2, 'bootstrap': True, 'max_samples': 0.7681676583165531}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:42,753] Trial 200 finished with value: 1748.0491313295197 and parameters: {'n_estimators': 14, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8016872038095668}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:42,911] Trial 201 finished with value: 1897.01393986234 and parameters: {'n_estimators': 12, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8008317416816801}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:43,044] Trial 202 finished with value: 1974.9132738157236 and parameters: {'n_estimators': 10, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7822231108076835}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:43,108] Trial 203 finished with value: 2295.9255433777776 and parameters: {'n_estimators': 20, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.16075347915208765}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:43,494] Trial 204 finished with value: 1968.267770474883 and parameters: {'n_estimators': 30, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8339562634082734}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:43,782] Trial 205 finished with value: 2113.4524299237305 and parameters: {'n_estimators': 25, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7431677024879818}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:43,976] Trial 206 finished with value: 1881.8653816931724 and parameters: {'n_estimators': 15, 'max_depth': 19, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.8161571923257266}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:44,362] Trial 207 finished with value: 1850.251168967 and parameters: {'n_estimators': 32, 'max_depth': 21, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7608794039225627}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:44,839] Trial 208 finished with value: 2200.020601357922 and parameters: {'n_estimators': 19, 'max_depth': 18, 'min_samples_split': 2, 'bootstrap': False}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:45,226] Trial 209 finished with value: 1811.3852721982473 and parameters: {'n_estimators': 25, 'max_depth': 20, 'min_samples_split': 6, 'bootstrap': True, 'max_samples': 0.6877857895942764}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:45,666] Trial 210 finished with value: 1864.8370933829892 and parameters: {'n_estimators': 36, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7916928468555103}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:47,540] Trial 211 finished with value: 2005.4892785204413 and parameters: {'n_estimators': 150, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8572342518800865}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:47,900] Trial 212 finished with value: 1771.653646337095 and parameters: {'n_estimators': 29, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8223312193001124}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:48,229] Trial 213 finished with value: 1723.803570648388 and parameters: {'n_estimators': 27, 'max_depth': 16, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8086058700663584}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:48,753] Trial 214 finished with value: 1978.9266558282698 and parameters: {'n_estimators': 42, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8362128305533327}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:49,106] Trial 215 finished with value: 1837.5480307843352 and parameters: {'n_estimators': 29, 'max_depth': 16, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8169814948870178}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:49,503] Trial 216 finished with value: 1896.449741384446 and parameters: {'n_estimators': 33, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7958561745471715}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:49,823] Trial 217 finished with value: 1839.6596511914274 and parameters: {'n_estimators': 25, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.850375130878492}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:50,250] Trial 218 finished with value: 1782.5321764700775 and parameters: {'n_estimators': 35, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8081628477844371}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:50,792] Trial 219 finished with value: 1880.6192815828965 and parameters: {'n_estimators': 44, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8107366352393351}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:51,219] Trial 220 finished with value: 1895.6637596685298 and parameters: {'n_estimators': 34, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8239747189176141}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:51,361] Trial 221 finished with value: 1970.7189168846633 and parameters: {'n_estimators': 27, 'max_depth': 4, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7831303495556206}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:51,831] Trial 222 finished with value: 1820.142122226447 and parameters: {'n_estimators': 37, 'max_depth': 18, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7998131109750345}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:52,113] Trial 223 finished with value: 2227.2540941178013 and parameters: {'n_estimators': 21, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8759517373805104}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:52,308] Trial 224 finished with value: 2081.818457402035 and parameters: {'n_estimators': 15, 'max_depth': 17, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8396479771214139}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:52,618] Trial 225 finished with value: 2060.8263950477285 and parameters: {'n_estimators': 29, 'max_depth': 18, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.6411553354872919}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:53,190] Trial 226 finished with value: 1932.76126576759 and parameters: {'n_estimators': 49, 'max_depth': 16, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.7736031664605933}. Best is trial 103 with value: 1646.6170669987123.\n",
      "[I 2025-08-01 08:10:53,486] Trial 227 finished with value: 1637.2832705168728 and parameters: {'n_estimators': 23, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8089360796045448}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:53,933] Trial 228 finished with value: 1739.7289994746577 and parameters: {'n_estimators': 35, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.812241032359936}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:54,405] Trial 229 finished with value: 1792.076049994886 and parameters: {'n_estimators': 38, 'max_depth': 20, 'min_samples_split': 4, 'bootstrap': True, 'max_samples': 0.8098510916842223}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:54,837] Trial 230 finished with value: 1936.3777266322995 and parameters: {'n_estimators': 34, 'max_depth': 19, 'min_samples_split': 5, 'bootstrap': True, 'max_samples': 0.8270150014840989}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:55,188] Trial 231 finished with value: 1669.0378272798898 and parameters: {'n_estimators': 28, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8035082453605299}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:55,478] Trial 232 finished with value: 1819.0167322850987 and parameters: {'n_estimators': 23, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8049716979303884}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:57,208] Trial 233 finished with value: 1965.8032483385327 and parameters: {'n_estimators': 123, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8505997993508719}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:57,580] Trial 234 finished with value: 1693.1617046826666 and parameters: {'n_estimators': 29, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7879234110941905}. Best is trial 227 with value: 1637.2832705168728.\n",
      "[I 2025-08-01 08:10:57,902] Trial 235 finished with value: 1595.5759502847902 and parameters: {'n_estimators': 25, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7895522618947375}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:58,418] Trial 236 finished with value: 1920.0619595028074 and parameters: {'n_estimators': 41, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7829181201471171}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:58,691] Trial 237 finished with value: 2018.3523970501385 and parameters: {'n_estimators': 22, 'max_depth': 20, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7640953746620744}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:59,092] Trial 238 finished with value: 1894.4176458653951 and parameters: {'n_estimators': 32, 'max_depth': 19, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7911334861917714}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:59,272] Trial 239 finished with value: 1773.7111126102648 and parameters: {'n_estimators': 14, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7501110910568843}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:59,425] Trial 240 finished with value: 2020.6707192288707 and parameters: {'n_estimators': 12, 'max_depth': 21, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7391948573123674}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:59,640] Trial 241 finished with value: 1839.5643177197146 and parameters: {'n_estimators': 17, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7551060351738218}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:10:59,950] Trial 242 finished with value: 1743.234976999387 and parameters: {'n_estimators': 23, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8042352567779565}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:00,231] Trial 243 finished with value: 1771.4600872242017 and parameters: {'n_estimators': 21, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7762052539028537}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:00,458] Trial 244 finished with value: 1649.5917302521007 and parameters: {'n_estimators': 17, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.778753852268243}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:00,669] Trial 245 finished with value: 1788.3101132325771 and parameters: {'n_estimators': 16, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.774922190616804}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:00,971] Trial 246 finished with value: 1650.0574736093895 and parameters: {'n_estimators': 22, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7836650832883009}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:01,257] Trial 247 finished with value: 1751.1899153706827 and parameters: {'n_estimators': 22, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7908533722006992}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:01,930] Trial 248 finished with value: 2082.8243114 and parameters: {'n_estimators': 25, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:02,196] Trial 249 finished with value: 1679.8270013085598 and parameters: {'n_estimators': 20, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7857991560836488}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:02,454] Trial 250 finished with value: 1720.3898214941896 and parameters: {'n_estimators': 20, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.792168703118054}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:02,606] Trial 251 finished with value: 1851.701505057814 and parameters: {'n_estimators': 11, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7906808357117139}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:02,863] Trial 252 finished with value: 1676.5076256924747 and parameters: {'n_estimators': 20, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7902554612266305}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:03,102] Trial 253 finished with value: 1891.601780375217 and parameters: {'n_estimators': 19, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7649391519630403}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:03,399] Trial 254 finished with value: 1747.9250937630413 and parameters: {'n_estimators': 23, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7944683603819387}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:03,727] Trial 255 finished with value: 1883.6170200924935 and parameters: {'n_estimators': 26, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7751625140968985}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:03,864] Trial 256 finished with value: 1749.0574165867345 and parameters: {'n_estimators': 10, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8066119924053088}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:05,977] Trial 257 finished with value: 1941.0607844147326 and parameters: {'n_estimators': 163, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8078415365246426}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:06,126] Trial 258 finished with value: 2043.9659498022895 and parameters: {'n_estimators': 11, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7966690968704851}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:09,376] Trial 259 finished with value: 2071.035861336117 and parameters: {'n_estimators': 249, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8322559298257766}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:09,618] Trial 260 finished with value: 1824.3999638185537 and parameters: {'n_estimators': 19, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7818417389486919}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:09,765] Trial 261 finished with value: 2114.7201704097506 and parameters: {'n_estimators': 10, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7608893390377269}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:10,049] Trial 262 finished with value: 1907.004659594627 and parameters: {'n_estimators': 16, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8017429944742424}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:10,369] Trial 263 finished with value: 1669.569003347957 and parameters: {'n_estimators': 23, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8121227652625799}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:10,678] Trial 264 finished with value: 1872.0236040448506 and parameters: {'n_estimators': 23, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8406740091367039}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:10,992] Trial 265 finished with value: 1793.1551303560223 and parameters: {'n_estimators': 24, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8233205904755614}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:11,344] Trial 266 finished with value: 1624.9051713845613 and parameters: {'n_estimators': 28, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7766010923562776}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:11,720] Trial 267 finished with value: 1922.556145451244 and parameters: {'n_estimators': 30, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7453628816359136}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:11,747] Trial 268 finished with value: 3854.035621740363 and parameters: {'n_estimators': 28, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.017807001271483047}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:12,633] Trial 269 finished with value: 2089.297333571428 and parameters: {'n_estimators': 35, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:12,909] Trial 270 finished with value: 1918.0823659565506 and parameters: {'n_estimators': 22, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7728998560968887}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:13,261] Trial 271 finished with value: 1624.8907819516137 and parameters: {'n_estimators': 27, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7844677125238634}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:13,729] Trial 272 finished with value: 2027.139042967106 and parameters: {'n_estimators': 38, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7672035881258507}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:14,101] Trial 273 finished with value: 1918.1992316230146 and parameters: {'n_estimators': 29, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7539403672405941}. Best is trial 235 with value: 1595.5759502847902.\n",
      "[I 2025-08-01 08:11:14,505] Trial 274 finished with value: 1495.0818970990745 and parameters: {'n_estimators': 31, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7832644082990208}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:14,882] Trial 275 finished with value: 1762.35564823414 and parameters: {'n_estimators': 27, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8154949786920379}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:15,162] Trial 276 finished with value: 1625.4868784573955 and parameters: {'n_estimators': 20, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7848362173295917}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:15,410] Trial 277 finished with value: 1748.7107015790177 and parameters: {'n_estimators': 18, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7857359134424254}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:15,671] Trial 278 finished with value: 1660.1831963005807 and parameters: {'n_estimators': 18, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8350319514994275}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:15,948] Trial 279 finished with value: 1973.9340868985137 and parameters: {'n_estimators': 20, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.855293372267511}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:16,180] Trial 280 finished with value: 1719.6901775399633 and parameters: {'n_estimators': 17, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8351788543236659}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:16,430] Trial 281 finished with value: 2098.903287961675 and parameters: {'n_estimators': 18, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8412864273133009}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:16,652] Trial 282 finished with value: 2114.0672979171645 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8658030619570638}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:16,866] Trial 283 finished with value: 1931.2359756497438 and parameters: {'n_estimators': 16, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8271043742280313}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:17,055] Trial 284 finished with value: 2487.3466713976272 and parameters: {'n_estimators': 26, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.4095109832062977}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:19,250] Trial 285 finished with value: 2034.6887384820532 and parameters: {'n_estimators': 186, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7322135584722144}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:19,538] Trial 286 finished with value: 1681.5782304955044 and parameters: {'n_estimators': 22, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7829112023846294}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:19,803] Trial 287 finished with value: 1780.8016134005516 and parameters: {'n_estimators': 20, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.757290439334515}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:19,945] Trial 288 finished with value: 1998.5960118981288 and parameters: {'n_estimators': 10, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7839243398198288}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:20,410] Trial 289 finished with value: 2051.6686115397806 and parameters: {'n_estimators': 18, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': False}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:21,688] Trial 290 finished with value: 2013.9020754703693 and parameters: {'n_estimators': 106, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7707836745518579}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:21,994] Trial 291 finished with value: 1594.8135342279552 and parameters: {'n_estimators': 24, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7868088413225353}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:22,210] Trial 292 finished with value: 2046.0066259865287 and parameters: {'n_estimators': 16, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7396888479264135}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:22,525] Trial 293 finished with value: 1772.4584549365832 and parameters: {'n_estimators': 24, 'max_depth': 23, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7797157845440816}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:22,928] Trial 294 finished with value: 1910.3548866547676 and parameters: {'n_estimators': 31, 'max_depth': 22, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7597711912647772}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:23,198] Trial 295 finished with value: 1688.8630081338438 and parameters: {'n_estimators': 20, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.790538659663879}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:23,403] Trial 296 finished with value: 1922.268796645816 and parameters: {'n_estimators': 15, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.8386063321555048}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:23,681] Trial 297 finished with value: 2184.1543631220716 and parameters: {'n_estimators': 23, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7481084479189555}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:24,053] Trial 298 finished with value: 1787.7073972653825 and parameters: {'n_estimators': 30, 'max_depth': 25, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7814691642945756}. Best is trial 274 with value: 1495.0818970990745.\n",
      "[I 2025-08-01 08:11:24,189] Trial 299 finished with value: 1936.796963452495 and parameters: {'n_estimators': 10, 'max_depth': 24, 'min_samples_split': 3, 'bootstrap': True, 'max_samples': 0.7923894680862185}. Best is trial 274 with value: 1495.0818970990745.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "rf_stacking_study = optuna.create_study(direction='minimize')\n",
    "rf_stacking_study.optimize(stacked_objective_rf, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 31,\n",
       " 'max_depth': 24,\n",
       " 'min_samples_split': 3,\n",
       " 'bootstrap': True,\n",
       " 'max_samples': 0.7832644082990208}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/rf_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf_stacking_study.best_params, f\"../../split_income_models/ensemble/rf_stacking_best_params.pkl\")\n",
    "joblib.dump(rf_stacking_study, f\"../../split_income_models/ensemble/rf_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/rf_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = RandomForestRegressor(**rf_stacking_study.best_params)\n",
    "best_rf_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_rf_model, \"../../split_income_models/ensemble/rf_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_svm(trial):\n",
    "\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"poly\", \"rbf\"])\n",
    "\n",
    "    if kernel == \"poly\":\n",
    "        degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "\n",
    "    C = trial.suggest_float(\"C\", 0.1, 1)\n",
    "    epsilon = trial.suggest_float(\"epsilon\", 0.05, 1.0)\n",
    "\n",
    "    svm = SVR(kernel=kernel, degree=degree if kernel == \"poly\" else 0, C=C, epsilon=epsilon)\n",
    "    \n",
    "    svm.fit(X_meta_train, y_meta_train)\n",
    "    svm_predictions = svm.predict(X_meta_val)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, svm_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:11:24,725] A new study created in memory with name: no-name-1c678de4-65cd-4db3-bc1c-26ba243098cf\n",
      "[I 2025-08-01 08:11:24,800] Trial 0 finished with value: 4093.450753482156 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7121719739303414, 'epsilon': 0.4249466578421569}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:24,892] Trial 1 finished with value: 13536.551113529382 and parameters: {'kernel': 'rbf', 'C': 0.8638313342201797, 'epsilon': 0.21848330141219593}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,418] Trial 2 finished with value: 23639.562670039486 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.6435580606659803, 'epsilon': 0.7961177551837328}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,491] Trial 3 finished with value: 4978.281804748547 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.38176646876392367, 'epsilon': 0.8919869481289193}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,582] Trial 4 finished with value: 14136.741264321601 and parameters: {'kernel': 'rbf', 'C': 0.708620137536308, 'epsilon': 0.5477039472816814}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,709] Trial 5 finished with value: 8218.163529644627 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.3802419785888668, 'epsilon': 0.15528202375133196}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,798] Trial 6 finished with value: 13402.164569619914 and parameters: {'kernel': 'rbf', 'C': 0.8983304477030368, 'epsilon': 0.6127274111537295}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,867] Trial 7 finished with value: 5461.830376073891 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.1198165557733176, 'epsilon': 0.7606241881166432}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:25,942] Trial 8 finished with value: 4584.665347790485 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.8040267972337589, 'epsilon': 0.8363998574308993}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:26,108] Trial 9 finished with value: 11953.154987086958 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.7678582610425035, 'epsilon': 0.5996425865158429}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:26,204] Trial 10 finished with value: 15236.709593624491 and parameters: {'kernel': 'rbf', 'C': 0.4885700900074792, 'epsilon': 0.360985625174444}. Best is trial 0 with value: 4093.450753482156.\n",
      "[I 2025-08-01 08:11:26,276] Trial 11 finished with value: 4087.0299533759367 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9886307297529471, 'epsilon': 0.3617981687549492}. Best is trial 11 with value: 4087.0299533759367.\n",
      "[I 2025-08-01 08:11:26,347] Trial 12 finished with value: 4091.734829221496 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.964012594698926, 'epsilon': 0.36525986319767306}. Best is trial 11 with value: 4087.0299533759367.\n",
      "[I 2025-08-01 08:11:26,418] Trial 13 finished with value: 4088.421628595405 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9856959908613894, 'epsilon': 0.3068818657840777}. Best is trial 11 with value: 4087.0299533759367.\n",
      "[I 2025-08-01 08:11:26,489] Trial 14 finished with value: 4092.90133856764 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9837531333845997, 'epsilon': 0.07924976095386851}. Best is trial 11 with value: 4087.0299533759367.\n",
      "[I 2025-08-01 08:11:26,559] Trial 15 finished with value: 4085.757576232777 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9970164067761078, 'epsilon': 0.24142351079782254}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:26,629] Trial 16 finished with value: 4102.693046334445 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5832068978473512, 'epsilon': 0.22938860560525204}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:26,706] Trial 17 finished with value: 5425.191470125258 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.12633332749168535, 'epsilon': 0.46404131913427227}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:26,796] Trial 18 finished with value: 13546.498667121894 and parameters: {'kernel': 'rbf', 'C': 0.8588823173583912, 'epsilon': 0.9892384776788459}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,160] Trial 19 finished with value: 25410.906261126027 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.46783819045470276, 'epsilon': 0.0633174376738666}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,228] Trial 20 finished with value: 4117.336620573208 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.24558273862532565, 'epsilon': 0.27155285279060104}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,408] Trial 21 finished with value: 4091.001896515742 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9726947890806972, 'epsilon': 0.32879954063858396}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,484] Trial 22 finished with value: 4092.3323910720856 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9118533878361227, 'epsilon': 0.15608410605932904}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,588] Trial 23 finished with value: 4529.807977285858 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9999355514834881, 'epsilon': 0.3076864431190113}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,664] Trial 24 finished with value: 4087.2973140119825 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.828614212978304, 'epsilon': 0.45120120767252053}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,754] Trial 25 finished with value: 4568.815687924935 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.8208261315533686, 'epsilon': 0.44798498094208783}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,846] Trial 26 finished with value: 13951.18358529566 and parameters: {'kernel': 'rbf', 'C': 0.7542832860592469, 'epsilon': 0.6742691935409059}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:27,920] Trial 27 finished with value: 4104.117385422493 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6547742393093424, 'epsilon': 0.528478438345983}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,095] Trial 28 finished with value: 13551.758395392419 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9031319766300361, 'epsilon': 0.41422683501809276}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,169] Trial 29 finished with value: 4093.916080852471 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7072580620378376, 'epsilon': 0.403898122341614}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,249] Trial 30 finished with value: 4561.590580677487 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9352331034003638, 'epsilon': 0.4670083078081018}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,320] Trial 31 finished with value: 4087.9690947215686 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8344321498274074, 'epsilon': 0.2542558904329116}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,391] Trial 32 finished with value: 4089.3735677175887 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8470311278087167, 'epsilon': 0.19722075598201882}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,463] Trial 33 finished with value: 4090.6550804758813 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7842014569044596, 'epsilon': 0.2627063682397563}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,533] Trial 34 finished with value: 4090.662355052346 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8582262021001863, 'epsilon': 0.1457095282579372}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,630] Trial 35 finished with value: 13273.349607989836 and parameters: {'kernel': 'rbf', 'C': 0.9336271706661491, 'epsilon': 0.3819888592365823}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,706] Trial 36 finished with value: 4105.3499274018795 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6321283228279557, 'epsilon': 0.5016809615011433}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,781] Trial 37 finished with value: 4093.99592682941 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7175875460674644, 'epsilon': 0.24175068720806786}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,879] Trial 38 finished with value: 13443.309857104901 and parameters: {'kernel': 'rbf', 'C': 0.8874950323282211, 'epsilon': 0.19159156016715123}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:28,965] Trial 39 finished with value: 4564.08345243995 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9363863461853497, 'epsilon': 0.11786104316834331}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,038] Trial 40 finished with value: 4087.563121550692 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8197048201599438, 'epsilon': 0.582332510596203}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,107] Trial 41 finished with value: 4087.913190225474 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.830218422154811, 'epsilon': 0.6754007931299099}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,177] Trial 42 finished with value: 4088.9643612161676 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7709813058599507, 'epsilon': 0.672293170913986}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,247] Trial 43 finished with value: 4095.4649978733323 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7178893378415472, 'epsilon': 0.6034098559096465}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,318] Trial 44 finished with value: 4089.967261043809 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8786580667205552, 'epsilon': 0.6994154329615192}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,407] Trial 45 finished with value: 4573.999129307449 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.8083841172418693, 'epsilon': 0.5811914636802795}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,688] Trial 46 finished with value: 23546.99968408415 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.6493568547102316, 'epsilon': 0.746947191269987}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,781] Trial 47 finished with value: 13196.732952617702 and parameters: {'kernel': 'rbf', 'C': 0.9572395032212498, 'epsilon': 0.6467564992666492}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,852] Trial 48 finished with value: 4102.6724578272315 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5230145843330939, 'epsilon': 0.5591116761467264}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,927] Trial 49 finished with value: 4961.595962933101 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.384119928658351, 'epsilon': 0.5117209246543533}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:29,998] Trial 50 finished with value: 4100.160908288701 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6831924052387146, 'epsilon': 0.7995247521367255}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,069] Trial 51 finished with value: 4087.402871887036 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8235379588815652, 'epsilon': 0.353585179279919}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,140] Trial 52 finished with value: 4090.2206218518 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7577368647470791, 'epsilon': 0.3380017024844318}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,211] Trial 53 finished with value: 4090.657552166562 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9078443662450758, 'epsilon': 0.4886405507569455}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,283] Trial 54 finished with value: 4087.7266712839782 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8080612306469721, 'epsilon': 0.42041381173022174}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,354] Trial 55 finished with value: 4100.879521953474 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5814434865586292, 'epsilon': 0.4243225716099874}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,528] Trial 56 finished with value: 14541.135161404212 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9938235691285664, 'epsilon': 0.38088035662574626}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,624] Trial 57 finished with value: 13814.371884655255 and parameters: {'kernel': 'rbf', 'C': 0.787706714670186, 'epsilon': 0.28129629644596127}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,694] Trial 58 finished with value: 4093.0618235320894 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.950381283111412, 'epsilon': 0.3514832305208535}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,766] Trial 59 finished with value: 4090.306629380988 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7396932444003783, 'epsilon': 0.4425508434241997}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,853] Trial 60 finished with value: 4575.138255684302 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.8709858851780272, 'epsilon': 0.3160361926485366}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,924] Trial 61 finished with value: 4088.1831880956033 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.83130330425474, 'epsilon': 0.5506730739882056}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:30,995] Trial 62 finished with value: 4088.4729580919056 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8014862457201832, 'epsilon': 0.6299599367120251}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,067] Trial 63 finished with value: 4089.5128955558685 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9021748401059487, 'epsilon': 0.7166742850235586}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,140] Trial 64 finished with value: 4087.784146853225 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8183727512810227, 'epsilon': 0.40548980727449074}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,213] Trial 65 finished with value: 4089.2311004351236 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8671166802681458, 'epsilon': 0.47042156949040737}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,286] Trial 66 finished with value: 4098.228412892888 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6797925664327301, 'epsilon': 0.39120001328394505}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,359] Trial 67 finished with value: 4091.627682480922 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9242733896558124, 'epsilon': 0.2878859174754943}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,432] Trial 68 finished with value: 4091.7174431849053 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9656199536775999, 'epsilon': 0.3563513909328018}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,528] Trial 69 finished with value: 16583.67925100033 and parameters: {'kernel': 'rbf', 'C': 0.2760388970435118, 'epsilon': 0.4265269970218072}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,612] Trial 70 finished with value: 4696.7011423329595 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.6179538632125497, 'epsilon': 0.4804238125735577}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,684] Trial 71 finished with value: 4087.4248513698444 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.822102092512358, 'epsilon': 0.5249720754267783}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,758] Trial 72 finished with value: 4092.029942058209 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7331760215884544, 'epsilon': 0.5245183324892251}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,830] Trial 73 finished with value: 4086.9733852845125 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8072160552121675, 'epsilon': 0.5695130566927032}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,901] Trial 74 finished with value: 4088.864279663419 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8510048138170172, 'epsilon': 0.5465151205916373}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:31,973] Trial 75 finished with value: 4086.5342784432964 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7938869186607135, 'epsilon': 0.5727985398817151}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,044] Trial 76 finished with value: 4086.935675046627 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7785544711984358, 'epsilon': 0.5753050649762542}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,117] Trial 77 finished with value: 4087.318572181467 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.775254177182552, 'epsilon': 0.5745344221432929}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,187] Trial 78 finished with value: 4098.24535571645 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.6885837917048974, 'epsilon': 0.573515453309141}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,259] Trial 79 finished with value: 4092.288721422016 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7786359384739607, 'epsilon': 0.21342191847570346}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,364] Trial 80 finished with value: 13984.220242486785 and parameters: {'kernel': 'rbf', 'C': 0.7485135108805046, 'epsilon': 0.5953395959844812}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,435] Trial 81 finished with value: 4090.9257584251836 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8886188927486575, 'epsilon': 0.6336544667799593}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,506] Trial 82 finished with value: 4087.685871564855 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7899938046543336, 'epsilon': 0.6127835577393422}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,579] Trial 83 finished with value: 4088.589456083047 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8456027601954244, 'epsilon': 0.5406615337663973}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:32,651] Trial 84 finished with value: 4094.124962315622 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7620680581657967, 'epsilon': 0.9886170731938537}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,156] Trial 85 finished with value: 22899.69266637016 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.7044516242750668, 'epsilon': 0.506526832151552}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,227] Trial 86 finished with value: 4088.5806046702182 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9794675377980351, 'epsilon': 0.454607430611334}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,299] Trial 87 finished with value: 4090.6551653154547 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9227400445704637, 'epsilon': 0.5625626478087059}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,369] Trial 88 finished with value: 4092.0147146331783 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9464465855806097, 'epsilon': 0.5325014191422622}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,546] Trial 89 finished with value: 11590.978689356063 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.7268077586507444, 'epsilon': 0.5139268480998375}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,627] Trial 90 finished with value: 4107.1328773021305 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.4363297633905834, 'epsilon': 0.6589144068408881}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,707] Trial 91 finished with value: 4088.4813495667 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8362123666122643, 'epsilon': 0.5954697697597933}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,784] Trial 92 finished with value: 4086.9535113794386 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.807335116157437, 'epsilon': 0.574530974719548}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,855] Trial 93 finished with value: 4088.102693348539 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7969033177823388, 'epsilon': 0.6198358718687125}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,928] Trial 94 finished with value: 4087.393245591527 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7702413219163642, 'epsilon': 0.4968776762567248}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:33,999] Trial 95 finished with value: 4086.7330825767744 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7733267250612238, 'epsilon': 0.48826516333987785}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,071] Trial 96 finished with value: 4087.3695556174093 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7686707184037047, 'epsilon': 0.49005354191837736}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,142] Trial 97 finished with value: 4090.560992457568 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7484099774303465, 'epsilon': 0.5726688471949225}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,323] Trial 98 finished with value: 4658.330064087911 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.6684665849668423, 'epsilon': 0.44121866515780106}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,395] Trial 99 finished with value: 4094.8834733307044 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7098809455139747, 'epsilon': 0.48547730338617}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,490] Trial 100 finished with value: 14525.794917063422 and parameters: {'kernel': 'rbf', 'C': 0.6149490421292332, 'epsilon': 0.46021901256512293}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,560] Trial 101 finished with value: 4087.498840805683 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7681483754474702, 'epsilon': 0.49196940343290024}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,632] Trial 102 finished with value: 4087.3054583700323 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7770637887990421, 'epsilon': 0.5542620943030734}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,703] Trial 103 finished with value: 4087.246561884282 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7982302140456267, 'epsilon': 0.5917239145298041}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,776] Trial 104 finished with value: 4089.2962040758102 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8682111894568401, 'epsilon': 0.5889215389640919}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,846] Trial 105 finished with value: 4088.1929752894634 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7996786466187067, 'epsilon': 0.6378419008716322}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,919] Trial 106 finished with value: 4088.2132501327906 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8457715918703924, 'epsilon': 0.563385088203682}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:34,992] Trial 107 finished with value: 4093.2547528813593 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7385317395165627, 'epsilon': 0.6150029318224349}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,064] Trial 108 finished with value: 4087.3086210902948 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7867567501225148, 'epsilon': 0.683875814932814}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,135] Trial 109 finished with value: 4089.7340694220215 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8820578977926256, 'epsilon': 0.6890196143191631}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,205] Trial 110 finished with value: 4088.8392830803505 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8142130111899064, 'epsilon': 0.7175110123803895}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,276] Trial 111 finished with value: 4087.1309148599134 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7951431705886249, 'epsilon': 0.5487257692376618}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,346] Trial 112 finished with value: 4086.2050548844104 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.7874921575410401, 'epsilon': 0.5330196726959812}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,418] Trial 113 finished with value: 4088.8929800774454 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.8572663351535207, 'epsilon': 0.5369989475911375}. Best is trial 15 with value: 4085.757576232777.\n",
      "[I 2025-08-01 08:11:35,489] Trial 114 finished with value: 4083.5168969208944 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9975508089621155, 'epsilon': 0.518582050878731}. Best is trial 114 with value: 4083.5168969208944.\n",
      "[I 2025-08-01 08:11:35,559] Trial 115 finished with value: 4092.1511150073065 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9526176961756138, 'epsilon': 0.5193445585621216}. Best is trial 114 with value: 4083.5168969208944.\n",
      "[I 2025-08-01 08:11:35,631] Trial 116 finished with value: 4085.1520035992053 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.984277843159707, 'epsilon': 0.6537738368608702}. Best is trial 114 with value: 4083.5168969208944.\n",
      "[I 2025-08-01 08:11:35,721] Trial 117 finished with value: 4086.5888005008937 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.975559056598876, 'epsilon': 0.6610253741183688}. Best is trial 114 with value: 4083.5168969208944.\n",
      "[I 2025-08-01 08:11:35,797] Trial 118 finished with value: 4090.300528016926 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9951647842756847, 'epsilon': 0.08576670885878435}. Best is trial 114 with value: 4083.5168969208944.\n",
      "[I 2025-08-01 08:11:35,890] Trial 119 finished with value: 13155.458768217728 and parameters: {'kernel': 'rbf', 'C': 0.9718950605776179, 'epsilon': 0.6592408582330578}. Best is trial 114 with value: 4083.5168969208944.\n",
      "[I 2025-08-01 08:11:35,962] Trial 120 finished with value: 4083.4484205623994 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9862700610173152, 'epsilon': 0.7403887763586017}. Best is trial 120 with value: 4083.4484205623994.\n",
      "[I 2025-08-01 08:11:36,036] Trial 121 finished with value: 4087.9050631574673 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9652687369862545, 'epsilon': 0.7685418863678141}. Best is trial 120 with value: 4083.4484205623994.\n",
      "[I 2025-08-01 08:11:36,107] Trial 122 finished with value: 4091.3630577366657 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9213532573405511, 'epsilon': 0.8364874104125787}. Best is trial 120 with value: 4083.4484205623994.\n",
      "[I 2025-08-01 08:11:36,177] Trial 123 finished with value: 4087.333431351828 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.965610993206876, 'epsilon': 0.7103982479582676}. Best is trial 120 with value: 4083.4484205623994.\n",
      "[I 2025-08-01 08:11:36,252] Trial 124 finished with value: 4089.58659120794 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9375833099773057, 'epsilon': 0.7389651637829324}. Best is trial 120 with value: 4083.4484205623994.\n",
      "[I 2025-08-01 08:11:36,326] Trial 125 finished with value: 4081.2148209890006 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9982621968510141, 'epsilon': 0.7805002504487023}. Best is trial 125 with value: 4081.2148209890006.\n",
      "[I 2025-08-01 08:11:36,538] Trial 126 finished with value: 14493.882235989937 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9914544918436234, 'epsilon': 0.8083526406177238}. Best is trial 125 with value: 4081.2148209890006.\n",
      "[I 2025-08-01 08:11:36,609] Trial 127 finished with value: 4082.8653392796805 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9886623163951048, 'epsilon': 0.7593819631916301}. Best is trial 125 with value: 4081.2148209890006.\n",
      "[I 2025-08-01 08:11:36,680] Trial 128 finished with value: 4081.0241892674157 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9978682913375623, 'epsilon': 0.7765775960792071}. Best is trial 128 with value: 4081.0241892674157.\n",
      "[I 2025-08-01 08:11:36,750] Trial 129 finished with value: 4080.997543953121 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9992389298467907, 'epsilon': 0.7797328161464541}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:36,820] Trial 130 finished with value: 4083.180508636234 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9967917373638565, 'epsilon': 0.8531867705134702}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:36,892] Trial 131 finished with value: 4086.1134978515556 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9813452836022725, 'epsilon': 0.8428483785907437}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:36,963] Trial 132 finished with value: 4082.3860185687076 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9962097798232122, 'epsilon': 0.88427283774056}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,045] Trial 133 finished with value: 4085.966121379611 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9812096317039948, 'epsilon': 0.869544639441202}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,124] Trial 134 finished with value: 4082.287181247072 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.995199004567938, 'epsilon': 0.8925689801759117}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,196] Trial 135 finished with value: 4082.301782712425 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.992425098169681, 'epsilon': 0.8966180611030374}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,267] Trial 136 finished with value: 4081.9174709420313 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9969846741484657, 'epsilon': 0.8927975735730429}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,347] Trial 137 finished with value: 4082.170989122309 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9921197086377719, 'epsilon': 0.9019373905225977}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,423] Trial 138 finished with value: 4081.852204311832 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9952898362765076, 'epsilon': 0.9223354480439868}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,494] Trial 139 finished with value: 4081.3767329346315 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9970576829346727, 'epsilon': 0.9175463709848788}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,565] Trial 140 finished with value: 4081.702553642167 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9961677106481116, 'epsilon': 0.9237103414305781}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,636] Trial 141 finished with value: 4081.8330749448155 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9965295528537, 'epsilon': 0.9327049482339725}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,711] Trial 142 finished with value: 4091.5343316196177 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9476098126018414, 'epsilon': 0.9342796712038219}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,786] Trial 143 finished with value: 4089.3926108947303 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9578055584416192, 'epsilon': 0.9112811710351617}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,857] Trial 144 finished with value: 4081.4334703759387 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9986272856704288, 'epsilon': 0.9405500923122688}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:37,933] Trial 145 finished with value: 4091.3732834921516 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9425064559320911, 'epsilon': 0.9458914834801374}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,089] Trial 146 finished with value: 4081.722122018791 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9985919807368064, 'epsilon': 0.8892308023525891}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,161] Trial 147 finished with value: 4081.50406104326 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9986508497521986, 'epsilon': 0.8945340581195413}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,252] Trial 148 finished with value: 13048.289215821545 and parameters: {'kernel': 'rbf', 'C': 0.9999648406826863, 'epsilon': 0.8939971600415816}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,322] Trial 149 finished with value: 4087.334537474428 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9641917043230444, 'epsilon': 0.9692985205896956}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,393] Trial 150 finished with value: 4091.0360057539597 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.913944536258511, 'epsilon': 0.9137352181281795}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,464] Trial 151 finished with value: 4088.0738172357546 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9705180557896675, 'epsilon': 0.8714006452075707}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,535] Trial 152 finished with value: 4081.0664194338788 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995986613138557, 'epsilon': 0.9451612454014586}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,606] Trial 153 finished with value: 4091.7368710040264 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9340980458370814, 'epsilon': 0.9459452927238176}. Best is trial 129 with value: 4080.997543953121.\n",
      "[I 2025-08-01 08:11:38,676] Trial 154 finished with value: 4080.8979486058233 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9994621056798265, 'epsilon': 0.8978704525524921}. Best is trial 154 with value: 4080.8979486058233.\n",
      "[I 2025-08-01 08:11:38,746] Trial 155 finished with value: 4090.6355892360675 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9530332241546967, 'epsilon': 0.9220077828460995}. Best is trial 154 with value: 4080.8979486058233.\n",
      "[I 2025-08-01 08:11:38,818] Trial 156 finished with value: 4086.405845258416 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9712464569143687, 'epsilon': 0.959075501495383}. Best is trial 154 with value: 4080.8979486058233.\n",
      "[I 2025-08-01 08:11:38,888] Trial 157 finished with value: 4080.761314896951 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999501235150273, 'epsilon': 0.899138508990938}. Best is trial 157 with value: 4080.761314896951.\n",
      "[I 2025-08-01 08:11:38,959] Trial 158 finished with value: 4090.3525548596067 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9580573893136173, 'epsilon': 0.8183303424311101}. Best is trial 157 with value: 4080.761314896951.\n",
      "[I 2025-08-01 08:11:39,030] Trial 159 finished with value: 4091.8701865843514 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9322368202710166, 'epsilon': 0.9241152006207561}. Best is trial 157 with value: 4080.761314896951.\n",
      "[I 2025-08-01 08:11:39,118] Trial 160 finished with value: 4079.6699970531236 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9989971585460742, 'epsilon': 0.9977179218908263}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,197] Trial 161 finished with value: 4084.5034327031153 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9754011515553496, 'epsilon': 0.9958246607070345}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,270] Trial 162 finished with value: 4084.870425120345 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9765462918844356, 'epsilon': 0.9711926936767867}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,342] Trial 163 finished with value: 4081.037459473216 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9976831485891944, 'epsilon': 0.903010820475437}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,414] Trial 164 finished with value: 4090.057476001764 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9650757512304439, 'epsilon': 0.861678321201721}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,489] Trial 165 finished with value: 4091.3963747548555 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9478953010573776, 'epsilon': 0.9375517705701802}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,560] Trial 166 finished with value: 4084.403173600032 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9816812066412525, 'epsilon': 0.910525704512179}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,631] Trial 167 finished with value: 4081.250259369997 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9984568097736702, 'epsilon': 0.7837994024785193}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,701] Trial 168 finished with value: 4090.1131070169235 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9538227667829536, 'epsilon': 0.7779858123522558}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,772] Trial 169 finished with value: 4080.5677969675835 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9993069060825378, 'epsilon': 0.9605427533897647}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,844] Trial 170 finished with value: 4085.2741162921016 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9719051526526328, 'epsilon': 0.9782880172896303}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,918] Trial 171 finished with value: 4081.020192711 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990457120374979, 'epsilon': 0.9496202266208705}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:39,992] Trial 172 finished with value: 4086.1234568463447 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9764364886383373, 'epsilon': 0.9374929469982037}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,064] Trial 173 finished with value: 4080.729578325436 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9990056713199933, 'epsilon': 0.9578004972476923}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,136] Trial 174 finished with value: 4080.821149197777 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9981728865184835, 'epsilon': 0.9599957729266703}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,207] Trial 175 finished with value: 4089.189672344156 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9572126531319796, 'epsilon': 0.9572966574915098}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,280] Trial 176 finished with value: 4090.8337928393516 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9383652867035164, 'epsilon': 0.9971031526559283}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,375] Trial 177 finished with value: 13049.716827808208 and parameters: {'kernel': 'rbf', 'C': 0.9997083887788448, 'epsilon': 0.9593432479228138}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,445] Trial 178 finished with value: 4123.7724393083 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.19443258674572078, 'epsilon': 0.8181921623121502}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:40,961] Trial 179 finished with value: 22233.083801216624 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.975285269142949, 'epsilon': 0.9806568256394882}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,039] Trial 180 finished with value: 4089.498196203641 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9046827801382771, 'epsilon': 0.7939980499024395}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,117] Trial 181 finished with value: 4080.886443182445 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996558355733276, 'epsilon': 0.9498055614222082}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,192] Trial 182 finished with value: 4085.356960453761 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.977316895102852, 'epsilon': 0.9534188030463892}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,267] Trial 183 finished with value: 4090.1188392732606 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9597341951394024, 'epsilon': 0.8756090016336938}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,344] Trial 184 finished with value: 4080.1685132295565 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9988597072168047, 'epsilon': 0.9747185407884644}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,414] Trial 185 finished with value: 4084.8772905122855 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9739503427559677, 'epsilon': 0.9777962285571232}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,486] Trial 186 finished with value: 4080.674946527435 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.998524612962458, 'epsilon': 0.9620234918337557}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,563] Trial 187 finished with value: 4080.337286091135 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998905946840981, 'epsilon': 0.9635772729550736}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,645] Trial 188 finished with value: 4090.5368037425205 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9476616522925927, 'epsilon': 0.9666101402159012}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,724] Trial 189 finished with value: 4084.087412788239 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.977641013025388, 'epsilon': 0.9979423003554554}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,799] Trial 190 finished with value: 4091.3038476199845 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9243968345634053, 'epsilon': 0.9507690448808638}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,876] Trial 191 finished with value: 4083.7999783000964 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9786600742468359, 'epsilon': 0.9811887576052256}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:41,949] Trial 192 finished with value: 4081.735826716389 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9967470764801056, 'epsilon': 0.9428756240211936}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,019] Trial 193 finished with value: 4088.444993256957 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9593372849534706, 'epsilon': 0.9658942324185067}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,093] Trial 194 finished with value: 4084.836269145757 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9816551571624289, 'epsilon': 0.9292136596519185}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,245] Trial 195 finished with value: 4081.302315483495 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9984711379571873, 'epsilon': 0.7862102519891476}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,317] Trial 196 finished with value: 4088.1789531542327 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9638405467334554, 'epsilon': 0.9480459274223804}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,391] Trial 197 finished with value: 4084.9601196221906 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.981268799075505, 'epsilon': 0.7918394702181208}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,463] Trial 198 finished with value: 4081.4338772857313 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9973250473363267, 'epsilon': 0.7816705481900736}. Best is trial 160 with value: 4079.6699970531236.\n",
      "[I 2025-08-01 08:11:42,537] Trial 199 finished with value: 4079.544191433267 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996756280397642, 'epsilon': 0.9814964068034436}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:42,613] Trial 200 finished with value: 4090.2131242544665 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9424990999944158, 'epsilon': 0.9840372465022622}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:42,687] Trial 201 finished with value: 4080.1869966684003 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998953212481781, 'epsilon': 0.9677187918506851}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:42,759] Trial 202 finished with value: 4083.8679003733982 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9786011325237053, 'epsilon': 0.9970540744112122}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:42,961] Trial 203 finished with value: 14203.281561951835 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.964251260865123, 'epsilon': 0.9712972511776286}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,032] Trial 204 finished with value: 4080.5193562666223 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9992049259636999, 'epsilon': 0.9624457870867709}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,107] Trial 205 finished with value: 4080.3671190681866 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999409580136341, 'epsilon': 0.9624866221209909}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,182] Trial 206 finished with value: 4084.338501251729 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9796281078650337, 'epsilon': 0.9682950737093445}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,258] Trial 207 finished with value: 4089.260039091343 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9579010253154451, 'epsilon': 0.9515063277423552}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,330] Trial 208 finished with value: 4079.593507100979 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995125882647752, 'epsilon': 0.9989971675157234}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,421] Trial 209 finished with value: 13134.683643224731 and parameters: {'kernel': 'rbf', 'C': 0.9795641904016935, 'epsilon': 0.9989336876292682}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,492] Trial 210 finished with value: 4086.449953070854 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9661073034037583, 'epsilon': 0.9763035340357659}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,564] Trial 211 finished with value: 4083.896501869793 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9834855931237291, 'epsilon': 0.9587182826630796}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,636] Trial 212 finished with value: 4079.8283795530783 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.998921033060352, 'epsilon': 0.9778600627702089}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,707] Trial 213 finished with value: 4082.8565858017273 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.98317592567811, 'epsilon': 0.9820102289703101}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,780] Trial 214 finished with value: 4079.763358682245 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9987113831325677, 'epsilon': 0.9992253886807614}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,850] Trial 215 finished with value: 4086.5582534748987 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9658380753831832, 'epsilon': 0.9989454987598874}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:43,921] Trial 216 finished with value: 4080.8205949080216 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9980064415792883, 'epsilon': 0.9609444894994512}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,052] Trial 217 finished with value: 4080.122461671837 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995741150961666, 'epsilon': 0.9712963997931575}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,122] Trial 218 finished with value: 4121.122407671395 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.33429273813584004, 'epsilon': 0.9661377639383303}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,193] Trial 219 finished with value: 4090.080394276561 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9455164033669643, 'epsilon': 0.9832942762224061}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,264] Trial 220 finished with value: 4084.9758318408 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9780519675529084, 'epsilon': 0.9597140785895865}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,335] Trial 221 finished with value: 4081.176153472863 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995792145634118, 'epsilon': 0.9315617441581479}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,408] Trial 222 finished with value: 4079.61945935976 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998519223943717, 'epsilon': 0.9784435530586836}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,479] Trial 223 finished with value: 4083.5441917133026 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9799417729834324, 'epsilon': 0.9811048489225753}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,549] Trial 224 finished with value: 4079.5640283739453 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995812947938928, 'epsilon': 0.9983726762973686}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,620] Trial 225 finished with value: 4086.9508399943743 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.96390013738984, 'epsilon': 0.9984995959191797}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,690] Trial 226 finished with value: 4083.7635519824757 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9825224854632973, 'epsilon': 0.9676921647463963}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,761] Trial 227 finished with value: 4086.210884478124 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9660920140511416, 'epsilon': 0.9829680275196144}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,832] Trial 228 finished with value: 4084.4520004860897 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9819444203111294, 'epsilon': 0.9520322168042505}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,902] Trial 229 finished with value: 4079.6125110410508 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995191486585802, 'epsilon': 0.9999134271232015}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:44,973] Trial 230 finished with value: 4113.83477541837 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.5499175918298822, 'epsilon': 0.9967905845416728}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,046] Trial 231 finished with value: 4080.2661983394537 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999918784903881, 'epsilon': 0.9649887446712776}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,121] Trial 232 finished with value: 4080.0724291540573 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9991903717493051, 'epsilon': 0.9734519127573537}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,197] Trial 233 finished with value: 4083.4042098587 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9817209271488118, 'epsilon': 0.9750158546251927}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,272] Trial 234 finished with value: 4079.6871464142414 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.999148781753668, 'epsilon': 0.9998298034816886}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,348] Trial 235 finished with value: 4087.070916790236 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9634820134980617, 'epsilon': 0.999941601066323}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,428] Trial 236 finished with value: 4083.976821649705 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9810519787956278, 'epsilon': 0.9701771134782058}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,503] Trial 237 finished with value: 4083.0770501756297 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9822012462868964, 'epsilon': 0.9813803168243335}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,581] Trial 238 finished with value: 4087.925441558946 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9628517222741592, 'epsilon': 0.9605409182479143}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,658] Trial 239 finished with value: 4079.74029903077 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9983180554691096, 'epsilon': 0.9836267554373819}. Best is trial 199 with value: 4079.544191433267.\n",
      "[I 2025-08-01 08:11:45,734] Trial 240 finished with value: 4079.4781644710647 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996921124734317, 'epsilon': 0.9832226332199212}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:45,809] Trial 241 finished with value: 4083.0001728247516 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9831076198804582, 'epsilon': 0.999897303435261}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:45,884] Trial 242 finished with value: 4079.9014734968905 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9983178060522891, 'epsilon': 0.9792067520469991}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:45,958] Trial 243 finished with value: 4082.747494277872 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9836666062733155, 'epsilon': 0.9822828239001479}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,033] Trial 244 finished with value: 4079.8521170585946 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9984183306279627, 'epsilon': 0.9800017147497133}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,132] Trial 245 finished with value: 4542.002453617961 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9669713016625849, 'epsilon': 0.9834323986145078}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,202] Trial 246 finished with value: 4089.3879954978293 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9522966301274782, 'epsilon': 0.9994637712132445}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,274] Trial 247 finished with value: 4083.471688656022 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9807547713023159, 'epsilon': 0.9785425963601574}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,345] Trial 248 finished with value: 4083.6793683489013 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9821432681440113, 'epsilon': 0.9721523877627013}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,416] Trial 249 finished with value: 4087.2257795687424 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9706963504577402, 'epsilon': 0.9396390536524899}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,508] Trial 250 finished with value: 13051.379383484467 and parameters: {'kernel': 'rbf', 'C': 0.999284221532075, 'epsilon': 0.9827905084476165}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,582] Trial 251 finished with value: 4080.296128706557 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9994550969778782, 'epsilon': 0.9671959711425199}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,653] Trial 252 finished with value: 4090.6976378888444 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9481494343088918, 'epsilon': 0.9622917290499183}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,725] Trial 253 finished with value: 4079.685298475606 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9991519910985756, 'epsilon': 0.9997786212721006}. Best is trial 240 with value: 4079.4781644710647.\n",
      "[I 2025-08-01 08:11:46,798] Trial 254 finished with value: 4079.3765215976537 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9998176831946453, 'epsilon': 0.9853337876180778}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:46,872] Trial 255 finished with value: 4085.779578600605 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.969383145802901, 'epsilon': 0.9970938409076243}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:46,944] Trial 256 finished with value: 4083.3576102472402 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9813296362366758, 'epsilon': 0.9994052550026373}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,015] Trial 257 finished with value: 4106.319183222808 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.4618066008114422, 'epsilon': 0.9814096558113072}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,087] Trial 258 finished with value: 4088.336829638711 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9562552289781294, 'epsilon': 0.9806850608137939}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,159] Trial 259 finished with value: 4084.9765892618884 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9818816427770555, 'epsilon': 0.9373773050365847}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,231] Trial 260 finished with value: 4083.6444361197928 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9821026019208076, 'epsilon': 0.9733448685557776}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,304] Trial 261 finished with value: 4079.843462672866 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.998389846974588, 'epsilon': 0.9804025464062943}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,377] Trial 262 finished with value: 4090.9288264852494 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.93821680255168, 'epsilon': 0.999860373849077}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,450] Trial 263 finished with value: 4085.6306456653347 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9690463759807748, 'epsilon': 0.983105939258282}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,521] Trial 264 finished with value: 4081.208725859355 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999134824768995, 'epsilon': 0.9394610434865482}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,594] Trial 265 finished with value: 4087.2130572817205 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.962762409623367, 'epsilon': 0.9744340026162579}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,668] Trial 266 finished with value: 4079.4505414055607 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9996656543945993, 'epsilon': 0.9841464522675074}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,743] Trial 267 finished with value: 4083.62762757557 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9791061776416887, 'epsilon': 0.9834452338017043}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,815] Trial 268 finished with value: 4089.447056841256 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9520430134768878, 'epsilon': 0.999756596596926}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,907] Trial 269 finished with value: 13128.406095116841 and parameters: {'kernel': 'rbf', 'C': 0.9824496652381615, 'epsilon': 0.9512943689573443}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:47,979] Trial 270 finished with value: 4083.2255053942154 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9822226701276411, 'epsilon': 0.9771758934582558}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,051] Trial 271 finished with value: 4079.564318816389 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9997637113188442, 'epsilon': 0.9999965192281719}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,131] Trial 272 finished with value: 4542.641256912874 and parameters: {'kernel': 'poly', 'degree': 3, 'C': 0.9659196991066057, 'epsilon': 0.999634634245194}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,206] Trial 273 finished with value: 4079.4554045661275 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9994596802749297, 'epsilon': 0.9851426534595717}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,278] Trial 274 finished with value: 4091.1606181435322 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9335469968887156, 'epsilon': 0.9999337960026348}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,351] Trial 275 finished with value: 4079.6348470628773 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9999554927877561, 'epsilon': 0.9774649395711023}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,423] Trial 276 finished with value: 4085.904621383758 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9674940974923149, 'epsilon': 0.9853440766406761}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,495] Trial 277 finished with value: 4083.3162434724877 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9815606732601582, 'epsilon': 0.9783388544535225}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,566] Trial 278 finished with value: 4090.4454165127327 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9479807719479403, 'epsilon': 0.9995750041632024}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:48,637] Trial 279 finished with value: 4084.428190000313 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9837665278393121, 'epsilon': 0.9423607019857315}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,534] Trial 280 finished with value: 22415.56738437289 and parameters: {'kernel': 'poly', 'degree': 5, 'C': 0.9995401484126795, 'epsilon': 0.9801448662200739}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,606] Trial 281 finished with value: 4085.914073619261 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9683902742832735, 'epsilon': 0.9780273091808406}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,677] Trial 282 finished with value: 4084.484325465157 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9816643281669897, 'epsilon': 0.9527468083401194}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,749] Trial 283 finished with value: 4089.7892395587965 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9573832937153687, 'epsilon': 0.9247824252201453}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,820] Trial 284 finished with value: 4083.09712828394 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9826082025427506, 'epsilon': 0.9996127995658417}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,892] Trial 285 finished with value: 4082.395658382293 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9853209121615204, 'epsilon': 0.9827580647195708}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:49,964] Trial 286 finished with value: 4087.4247852888234 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.965158837495565, 'epsilon': 0.9614205447771972}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,036] Trial 287 finished with value: 4082.570211191239 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9843520149328977, 'epsilon': 0.9833490415567027}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,109] Trial 288 finished with value: 4091.2354572190893 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9470897228311408, 'epsilon': 0.9439476020874574}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,200] Trial 289 finished with value: 13052.439799319722 and parameters: {'kernel': 'rbf', 'C': 0.9991220079543384, 'epsilon': 0.9658143647168104}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,273] Trial 290 finished with value: 4079.4564075258477 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9995451567133532, 'epsilon': 0.9846624058369514}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,341] Trial 291 finished with value: 4106.935674829167 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.14338159717299093, 'epsilon': 0.985299988992943}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,414] Trial 292 finished with value: 4085.8436254976937 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9679250056213787, 'epsilon': 0.9866096185327212}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,485] Trial 293 finished with value: 4079.5932585983132 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9994594007321675, 'epsilon': 0.9985107857884857}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,558] Trial 294 finished with value: 4090.9511033670196 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9290064617442512, 'epsilon': 0.9965122392567345}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,633] Trial 295 finished with value: 4085.6026209086945 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9703534053211244, 'epsilon': 0.9981390442851327}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,869] Trial 296 finished with value: 14562.34746682703 and parameters: {'kernel': 'poly', 'degree': 4, 'C': 0.9994278904926066, 'epsilon': 0.9502356017719389}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:50,941] Trial 297 finished with value: 4083.5992308807276 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9826174141010104, 'epsilon': 0.9716616402336311}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:51,012] Trial 298 finished with value: 4089.3702435148575 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9506956461565195, 'epsilon': 0.9840843770492252}. Best is trial 254 with value: 4079.3765215976537.\n",
      "[I 2025-08-01 08:11:51,084] Trial 299 finished with value: 4082.8182587319607 and parameters: {'kernel': 'poly', 'degree': 2, 'C': 0.9839875447249513, 'epsilon': 0.999887489517548}. Best is trial 254 with value: 4079.3765215976537.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "svm_stacking_study = optuna.create_study(direction='minimize')\n",
    "svm_stacking_study.optimize(stacked_objective_svm, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'poly',\n",
       " 'degree': 2,\n",
       " 'C': 0.9998176831946453,\n",
       " 'epsilon': 0.9853337876180778}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_stacking_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/svm_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_stacking_study.best_params, f\"../../split_income_models/ensemble/svm_stacking_best_params.pkl\")\n",
    "joblib.dump(svm_stacking_study, f\"../../split_income_models/ensemble/svm_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/svm_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model = SVR(**svm_stacking_study.best_params)\n",
    "best_svm_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_svm_model, \"../../split_income_models/ensemble/svm_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_objective_mlp(trial):\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "\n",
    "    hidden_layer_sizes = []\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        hidden_layer_sizes.append(trial.suggest_int(\"size_hidden_layer_\" + str(i), 5, 150))\n",
    "    \n",
    "    activation = trial.suggest_categorical(\"activation\", [\"logistic\", \"relu\"])\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.001, 0.1)\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"])\n",
    "\n",
    "    mlp = MLPRegressor(random_state=42, hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver='adam', alpha=alpha, learning_rate=learning_rate)\n",
    "    mlp.fit(X_meta_train_scaled, y_meta_train)\n",
    "    mlp_predictions = mlp.predict(X_meta_val_scaled)\n",
    "\n",
    "    return mean_squared_error(y_meta_val, mlp_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-01 08:14:18,869] A new study created in memory with name: no-name-934b94b8-444c-4b69-83b7-a8eed9d8eef5\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:19,132] Trial 0 finished with value: 18275.73199484434 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 9, 'size_hidden_layer_1': 18, 'activation': 'logistic', 'alpha': 0.08199327679839544, 'learning_rate': 'adaptive'}. Best is trial 0 with value: 18275.73199484434.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:22,720] Trial 1 finished with value: 1689.3522024535578 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 84, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 116, 'activation': 'relu', 'alpha': 0.04860551891579007, 'learning_rate': 'adaptive'}. Best is trial 1 with value: 1689.3522024535578.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:24,733] Trial 2 finished with value: 1658.1997706014727 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 96, 'activation': 'relu', 'alpha': 0.0973706970823683, 'learning_rate': 'adaptive'}. Best is trial 2 with value: 1658.1997706014727.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:29,459] Trial 3 finished with value: 1610.5261452161394 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 149, 'size_hidden_layer_1': 140, 'activation': 'relu', 'alpha': 0.050477192292904795, 'learning_rate': 'constant'}. Best is trial 3 with value: 1610.5261452161394.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:35,322] Trial 4 finished with value: 1511.462114310375 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 52, 'size_hidden_layer_1': 35, 'size_hidden_layer_2': 58, 'size_hidden_layer_3': 121, 'activation': 'relu', 'alpha': 0.03240137084145862, 'learning_rate': 'adaptive'}. Best is trial 4 with value: 1511.462114310375.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:42,930] Trial 5 finished with value: 18227.66490688119 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 141, 'size_hidden_layer_1': 85, 'size_hidden_layer_2': 116, 'size_hidden_layer_3': 103, 'size_hidden_layer_4': 96, 'activation': 'logistic', 'alpha': 0.050809174387795274, 'learning_rate': 'constant'}. Best is trial 4 with value: 1511.462114310375.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:45,768] Trial 6 finished with value: 20700.765501512327 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 68, 'size_hidden_layer_1': 8, 'size_hidden_layer_2': 126, 'size_hidden_layer_3': 59, 'size_hidden_layer_4': 5, 'activation': 'logistic', 'alpha': 0.027849495266023566, 'learning_rate': 'invscaling'}. Best is trial 4 with value: 1511.462114310375.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:48,813] Trial 7 finished with value: 14525.601405885118 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 74, 'activation': 'logistic', 'alpha': 0.03591296318150942, 'learning_rate': 'constant'}. Best is trial 4 with value: 1511.462114310375.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:52,614] Trial 8 finished with value: 13673.007479808493 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 74, 'size_hidden_layer_1': 66, 'size_hidden_layer_2': 101, 'size_hidden_layer_3': 114, 'activation': 'logistic', 'alpha': 0.03245212654281624, 'learning_rate': 'constant'}. Best is trial 4 with value: 1511.462114310375.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:54,453] Trial 9 finished with value: 1750.2626165361287 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 78, 'activation': 'relu', 'alpha': 0.08007583798780764, 'learning_rate': 'constant'}. Best is trial 4 with value: 1511.462114310375.\n",
      "[I 2025-08-01 08:14:55,914] Trial 10 finished with value: 1505.321141640669 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 33, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 18, 'size_hidden_layer_3': 144, 'activation': 'relu', 'alpha': 0.006222902615939704, 'learning_rate': 'invscaling'}. Best is trial 10 with value: 1505.321141640669.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:14:57,795] Trial 11 finished with value: 1513.8137526272717 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 32, 'size_hidden_layer_1': 41, 'size_hidden_layer_2': 13, 'size_hidden_layer_3': 148, 'activation': 'relu', 'alpha': 0.0030338305265715094, 'learning_rate': 'invscaling'}. Best is trial 10 with value: 1505.321141640669.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:00,090] Trial 12 finished with value: 1840.5891144096079 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 49, 'size_hidden_layer_2': 25, 'size_hidden_layer_3': 150, 'activation': 'relu', 'alpha': 0.006110780161306386, 'learning_rate': 'invscaling'}. Best is trial 10 with value: 1505.321141640669.\n",
      "[I 2025-08-01 08:15:01,881] Trial 13 finished with value: 1920.3764472123585 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 35, 'size_hidden_layer_2': 54, 'size_hidden_layer_3': 20, 'activation': 'relu', 'alpha': 0.01333072995560593, 'learning_rate': 'invscaling'}. Best is trial 10 with value: 1505.321141640669.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:05,466] Trial 14 finished with value: 1487.743133245538 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 8, 'size_hidden_layer_1': 58, 'size_hidden_layer_2': 43, 'size_hidden_layer_3': 118, 'size_hidden_layer_4': 149, 'activation': 'relu', 'alpha': 0.019672656945445406, 'learning_rate': 'adaptive'}. Best is trial 14 with value: 1487.743133245538.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:08,583] Trial 15 finished with value: 1798.1690366169894 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 9, 'size_hidden_layer_1': 58, 'size_hidden_layer_2': 36, 'size_hidden_layer_3': 79, 'size_hidden_layer_4': 144, 'activation': 'relu', 'alpha': 0.022486226929680067, 'learning_rate': 'adaptive'}. Best is trial 14 with value: 1487.743133245538.\n",
      "[I 2025-08-01 08:15:09,797] Trial 16 finished with value: 1675.8143123049465 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 26, 'size_hidden_layer_1': 23, 'size_hidden_layer_2': 5, 'size_hidden_layer_3': 126, 'size_hidden_layer_4': 149, 'activation': 'relu', 'alpha': 0.02016192630012373, 'learning_rate': 'invscaling'}. Best is trial 14 with value: 1487.743133245538.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:11,560] Trial 17 finished with value: 1627.057077318063 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 25, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 43, 'activation': 'relu', 'alpha': 0.011249906611380383, 'learning_rate': 'invscaling'}. Best is trial 14 with value: 1487.743133245538.\n",
      "[I 2025-08-01 08:15:14,436] Trial 18 finished with value: 2013.9746610045663 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 5, 'size_hidden_layer_1': 59, 'size_hidden_layer_2': 82, 'size_hidden_layer_3': 85, 'size_hidden_layer_4': 77, 'activation': 'relu', 'alpha': 0.061352511061693746, 'learning_rate': 'adaptive'}. Best is trial 14 with value: 1487.743133245538.\n",
      "[I 2025-08-01 08:15:17,844] Trial 19 finished with value: 1925.423093953317 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 58, 'size_hidden_layer_1': 68, 'size_hidden_layer_2': 28, 'size_hidden_layer_3': 133, 'size_hidden_layer_4': 93, 'activation': 'relu', 'alpha': 0.0020005355944372064, 'learning_rate': 'invscaling'}. Best is trial 14 with value: 1487.743133245538.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:19,847] Trial 20 finished with value: 1622.4527899314937 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 22, 'size_hidden_layer_1': 5, 'size_hidden_layer_2': 148, 'size_hidden_layer_3': 96, 'activation': 'relu', 'alpha': 0.018070872013408103, 'learning_rate': 'adaptive'}. Best is trial 14 with value: 1487.743133245538.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:22,309] Trial 21 finished with value: 2267.565599071502 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 48, 'size_hidden_layer_1': 33, 'size_hidden_layer_2': 59, 'size_hidden_layer_3': 122, 'activation': 'relu', 'alpha': 0.03834765480987518, 'learning_rate': 'adaptive'}. Best is trial 14 with value: 1487.743133245538.\n",
      "[I 2025-08-01 08:15:23,901] Trial 22 finished with value: 1474.9867355063739 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 59, 'size_hidden_layer_1': 46, 'size_hidden_layer_2': 60, 'activation': 'relu', 'alpha': 0.025400458192933625, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:25,529] Trial 23 finished with value: 1719.6141370467376 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 33, 'size_hidden_layer_1': 50, 'size_hidden_layer_2': 74, 'activation': 'relu', 'alpha': 0.014486280481915184, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:26,052] Trial 24 finished with value: 1712.0720504451017 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 15, 'size_hidden_layer_1': 21, 'size_hidden_layer_2': 46, 'activation': 'relu', 'alpha': 0.024277237399882284, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:27,346] Trial 25 finished with value: 1701.465512939183 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 61, 'size_hidden_layer_1': 49, 'size_hidden_layer_2': 20, 'activation': 'relu', 'alpha': 0.04254933071006664, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:29,075] Trial 26 finished with value: 17826.310518976345 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 37, 'size_hidden_layer_1': 71, 'size_hidden_layer_2': 37, 'activation': 'logistic', 'alpha': 0.009185923175556061, 'learning_rate': 'invscaling'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:32,225] Trial 27 finished with value: 1599.3983877791654 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 119, 'size_hidden_layer_1': 58, 'size_hidden_layer_2': 84, 'size_hidden_layer_3': 55, 'activation': 'relu', 'alpha': 0.059953863885225056, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:33,834] Trial 28 finished with value: 1700.9652211778969 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 19, 'size_hidden_layer_1': 45, 'size_hidden_layer_2': 66, 'size_hidden_layer_3': 7, 'size_hidden_layer_4': 41, 'activation': 'relu', 'alpha': 0.02729485567433379, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:34,215] Trial 29 finished with value: 17463.430445017628 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 12, 'size_hidden_layer_1': 24, 'activation': 'logistic', 'alpha': 0.017545303174120976, 'learning_rate': 'invscaling'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "[I 2025-08-01 08:15:36,160] Trial 30 finished with value: 1682.510048962798 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 65, 'size_hidden_layer_1': 79, 'size_hidden_layer_2': 48, 'size_hidden_layer_3': 134, 'activation': 'relu', 'alpha': 0.00868603708367948, 'learning_rate': 'adaptive'}. Best is trial 22 with value: 1474.9867355063739.\n",
      "[I 2025-08-01 08:15:38,393] Trial 31 finished with value: 1327.3081356505725 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 48, 'size_hidden_layer_1': 34, 'size_hidden_layer_2': 61, 'size_hidden_layer_3': 110, 'activation': 'relu', 'alpha': 0.03252714507592128, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "[I 2025-08-01 08:15:40,248] Trial 32 finished with value: 1622.7459461733583 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 39, 'size_hidden_layer_1': 30, 'size_hidden_layer_2': 92, 'size_hidden_layer_3': 96, 'activation': 'relu', 'alpha': 0.04332182615996046, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:42,085] Trial 33 finished with value: 1429.264467526261 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 76, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.028598502065128442, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:44,190] Trial 34 finished with value: 1595.8761736933761 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 56, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.029829557644381544, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:45,064] Trial 35 finished with value: 1657.2870520752106 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 75, 'size_hidden_layer_1': 17, 'activation': 'relu', 'alpha': 0.0382920121666125, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:46,488] Trial 36 finished with value: 1463.716933663327 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 94, 'size_hidden_layer_1': 14, 'size_hidden_layer_2': 69, 'activation': 'relu', 'alpha': 0.055149717377855206, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "[I 2025-08-01 08:15:48,325] Trial 37 finished with value: 1583.9158768622206 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 11, 'size_hidden_layer_2': 90, 'activation': 'relu', 'alpha': 0.06202568049557575, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:51,846] Trial 38 finished with value: 15022.393004380136 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 118, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 70, 'activation': 'logistic', 'alpha': 0.054621666314722095, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:53,143] Trial 39 finished with value: 1572.8224878112362 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 83, 'size_hidden_layer_1': 15, 'size_hidden_layer_2': 55, 'activation': 'relu', 'alpha': 0.06785339343038378, 'learning_rate': 'adaptive'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:54,195] Trial 40 finished with value: 17536.47008400768 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 52, 'size_hidden_layer_1': 29, 'activation': 'logistic', 'alpha': 0.09873240051685996, 'learning_rate': 'constant'}. Best is trial 31 with value: 1327.3081356505725.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:56,126] Trial 41 finished with value: 1316.169687280408 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 62, 'activation': 'relu', 'alpha': 0.04599997897356294, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:15:58,149] Trial 42 finished with value: 1864.9632616191561 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 39, 'size_hidden_layer_2': 63, 'activation': 'relu', 'alpha': 0.04550522584077082, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:00,045] Trial 43 finished with value: 1591.6879979826977 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 26, 'size_hidden_layer_2': 79, 'activation': 'relu', 'alpha': 0.03430690118462218, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "[I 2025-08-01 08:16:00,904] Trial 44 finished with value: 1704.4307552400833 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 80, 'size_hidden_layer_1': 14, 'size_hidden_layer_2': 55, 'activation': 'relu', 'alpha': 0.05411316884304994, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "[I 2025-08-01 08:16:02,727] Trial 45 finished with value: 1628.5268354925308 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.047653796523183245, 'learning_rate': 'constant'}. Best is trial 41 with value: 1316.169687280408.\n",
      "[I 2025-08-01 08:16:04,034] Trial 46 finished with value: 1672.5051757601375 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 73, 'size_hidden_layer_1': 114, 'activation': 'relu', 'alpha': 0.02720432399594265, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:05,991] Trial 47 finished with value: 1370.8417359943876 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 34, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.06815916795705736, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:08,092] Trial 48 finished with value: 1675.4200485768254 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 134, 'size_hidden_layer_1': 33, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.0753337391446232, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:09,474] Trial 49 finished with value: 18633.0175125383 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 19, 'activation': 'logistic', 'alpha': 0.0689901636337314, 'learning_rate': 'constant'}. Best is trial 41 with value: 1316.169687280408.\n",
      "[I 2025-08-01 08:16:11,424] Trial 50 finished with value: 1459.9184389415493 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 91, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 61, 'activation': 'relu', 'alpha': 0.07715048845549169, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:15,284] Trial 51 finished with value: 2538.4147607754226 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 135, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 115, 'size_hidden_layer_3': 57, 'activation': 'relu', 'alpha': 0.0861648521312159, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:18,685] Trial 52 finished with value: 1683.3325293520998 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 99, 'size_hidden_layer_3': 39, 'activation': 'relu', 'alpha': 0.08493750759947319, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:24,491] Trial 53 finished with value: 2239.0756493331473 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 86, 'size_hidden_layer_2': 87, 'size_hidden_layer_3': 68, 'activation': 'relu', 'alpha': 0.09311702489351109, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:29,178] Trial 54 finished with value: 1776.4575951192173 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 109, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 76, 'activation': 'relu', 'alpha': 0.07030514023429132, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "[I 2025-08-01 08:16:31,729] Trial 55 finished with value: 1595.5811381738552 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 126, 'size_hidden_layer_1': 9, 'size_hidden_layer_2': 70, 'size_hidden_layer_3': 31, 'activation': 'relu', 'alpha': 0.07804426203979842, 'learning_rate': 'adaptive'}. Best is trial 41 with value: 1316.169687280408.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:36,861] Trial 56 finished with value: 1225.8292390225865 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 90, 'size_hidden_layer_2': 109, 'activation': 'relu', 'alpha': 0.05359469731589813, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:16:40,018] Trial 57 finished with value: 1700.931705018132 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 146, 'size_hidden_layer_1': 89, 'size_hidden_layer_2': 123, 'size_hidden_layer_3': 46, 'activation': 'relu', 'alpha': 0.05127316798260701, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:43,018] Trial 58 finished with value: 1526.1810177328505 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 116, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 109, 'activation': 'relu', 'alpha': 0.0314636431835964, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:16:45,406] Trial 59 finished with value: 1847.9856615772715 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 70, 'size_hidden_layer_1': 105, 'size_hidden_layer_2': 141, 'activation': 'relu', 'alpha': 0.0744325225190296, 'learning_rate': 'constant'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:16:47,644] Trial 60 finished with value: 1468.7831356437753 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 125, 'size_hidden_layer_1': 70, 'size_hidden_layer_2': 131, 'size_hidden_layer_3': 76, 'activation': 'relu', 'alpha': 0.0396316377505534, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:51,632] Trial 61 finished with value: 1638.7532647784049 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 51, 'activation': 'relu', 'alpha': 0.05646222728619247, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:16:56,769] Trial 62 finished with value: 1579.0561144039389 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 35, 'size_hidden_layer_2': 109, 'activation': 'relu', 'alpha': 0.06575516617599579, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:16:58,890] Trial 63 finished with value: 1664.105956359507 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 53, 'size_hidden_layer_2': 79, 'activation': 'relu', 'alpha': 0.05825601745060881, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:17:02,313] Trial 64 finished with value: 1582.1969951779615 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 43, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.06436331959099015, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:17:04,865] Trial 65 finished with value: 1507.8567537122642 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 80, 'size_hidden_layer_1': 76, 'size_hidden_layer_2': 98, 'activation': 'relu', 'alpha': 0.051631452963115235, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:17:09,359] Trial 66 finished with value: 1495.5594281204367 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 26, 'size_hidden_layer_2': 59, 'size_hidden_layer_3': 105, 'activation': 'relu', 'alpha': 0.04825554445256042, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:15,012] Trial 67 finished with value: 17768.93265810252 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 129, 'size_hidden_layer_2': 39, 'activation': 'logistic', 'alpha': 0.07155793207610937, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:20,037] Trial 68 finished with value: 1459.6934411918348 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 66, 'size_hidden_layer_2': 94, 'activation': 'relu', 'alpha': 0.042371086880358746, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:17:22,836] Trial 69 finished with value: 1501.7366275344957 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 84, 'size_hidden_layer_1': 62, 'size_hidden_layer_2': 91, 'size_hidden_layer_3': 88, 'activation': 'relu', 'alpha': 0.03481328913408124, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:27,141] Trial 70 finished with value: 1642.4173794488117 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 53, 'size_hidden_layer_1': 64, 'size_hidden_layer_2': 95, 'activation': 'relu', 'alpha': 0.043868142067623746, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:32,357] Trial 71 finished with value: 2523.034588151382 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 92, 'size_hidden_layer_2': 108, 'activation': 'relu', 'alpha': 0.03991627619433132, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:36,439] Trial 72 finished with value: 1486.3513259950205 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 86, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 75, 'activation': 'relu', 'alpha': 0.04710538467556732, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:41,919] Trial 73 finished with value: 1384.4955612263866 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 83, 'size_hidden_layer_2': 85, 'activation': 'relu', 'alpha': 0.041389218041545196, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:45,506] Trial 74 finished with value: 1463.3232020776136 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 122, 'size_hidden_layer_1': 83, 'size_hidden_layer_2': 84, 'activation': 'relu', 'alpha': 0.03739672758152567, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:17:48,207] Trial 75 finished with value: 1457.3063324962177 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 87, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.041722556416037365, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:52,467] Trial 76 finished with value: 1578.7826436912771 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 112, 'size_hidden_layer_1': 76, 'size_hidden_layer_2': 62, 'activation': 'relu', 'alpha': 0.041636120143824215, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:17:56,803] Trial 77 finished with value: 1538.522443265919 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 48, 'size_hidden_layer_2': 104, 'activation': 'relu', 'alpha': 0.03306662298349568, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:02,685] Trial 78 finished with value: 10473.992645181448 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 38, 'size_hidden_layer_2': 122, 'activation': 'logistic', 'alpha': 0.0362401866687988, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:06,479] Trial 79 finished with value: 1868.3384672452285 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 65, 'size_hidden_layer_1': 74, 'size_hidden_layer_2': 114, 'activation': 'relu', 'alpha': 0.02969583627056962, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:11,231] Trial 80 finished with value: 2428.134919659354 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 82, 'activation': 'relu', 'alpha': 0.04518611150152591, 'learning_rate': 'constant'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:18:14,427] Trial 81 finished with value: 1601.9497132850236 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 114, 'size_hidden_layer_1': 83, 'size_hidden_layer_2': 94, 'activation': 'relu', 'alpha': 0.022731437893468855, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:22,212] Trial 82 finished with value: 1776.3070203205668 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 79, 'size_hidden_layer_1': 89, 'size_hidden_layer_2': 105, 'size_hidden_layer_3': 66, 'activation': 'relu', 'alpha': 0.04062635291799094, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:18:24,002] Trial 83 finished with value: 1726.4793001315325 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 86, 'activation': 'relu', 'alpha': 0.05006420974926151, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:18:26,454] Trial 84 finished with value: 1660.1257152104167 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 30, 'size_hidden_layer_2': 100, 'activation': 'relu', 'alpha': 0.08296665991442922, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:28,939] Trial 85 finished with value: 1495.9935413066103 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 89, 'activation': 'relu', 'alpha': 0.0363059972517839, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:35,483] Trial 86 finished with value: 1587.6906736012427 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 120, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 89, 'activation': 'relu', 'alpha': 0.031235813656999435, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:40,360] Trial 87 finished with value: 1713.6509479113888 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 76, 'size_hidden_layer_1': 54, 'size_hidden_layer_2': 51, 'size_hidden_layer_3': 108, 'activation': 'relu', 'alpha': 0.042839469982305645, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:43,450] Trial 88 finished with value: 1991.211697461706 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 73, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.09136897347427345, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:46,764] Trial 89 finished with value: 1493.8075596978067 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 83, 'size_hidden_layer_1': 67, 'size_hidden_layer_2': 72, 'size_hidden_layer_3': 27, 'activation': 'relu', 'alpha': 0.04599244623783544, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:53,535] Trial 90 finished with value: 13075.878915467 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 150, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 96, 'activation': 'logistic', 'alpha': 0.025154352530519578, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:18:58,677] Trial 91 finished with value: 1521.7155371133258 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 123, 'size_hidden_layer_1': 86, 'size_hidden_layer_2': 83, 'activation': 'relu', 'alpha': 0.03857084260588478, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:06,224] Trial 92 finished with value: 1456.4341876757885 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 82, 'size_hidden_layer_2': 80, 'activation': 'relu', 'alpha': 0.037256840076395466, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:10,620] Trial 93 finished with value: 1553.352059514642 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 130, 'size_hidden_layer_1': 44, 'size_hidden_layer_2': 57, 'activation': 'relu', 'alpha': 0.05261662129964232, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:13,651] Trial 94 finished with value: 1644.4121543618442 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 83, 'size_hidden_layer_2': 78, 'activation': 'relu', 'alpha': 0.02901404387423871, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:16,032] Trial 95 finished with value: 1693.8060118818926 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 140, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 113, 'activation': 'relu', 'alpha': 0.03411572531030728, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:18,407] Trial 96 finished with value: 1564.198382352363 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 136, 'size_hidden_layer_1': 36, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.07896270060841168, 'learning_rate': 'constant'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:21,047] Trial 97 finished with value: 1726.2102301701377 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 129, 'size_hidden_layer_1': 32, 'size_hidden_layer_2': 73, 'activation': 'relu', 'alpha': 0.049509024078249815, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:24,977] Trial 98 finished with value: 1954.208453106663 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 117, 'size_hidden_layer_1': 23, 'size_hidden_layer_2': 80, 'size_hidden_layer_3': 94, 'size_hidden_layer_4': 8, 'activation': 'relu', 'alpha': 0.044702181735808845, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:29,191] Trial 99 finished with value: 1282.8085339640077 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 88, 'activation': 'relu', 'alpha': 0.03247752524255515, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:30,126] Trial 100 finished with value: 1669.2022238271431 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 99, 'size_hidden_layer_2': 89, 'activation': 'relu', 'alpha': 0.04107746424269488, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:34,039] Trial 101 finished with value: 1427.507473265832 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 102, 'activation': 'relu', 'alpha': 0.03176187351820257, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:38,956] Trial 102 finished with value: 2069.2384169041006 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 119, 'activation': 'relu', 'alpha': 0.02650288558526569, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:40,158] Trial 103 finished with value: 1644.8912915728083 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 92, 'activation': 'relu', 'alpha': 0.03240696798733492, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:44,684] Trial 104 finished with value: 1581.8279370392256 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 107, 'activation': 'relu', 'alpha': 0.03756806815424787, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:47,323] Trial 105 finished with value: 1455.6820474078186 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 42, 'size_hidden_layer_2': 87, 'activation': 'relu', 'alpha': 0.02102013701589483, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:48,747] Trial 106 finished with value: 1573.566000737094 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 104, 'size_hidden_layer_1': 42, 'size_hidden_layer_2': 76, 'activation': 'relu', 'alpha': 0.02029393722068664, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:50,766] Trial 107 finished with value: 1605.3227115254738 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 51, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.01372412886575203, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:53,071] Trial 108 finished with value: 1564.922083612174 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 27, 'size_hidden_layer_2': 101, 'activation': 'relu', 'alpha': 0.022053846900322464, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:19:54,857] Trial 109 finished with value: 13091.004444846609 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 27, 'size_hidden_layer_1': 38, 'size_hidden_layer_2': 87, 'activation': 'logistic', 'alpha': 0.015869968335730747, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:19:59,063] Trial 110 finished with value: 1493.71952417367 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 61, 'activation': 'relu', 'alpha': 0.023609310342697566, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:20:02,570] Trial 111 finished with value: 1496.753964885869 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 47, 'size_hidden_layer_2': 111, 'activation': 'relu', 'alpha': 0.03106955551323677, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:07,718] Trial 112 finished with value: 1736.6506164488617 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 72, 'size_hidden_layer_1': 60, 'size_hidden_layer_2': 94, 'activation': 'relu', 'alpha': 0.03537848718524494, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:20:09,803] Trial 113 finished with value: 1763.0250006919298 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 88, 'size_hidden_layer_2': 81, 'activation': 'relu', 'alpha': 0.02875795083534847, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:12,509] Trial 114 finished with value: 1411.058989625747 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 34, 'size_hidden_layer_2': 101, 'activation': 'relu', 'alpha': 0.039356056243937794, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:15,609] Trial 115 finished with value: 1777.2085866781194 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 56, 'size_hidden_layer_1': 35, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.033828124943493645, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:20,176] Trial 116 finished with value: 1713.445787272587 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 33, 'size_hidden_layer_1': 39, 'size_hidden_layer_2': 73, 'activation': 'relu', 'alpha': 0.038906055143652196, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:20:23,039] Trial 117 finished with value: 1723.4694882531605 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 46, 'size_hidden_layer_1': 33, 'size_hidden_layer_2': 85, 'activation': 'relu', 'alpha': 0.02682951435387552, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:25,690] Trial 118 finished with value: 1643.238262398045 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 29, 'size_hidden_layer_2': 57, 'activation': 'relu', 'alpha': 0.03667099930259243, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:30,616] Trial 119 finished with value: 1314.3955647880775 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 42, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.03076812826165244, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:35,220] Trial 120 finished with value: 1524.9891502425683 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 41, 'size_hidden_layer_1': 107, 'size_hidden_layer_2': 53, 'activation': 'relu', 'alpha': 0.01791892231900417, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:38,318] Trial 121 finished with value: 1937.431675024179 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 48, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.03045828624828326, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:20:41,926] Trial 122 finished with value: 1378.5685582335811 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 39, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 67, 'activation': 'relu', 'alpha': 0.03270203427489803, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:44,951] Trial 123 finished with value: 1604.130395560788 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 41, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.028086529055426086, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:20:46,444] Trial 124 finished with value: 1511.4794189828183 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 29, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 77, 'activation': 'relu', 'alpha': 0.031846160082299776, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:49,843] Trial 125 finished with value: 1457.9435000154165 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 38, 'size_hidden_layer_1': 94, 'size_hidden_layer_2': 60, 'activation': 'relu', 'alpha': 0.02489859721481942, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:52,045] Trial 126 finished with value: 1484.393972754646 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 50, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 67, 'activation': 'relu', 'alpha': 0.03357554197136433, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:54,154] Trial 127 finished with value: 1796.3388756812792 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 102, 'size_hidden_layer_2': 71, 'activation': 'relu', 'alpha': 0.0213891901545985, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:55,244] Trial 128 finished with value: 1409.5417522852076 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 37, 'size_hidden_layer_1': 20, 'size_hidden_layer_2': 63, 'activation': 'relu', 'alpha': 0.03557087863382315, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:55,947] Trial 129 finished with value: 1801.7885654064908 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 22, 'size_hidden_layer_1': 6, 'size_hidden_layer_2': 48, 'activation': 'relu', 'alpha': 0.03973032765324497, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:20:57,011] Trial 130 finished with value: 14136.917155398269 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 35, 'size_hidden_layer_1': 19, 'size_hidden_layer_2': 63, 'activation': 'logistic', 'alpha': 0.03462033724182746, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:00,035] Trial 131 finished with value: 1714.2708173160506 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 41, 'size_hidden_layer_1': 45, 'size_hidden_layer_2': 69, 'activation': 'relu', 'alpha': 0.03574621694771926, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:02,660] Trial 132 finished with value: 1432.7152351890536 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 31, 'size_hidden_layer_1': 41, 'size_hidden_layer_2': 74, 'activation': 'relu', 'alpha': 0.029550625166298132, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:04,238] Trial 133 finished with value: 1762.0431288609816 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 30, 'size_hidden_layer_1': 22, 'size_hidden_layer_2': 58, 'activation': 'relu', 'alpha': 0.029880381090918496, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:07,359] Trial 134 finished with value: 1766.2080969423591 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 35, 'size_hidden_layer_1': 42, 'size_hidden_layer_2': 74, 'activation': 'relu', 'alpha': 0.02742896480443674, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:12,421] Trial 135 finished with value: 1663.8539209346202 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 43, 'size_hidden_layer_1': 37, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.03298427177350448, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:21:16,193] Trial 136 finished with value: 1529.5037245511498 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 23, 'size_hidden_layer_1': 32, 'size_hidden_layer_2': 62, 'activation': 'relu', 'alpha': 0.025500318635479458, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:20,987] Trial 137 finished with value: 1609.0640422698984 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 47, 'size_hidden_layer_1': 26, 'size_hidden_layer_2': 55, 'activation': 'relu', 'alpha': 0.046952728397456914, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:28,055] Trial 138 finished with value: 1785.4726164508252 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 16, 'size_hidden_layer_1': 105, 'size_hidden_layer_2': 69, 'activation': 'relu', 'alpha': 0.031050373902541784, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:34,245] Trial 139 finished with value: 1738.2159350853342 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 38, 'size_hidden_layer_1': 127, 'size_hidden_layer_2': 76, 'activation': 'relu', 'alpha': 0.02874785691931338, 'learning_rate': 'constant'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:37,983] Trial 140 finished with value: 1826.840862566845 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 56, 'size_hidden_layer_1': 42, 'size_hidden_layer_2': 60, 'activation': 'relu', 'alpha': 0.04372819206549852, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:40,548] Trial 141 finished with value: 1481.4714645787865 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 31, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 79, 'activation': 'relu', 'alpha': 0.036629226466814525, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:43,462] Trial 142 finished with value: 1477.7681318282462 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 94, 'size_hidden_layer_1': 12, 'size_hidden_layer_2': 89, 'activation': 'relu', 'alpha': 0.037492924822027804, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:46,859] Trial 143 finished with value: 1564.1969956957491 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 37, 'size_hidden_layer_1': 83, 'size_hidden_layer_2': 72, 'activation': 'relu', 'alpha': 0.03959272914212647, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:21:49,037] Trial 144 finished with value: 1715.9082245660334 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 67, 'size_hidden_layer_1': 50, 'size_hidden_layer_2': 82, 'activation': 'relu', 'alpha': 0.031616204313002036, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:53,379] Trial 145 finished with value: 1816.9157828847055 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 90, 'size_hidden_layer_2': 63, 'activation': 'relu', 'alpha': 0.0349891908757961, 'learning_rate': 'constant'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:21:57,392] Trial 146 finished with value: 1465.011267371891 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 29, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.06265435498652444, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:22:00,868] Trial 147 finished with value: 1549.5785017442558 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 52, 'size_hidden_layer_1': 34, 'size_hidden_layer_2': 85, 'activation': 'relu', 'alpha': 0.059583815549108604, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:22:05,050] Trial 148 finished with value: 1786.233510839622 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 27, 'size_hidden_layer_1': 80, 'size_hidden_layer_2': 99, 'activation': 'relu', 'alpha': 0.03350345069679415, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:22:09,528] Trial 149 finished with value: 1496.7545518582276 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 34, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 106, 'activation': 'relu', 'alpha': 0.04113987638890404, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:22:14,205] Trial 150 finished with value: 1726.7094030852745 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 45, 'size_hidden_layer_2': 74, 'activation': 'relu', 'alpha': 0.02373114798432177, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:22:18,732] Trial 151 finished with value: 1698.250307840012 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 85, 'size_hidden_layer_2': 97, 'activation': 'relu', 'alpha': 0.04522532967056398, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:22:26,247] Trial 152 finished with value: 1726.7537478853824 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 62, 'size_hidden_layer_1': 86, 'size_hidden_layer_2': 110, 'activation': 'relu', 'alpha': 0.041874861687546026, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:22:34,822] Trial 153 finished with value: 1784.4230774561324 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 94, 'size_hidden_layer_2': 102, 'activation': 'relu', 'alpha': 0.03787296828183441, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:22:39,913] Trial 154 finished with value: 1807.331403570334 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 77, 'size_hidden_layer_2': 116, 'activation': 'relu', 'alpha': 0.042805965078038674, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:22:50,302] Trial 155 finished with value: 1779.008741647353 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 146, 'size_hidden_layer_1': 90, 'size_hidden_layer_2': 92, 'activation': 'relu', 'alpha': 0.029368291509699364, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:22:56,826] Trial 156 finished with value: 13623.613259439822 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 37, 'size_hidden_layer_2': 79, 'activation': 'logistic', 'alpha': 0.04825413333800777, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:23:06,047] Trial 157 finished with value: 1381.4957336895127 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 105, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.03254730535564566, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:23:13,577] Trial 158 finished with value: 1603.6549220206737 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 106, 'activation': 'relu', 'alpha': 0.026253145224085374, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:23:17,524] Trial 159 finished with value: 1708.1851129510985 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 80, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.03226141068592686, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:23:25,771] Trial 160 finished with value: 1730.582077963883 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 59, 'activation': 'relu', 'alpha': 0.03599143308670587, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:23:32,129] Trial 161 finished with value: 1999.428917522365 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.03852728772126891, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:23:37,009] Trial 162 finished with value: 1462.3271153704943 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 42, 'size_hidden_layer_1': 95, 'size_hidden_layer_2': 55, 'activation': 'relu', 'alpha': 0.03481843894839793, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:23:42,415] Trial 163 finished with value: 1695.9321097644493 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 45, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 63, 'activation': 'relu', 'alpha': 0.011639991082947032, 'learning_rate': 'adaptive'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:23:49,876] Trial 164 finished with value: 1657.9558962281726 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 84, 'size_hidden_layer_1': 87, 'size_hidden_layer_2': 112, 'activation': 'relu', 'alpha': 0.030378546159039812, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 1225.8292390225865.\n",
      "[I 2025-08-01 08:23:56,865] Trial 165 finished with value: 1223.0303596101976 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.04045559344660877, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:24:00,550] Trial 166 finished with value: 1779.9270365226084 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 76, 'activation': 'relu', 'alpha': 0.03982285953948802, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:24:08,082] Trial 167 finished with value: 1638.7318609093675 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 115, 'size_hidden_layer_2': 71, 'activation': 'relu', 'alpha': 0.0336392083262006, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:24:14,519] Trial 168 finished with value: 1551.6193889760398 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 82, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 87, 'activation': 'relu', 'alpha': 0.028048408475344677, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:24:21,413] Trial 169 finished with value: 1566.1978301311442 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 32, 'size_hidden_layer_2': 108, 'activation': 'relu', 'alpha': 0.03235244927710465, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:24:26,653] Trial 170 finished with value: 1619.5414778308798 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 40, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.06636229766514096, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:24:34,115] Trial 171 finished with value: 1773.7942260798575 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.042248097265093695, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:24:36,976] Trial 172 finished with value: 1712.1445751289707 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 82, 'size_hidden_layer_2': 6, 'activation': 'relu', 'alpha': 0.03730504693346917, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:24:45,236] Trial 173 finished with value: 2083.1500375820087 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 40, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.044327068089421585, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:24:51,860] Trial 174 finished with value: 1720.9588089837334 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 100, 'activation': 'relu', 'alpha': 0.04077144728913358, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:00,862] Trial 175 finished with value: 1626.0756260485778 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 116, 'size_hidden_layer_1': 120, 'size_hidden_layer_2': 61, 'size_hidden_layer_3': 136, 'size_hidden_layer_4': 55, 'activation': 'relu', 'alpha': 0.03572990123782105, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:07,714] Trial 176 finished with value: 1832.9810663721348 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 36, 'size_hidden_layer_2': 82, 'activation': 'relu', 'alpha': 0.0719820753044101, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:11,988] Trial 177 finished with value: 1448.5115530181765 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 36, 'size_hidden_layer_1': 91, 'size_hidden_layer_2': 97, 'activation': 'relu', 'alpha': 0.0385624517879934, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:14,204] Trial 178 finished with value: 1810.9018732505965 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 36, 'size_hidden_layer_1': 92, 'size_hidden_layer_2': 90, 'activation': 'relu', 'alpha': 0.03812037899065577, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:16,930] Trial 179 finished with value: 1760.6780627112269 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 31, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 96, 'activation': 'relu', 'alpha': 0.03222808393636465, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:20,688] Trial 180 finished with value: 15889.692127013192 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 49, 'size_hidden_layer_1': 46, 'size_hidden_layer_2': 52, 'activation': 'logistic', 'alpha': 0.02991172154314857, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:23,539] Trial 181 finished with value: 1570.7075717433427 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 39, 'size_hidden_layer_1': 91, 'size_hidden_layer_2': 107, 'activation': 'relu', 'alpha': 0.040326026988001425, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:29,692] Trial 182 finished with value: 1317.8610175887852 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 93, 'activation': 'relu', 'alpha': 0.034671236120961235, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:34,710] Trial 183 finished with value: 1517.2788290062983 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 94, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 93, 'activation': 'relu', 'alpha': 0.03436084129279353, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:40,476] Trial 184 finished with value: 1315.1733250387217 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 96, 'activation': 'relu', 'alpha': 0.03638783700353077, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:46,175] Trial 185 finished with value: 1366.9032060326263 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 98, 'activation': 'relu', 'alpha': 0.03545833624509702, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:52,401] Trial 186 finished with value: 1803.6649010854308 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 97, 'activation': 'relu', 'alpha': 0.03552436140847518, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:25:56,336] Trial 187 finished with value: 1576.0041313775082 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 44, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 98, 'activation': 'relu', 'alpha': 0.03301808223522347, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:25:59,902] Trial 188 finished with value: 1615.5047624211056 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 99, 'activation': 'relu', 'alpha': 0.028358894483446456, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:26:05,081] Trial 189 finished with value: 1239.1754308072752 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 101, 'activation': 'relu', 'alpha': 0.03100880901470361, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:26:10,560] Trial 190 finished with value: 1586.6008576861 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 94, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.03079210687570824, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:26:14,820] Trial 191 finished with value: 1343.056315415443 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 95, 'activation': 'relu', 'alpha': 0.03397680462802719, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:26:25,502] Trial 192 finished with value: 1670.457824597656 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 91, 'activation': 'relu', 'alpha': 0.030975048869638835, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:26:34,779] Trial 193 finished with value: 1948.0865985736864 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 94, 'activation': 'relu', 'alpha': 0.033731500345669796, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:26:41,939] Trial 194 finished with value: 1892.8745358326216 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 95, 'activation': 'relu', 'alpha': 0.026490861651421702, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:26:49,609] Trial 195 finished with value: 1340.7465095183527 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.036109891191644115, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:26:55,323] Trial 196 finished with value: 1549.4052958191164 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 99, 'size_hidden_layer_2': 102, 'activation': 'relu', 'alpha': 0.036307702943973376, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:27:00,465] Trial 197 finished with value: 1590.8071545548473 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 77, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 111, 'activation': 'relu', 'alpha': 0.034582346990473516, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:27:08,798] Trial 198 finished with value: 1619.3682209553817 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 107, 'size_hidden_layer_2': 101, 'activation': 'relu', 'alpha': 0.032718368717287304, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:27:12,752] Trial 199 finished with value: 1540.3157760811048 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 86, 'size_hidden_layer_1': 102, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.03712361358341168, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:27:18,241] Trial 200 finished with value: 1789.6859065003018 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 99, 'activation': 'relu', 'alpha': 0.03558123736984276, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:27:25,690] Trial 201 finished with value: 1531.750040733601 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 99, 'size_hidden_layer_2': 108, 'activation': 'relu', 'alpha': 0.028959613067418222, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:27:32,823] Trial 202 finished with value: 1693.0998156558633 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 105, 'size_hidden_layer_2': 63, 'activation': 'relu', 'alpha': 0.031662074919929215, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:27:36,501] Trial 203 finished with value: 1346.0236294731822 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.02952952171844925, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:27:43,570] Trial 204 finished with value: 1421.1668402730254 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.033624268685008445, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:27:48,572] Trial 205 finished with value: 1627.041749406347 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.03366634911772211, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:27:53,288] Trial 206 finished with value: 1790.4773190367878 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.039312509689966635, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:27:57,318] Trial 207 finished with value: 1423.585270358977 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.035909410177891454, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:06,082] Trial 208 finished with value: 1890.304261109059 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 115, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.037115343482560334, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:13,545] Trial 209 finished with value: 1686.8837996752536 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 83, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 59, 'activation': 'relu', 'alpha': 0.03530276316218815, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:28:16,262] Trial 210 finished with value: 1381.3984607130976 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.0386059830206167, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:25,241] Trial 211 finished with value: 1532.5805485349633 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.056958833338478496, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:32,635] Trial 212 finished with value: 2406.452477258477 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 114, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.03854600428751584, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:40,081] Trial 213 finished with value: 1756.8885745273649 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 98, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.04090809873853344, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:48,648] Trial 214 finished with value: 1530.0050026498982 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 57, 'activation': 'relu', 'alpha': 0.05327022567929889, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:28:55,823] Trial 215 finished with value: 1460.183959859393 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 71, 'activation': 'relu', 'alpha': 0.03395833137204966, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:29:04,526] Trial 216 finished with value: 2371.0602302356183 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 118, 'size_hidden_layer_2': 61, 'activation': 'relu', 'alpha': 0.036502303360206496, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:29:12,665] Trial 217 finished with value: 1291.813615240245 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 122, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.032704492083941154, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:29:22,689] Trial 218 finished with value: 1495.4045177450441 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 113, 'size_hidden_layer_1': 134, 'size_hidden_layer_2': 62, 'activation': 'relu', 'alpha': 0.031996197094041584, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:29:29,737] Trial 219 finished with value: 18483.962006217465 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 110, 'size_hidden_layer_1': 124, 'size_hidden_layer_2': 31, 'activation': 'logistic', 'alpha': 0.043052559660603465, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:29:35,522] Trial 220 finished with value: 1698.9000277784094 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 106, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 67, 'activation': 'relu', 'alpha': 0.030719503497541316, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:29:41,004] Trial 221 finished with value: 1806.0695687003688 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 94, 'size_hidden_layer_2': 66, 'activation': 'relu', 'alpha': 0.03381257545346732, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:29:42,901] Trial 222 finished with value: 1679.713055626694 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 120, 'size_hidden_layer_2': 72, 'activation': 'relu', 'alpha': 0.03578307838914631, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:29:51,897] Trial 223 finished with value: 1669.2975668823785 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.03944042476611848, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:29:58,259] Trial 224 finished with value: 1607.3861572021908 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 103, 'size_hidden_layer_1': 111, 'size_hidden_layer_2': 69, 'activation': 'relu', 'alpha': 0.037636812501880584, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:30:08,017] Trial 225 finished with value: 1546.6734379023153 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 102, 'size_hidden_layer_2': 92, 'activation': 'relu', 'alpha': 0.032685496392498556, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:30:16,932] Trial 226 finished with value: 1588.5734208949923 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 126, 'size_hidden_layer_2': 59, 'activation': 'relu', 'alpha': 0.03480678093622416, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:30:24,127] Trial 227 finished with value: 1714.1204774175878 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 88, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 95, 'activation': 'relu', 'alpha': 0.029930653895133046, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:30:29,832] Trial 228 finished with value: 1877.3226056812869 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 131, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.03703798375961239, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:30:37,912] Trial 229 finished with value: 1453.1541291970648 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 62, 'activation': 'relu', 'alpha': 0.03257957903725161, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:30:45,126] Trial 230 finished with value: 1570.0964085172106 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 94, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 67, 'activation': 'relu', 'alpha': 0.03947944699766305, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:30:54,253] Trial 231 finished with value: 1633.2560317982745 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 105, 'size_hidden_layer_2': 100, 'activation': 'relu', 'alpha': 0.03228766050899513, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:30:56,950] Trial 232 finished with value: 1747.0941423300173 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 102, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.03489833202671575, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:30:59,501] Trial 233 finished with value: 1651.428490400563 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 88, 'activation': 'relu', 'alpha': 0.0310334608969105, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:07,993] Trial 234 finished with value: 1557.1009079949717 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 99, 'size_hidden_layer_2': 107, 'activation': 'relu', 'alpha': 0.02903840314472845, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:15,468] Trial 235 finished with value: 1726.8174207563181 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 112, 'size_hidden_layer_2': 96, 'activation': 'relu', 'alpha': 0.04651125411268527, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:31:22,117] Trial 236 finished with value: 2085.1830666274486 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 109, 'activation': 'relu', 'alpha': 0.03410500811092397, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:27,585] Trial 237 finished with value: 1631.7886071476546 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 107, 'size_hidden_layer_1': 17, 'size_hidden_layer_2': 69, 'activation': 'relu', 'alpha': 0.031249996711401325, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:33,390] Trial 238 finished with value: 2138.5338525146817 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 96, 'size_hidden_layer_1': 94, 'size_hidden_layer_2': 72, 'activation': 'relu', 'alpha': 0.03612653412760263, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:38,468] Trial 239 finished with value: 1543.536482979257 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 57, 'activation': 'relu', 'alpha': 0.02755873117941216, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:31:41,295] Trial 240 finished with value: 1615.2086183571319 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 116, 'size_hidden_layer_2': 92, 'activation': 'relu', 'alpha': 0.03799269363923386, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:45,589] Trial 241 finished with value: 1543.0750752036167 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 94, 'size_hidden_layer_1': 99, 'size_hidden_layer_2': 65, 'activation': 'relu', 'alpha': 0.02954740836939287, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:47,702] Trial 242 finished with value: 1624.66021560683 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 40, 'size_hidden_layer_1': 28, 'size_hidden_layer_2': 62, 'activation': 'relu', 'alpha': 0.032922237899399694, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:51,181] Trial 243 finished with value: 1705.6334257859044 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 82, 'size_hidden_layer_1': 24, 'size_hidden_layer_2': 67, 'activation': 'relu', 'alpha': 0.02668537642379167, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:31:57,035] Trial 244 finished with value: 1773.9354589117106 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 46, 'size_hidden_layer_1': 102, 'size_hidden_layer_2': 101, 'activation': 'relu', 'alpha': 0.030792464305381007, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:32:05,605] Trial 245 finished with value: 1482.074643911179 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 109, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.034852446891885526, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:32:13,335] Trial 246 finished with value: 1784.8569097037105 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 104, 'size_hidden_layer_1': 105, 'size_hidden_layer_2': 98, 'activation': 'relu', 'alpha': 0.04180195175346103, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:32:17,036] Trial 247 finished with value: 1569.4661876989462 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 43, 'size_hidden_layer_1': 34, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.03298752609493959, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:32:24,638] Trial 248 finished with value: 1993.5775756688752 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 96, 'size_hidden_layer_2': 61, 'activation': 'relu', 'alpha': 0.03613065393835556, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:32:33,454] Trial 249 finished with value: 2055.4400566136605 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 121, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.028428181509573606, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:32:46,125] Trial 250 finished with value: 1777.4188098982163 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 88, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 110, 'activation': 'relu', 'alpha': 0.09479487475402276, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:32:51,655] Trial 251 finished with value: 1459.811694444877 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 113, 'size_hidden_layer_2': 67, 'activation': 'relu', 'alpha': 0.0384144265881889, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:32:56,347] Trial 252 finished with value: 1590.6297338321122 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 30, 'size_hidden_layer_2': 74, 'activation': 'relu', 'alpha': 0.03088314921213851, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:33:09,843] Trial 253 finished with value: 13681.126665511441 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 107, 'size_hidden_layer_2': 95, 'activation': 'logistic', 'alpha': 0.034785981945807176, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:33:19,162] Trial 254 finished with value: 1585.6332205504605 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 59, 'activation': 'relu', 'alpha': 0.044194450515339864, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:33:28,855] Trial 255 finished with value: 1704.9283404508456 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 90, 'activation': 'relu', 'alpha': 0.032935643994853325, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:33:39,282] Trial 256 finished with value: 1638.6205174921108 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 89, 'size_hidden_layer_1': 117, 'size_hidden_layer_2': 133, 'activation': 'relu', 'alpha': 0.04078343342617525, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:33:43,897] Trial 257 finished with value: 1745.8911487926462 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 104, 'size_hidden_layer_1': 10, 'size_hidden_layer_2': 64, 'activation': 'relu', 'alpha': 0.03700242010491908, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:33:53,142] Trial 258 finished with value: 1650.619318839958 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 104, 'activation': 'relu', 'alpha': 0.03170499075644666, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:34:02,671] Trial 259 finished with value: 1654.5615433552284 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 116, 'activation': 'relu', 'alpha': 0.04952256087270702, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:34:08,089] Trial 260 finished with value: 1562.526842810446 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 39, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 85, 'activation': 'relu', 'alpha': 0.028094535909994518, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:34:13,987] Trial 261 finished with value: 1550.7582477217784 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 71, 'size_hidden_layer_1': 38, 'size_hidden_layer_2': 71, 'activation': 'relu', 'alpha': 0.08073909449712936, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:34:17,186] Trial 262 finished with value: 1566.4968942854316 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 91, 'size_hidden_layer_1': 108, 'size_hidden_layer_2': 68, 'activation': 'relu', 'alpha': 0.08739233368518887, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:34:26,377] Trial 263 finished with value: 1308.0791348632229 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 102, 'size_hidden_layer_3': 74, 'activation': 'relu', 'alpha': 0.02485348378153144, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:34:34,335] Trial 264 finished with value: 1618.719757656773 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 101, 'activation': 'relu', 'alpha': 0.034974816245105705, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:34:48,876] Trial 265 finished with value: 1752.2653778874478 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 90, 'size_hidden_layer_1': 101, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 48, 'activation': 'relu', 'alpha': 0.03924716541796772, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:34:52,562] Trial 266 finished with value: 1710.1793955471455 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 6, 'size_hidden_layer_1': 95, 'size_hidden_layer_2': 103, 'activation': 'relu', 'alpha': 0.036268265580621135, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:35:11,101] Trial 267 finished with value: 3172.744653411528 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 147, 'size_hidden_layer_2': 108, 'size_hidden_layer_3': 76, 'activation': 'relu', 'alpha': 0.03346960140845133, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:35:21,865] Trial 268 finished with value: 1424.4050542618083 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 80, 'size_hidden_layer_1': 112, 'size_hidden_layer_2': 97, 'size_hidden_layer_3': 70, 'activation': 'relu', 'alpha': 0.023785216581633475, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:35:34,434] Trial 269 finished with value: 1793.9283247710023 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 79, 'size_hidden_layer_1': 119, 'size_hidden_layer_2': 95, 'size_hidden_layer_3': 69, 'activation': 'relu', 'alpha': 0.025810524585690543, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:35:42,920] Trial 270 finished with value: 1826.6893381031532 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 82, 'size_hidden_layer_1': 115, 'size_hidden_layer_2': 94, 'size_hidden_layer_3': 86, 'activation': 'relu', 'alpha': 0.022195131767749007, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:35:58,725] Trial 271 finished with value: 13593.384278203646 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 82, 'size_hidden_layer_1': 112, 'size_hidden_layer_2': 92, 'size_hidden_layer_3': 115, 'activation': 'logistic', 'alpha': 0.019505674927079355, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:36:10,679] Trial 272 finished with value: 1726.4682150964543 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 85, 'size_hidden_layer_1': 110, 'size_hidden_layer_2': 98, 'size_hidden_layer_3': 100, 'activation': 'relu', 'alpha': 0.023802827953170687, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:36:27,441] Trial 273 finished with value: 1955.2235457259962 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 74, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 100, 'size_hidden_layer_3': 80, 'activation': 'relu', 'alpha': 0.024500158710676897, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:36:32,693] Trial 274 finished with value: 1509.6942511042641 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 77, 'size_hidden_layer_1': 14, 'size_hidden_layer_2': 88, 'size_hidden_layer_3': 90, 'activation': 'relu', 'alpha': 0.06363446241274565, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:36:39,329] Trial 275 finished with value: 1403.0805838488088 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 21, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 43, 'activation': 'relu', 'alpha': 0.042796773937955494, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:36:52,798] Trial 276 finished with value: 1966.2757499843028 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 22, 'size_hidden_layer_2': 62, 'size_hidden_layer_3': 47, 'activation': 'relu', 'alpha': 0.04247429108908591, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:37:04,710] Trial 277 finished with value: 1747.1190009583263 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 90, 'size_hidden_layer_2': 119, 'size_hidden_layer_3': 19, 'activation': 'relu', 'alpha': 0.04623204051726601, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:37:15,341] Trial 278 finished with value: 1790.2809177183633 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 24, 'size_hidden_layer_2': 111, 'size_hidden_layer_3': 127, 'activation': 'relu', 'alpha': 0.07542070833916334, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:37:23,776] Trial 279 finished with value: 1687.7714964602812 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 101, 'size_hidden_layer_1': 15, 'size_hidden_layer_2': 114, 'activation': 'relu', 'alpha': 0.043799355143208825, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:37:34,136] Trial 280 finished with value: 2080.3835886697643 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 97, 'size_hidden_layer_2': 106, 'activation': 'relu', 'alpha': 0.04117019365125791, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:37:47,215] Trial 281 finished with value: 2486.96840695303 and parameters: {'n_layers': 5, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 19, 'size_hidden_layer_2': 113, 'size_hidden_layer_3': 39, 'size_hidden_layer_4': 122, 'activation': 'relu', 'alpha': 0.038380425487325585, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:37:54,415] Trial 282 finished with value: 1750.8820324858214 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 108, 'size_hidden_layer_1': 20, 'size_hidden_layer_2': 73, 'activation': 'relu', 'alpha': 0.03985516562091049, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:01,799] Trial 283 finished with value: 1955.1335733388873 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 100, 'size_hidden_layer_1': 139, 'size_hidden_layer_2': 56, 'activation': 'relu', 'alpha': 0.03740996166109946, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:09,171] Trial 284 finished with value: 1674.8575840153467 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 115, 'size_hidden_layer_1': 124, 'size_hidden_layer_2': 109, 'activation': 'relu', 'alpha': 0.0346852311187777, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:38:13,140] Trial 285 finished with value: 1813.3273056582877 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 42, 'size_hidden_layer_1': 102, 'size_hidden_layer_2': 66, 'size_hidden_layer_3': 141, 'activation': 'relu', 'alpha': 0.06840218886800625, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:18,638] Trial 286 finished with value: 1530.3911780065805 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 93, 'size_hidden_layer_1': 71, 'size_hidden_layer_2': 76, 'activation': 'relu', 'alpha': 0.04238611762133273, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:25,289] Trial 287 finished with value: 2019.6221970784384 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 105, 'size_hidden_layer_1': 98, 'size_hidden_layer_2': 119, 'activation': 'relu', 'alpha': 0.045319220184534825, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:30,397] Trial 288 finished with value: 1900.8373085942042 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 37, 'size_hidden_layer_1': 106, 'size_hidden_layer_2': 70, 'activation': 'relu', 'alpha': 0.03979158825723297, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:38:36,093] Trial 289 finished with value: 1582.5563892160044 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 97, 'size_hidden_layer_1': 93, 'size_hidden_layer_2': 60, 'activation': 'relu', 'alpha': 0.03659581615344991, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:40,213] Trial 290 finished with value: 14421.961332926614 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 50, 'size_hidden_layer_1': 31, 'size_hidden_layer_2': 64, 'activation': 'logistic', 'alpha': 0.03364258343366273, 'learning_rate': 'constant'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:46,439] Trial 291 finished with value: 1377.8987045265192 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 88, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 106, 'activation': 'relu', 'alpha': 0.03017142692263782, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:38:49,033] Trial 292 finished with value: 1671.5155733018346 and parameters: {'n_layers': 2, 'size_hidden_layer_0': 46, 'size_hidden_layer_1': 96, 'activation': 'relu', 'alpha': 0.030127765734490473, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:38:54,068] Trial 293 finished with value: 1800.1655380629163 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 99, 'size_hidden_layer_1': 100, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.029655150895446594, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:38:59,628] Trial 294 finished with value: 1656.5362725165803 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 92, 'size_hidden_layer_1': 103, 'size_hidden_layer_2': 108, 'activation': 'relu', 'alpha': 0.04797727604824359, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:39:05,043] Trial 295 finished with value: 1599.0308728337511 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 102, 'size_hidden_layer_1': 87, 'size_hidden_layer_2': 105, 'activation': 'relu', 'alpha': 0.03148030335541611, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:39:07,859] Trial 296 finished with value: 1660.0073692139028 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 87, 'size_hidden_layer_1': 7, 'size_hidden_layer_2': 111, 'activation': 'relu', 'alpha': 0.02751295209198936, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:39:12,530] Trial 297 finished with value: 1743.5921536389837 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 33, 'size_hidden_layer_1': 99, 'size_hidden_layer_2': 102, 'activation': 'relu', 'alpha': 0.0332022853607625, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "[I 2025-08-01 08:39:15,633] Trial 298 finished with value: 1764.6706862364479 and parameters: {'n_layers': 3, 'size_hidden_layer_0': 111, 'size_hidden_layer_1': 104, 'size_hidden_layer_2': 149, 'activation': 'relu', 'alpha': 0.030287494169397633, 'learning_rate': 'invscaling'}. Best is trial 165 with value: 1223.0303596101976.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-08-01 08:39:21,499] Trial 299 finished with value: 1776.7949372672772 and parameters: {'n_layers': 4, 'size_hidden_layer_0': 95, 'size_hidden_layer_1': 95, 'size_hidden_layer_2': 90, 'size_hidden_layer_3': 6, 'activation': 'relu', 'alpha': 0.031883971832271985, 'learning_rate': 'adaptive'}. Best is trial 165 with value: 1223.0303596101976.\n"
     ]
    }
   ],
   "source": [
    "#Create a study object and optimize the objective function.\n",
    "mlp_stacking_study = optuna.create_study(direction='minimize')\n",
    "mlp_stacking_study.optimize(stacked_objective_mlp, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.04045559344660877,\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': [91, 114, 105]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bp = mlp_stacking_study.best_params\n",
    "mlp_bp_subset = mlp_bp.copy()\n",
    "del mlp_bp_subset['n_layers']\n",
    "mlp_bp_subset['hidden_layer_sizes'] = [mlp_bp_subset.pop(f'size_hidden_layer_{i}') for i in range(mlp_bp['n_layers'])]\n",
    "mlp_bp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 3,\n",
       " 'size_hidden_layer_0': 91,\n",
       " 'size_hidden_layer_1': 114,\n",
       " 'size_hidden_layer_2': 105,\n",
       " 'activation': 'relu',\n",
       " 'alpha': 0.04045559344660877,\n",
       " 'learning_rate': 'adaptive'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/mlp_stacking_optuna_study.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlp_stacking_study.best_params, f\"../../split_income_models/ensemble/mlp_stacking_best_params.pkl\")\n",
    "joblib.dump(mlp_stacking_study, f\"../../split_income_models/ensemble/mlp_stacking_optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/mlp_stacking_best_model.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp_model = MLPRegressor(**mlp_bp_subset)\n",
    "best_mlp_model.fit(stacked_predictions, train_val_label)\n",
    "joblib.dump(best_mlp_model, \"../../split_income_models/ensemble/mlp_stacking_best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values on Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Estimators' Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = pd.read_csv(filepath + '/test/X_test.csv')\n",
    "test_data_x = test_data_x.drop(columns=['Unnamed: 0'], axis=1)\n",
    "test_data_x['setting'] = test_data_x['setting'].astype(\"category\")\n",
    "test_data_y = pd.read_csv(filepath + '/test/y_test.csv')\n",
    "test_data_y = test_data_y.drop(columns=['Unnamed: 0'], axis=1)\n",
    "\n",
    "test_predictions = []\n",
    "\n",
    "for idx, model in enumerate(base_estimators):\n",
    "        if idx < 10:\n",
    "            test_subset = test_data_x.copy()\n",
    "            test_subset.columns = test_subset.columns.str.replace(r'[\\\"\\[\\]\\{\\}\\\\:,]', '', regex=True)\n",
    "            test_subset = test_subset[lgbm_col_needed[idx]]\n",
    "            \n",
    "        else:\n",
    "            test_relevant = test_data_x[rf_col_needed[idx - 10]]\n",
    "            test_subset = test_relevant.copy()\n",
    "            test_subset['setting'] = test_subset['setting'].map(countries_dict)\n",
    "\n",
    "        test_predictions.append(model.predict(test_subset))\n",
    "\n",
    "stacked_test_predictions = np.column_stack(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles' Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Relative Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   MSE  MAE   R2 RMSE Relative Error\n",
       "Voting             NaN  NaN  NaN  NaN            NaN\n",
       "Linear Regression  NaN  NaN  NaN  NaN            NaN\n",
       "Random Forest      NaN  NaN  NaN  NaN            NaN\n",
       "SVM                NaN  NaN  NaN  NaN            NaN\n",
       "MLP                NaN  NaN  NaN  NaN            NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the dataframe to hold test results\n",
    "index_rows = ['Voting', 'Linear Regression', 'Random Forest', 'SVM', 'MLP']\n",
    "\n",
    "index_cols = ['MSE', 'MAE', 'R2', 'RMSE', 'Relative Error']\n",
    "\n",
    "test_stats = pd.DataFrame(index=index_rows, columns=index_cols)\n",
    "\n",
    "test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the models' predictions\n",
    "linreg_pred = best_linreg_model.predict(stacked_test_predictions)\n",
    "rf_pred = best_rf_model.predict(stacked_test_predictions)\n",
    "svm_pred = best_svm_model.predict(stacked_test_predictions)\n",
    "mlp_pred = best_mlp_model.predict(stacked_test_predictions)\n",
    "voting_pred = np.dot(stacked_test_predictions, np.array(list(normalised_bp.values())))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2883172136.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  test_stats.loc[model, 'Relative Error'] = mape[0]\n"
     ]
    }
   ],
   "source": [
    "#to evaluate the models' test_predictions\n",
    "for model in ['Voting', 'Linear Regression', 'Random Forest', 'SVM', 'MLP']:\n",
    "    if model == 'Voting':\n",
    "        test_prediction = voting_pred\n",
    "    elif model == 'Linear Regression':\n",
    "        test_prediction = linreg_pred\n",
    "    elif model == 'Random Forest':\n",
    "        test_prediction = rf_pred\n",
    "    elif model == 'SVM':\n",
    "        test_prediction = svm_pred\n",
    "    elif model == 'MLP':\n",
    "        test_prediction = mlp_pred\n",
    "\n",
    "    mse = mean_squared_error(test_data_y, test_prediction)\n",
    "    mae = mean_absolute_error(test_data_y, test_prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(test_data_y, test_prediction)\n",
    "\n",
    "    #to calculate mape\n",
    "    num_test_predictions = len(test_prediction)\n",
    "    mape = 0\n",
    "    for p in range(0, num_test_predictions):\n",
    "        mape += np.abs(test_prediction[p] - test_data_y.iloc[p]) / np.maximum(np.abs(test_prediction[p]), np.abs(test_data_y.iloc[p]))\n",
    "    mape = mape/num_test_predictions\n",
    "\n",
    "    test_stats.loc[model, 'MSE'] = mse\n",
    "    test_stats.loc[model, 'MAE'] = mae\n",
    "    test_stats.loc[model, 'RMSE'] = rmse\n",
    "    test_stats.loc[model, 'R2'] = r2\n",
    "    test_stats.loc[model, 'Relative Error'] = mape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Relative Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>7962.470768</td>\n",
       "      <td>36.964055</td>\n",
       "      <td>0.712332</td>\n",
       "      <td>89.232678</td>\n",
       "      <td>0.429879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>8196.510332</td>\n",
       "      <td>38.983386</td>\n",
       "      <td>0.703876</td>\n",
       "      <td>90.534581</td>\n",
       "      <td>0.455243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>2229.097521</td>\n",
       "      <td>17.769626</td>\n",
       "      <td>0.919467</td>\n",
       "      <td>47.213319</td>\n",
       "      <td>0.261227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>12993.526139</td>\n",
       "      <td>48.360279</td>\n",
       "      <td>0.530569</td>\n",
       "      <td>113.989149</td>\n",
       "      <td>0.543526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>7823.867826</td>\n",
       "      <td>37.760144</td>\n",
       "      <td>0.717339</td>\n",
       "      <td>88.45263</td>\n",
       "      <td>0.443238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MSE        MAE        R2        RMSE  \\\n",
       "Voting              7962.470768  36.964055  0.712332   89.232678   \n",
       "Linear Regression   8196.510332  38.983386  0.703876   90.534581   \n",
       "Random Forest       2229.097521  17.769626  0.919467   47.213319   \n",
       "SVM                12993.526139  48.360279  0.530569  113.989149   \n",
       "MLP                 7823.867826  37.760144  0.717339    88.45263   \n",
       "\n",
       "                  Relative Error  \n",
       "Voting                  0.429879  \n",
       "Linear Regression       0.455243  \n",
       "Random Forest           0.261227  \n",
       "SVM                     0.543526  \n",
       "MLP                     0.443238  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../split_income_models/ensemble/models_test_values.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(test_stats, f\"../../split_income_models/ensemble/models_test_values.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_concat = joblib.load('../../split_income_models/base_mean_metrics.pkl')\n",
    "\n",
    "std_concat = joblib.load('../../split_income_models/base_std_metrics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2683943296.py:1: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  without_xgb = mean_concat.drop(columns=['XGBoost'], axis=1)\n",
      "/var/folders/jd/0gmk2m5x1cl2hh0v_hsx43q40000gn/T/ipykernel_2415/2683943296.py:2: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  without_xgb_std = std_concat.drop(columns=['XGBoost'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "without_xgb = mean_concat.drop(columns=['XGBoost'], axis=1)\n",
    "without_xgb_std = std_concat.drop(columns=['XGBoost'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_validation_values = {'voting' : voting_study.best_value, \n",
    "               'linreg_stacking' : linreg_stacking_study.best_value,\n",
    "               'rf_stacking' : rf_stacking_study.best_value,\n",
    "               'svm_stacking' : svm_stacking_study.best_value,\n",
    "               'mlp_stacking' : mlp_stacking_study.best_value}\n",
    "\n",
    "with open(f\"../../split_income_models/ensemble/models_best_values.json\", 'w') as f:\n",
    "    json.dump(best_validation_values, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voting': 3002.1264270475076,\n",
       " 'linreg_stacking': 1896.8827532200382,\n",
       " 'rf_stacking': 1495.0818970990745,\n",
       " 'svm_stacking': 4079.3765215976537,\n",
       " 'mlp_stacking': 1223.0303596101976}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_validation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = ['Relative Error', 'MAE', \"MSE\", 'RMSE', \"R2\"]\n",
    "bar_index = ['Voting', 'Linear Regression', 'Random Forest', 'SVM', 'MLP']\n",
    "\n",
    "for metric in metrics:\n",
    "    data_metric = test_stats[metric]\n",
    "    ax = data_metric.plot.bar(rot=0, figsize=(12, 6))     \n",
    "    plt.title(\"Test \" + metric + \" For Data Split by Country with Mean Base Estimator Metrics\")\n",
    "    plt.xlabel(\"Missing Data Threshold\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    data_metric = test_stats[metric]\n",
    "    \n",
    "    if metric == 'Relative Error':\n",
    "        dmetric = 'MAPE'\n",
    "    else: \n",
    "        dmetric = metric\n",
    "    \n",
    "    data_mean = without_xgb.xs(dmetric, axis=1, level='Metric')\n",
    "    error = without_xgb_std.xs(dmetric, axis=1, level='Metric')\n",
    "\n",
    "    # Combine the two for plotting\n",
    "    combined_df = pd.concat(\n",
    "        [data_metric, data_mean.add_suffix(' (Mean)')],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Plot grouped bars\n",
    "    ax = combined_df.plot.bar(rot=0, figsize=(12, 6))\n",
    "\n",
    "    plt.title(f\"Test and Mean {metric} by Country\")\n",
    "    plt.xlabel(\"Missing Data Threshold\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
